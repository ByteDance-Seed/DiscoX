[
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThe preceding sections have examined various theories on concepts and representations in philosophy, cognitive science, and machine learning, classifying them into four categories: abstractionist, similarity, functional, and invariance approaches. This section compares these views from a meta-perspective, exploring their connections and deriving implications for further studies. By identifying the intersections and differences among these approaches, this discussion section aims to provide a clearer framework for interdisciplinary studies of concepts and representations.\nThe first axis for comparison is the role of concepts. Arguably, concepts play various roles in classification, learning, communication, problem solving, and so on; but these roles can be further understood through the lens of two major functionalities: descriptive and inferential. In the descriptive use, concepts serve to characterize and summarize data in various formats. Among the approaches discussed so far, the abstractionist and similarity approaches are particularly motivated by these descriptive tasks. The major goal of abstractionists is to classify objects in the hierarchical manner, by constructing a conceptual lattice from a data table or “context” that lists items and their observed properties (Section 2). Given a similar (but possibly continuous) dataset, the similarity approach visualizes mutual relationships between items in a two or more dimensional space based on their attributes and delineates concepts as clustered points that are close to each other (Section 3). These outcomes—lattices or plots—reveal the inherent structure of data not visible in the original format.\nConcepts also play a central role in inferential tasks, e.g., for the purpose of predicting future events or possible behaviors of objects. By identifying an object in front of me as a dog, I can anticipate what it will and will not do: it may bark, chase after balls, and sniff around, but probably not climb trees or purr like a cat. Though very simplistic, it is nonetheless a bona fide act of prediction: based on some observable cues like floppy ears, I derive its behavioral characteristics that I have not yet seen, at least with respect to this particular dog in front of me. Such inferential role of concepts is the primary focus of the functional perspective (Section 4). Inferences from one set of attributes to another exploit the information about internal constraints on the possible combinations of attributes. This information, encoded in the functional form, constitutes our understanding of concepts. Alternatively, the invariance approach captures inference from a different perspective, by identifying a concept as a set of trans- formation rules that govern possible changes in the object (Section 5). Such equivariant group actions highlight the inferential role of concepts that allows us to simulate how objects or their perceptions transform in accordance with changes in the environment or the perceiving subject.\nThe above discussion should not imply that models are inherently connected to or designed for particular roles. Indeed, there is no contradiction in taking a conceptual lattice as representing internal constraints of concepts or using the similarity space for the purpose of prediction, as is quite common in natural language processing. The descriptive/inferential contrast rather concerns the modeling purpose: namely whether one is interested in data themselves, or in some underlying structure of “uniformity of nature” from which data are sampled. In the former context, mathematical models are taken as a sort of descriptive statistics that serve for the economy of thought; while in the latter, they are interpreted as representing a generative mechanism that lies beyond any particular data (Otsuka, 2022). These two desiderata are often in conflict: the more one tries to adjusts one’s concepts as faithful as possible to given data, the more likely they are to overfit the data, resulting in a loss of predictive ability (Forster and Sober, 1994). A good descriptive model needs not be a good inferential model, and vice versa. Therefore, when evaluating a particular model, it is essential to clearly specify the criteria by which it is being evaluated. Our second point of consideration concerns the relationship between concepts and their defining features. In the philosophical and cognitive science literature, concepts have been defined or characterized in terms of familiar and explicit features we use in everyday life, such as color, size, shape, and so on. Accordingly, conceptual hierarchies or similarity maps have been build and evaluated on the basis of a pre-specified set of mostly ostensible features. This represents a “feature-first” approach, where features act as the raw material for thoughts, with concepts being formed by combining or mixing these features. In contrast, features in representation learning are not fixed beforehand, but rather are extracted from data as axes or dimensions that constitute the latent space. In addition, the meaning of these extracted features is not given a priori, but must be determined by unpacking the internal intricate structure of the trained neural network through detailed analysis. This can be seen as a “representation-first” approach, considering representations to be epistemologically prior to features. These two approach faces different challenges. The main challenge of the feature-first approach lies in its empirical adequacy. A common criticism against abstractionism or the classic view of concepts points out that it is simply im- possible to define concepts, such as game or human, through combinations of existing features or traits (Wittgenstein, 1953; Boyd, 1991). Moreover, it is not clear which features should be considered to define concepts. Outcomes of formal concept analysis heavily depend on the list of attributes used to characterize data (Section 2). And Feigenbaum’s bottleneck highlights the difficulty of determining the relevant attributes for the problem at hand. A similar issue arises for prototype and exemplar theorists in determining the appropriate at- tributes/dimensions and their relative importance in constructing the similarity space, which significantly affects similarity judgments (Murphy, 2004).\nWith its successful applications to a range of empirical problems, the representation- first approach seems to be overcoming all the above issues: deep learning models are able to learn robust representations (with some reservations discussed shortly) that automatically extract relevant features from data, capture complex patterns, and generalize well to new situations. The problem, however, is that these features generally resist intuitive interpretation. One thus needs to read off meanings from trained models, but to do so requires a clear understanding of what one is looking for—that is, what are meaningful features? The idea of disentangled representation discussed in Section 5 is one attempt to explicate what we consider meaningful features of a representation in terms of independent group actions. Understanding features is crucial not just for interpretability but also to enhance model performance, ensure robustness, and improve fair- ness in machine learning applications (Lipton, 2016). It is pointed out that the well-known phenomenon of adversarial attack, where deep learning models mis- classify objects due to the addition of small, often imperceptible perturbations to the input data, is a consequence of the model’s using complex, high-dimensional features that are not necessarily aligned with human-perceptible features (Ilyas et al., 2019). Also, understanding features allows data scientists to identify and mitigate biases in machine learning models by examining how different features influence predictions (Ribeiro et al., 2016). These efforts can be understood as attempts to identify the concepts (representations) used by machines and analyze them into components (features) amenable to human understanding.\nThe feature-first and representation-first approaches can thus be understood as akin to digging a tunnel from opposite sides. The former starts with a set of explicit features and builds complex concepts in a bottom-up way, while the latter aims to break down given representations into understandable pieces in a top-down fashion. The important challenge in contemporary concept research is to make these approaches meet halfway.\nThe final, but not least, point concerns the relationship among the four approaches discussed in this paper. In his influential book, Edouard Machery (2009) argued for the disunity of concepts, challenging the traditional view that concepts are a unified phenomenon within cognitive science. His view is that what are labeled “concepts” actually involve heterogeneous mental kinds with different functionalities, purposes, and empirical bases. Be that as it may, mathematical considerations naturally suggest the logical relationships between different conceptual models. Indeed, we have already seen some of such attempts in the present paper. The group-theoretic analysis of disentangled representations can be thought as an attempt to integrate the theoretic aspect of concepts (encoded by group operations) and their similarity-based aspect (represented by a manifold). In Section 3, we have seen some recent works in natural language processing that aim to encode the hierarchical structure of concepts into the word vector space by using non-Euclidean (hyperbolic) spaces (Nickel and Kiela, 2017) or representing words by boxes instead of vectors (Vilnis et al., 2018). If successful, this line of research will reconcile the abstractionist and similarity approaches, which have been considered rivals in both philosophy and cognitive science literature.\nUnderlying these studies is the overarching theme of the relationship be- tween geometry and algebra. Lattices and groups are algebraic in nature, while metric spaces and manifolds have a clear geometric character. Hence the four approaches discussed in this paper can each be seen as shedding light on the geometric or algebraic aspects of concepts. Kant (1999) was the first to make a clear distinction between, and propose a unification of, these two aspects of human cognition—namely sensibility equipped with a geometric form, and understanding that follows logical and algebraic principles. Over two centuries after Kant, the contemporary machine learning research is trying to integrate the both components to understand and improve the performance of neural networks, with the aid of much more advanced mathematical machinery than those available to Kant, including non-Euclidean geometry, topology, and group or gauge theory (Sanborn et al., 2024). Just as Kant was inspired by Newtonian physics in his time, these developments in machine learning will provide new insights into the philosophical understanding of concepts.\n",
    "ori_text": "\n\nThe preceding sections have examined various theories on concepts and representations in philosophy, cognitive science, and machine learning, classifying them into four categories: abstractionist, similarity, functional, and invariance approaches. This section compares these views from a meta-perspective, exploring their connections and deriving implications for further studies. By identifying the intersections and differences among these approaches, this discussion section aims to provide a clearer framework for interdisciplinary studies of concepts and representations.\nThe first axis for comparison is the role of concepts. Arguably, concepts play various roles in classification, learning, communication, problem solving, and so on; but these roles can be further understood through the lens of two major functionalities: descriptive and inferential. In the descriptive use, concepts serve to characterize and summarize data in various formats. Among the approaches discussed so far, the abstractionist and similarity approaches are particularly motivated by these descriptive tasks. The major goal of abstractionists is to classify objects in the hierarchical manner, by constructing a conceptual lattice from a data table or “context” that lists items and their observed properties (Section 2). Given a similar (but possibly continuous) dataset, the similarity approach visualizes mutual relationships between items in a two or more dimensional space based on their attributes and delineates concepts as clustered points that are close to each other (Section 3). These outcomes—lattices or plots—reveal the inherent structure of data not visible in the original format.\nConcepts also play a central role in inferential tasks, e.g., for the purpose of predicting future events or possible behaviors of objects. By identifying an object in front of me as a dog, I can anticipate what it will and will not do: it may bark, chase after balls, and sniff around, but probably not climb trees or purr like a cat. Though very simplistic, it is nonetheless a bona fide act of prediction: based on some observable cues like floppy ears, I derive its behavioral characteristics that I have not yet seen, at least with respect to this particular dog in front of me. Such inferential role of concepts is the primary focus of the functional perspective (Section 4). Inferences from one set of attributes to another exploit the information about internal constraints on the possible combinations of attributes. This information, encoded in the functional form, constitutes our understanding of concepts. Alternatively, the invariance approach captures inference from a different perspective, by identifying a concept as a set of trans- formation rules that govern possible changes in the object (Section 5). Such equivariant group actions highlight the inferential role of concepts that allows us to simulate how objects or their perceptions transform in accordance with changes in the environment or the perceiving subject.\nThe above discussion should not imply that models are inherently connected to or designed for particular roles. Indeed, there is no contradiction in taking a conceptual lattice as representing internal constraints of concepts or using the similarity space for the purpose of prediction, as is quite common in natural language processing. The descriptive/inferential contrast rather concerns the modeling purpose: namely whether one is interested in data themselves, or in some underlying structure of “uniformity of nature” from which data are sampled. In the former context, mathematical models are taken as a sort of descriptive statistics that serve for the economy of thought; while in the latter, they are interpreted as representing a generative mechanism that lies beyond any particular data (Otsuka, 2022). These two desiderata are often in conflict: the more one tries to adjusts one’s concepts as faithful as possible to given data, the more likely they are to overfit the data, resulting in a loss of predictive ability (Forster and Sober, 1994). A good descriptive model needs not be a good inferential model, and vice versa. Therefore, when evaluating a particular model, it is essential to clearly specify the criteria by which it is being evaluated. Our second point of consideration concerns the relationship between concepts and their defining features. In the philosophical and cognitive science literature, concepts have been defined or characterized in terms of familiar and explicit features we use in everyday life, such as color, size, shape, and so on. Accordingly, conceptual hierarchies or similarity maps have been build and evaluated on the basis of a pre-specified set of mostly ostensible features. This represents a “feature-first” approach, where features act as the raw material for thoughts, with concepts being formed by combining or mixing these features. In contrast, features in representation learning are not fixed beforehand, but rather are extracted from data as axes or dimensions that constitute the latent space. In addition, the meaning of these extracted features is not given a priori, but must be determined by unpacking the internal intricate structure of the trained neural network through detailed analysis. This can be seen as a “representation-first” approach, considering representations to be epistemologically prior to features. These two approach faces different challenges. The main challenge of the feature-first approach lies in its empirical adequacy. A common criticism against abstractionism or the classic view of concepts points out that it is simply im- possible to define concepts, such as game or human, through combinations of existing features or traits (Wittgenstein, 1953; Boyd, 1991). Moreover, it is not clear which features should be considered to define concepts. Outcomes of formal concept analysis heavily depend on the list of attributes used to characterize data (Section 2). And Feigenbaum’s bottleneck highlights the difficulty of determining the relevant attributes for the problem at hand. A similar issue arises for prototype and exemplar theorists in determining the appropriate at- tributes/dimensions and their relative importance in constructing the similarity space, which significantly affects similarity judgments (Murphy, 2004).\nWith its successful applications to a range of empirical problems, the representation- first approach seems to be overcoming all the above issues: deep learning models are able to learn robust representations (with some reservations discussed shortly) that automatically extract relevant features from data, capture complex patterns, and generalize well to new situations. The problem, however, is that these features generally resist intuitive interpretation. One thus needs to read off meanings from trained models, but to do so requires a clear understanding of what one is looking for—that is, what are meaningful features? The idea of disentangled representation discussed in Section 5 is one attempt to explicate what we consider meaningful features of a representation in terms of independent group actions. Understanding features is crucial not just for interpretability but also to enhance model performance, ensure robustness, and improve fair- ness in machine learning applications (Lipton, 2016). It is pointed out that the well-known phenomenon of adversarial attack, where deep learning models mis- classify objects due to the addition of small, often imperceptible perturbations to the input data, is a consequence of the model’s using complex, high-dimensional features that are not necessarily aligned with human-perceptible features (Ilyas et al., 2019). Also, understanding features allows data scientists to identify and mitigate biases in machine learning models by examining how different features influence predictions (Ribeiro et al., 2016). These efforts can be understood as attempts to identify the concepts (representations) used by machines and analyze them into components (features) amenable to human understanding.\nThe feature-first and representation-first approaches can thus be understood as akin to digging a tunnel from opposite sides. The former starts with a set of explicit features and builds complex concepts in a bottom-up way, while the latter aims to break down given representations into understandable pieces in a top-down fashion. The important challenge in contemporary concept research is to make these approaches meet halfway.\nThe final, but not least, point concerns the relationship among the four approaches discussed in this paper. In his influential book, Edouard Machery (2009) argued for the disunity of concepts, challenging the traditional view that concepts are a unified phenomenon within cognitive science. His view is that what are labeled “concepts” actually involve heterogeneous mental kinds with different functionalities, purposes, and empirical bases. Be that as it may, mathematical considerations naturally suggest the logical relationships between different conceptual models. Indeed, we have already seen some of such attempts in the present paper. The group-theoretic analysis of disentangled representations can be thought as an attempt to integrate the theoretic aspect of concepts (encoded by group operations) and their similarity-based aspect (represented by a manifold). In Section 3, we have seen some recent works in natural language processing that aim to encode the hierarchical structure of concepts into the word vector space by using non-Euclidean (hyperbolic) spaces (Nickel and Kiela, 2017) or representing words by boxes instead of vectors (Vilnis et al., 2018). If successful, this line of research will reconcile the abstractionist and similarity approaches, which have been considered rivals in both philosophy and cognitive science literature.\nUnderlying these studies is the overarching theme of the relationship be- tween geometry and algebra. Lattices and groups are algebraic in nature, while metric spaces and manifolds have a clear geometric character. Hence the four approaches discussed in this paper can each be seen as shedding light on the geometric or algebraic aspects of concepts. Kant (1999) was the first to make a clear distinction between, and propose a unification of, these two aspects of human cognition—namely sensibility equipped with a geometric form, and understanding that follows logical and algebraic principles. Over two centuries after Kant, the contemporary machine learning research is trying to integrate the both components to understand and improve the performance of neural networks, with the aid of much more advanced mathematical machinery than those available to Kant, including non-Euclidean geometry, topology, and group or gauge theory (Sanborn et al., 2024). Just as Kant was inspired by Newtonian physics in his time, these developments in machine learning will provide new insights into the philosophical understanding of concepts.\n",
    "reference_list": "考点1：“Sensibility”推荐译为“感性”\n考点2：“unpacking”推荐译为“解析”，不可译为“拆解”\n考点3：“The first axis for comparison is the role of concepts”中“axis”不可直译为“轴”，应为“维度”或“方面”\n考点4：“read off meanings”推荐译为“解读含义”“阐释含义”，不可译为“读出含义”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "185"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n1. Why has the global capital market grown so rapidly in recent decades  \n\nIn recent decades, the global capital market has grown so rapidly because of the rise of privatizations mainly. With private capital flows rising from less than 5 percent of world GDP in 1975 to about 20 percent today, privatizations have significantly increased market liquidity. And also privatization takes a potential role global capital market development.  \n  \nA. The Rise of Capital Market-Based Finance    \nCapital market-based finance has in fact been increasing in importance, both absolutely and relative to financial intermediary-based finance, in both developed and developing countries over the past decade. And also capital markets are in fact winning the present and seem likely to dominate the future of corporate finance in developed and developing countries alike.  \n  \na. The Stable Role of Commercial Banking in Modern Economies    \nOrdinary \"relationship banking\" appears to be (at best) holding its own as a source of corporate financing around the world, and is more likely in decline. The bits of banking that are growing rapidly are those parts that provide high value-added products (especially risk management tools) and provide large-scale syndicated credits to corporate borrowers. During the late-1980s and early-1990s, when Japan and Germany appeared to be outperforming major capital market-oriented countries such as Britain and the US, the academic literature often favored bank-based systems. Examples of this literature include Prowse (1992), Kester (1992), and Porter (1992), while the supporting arguments are summarized in Maher and Andersson (1999) and Tsuru (2000). More recently, however, the weight of opinion has swung strongly in favor of the idea that capital markets have decisive comparative advantages over banks and other financial intermediaries as optimal monitors and financiers of a nation's corporate life. This reassessment has been driven in part by the observation, discussed at length above, that capital markets have been prospering relative to banks for many years now. The repetitive nature--and massive costs--of banking crises in developing and developed countries alike has also convinced many observers that banks are inherently fragile institutions, whose role in corporate finance should be minimized as much and as quickly as possible (Economist (1997, 1999)).  \n  \nb. The Rapid Growth in Stock Market Capitalization and Trading Volume Since 1983    \nFrom 1983 to 2000, this was a period of very rapid growth in the capitalization of markets in every country except Japan. Total world market capitalization increased over ten-fold (to $ 35.0 trillion) between 1983 and 1999, and the total capitalization of the US market increased almost nine-fold (from $ 1.9 trillion to $ 16.6 trillion) over the same period.  \n  \nc. The Dramatic Growth in Securities Issuance Volume Since 1990    \nAnother way of measuring the rise of capital markets is to examine whether their share of annual corporate financing activity has grown relative to that of other sources of funding. Security offerings by US issuers accounted for two-thirds of the global total throughout 1990-1999, that implies that non-US securities issues in creased from $ 191 billion in 1990 to $ 750 billion in 1998, and then to $ 1.19 trillion in 1999. The surge in non-US issuance volume in 1999 was largely due to the popularity of euro-denominated bond issues, which actually exceeded dollar-denominated bond issues for much of 1999.  \n  \nd. The Phenomenal Growth in Venture Capital Financing in the United States    \nOne highly specialized, but extremely important type of financing has also grown very rapidly over the past decade, and especially so since 1997. This is venture capital investment by US venture capital partnerships. The fund-raising patterns of these private equity investors are discussed in Gompers and Lerner (1998), and the competitive advantages of US venture capitalists versus those in other developed countries are described in Black and Gilson (1998).  \n  \ne. The Surge in Mergers and Acquisitions Worldwide    \nThe almost incredible increase in the total volume of merger and acquisition activity that has occurred since 1990. While takeovers have always played an important role in the United States, the rise in M&A (Merger and Acquisition) activity in Europe during the 1990s was even more dramatic. From less than $ 50 billion annually in the late-1980s, the total value of M&A involving a European target reached $ 592 billion in 1998, before more than doubling to $ 1.22 trillion in 1999--rivaling the US total. The global value of M&A activity in 1999 reached $ 3.4 trillion, an astounding 10% of world GDP.  \nNext I will document that share issue privatizations have truly transformed share ownership patterns of investors in many different countries.  \n  \nB. Privatization's Impact on Stock and Bond Market Development    \nWe should be careful in inferring causation regarding privatization's impact on market growth, since a shift in ideology or some other exogenous political or economic change might have caused both the privatization and the overall boom.  \n  \na. Total Proceeds Raised by Privatization Programs    \nIt is clear that national governments have been among the biggest winners from privatization programs, since these have dramatically increased government revenues, which is clearly one reason the policy has spread so rapidly. As mentioned above, Privatisation International [Gibbon (1998, 2000)] reports that the cumulative value of proceeds raised by privatizing governments exceeded $ 1 trillion sometime during the second half of 1999. As an added benefit, this revenue has come to governments without having to raise taxes or cut other public services.  \n  \nb. Privatization's Impact on International Investment Banking  \nAll international investment banks compete fiercely for share issue privatization mandates, for two principal reasons. First, because the offerings are so large and so visible--and are almost always designed to help promote the market's capacity to absorb subsequent stock offerings by private companies--these are very prestigious mandates. To date, the large US and British brokerage houses have had the most success in winning advisory and underwriting mandates, though all countries that launch large-scale SIP programs tend to favor local investment banks as \"national champions\" to handle the domestic share tranche. The second reason banks compete so fiercely for SIP mandates is because they can be extremely profitable. In spite of the fact--documented by Jones, et al (1999) and Ljungqvist, et al (2000)--that SIPs have significantly lower underwriting spreads than private sector offerings, their sheer size and lack of downside price risk make them very lucrative for underwriters.  \n  \n2. Will this growth continue throughout the 2000s?  \n  \nAs we indicated above, the global capital market has grown so rapidly in recent decades cause of the privatizations rise. Privatizations increased the market liquidity. Now we have already stepped into the 21st century. I believe that the growth will continue for the following reasons. First, most of the south-east Asia countries have recovered from the 1997 financial crisis. For these countries, they now have the capital to do businesses. And they get back on the fast growing track. Second, by the end of 2001, world's biggest developing country, China, has entered the WTO (World Trade Organization). This is real great news. As we all know, today's China takes a serious position in world's economy. Its innovation and opening policy make china keep achieving high GDP growth rate. This drives the global capital market keep growing.  \n  \nSummary and Conclusions  \n  \nThis essay examines the impact of share issue privatizations (SIPs) on the growth of world capital markets (especially stock markets). I begin by documenting the increasing importance of capital markets, and the declining role of commercial banks, in corporate financial systems around the world. I then show that privatization programs-- particularly those involving public share offerings--have had a dramatic impact both on the development of non-US stock markets and on the participation of individual and institutional investors in those stock markets.  \n  \nThis has told the reason of the fast growth of global capital market. And then I succinctly indicated the continuance of the rapid growth, the great future.  \n  \nThe last but not the least is the recommendation. I can confidently assert that, if executed properly, a series of share issue privatizations can indeed promote the growth of global capital market, which will yield economic and political dividends for many years to come. That means there is a need to encourage the development of SIPs in order to gain growth of global capital market.",
    "ori_text": "1. Why has the global capital market grown so rapidly in recent decades  \n\nIn recent decades, the global capital market has grown so rapidly because of the rise of privatizations mainly. With private capital flows rising from less than 5 percent of world GDP in 1975 to about 20 percent today, privatizations have significantly increased market liquidity. And also privatization takes a potential role global capital market development.  \n  \nA. The Rise of Capital Market-Based Finance    \nCapital market-based finance has in fact been increasing in importance, both absolutely and relative to financial intermediary-based finance, in both developed and developing countries over the past decade. And also capital markets are in fact winning the present and seem likely to dominate the future of corporate finance in developed and developing countries alike.  \n  \na. The Stable Role of Commercial Banking in Modern Economies    \nOrdinary \"relationship banking\" appears to be (at best) holding its own as a source of corporate financing around the world, and is more likely in decline. The bits of banking that are growing rapidly are those parts that provide high value-added products (especially risk management tools) and provide large-scale syndicated credits to corporate borrowers. During the late-1980s and early-1990s, when Japan and Germany appeared to be outperforming major capital market-oriented countries such as Britain and the US, the academic literature often favored bank-based systems. Examples of this literature include Prowse (1992), Kester (1992), and Porter (1992), while the supporting arguments are summarized in Maher and Andersson (1999) and Tsuru (2000). More recently, however, the weight of opinion has swung strongly in favor of the idea that capital markets have decisive comparative advantages over banks and other financial intermediaries as optimal monitors and financiers of a nation's corporate life. This reassessment has been driven in part by the observation, discussed at length above, that capital markets have been prospering relative to banks for many years now. The repetitive nature--and massive costs--of banking crises in developing and developed countries alike has also convinced many observers that banks are inherently fragile institutions, whose role in corporate finance should be minimized as much and as quickly as possible (Economist (1997, 1999)).  \n  \nb. The Rapid Growth in Stock Market Capitalization and Trading Volume Since 1983    \nFrom 1983 to 2000, this was a period of very rapid growth in the capitalization of markets in every country except Japan. Total world market capitalization increased over ten-fold (to $ 35.0 trillion) between 1983 and 1999, and the total capitalization of the US market increased almost nine-fold (from $ 1.9 trillion to $ 16.6 trillion) over the same period.  \n  \nc. The Dramatic Growth in Securities Issuance Volume Since 1990    \nAnother way of measuring the rise of capital markets is to examine whether their share of annual corporate financing activity has grown relative to that of other sources of funding. Security offerings by US issuers accounted for two-thirds of the global total throughout 1990-1999, that implies that non-US securities issues in creased from $ 191 billion in 1990 to $ 750 billion in 1998, and then to $ 1.19 trillion in 1999. The surge in non-US issuance volume in 1999 was largely due to the popularity of euro-denominated bond issues, which actually exceeded dollar-denominated bond issues for much of 1999.  \n  \nd. The Phenomenal Growth in Venture Capital Financing in the United States    \nOne highly specialized, but extremely important type of financing has also grown very rapidly over the past decade, and especially so since 1997. This is venture capital investment by US venture capital partnerships. The fund-raising patterns of these private equity investors are discussed in Gompers and Lerner (1998), and the competitive advantages of US venture capitalists versus those in other developed countries are described in Black and Gilson (1998).  \n  \ne. The Surge in Mergers and Acquisitions Worldwide    \nThe almost incredible increase in the total volume of merger and acquisition activity that has occurred since 1990. While takeovers have always played an important role in the United States, the rise in M&A (Merger and Acquisition) activity in Europe during the 1990s was even more dramatic. From less than $ 50 billion annually in the late-1980s, the total value of M&A involving a European target reached $ 592 billion in 1998, before more than doubling to $ 1.22 trillion in 1999--rivaling the US total. The global value of M&A activity in 1999 reached $ 3.4 trillion, an astounding 10% of world GDP.  \nNext I will document that share issue privatizations have truly transformed share ownership patterns of investors in many different countries.  \n  \nB. Privatization's Impact on Stock and Bond Market Development    \nWe should be careful in inferring causation regarding privatization's impact on market growth, since a shift in ideology or some other exogenous political or economic change might have caused both the privatization and the overall boom.  \n  \na. Total Proceeds Raised by Privatization Programs    \nIt is clear that national governments have been among the biggest winners from privatization programs, since these have dramatically increased government revenues, which is clearly one reason the policy has spread so rapidly. As mentioned above, Privatisation International [Gibbon (1998, 2000)] reports that the cumulative value of proceeds raised by privatizing governments exceeded $ 1 trillion sometime during the second half of 1999. As an added benefit, this revenue has come to governments without having to raise taxes or cut other public services.  \n  \nb. Privatization's Impact on International Investment Banking  \nAll international investment banks compete fiercely for share issue privatization mandates, for two principal reasons. First, because the offerings are so large and so visible--and are almost always designed to help promote the market's capacity to absorb subsequent stock offerings by private companies--these are very prestigious mandates. To date, the large US and British brokerage houses have had the most success in winning advisory and underwriting mandates, though all countries that launch large-scale SIP programs tend to favor local investment banks as \"national champions\" to handle the domestic share tranche. The second reason banks compete so fiercely for SIP mandates is because they can be extremely profitable. In spite of the fact--documented by Jones, et al (1999) and Ljungqvist, et al (2000)--that SIPs have significantly lower underwriting spreads than private sector offerings, their sheer size and lack of downside price risk make them very lucrative for underwriters.  \n  \n2. Will this growth continue throughout the 2000s?  \n  \nAs we indicated above, the global capital market has grown so rapidly in recent decades cause of the privatizations rise. Privatizations increased the market liquidity. Now we have already stepped into the 21st century. I believe that the growth will continue for the following reasons. First, most of the south-east Asia countries have recovered from the 1997 financial crisis. For these countries, they now have the capital to do businesses. And they get back on the fast growing track. Second, by the end of 2001, world's biggest developing country, China, has entered the WTO (World Trade Organization). This is real great news. As we all know, today's China takes a serious position in world's economy. Its innovation and opening policy make china keep achieving high GDP growth rate. This drives the global capital market keep growing.  \n  \nSummary and Conclusions  \n  \nThis essay examines the impact of share issue privatizations (SIPs) on the growth of world capital markets (especially stock markets). I begin by documenting the increasing importance of capital markets, and the declining role of commercial banks, in corporate financial systems around the world. I then show that privatization programs-- particularly those involving public share offerings--have had a dramatic impact both on the development of non-US stock markets and on the participation of individual and institutional investors in those stock markets.  \n  \nThis has told the reason of the fast growth of global capital market. And then I succinctly indicated the continuance of the rapid growth, the great future.  \n  \nThe last but not the least is the recommendation. I can confidently assert that, if executed properly, a series of share issue privatizations can indeed promote the growth of global capital market, which will yield economic and political dividends for many years to come. That means there is a need to encourage the development of SIPs in order to gain growth of global capital market.",
    "reference_list": "考点1：“market-based finance”推荐译为“市场主导式金融”\n考点2：“The bits of banking” 推荐译为“银行业务”\n考点3：“intermediary-based finance”应译为“以中介为基础的金融”\n考点4：“syndicated credits”应译为“银团贷款”\n考点5：“the weight of opinion” 应译为“主流观点”\n考点6：“proceeds”应译为“单笔交易的收入所得”\n考点7：“offerings”应译为“发行”\n考点8：“prestigious mandates” 应译为“顶级授权”\n考点9：“brokerage houses”应译为“证券经纪商”\n考点10：“SIP”应译为“股票发行私有化”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "48"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n近年来，“替代两小时户外”的哺光仪、“模拟阳光”的大路灯等产品层出不穷。这些产品能否切实改善视力？背后是否暗藏风险？第30个全国“爱眼日”到来之际，听听权威专家的解读与建议。\n三分钟哺光能否替代两小时户外？\n哺光仪，也称重复低强度红光（RLRL），是一种以激光为光源照射眼睛，用于近视控制或弱视治疗的医疗设备产品。\n记者在某电商平台上输入“哺光仪”搜索发现，相关产品品类众多，最高价格近4000元，有商家还提供800元/月的租赁使用服务。\n2023年，因哺光仪不规范使用造成某12岁女童视网膜黄斑损伤，导致视力永久性受损。同年6月，国家药监局发布通知，将激光近视弱视治疗仪类产品划分为第三类医疗器械，并给予企业和市场一年过渡期。这意味着在2024年7月1日之后，企业生产、销售哺光仪，须具有第三类医疗器械注册证和生产许可证。\n今年4月，北京大学人民医院、北京同仁医院有关专家在国际知名眼科期刊共同发表名为《近视儿童重复低强度红光治疗后视锥细胞密度的变化》的论文，指出以激光作为光源对儿童眼睛进行照射以防控近视，有引发视锥光感受器受损的风险。\n中山大学孙逸仙纪念医院眼科副主任医师张一弛说，哺光仪目前临床研究观察最长时间为一年。部分孩子使用后眼轴增长确有所控制，但发生机制尚不明确，长期暴露情况下安全性、有效性也有待观察。\n首都医科大学附属北京康复医院眼科主任刘莹说，部分家长因孩子近视进展或眼轴增长过快而选择使用哺光仪，也有一些家长认为孩子度数不严重，想用三分钟哺光替代两小时户外，这些想法并不可取。\n这位专家表示，户外活动作为近视防控方案的循证医学证据在全球的观察时间更长、数据更多。建议家长们理性评估风险与收益，优先选择证据充分的防控手段。\n大路灯能“模拟自然光”？\n“相比普通台灯，大路灯的室内照明光线分布相对均匀，能够减少阴影和暗区，照射范围也更广，在一定程度上有助于减轻视疲劳，但并不足以单独作为一种近视防控方法。”刘莹说，与按照三类医疗器械管理的哺光仪不同，大路灯本质上是一种灯具。\n浙江大学眼科医院视光中心主任倪海龙表示，万物生长靠太阳，晴朗白天的太阳光照度可达10万勒克斯（lux），远超能提供1000lux左右光照强度的所谓大路灯。“同时，大路灯也无法替代户外光刺激视网膜分泌多巴胺的关键作用。”他说。\n很多临床医生都在门诊中遇到家长请求推荐灯具产品。不少家长表示，大路灯“参数眼花缭乱、价格五花八门”，“缺乏行业标准、质量良莠不齐”，购买后发现部分低价产品夸大宣传。\n《近视防治指南（2024年版）》明确，读写应在采光良好、照明充足的环境中进行，桌面的平均照度值不应低于300lux。国家标准《读写作业台灯性能要求》对灯具色温、显色指数、照度、视网膜蓝光危害和闪烁等多项指标提出要求。\n专家强调，近视的发展受环境因素、遗传因素等共同影响，采光照明只是其中一个方面。选购灯具应优先参照国家出台的相关标准。\n改善整体光环境和用眼习惯，避免依赖单一技术手段\n倪海龙强调，近视防控的关键仍在于一增一减，即增加户外活动，减少近距离用眼负担，同时可辅以改善光环境及用眼习惯，要打组合拳，而非依赖单一技术手段。\n专家建议要科学看待人工光源，辅助工具不可替代自然光照和基础防控。\n“不论是儿童青少年还是成年人，自然光作为视觉的核心保护因素，其作用不可替代。”刘莹说，人工光源的应用需以“安全、循证”为原则，避免因商业营销或焦虑心理陷入误区。\n近年来，党和国家高度重视青少年近视防控，部署三级干预措施。一级预防包括从婴幼儿期（2岁半起）就定期筛查视力，避免过早接触电子产品；二级预防包括通过户外活动、用眼习惯调整降低近视风险；三级预防包括采用离焦眼镜、角膜塑形镜及低浓度阿托品等医学手段延缓近视加深。\n专家表示，近视防控是个系统工程，需要全社会行动起来，关注全生命周期的用眼健康。",
    "ori_text": "近年来，“替代两小时户外”的哺光仪、“模拟阳光”的大路灯等产品层出不穷。这些产品能否切实改善视力？背后是否暗藏风险？第30个全国“爱眼日”到来之际，听听权威专家的解读与建议。\n三分钟哺光能否替代两小时户外？\n哺光仪，也称重复低强度红光（RLRL），是一种以激光为光源照射眼睛，用于近视控制或弱视治疗的医疗设备产品。\n记者在某电商平台上输入“哺光仪”搜索发现，相关产品品类众多，最高价格近4000元，有商家还提供800元/月的租赁使用服务。\n2023年，因哺光仪不规范使用造成某12岁女童视网膜黄斑损伤，导致视力永久性受损。同年6月，国家药监局发布通知，将激光近视弱视治疗仪类产品划分为第三类医疗器械，并给予企业和市场一年过渡期。这意味着在2024年7月1日之后，企业生产、销售哺光仪，须具有第三类医疗器械注册证和生产许可证。\n今年4月，北京大学人民医院、北京同仁医院有关专家在国际知名眼科期刊共同发表名为《近视儿童重复低强度红光治疗后视锥细胞密度的变化》的论文，指出以激光作为光源对儿童眼睛进行照射以防控近视，有引发视锥光感受器受损的风险。\n中山大学孙逸仙纪念医院眼科副主任医师张一弛说，哺光仪目前临床研究观察最长时间为一年。部分孩子使用后眼轴增长确有所控制，但发生机制尚不明确，长期暴露情况下安全性、有效性也有待观察。\n首都医科大学附属北京康复医院眼科主任刘莹说，部分家长因孩子近视进展或眼轴增长过快而选择使用哺光仪，也有一些家长认为孩子度数不严重，想用三分钟哺光替代两小时户外，这些想法并不可取。\n这位专家表示，户外活动作为近视防控方案的循证医学证据在全球的观察时间更长、数据更多。建议家长们理性评估风险与收益，优先选择证据充分的防控手段。\n大路灯能“模拟自然光”？\n“相比普通台灯，大路灯的室内照明光线分布相对均匀，能够减少阴影和暗区，照射范围也更广，在一定程度上有助于减轻视疲劳，但并不足以单独作为一种近视防控方法。”刘莹说，与按照三类医疗器械管理的哺光仪不同，大路灯本质上是一种灯具。\n浙江大学眼科医院视光中心主任倪海龙表示，万物生长靠太阳，晴朗白天的太阳光照度可达10万勒克斯（lux），远超能提供1000lux左右光照强度的所谓大路灯。“同时，大路灯也无法替代户外光刺激视网膜分泌多巴胺的关键作用。”他说。\n很多临床医生都在门诊中遇到家长请求推荐灯具产品。不少家长表示，大路灯“参数眼花缭乱、价格五花八门”，“缺乏行业标准、质量良莠不齐”，购买后发现部分低价产品夸大宣传。\n《近视防治指南（2024年版）》明确，读写应在采光良好、照明充足的环境中进行，桌面的平均照度值不应低于300lux。国家标准《读写作业台灯性能要求》对灯具色温、显色指数、照度、视网膜蓝光危害和闪烁等多项指标提出要求。\n专家强调，近视的发展受环境因素、遗传因素等共同影响，采光照明只是其中一个方面。选购灯具应优先参照国家出台的相关标准。\n改善整体光环境和用眼习惯，避免依赖单一技术手段\n倪海龙强调，近视防控的关键仍在于一增一减，即增加户外活动，减少近距离用眼负担，同时可辅以改善光环境及用眼习惯，要打组合拳，而非依赖单一技术手段。\n专家建议要科学看待人工光源，辅助工具不可替代自然光照和基础防控。\n“不论是儿童青少年还是成年人，自然光作为视觉的核心保护因素，其作用不可替代。”刘莹说，人工光源的应用需以“安全、循证”为原则，避免因商业营销或焦虑心理陷入误区。\n近年来，党和国家高度重视青少年近视防控，部署三级干预措施。一级预防包括从婴幼儿期（2岁半起）就定期筛查视力，避免过早接触电子产品；二级预防包括通过户外活动、用眼习惯调整降低近视风险；三级预防包括采用离焦眼镜、角膜塑形镜及低浓度阿托品等医学手段延缓近视加深。\n专家表示，近视防控是个系统工程，需要全社会行动起来，关注全生命周期的用眼健康。",
    "reference_list": "考点 1： \"重复低强度红光（RLRL）\" 应译为 \"repeated low-level red light (RLRL)\"  \n考点 2： \"以激光为光源照射眼睛\" 应译为 \"laser-based ocular irradiation\"  \n考点 3： \"国家药监局\" 应译为 \"National Medical Products Administration (NMPA)\"  \n考点 4： \"注册证和生产许可证\" 应译为 \"registration certificate and production license\"  \n考点 5： \"视锥细胞密度\" 应译为 \"cone cell density\"  \n考点 6： \"视锥光感受器受损\" 应译为 \"cone photoreceptor damage\"  \n考点 7： \"质量良莠不齐\" 应译为 \"uneven product quality\"  \n考点 8： \"《近视防治指南（2024 年版）》\" 应译为 \"Guidelines for Myopia Prevention and Control (2024 edition)\"  \n考点 9： \"国家标准《读写作业台灯性能要求》\" 应译为 \"National Standard: Performance Requirements for Reading and Writing Desk Lamps\"  \n考点 10： \"一增一减\" 应译为 \"'one increase, one decrease\"'strategy\"  \n考点 11： \"组合拳\" 应译为 \"a combination strategy\" / \"multi-pronged approach\"  \n考点 12： \"青少年近视防控\" 应译为 \"juvenile myopia prevention and control\"  \n考点 13： \"离焦眼镜\" 应译为 \"defocus spectacles\"\n考点14： “全国爱眼日”应译为“Sight Day”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "96"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n国家金融监督管理总局是中国负责金融行业统一监督管理的机构，主要职责包括强化机构监管、行为监管、功能监管等，以维护金融业的合法和稳健运行。该局还参与金融业改革开放和监管有效性相关问题的研究，并拟订相关法律法规草案。近期，该局还修订了《货币经纪公司管理办法》，并向社会公开征求意见，以加强对货币经纪公司的监管。此外，局长李云泽在新闻发布会上表示，将推出八项增量政策，以支持经济回升。 \n2025年6月，为加强商业银行的市场风险管理，国家金融监督管理总局根据《中华人民共和国银行业监督管理法》《中华人民共和国商业银行法》以及其他有关法律和行政法规，制定了《商业银行市场风险管理办法》，并印发给各金融监管局，各政策性银行、大型银行、股份制银行、外资银行、直销银行、金融资产管理公司、金融资产投资公司。\n《商业银行市场风险管理办法》（下文简称《规则》）共五章四十三条，主要涵盖以下几个方面：首先，明确市场风险定义。《规则》明确了适用范围，明确排除了银行账簿中的利率风险，并加强了与《商业银行资本管理办法》和《银行业金融机构全面风险管理指引》的协调一致。其次，强调改进市场风险治理框架。规则阐明了董事会、监事会和高级管理层的责任，界定了三道防线具体范围和职责，并强调银行需要在集团层面加强市场风险管理。 第三，细化市场风险管理要求。规则要求银行进行端到端的市场风险管理，并详细规定了风险识别、计量、监测、控制和报告的总体要求。规则还改进了内部模型的定义，并提高了对模型治理和压力测试的要求，确保与当前市场风险计量框架和管理实践保持一致。未来，国家金融监督管理总局将加强监管和指导，确保规则的有效实施，并将指导银行提升其市场风险管理能力。\n同时，国家金融监督管理总局还具有对于中国大陆境内金融机构评级的职责，例如，同样在2025年6月，为了积极参与国际保险集团的监管治理，维护全球金融市场的稳定，推动中国保险业高水平对外开放，国家金融监督管理总局根据国际保险监督协会发布的《国际保险集团监管共同框架》，对中国具有国际影响力的保险集团进行了评估和认定。经评估，中国再保险（集团）股份有限公司（简称“中国再保”）被认定为具有国际影响力的保险集团。今后，国家金融监督管理总局将指导中国再保按照《国际保险集团监管共同框架》进一步健全其风险管理体系，持续提升经营管理能力和国际竞争力。\n提到再保险，可能很多人会觉得陌生。再保险也称分保，是保险人在原保险合同的基础上，通过签订分保合同，将其所承保的部分风险和责任向其他保险人进行保险的行为。再保险作为“保险的保险”，对于保障保险市场安全，为直接保险公司分散赔付风险、扩大承保能力和巨灾保障功能，并辅助保险市场调控以及强化行业风险管理发挥了重要的作用。以中国再保为例，中国再保险（集团）股份有限公司（简称“中国再保”）由中华人民共和国财政部和中央汇金投资有限责任公司发起设立，注册资本人民币42,479,808,085元，其中财政部持股11.45%，中央汇金投资有限责任公司持股71.56%。中国再保源于1949年10月成立的中国人民保险公司，2007年10月整体改制为股份有限公司。目前，中国再保主要控股7家境内子公司：中国财产再保险有限责任公司（简称“中再产险”）、中国人寿再保险有限责任公司（简称“中再寿险”）、中国大地财产保险股份有限公司等。\n截止2024年11月，中国大陆境内15家再保险公司中有9家为外资再保险公司，分别是慕尼黑再保险公司北京分公司、德国通用再保险股份公司上海分公司、RGA美国再保险公司上海分公司、大韩再保险公司上海分公司、法国再保险公司北京分公司、汉诺威再保险股份公司上海分公司、瑞士再保险股份有限公司北京分公司、信利再保险（中国）有限公司、曼福再保险公司北京分公司；6家为内资机构分别是中国农业再保险股份有限公司、人保再保险股份有限公司、太平再保险（中国）有限公司、中国财产再保险有限责任公司、中国人寿再保险有限责任公司。\n随着我国经济的快速增长和保险行业的不断发展，中国再保险市场专业主体逐渐丰富，保费规模和市场份额稳步扩大。但也要看到对标国际发达再保险市场水平，我国再保险市场还存在一定差距。业内人士建议，内资再保险公司可借助保险科技手段，加强自身的风险管理能力，更好地满足直保公司的服务需求。同时，加大资本投入，增强资本实力，提升自身的承保能力和抗风险能力。此外，加强国际合作与交流，学习国际先进的保险专业技术，利用国际市场进行风险分散，提升自己的承保能力与盈利能力。",
    "ori_text": "\n\n国家金融监督管理总局是中国负责金融行业统一监督管理的机构，主要职责包括强化机构监管、行为监管、功能监管等，以维护金融业的合法和稳健运行。该局还参与金融业改革开放和监管有效性相关问题的研究，并拟订相关法律法规草案。近期，该局还修订了《货币经纪公司管理办法》，并向社会公开征求意见，以加强对货币经纪公司的监管。此外，局长李云泽在新闻发布会上表示，将推出八项增量政策，以支持经济回升。 \n2025年6月，为加强商业银行的市场风险管理，国家金融监督管理总局根据《中华人民共和国银行业监督管理法》《中华人民共和国商业银行法》以及其他有关法律和行政法规，制定了《商业银行市场风险管理办法》，并印发给各金融监管局，各政策性银行、大型银行、股份制银行、外资银行、直销银行、金融资产管理公司、金融资产投资公司。\n《商业银行市场风险管理办法》（下文简称《规则》）共五章四十三条，主要涵盖以下几个方面：首先，明确市场风险定义。《规则》明确了适用范围，明确排除了银行账簿中的利率风险，并加强了与《商业银行资本管理办法》和《银行业金融机构全面风险管理指引》的协调一致。其次，强调改进市场风险治理框架。规则阐明了董事会、监事会和高级管理层的责任，界定了三道防线具体范围和职责，并强调银行需要在集团层面加强市场风险管理。 第三，细化市场风险管理要求。规则要求银行进行端到端的市场风险管理，并详细规定了风险识别、计量、监测、控制和报告的总体要求。规则还改进了内部模型的定义，并提高了对模型治理和压力测试的要求，确保与当前市场风险计量框架和管理实践保持一致。未来，国家金融监督管理总局将加强监管和指导，确保规则的有效实施，并将指导银行提升其市场风险管理能力。\n同时，国家金融监督管理总局还具有对于中国大陆境内金融机构评级的职责，例如，同样在2025年6月，为了积极参与国际保险集团的监管治理，维护全球金融市场的稳定，推动中国保险业高水平对外开放，国家金融监督管理总局根据国际保险监督协会发布的《国际保险集团监管共同框架》，对中国具有国际影响力的保险集团进行了评估和认定。经评估，中国再保险（集团）股份有限公司（简称“中国再保”）被认定为具有国际影响力的保险集团。今后，国家金融监督管理总局将指导中国再保按照《国际保险集团监管共同框架》进一步健全其风险管理体系，持续提升经营管理能力和国际竞争力。\n提到再保险，可能很多人会觉得陌生。再保险也称分保，是保险人在原保险合同的基础上，通过签订分保合同，将其所承保的部分风险和责任向其他保险人进行保险的行为。再保险作为“保险的保险”，对于保障保险市场安全，为直接保险公司分散赔付风险、扩大承保能力和巨灾保障功能，并辅助保险市场调控以及强化行业风险管理发挥了重要的作用。以中国再保为例，中国再保险（集团）股份有限公司（简称“中国再保”）由中华人民共和国财政部和中央汇金投资有限责任公司发起设立，注册资本人民币42,479,808,085元，其中财政部持股11.45%，中央汇金投资有限责任公司持股71.56%。中国再保源于1949年10月成立的中国人民保险公司，2007年10月整体改制为股份有限公司。目前，中国再保主要控股7家境内子公司：中国财产再保险有限责任公司（简称“中再产险”）、中国人寿再保险有限责任公司（简称“中再寿险”）、中国大地财产保险股份有限公司等。\n截止2024年11月，中国大陆境内15家再保险公司中有9家为外资再保险公司，分别是慕尼黑再保险公司北京分公司、德国通用再保险股份公司上海分公司、RGA美国再保险公司上海分公司、大韩再保险公司上海分公司、法国再保险公司北京分公司、汉诺威再保险股份公司上海分公司、瑞士再保险股份有限公司北京分公司、信利再保险（中国）有限公司、曼福再保险公司北京分公司；6家为内资机构分别是中国农业再保险股份有限公司、人保再保险股份有限公司、太平再保险（中国）有限公司、中国财产再保险有限责任公司、中国人寿再保险有限责任公司。\n随着我国经济的快速增长和保险行业的不断发展，中国再保险市场专业主体逐渐丰富，保费规模和市场份额稳步扩大。但也要看到对标国际发达再保险市场水平，我国再保险市场还存在一定差距。业内人士建议，内资再保险公司可借助保险科技手段，加强自身的风险管理能力，更好地满足直保公司的服务需求。同时，加大资本投入，增强资本实力，提升自身的承保能力和抗风险能力。此外，加强国际合作与交流，学习国际先进的保险专业技术，利用国际市场进行风险分散，提升自己的承保能力与盈利能力。",
    "reference_list": "考点1：国家金融监督管理总局只能译为National Financial Regulatory Administration，因为这是固定机构名称\n考点2：《中华人民共和国银行业监督管理法》只能为Banking Supervision Law of the People's Republic of China，因为这是法律文件名称\n考点3：《中华人民共和国商业银行法》只能译为Law of the People's Republic of China on Commercial Banks，因为这是法律文件名称\n考点4：《商业银行资本管理办法》只能译为Administrative Measures for the Capital of Commercial Banks，因为这是法律文件名称\n考点5：《国际保险集团监管共同框架》只能译为Common Framework for the Supervision of Internationally Active Insurance Groups，因为这是法律文件名称\n考点6：中央汇金投资有限责任公司只能译为Central Huijin Investment Ltd.，因为这是公司名称\n考点7：中国人民保险公司只能译为The People's Insurance Company (Group) of China，因为这是公司名称\n考点8：中国财产再保险有限责任公司（简称“中再产险”）只能译为China Property & Casualty Reinsurance Company Ltd.（CHINA RE P&C），因为这是公司名称\n考点9：中国人寿再保险有限责任公司（简称“中再寿险”）只能译为China Life Reinsurance Company Ltd. （China Re Life），因为这是公司名称\n考点10：中国大地财产保险股份有限公司只能译为China Continent Property & Casualty Insurance Co., Ltd (CCIC)，因为这是公司名称\n考点11：德国通用再保险股份公司上海分公司只能译为General Reinsurance AG Shanghai Branch，因为这是公司名称\n考点12：RGA美国再保险公司上海分公司只能译为RGA Reinsurance Company Shanghai Branch，因为这是公司名称\n考点13：大韩再保险公司上海分公司只能译为Korean Reinsurance Company, Shanghai Branch 或 Korean Reinsurance Company Shanghai Branch，因为这是公司名称\n考点14：法国再保险公司北京分公司只能译为SCOR SE Beijing Branch，因为这是公司名称\n考点15：汉诺威再保险股份公司上海分公司只能译为Hannover Rück SE Shanghai Branch，因为这是公司名称\n考点16：瑞士再保险股份有限公司北京分公司只能译为Swiss Reinsurance Company Ltd. Beijing Branch，因为这是公司名称\n考点17：曼福再保险公司北京分公司只能译为MAPFRE RE Beijing Branch，因为这是公司名称\n考点18：中国农业再保险股份有限公司只能译为China Agricultural Reinsurance Co., Ltd.，因为这是公司名称\n考点19：人保再保险股份有限公司只能译为PICC Reinsurance Company Limited，因为这是公司名称\n考点20：太平再保险（中国）有限公司只能译为Taiping Reinsurance(China)Company Limited，因为这是公司名称",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "金融",
    "prompt_id": "198"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 与过去相比，如今我们与他人交往的方式真是空前多样。曾经，我们只能依靠面对面交谈，但在过去的几千年中，新的交往技术不断被创造出来。数字时代的独特之处，便在于使人与人相联系的技术中介经历了快速转型。在面对面交谈、固定电话、邮政信件等传统交往方式的基础上，我们拥有了电子邮件、移动电话、短信、即时通信、网聊、留言板、社交网络、照片分享、视频分享、多人在线游戏等诸多新型交往方式。不过，在面对新媒体时，人们也时常感到困惑。在这个创新与扩散日新月异的时代，我们自然会关心这些新型交往方式对人际关系的影响。\n 面对层出不穷的新媒体，我们往往有两种反应： 一些人对人际交往的浅薄化表示担忧，对于很多人而言，日益频繁的中介化互动似乎威胁到了人际关系的神圣性；另一些人则认为， 新媒体为我们创造了更多与他人建立联系的机会，从而形成了更强大、更多样化的关系链。这两种观点都有着深厚的文化历史背景，也都印证了同一种观念：数字媒体正在改变社会关系的本质。随着时间的推移，当我们逐渐习惯了新的传播媒体时，人们的态度开始发生微妙的改变。这些媒体的存在被视为理所当然，甚至可以忽略不计。所以，我们思考科技、探索交往，以及反思两者关联的最佳时刻，就是这些新媒体刚刚出现，有关它们的使用准则还未固定之时。\n 本书围绕数字媒体和数字设备在人际关系中扮演的角色展开，旨在为大家提供一种批判性思考的方式。比起目不暇接、发人深省的故事逸闻，本书更愿意提供一些理论和数据资料，帮助读者理解人际关系中发生的重要变化。我从1990年开始关注这个领域，1991年启动了我第一项有关网络人际关系的研究，1994年起在传播学院开设传播和新技术的相关课程。本书的素材取自我的研究项目、观察以及大量与此相关的其他研究文献，这些素材为评估和理解人际关系的变迁奠定了框架。\n当我们试图理解数字媒体和它在我们生活中的位置，以及对我们的个性和人际关系的影响时，会发现各种各样值得思考的议题。在技术的最初发展阶段，它会影响我们如何看待世界、社区、关系和自我。这也会促使社会和文化的重构与反思。卡罗琳·马尔温的一项著名研究考察了19世纪大众科学杂志，她发现在人类历史中，电、电报、电话这些新技术的出现会将人们熟悉的事物陌生化，因此也更容易导致改变。这种改变又会造成人们的焦虑。在古代社会，人们曾为书写的出现担忧；在维多利亚时代，人们害怕电；如今，我们的“焦虑不仅针对电脑，还针对更广泛意义上的技术”。\n从远古时代起，这些传播技术出现的根本目的就是能让人们在身体缺席时，仍旧能够传递信息。在19世纪电报发明之前，这种超越空间的能力不可避免地会伴随时间的延迟，信息传达给受众可能要用上几年的时间。随着电报的出现，人类在历史上首次实现了不受距离限制的实时通信。人们也许曾对写作和出版感到震惊，不过，与面临这种全新的、瓦解时空边界的力量时产生的震惊相比，前者只能算是小巫见大巫。毕竟数千年来，人类早已习惯面对面社交，这种以极高速度进行远距离交流的能力，打破了我们根植于集体意识深处的社会认知。数字媒体的出现则造成了更严重的困扰。它们向学者和普通人提出了许多重要的问题：怎样才能既在场又缺席？如果自我不再需要身体作为载体，它将是什么样子？我们为何会在拥有如此多控制权的同时，又丧失了如此多的自由？当个人交流通过大众媒体传播时，意味着什么？当大众传播被用于个人交流时，其到底该被如何定义？“私人”和“公共”如何区分？“真实”到底是什么意思？\n肯尼思·格根认为我们正在与“缺席的在场所造成的挑战”做斗争。尽管在物理空间中，我们身边不乏有血有肉的人，但我们依然为自己在“漂浮世界”中与不在场的对象打交道感到忧心忡忡。雪莉·特克尔在《群体性孤独》一书中指出， 我们也许置身某地，但是心思和情感却在别处。例如，你的同伴虽然与你共进晚餐，但却一直低头用手机与别人聊天。那么他的身体既是在场的，但同时又是缺席的，于是，“自我”的本质就变得模糊起来。 “他”到底在哪里？哈拉维在《赛博格宣言》中宣告，人类和机器的界限已经瓦解。不仅如此，自我和身体的界限也陷入不确定性之中。很快，一些人便认为，他们的“真实自我”在网上能得到最佳呈现。异地恋的双方通过电子设备建立和维系关系，可穿戴设备被嵌入我们日常穿着之中，那么，我们又怎么确认真实的自我究竟在何处栖身呢？此外，如果数字媒体中的自我和面对面交流中的自我不一样，甚至相互矛盾时，我们又该怎么办呢？如果一个人在面对面交流中表现得很有教养，在一个网络论坛中咄咄逼人，在另一个论坛中则渴求关爱，那么，哪一个自我才是真实的呢？是否还存在真实的自我？它曾经存在过吗？",
    "ori_text": "\n\n 与过去相比，如今我们与他人交往的方式真是空前多样。曾经，我们只能依靠面对面交谈，但在过去的几千年中，新的交往技术不断被创造出来。数字时代的独特之处，便在于使人与人相联系的技术中介经历了快速转型。在面对面交谈、固定电话、邮政信件等传统交往方式的基础上，我们拥有了电子邮件、移动电话、短信、即时通信、网聊、留言板、社交网络、照片分享、视频分享、多人在线游戏等诸多新型交往方式。不过，在面对新媒体时，人们也时常感到困惑。在这个创新与扩散日新月异的时代，我们自然会关心这些新型交往方式对人际关系的影响。\n 面对层出不穷的新媒体，我们往往有两种反应： 一些人对人际交往的浅薄化表示担忧，对于很多人而言，日益频繁的中介化互动似乎威胁到了人际关系的神圣性；另一些人则认为， 新媒体为我们创造了更多与他人建立联系的机会，从而形成了更强大、更多样化的关系链。这两种观点都有着深厚的文化历史背景，也都印证了同一种观念：数字媒体正在改变社会关系的本质。随着时间的推移，当我们逐渐习惯了新的传播媒体时，人们的态度开始发生微妙的改变。这些媒体的存在被视为理所当然，甚至可以忽略不计。所以，我们思考科技、探索交往，以及反思两者关联的最佳时刻，就是这些新媒体刚刚出现，有关它们的使用准则还未固定之时。\n 本书围绕数字媒体和数字设备在人际关系中扮演的角色展开，旨在为大家提供一种批判性思考的方式。比起目不暇接、发人深省的故事逸闻，本书更愿意提供一些理论和数据资料，帮助读者理解人际关系中发生的重要变化。我从1990年开始关注这个领域，1991年启动了我第一项有关网络人际关系的研究，1994年起在传播学院开设传播和新技术的相关课程。本书的素材取自我的研究项目、观察以及大量与此相关的其他研究文献，这些素材为评估和理解人际关系的变迁奠定了框架。\n当我们试图理解数字媒体和它在我们生活中的位置，以及对我们的个性和人际关系的影响时，会发现各种各样值得思考的议题。在技术的最初发展阶段，它会影响我们如何看待世界、社区、关系和自我。这也会促使社会和文化的重构与反思。卡罗琳·马尔温的一项著名研究考察了19世纪大众科学杂志，她发现在人类历史中，电、电报、电话这些新技术的出现会将人们熟悉的事物陌生化，因此也更容易导致改变。这种改变又会造成人们的焦虑。在古代社会，人们曾为书写的出现担忧；在维多利亚时代，人们害怕电；如今，我们的“焦虑不仅针对电脑，还针对更广泛意义上的技术”。\n从远古时代起，这些传播技术出现的根本目的就是能让人们在身体缺席时，仍旧能够传递信息。在19世纪电报发明之前，这种超越空间的能力不可避免地会伴随时间的延迟，信息传达给受众可能要用上几年的时间。随着电报的出现，人类在历史上首次实现了不受距离限制的实时通信。人们也许曾对写作和出版感到震惊，不过，与面临这种全新的、瓦解时空边界的力量时产生的震惊相比，前者只能算是小巫见大巫。毕竟数千年来，人类早已习惯面对面社交，这种以极高速度进行远距离交流的能力，打破了我们根植于集体意识深处的社会认知。数字媒体的出现则造成了更严重的困扰。它们向学者和普通人提出了许多重要的问题：怎样才能既在场又缺席？如果自我不再需要身体作为载体，它将是什么样子？我们为何会在拥有如此多控制权的同时，又丧失了如此多的自由？当个人交流通过大众媒体传播时，意味着什么？当大众传播被用于个人交流时，其到底该被如何定义？“私人”和“公共”如何区分？“真实”到底是什么意思？\n肯尼思·格根认为我们正在与“缺席的在场所造成的挑战”做斗争。尽管在物理空间中，我们身边不乏有血有肉的人，但我们依然为自己在“漂浮世界”中与不在场的对象打交道感到忧心忡忡。雪莉·特克尔在《群体性孤独》一书中指出， 我们也许置身某地，但是心思和情感却在别处。例如，你的同伴虽然与你共进晚餐，但却一直低头用手机与别人聊天。那么他的身体既是在场的，但同时又是缺席的，于是，“自我”的本质就变得模糊起来。 “他”到底在哪里？哈拉维在《赛博格宣言》中宣告，人类和机器的界限已经瓦解。不仅如此，自我和身体的界限也陷入不确定性之中。很快，一些人便认为，他们的“真实自我”在网上能得到最佳呈现。异地恋的双方通过电子设备建立和维系关系，可穿戴设备被嵌入我们日常穿着之中，那么，我们又怎么确认真实的自我究竟在何处栖身呢？此外，如果数字媒体中的自我和面对面交流中的自我不一样，甚至相互矛盾时，我们又该怎么办呢？如果一个人在面对面交流中表现得很有教养，在一个网络论坛中咄咄逼人，在另一个论坛中则渴求关爱，那么，哪一个自我才是真实的呢？是否还存在真实的自我？它曾经存在过吗？",
    "reference_list": "考点1：“ 日新月异的时代”应该译为“ an era of rapid change”​，准确描述时代的特征\n考点2：“何处栖身”推荐译为“where ···to dwell/reside”​",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "158"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n　Abstract\nThe landscape of mobile gaming has evolved significantly over the years, with profound changes in network reliability and traffic patterns. In the early 2010s, mobile games faced challenges due to unreliable networks and primarily featured asynchronous gameplay. However, in the current era, modern mobile games benefit from robust network connectivity, mirroring PC gaming experiences by relying on persistent connections to game servers. This shift prompted us to conduct an in-depth traffic analysis of two mobile games that represent opposite ends of the genre spectrum: a massively multiplayer game resembling PC MMORPGs with tightly synchronized gameplay, and a single-player puzzle game that incorporates asynchronous social interactions. Surprisingly, both games exhibited remarkably similar traffic footprints; small packets with short inter-packet arrival times, indicating their high expectations for network reliability. This suggests that game developers now prioritize network quality similarly to their PC gaming counterparts. Additionally, our analysis of packet lengths unveiled that recent mobile games predominantly employ short packets dominated by a few key packet types closely tied to player actions, which conforms to observations from PC online games. However, the self-similarity in traffic patterns, a notable feature in PC online games, only partially explains the traffic in mobile games, varying across genres. These findings shed light on the evolving traffic patterns in mobile games and emphasize the need for further research in this dynamic domain.\nKeywords: mobile games; traffic analysis; Internet measurement\n1. Introduction\nNetwork traffic analysis reports have illustrated that gaming is one of the most popular Internet applications, accounting for an estimated 8–10% of total Internet traffic and ranking as the third biggest traffic source after video streaming and web applications, including social media [1,2,3]. Another report highlights that 92.3% of Internet users access the Internet using mobile phones, with gaming being the most common use for these devices [4]. Given that game servers are typically hosted in cloud data centers and that game service providers incur significant costs for network traffic, understanding mobile game traffic patterns is crucial, not only from an engineering viewpoint but also from a business perspective.\nAs mobile devices, including smartphones and tablets, have become the prevailing service environment for the gaming industry, game genres that run on mobile devices have also become diverse and complicated. In the early era of networked mobile gaming in the 2010s, most mobile games were asynchronous due to the poor robustness and high cost of mobile networks. In these games, players could interact with other players, such as family members and friends, but they generally played independently rather than tightly together.\nOn the other hand, today’s mobile network technology, especially in metropolitan areas, has significantly improved in connection stability. A recent survey showed that from October 2022 through March 2023, 5G and 4G networks in the UK exhibited 98.4% and 97.8% connection success rates on average, respectively, when a mobile device becomes active [5]. This suggests that mobile games enjoy much more robust network connectivity, even in the mobile network, and thus such games now rely more on a persistent network connection to the game server. This phenomenal change suggests that the current underlying network traffic patterns might differ from those of the 2010s and from those in the PC gaming environment.\nThis paper illustrates traffic analysis from two mobile games with global service. The analyzed games represent opposite extremes in terms of their genre. One is strongly synchronized and a massive multiplayer game similar to that of a PC environment, but with an “auto-hunt” feature to allow gameplay without human engagement. The other is less synchronized and primarily played by a single player, although it also features social interactions among players.\nThe primary contribution of our work is demonstrating that recent mobile games exhibit traffic patterns akin to those in PC games, particularly regarding packet length and inter-packet arrival times, but have differences regarding traffic self-similarity. Our analysis of the games’ traffic traces reveals that current mobile games typically feature notably short inter-packet arrival times, similar to traditional multiplayer games in the PC environment, accompanied by a long-tail distribution due to the intermittent sleep and resume nature of mobile applications. Concerning packet lengths, recent mobile games predominantly use shorter packets, favoring them over aggregated larger packets to conserve network bandwidth. These patterns, observed consistently across different game genres, suggest that modern mobile games are developed with expectations of reliable network connectivity, a notable shift from earlier in the 2010s. This consistency in traffic characteristics, irrespective of game genre, underscores a fundamental similarity in network usage between contemporary mobile and PC gaming platforms. Our analysis, however, discovered that the presence of self-similarity in traffic patterns, identified by previous research on PC online games’ traffic patterns, varies across game genres. This finding encourages further research to model mobile game traffic.\nThis paper is organized as follows: Section 2 reviews research related to the mobile gaming industry. Section 3 briefly introduces the mobile games analyzed and explains the methods for collecting and anonymizing traffic data. In Section 4, we describe our analysis methodology and present key findings. Finally, Section 5 summarizes these findings and proposes directions for future research.\n2. Related Work\nReports have shown that gaming is the most popular activity among mobile device users. Furthermore, gaming activities, which include those on PCs, mobile devices, and consoles, collectively constitute the third largest source of total Internet traffic [1,2,3,4]. Despite its significance in the context of today’s Internet traffic, there is a notable dearth of comprehensive research on mobile game traffic. In contrast, considerable research efforts have been directed towards analyzing PC online game traces, modeling traffic patterns, and optimizing traffic [6,7,8,9,10,11,12,13]. Previous research agrees that PC online games generate highly periodic bursty short packets. In particular, Chen et al. discovered traffic exhibits pronounced periodicity and temporal locality in inter-packet arrival times, attributable to player action patterns by a comprehensive traffic analysis using substantial packet traces from a PC MMORPG game [11]. Feng et al. also observed that the distribution of game session time in PC games is not heavy-tailed, a characteristic stemming from the synchronized nature of gameplay [12]. Henderson et al. explored the network quality of service (QoS) tolerance of game players [14]. Apart from previous research mainly focusing on PC online games, our work fills the gap for mobile games. We confirmed that mobile games share similarities with PC online games regarding traffic patterns while having unique differences at the same time. Chen et al. conducted a preliminary traffic analysis using Pokémon Go, which is a mobile AR game [15], but their preliminary results did not uncover relationships with PC online games.\nThere is considerable research measuring the real-life performance of various mobile network technologies (i.e., the 3G, 4G, and 5G) [5,16,17,18,19,20,21,22,23]. Based on these research findings, mobile application developers can reasonably assume that even 4G LTE, currently the most prevalent mobile network worldwide, can provide an average round-trip time (RTT) of about 50 ms between a carrier network and a player’s device in metro areas. In particular, Ref. [22] reports that a study conducted in London showed a 5-millisecond latency could be achieved with 99.999% reliability over a 5G network. This research indicates that applications, including games, running on mobile networks can reliably expect lower latency as mobile infrastructure evolves. The finding in mobile network robustness is the main motivation for our research on mobile game traffic patterns.\nKämäräinen et al. investigated factors contributing to end-to-end latency in cloud gaming, where game scenes are rendered at cloud servers. Their research highlights emerging technologies that could enhance gaming experiences demanding high network bandwidth and strict latency constraints [24]. Similarly, Braud et al. conducted research on mobile AR applications, which require computational offloading to cloud servers and are, therefore, also subject to network bandwidth and latency limitations [25]. Despite the disruptive approach of cloud gaming, it was not widely deployed in the mobile gaming industry because of high costs and the limited robustness of mobile networks. This approach is, however, being revitalized by the rapid emergence of virtual reality technologies and technological improvements in mobile networks. Therefore, understanding mobile traffic characteristics through our research can also contribute to cloud gaming.\n3. Materials and Methods\nDue to the exclusivity or closed nature of the gaming industry, game traffic traces are not readily accessible, even in anonymized form. Game companies hesitate to release traffic traces not only because of concerns over players’ privacy information but also due to fears that the data might be used to compromise the security of their services. This partially explains why there has been limited research conducted on the network traffic characteristics of online/mobile games, despite their significance in terms of traffic usage.\nFor this limitation, we selected two representative game genres at opposite ends of the spectrum and collected network traffic traces from a mobile game for each genre. The games are globally serviced and independently developed and operated by different game companies. Therefore, the games do not share any specific development methodology or assumptions about underlying network behavior.\n ",
    "ori_text": "　Abstract\nThe landscape of mobile gaming has evolved significantly over the years, with profound changes in network reliability and traffic patterns. In the early 2010s, mobile games faced challenges due to unreliable networks and primarily featured asynchronous gameplay. However, in the current era, modern mobile games benefit from robust network connectivity, mirroring PC gaming experiences by relying on persistent connections to game servers. This shift prompted us to conduct an in-depth traffic analysis of two mobile games that represent opposite ends of the genre spectrum: a massively multiplayer game resembling PC MMORPGs with tightly synchronized gameplay, and a single-player puzzle game that incorporates asynchronous social interactions. Surprisingly, both games exhibited remarkably similar traffic footprints; small packets with short inter-packet arrival times, indicating their high expectations for network reliability. This suggests that game developers now prioritize network quality similarly to their PC gaming counterparts. Additionally, our analysis of packet lengths unveiled that recent mobile games predominantly employ short packets dominated by a few key packet types closely tied to player actions, which conforms to observations from PC online games. However, the self-similarity in traffic patterns, a notable feature in PC online games, only partially explains the traffic in mobile games, varying across genres. These findings shed light on the evolving traffic patterns in mobile games and emphasize the need for further research in this dynamic domain.\nKeywords: mobile games; traffic analysis; Internet measurement\n1. Introduction\nNetwork traffic analysis reports have illustrated that gaming is one of the most popular Internet applications, accounting for an estimated 8–10% of total Internet traffic and ranking as the third biggest traffic source after video streaming and web applications, including social media [1,2,3]. Another report highlights that 92.3% of Internet users access the Internet using mobile phones, with gaming being the most common use for these devices [4]. Given that game servers are typically hosted in cloud data centers and that game service providers incur significant costs for network traffic, understanding mobile game traffic patterns is crucial, not only from an engineering viewpoint but also from a business perspective.\nAs mobile devices, including smartphones and tablets, have become the prevailing service environment for the gaming industry, game genres that run on mobile devices have also become diverse and complicated. In the early era of networked mobile gaming in the 2010s, most mobile games were asynchronous due to the poor robustness and high cost of mobile networks. In these games, players could interact with other players, such as family members and friends, but they generally played independently rather than tightly together.\nOn the other hand, today’s mobile network technology, especially in metropolitan areas, has significantly improved in connection stability. A recent survey showed that from October 2022 through March 2023, 5G and 4G networks in the UK exhibited 98.4% and 97.8% connection success rates on average, respectively, when a mobile device becomes active [5]. This suggests that mobile games enjoy much more robust network connectivity, even in the mobile network, and thus such games now rely more on a persistent network connection to the game server. This phenomenal change suggests that the current underlying network traffic patterns might differ from those of the 2010s and from those in the PC gaming environment.\nThis paper illustrates traffic analysis from two mobile games with global service. The analyzed games represent opposite extremes in terms of their genre. One is strongly synchronized and a massive multiplayer game similar to that of a PC environment, but with an “auto-hunt” feature to allow gameplay without human engagement. The other is less synchronized and primarily played by a single player, although it also features social interactions among players.\nThe primary contribution of our work is demonstrating that recent mobile games exhibit traffic patterns akin to those in PC games, particularly regarding packet length and inter-packet arrival times, but have differences regarding traffic self-similarity. Our analysis of the games’ traffic traces reveals that current mobile games typically feature notably short inter-packet arrival times, similar to traditional multiplayer games in the PC environment, accompanied by a long-tail distribution due to the intermittent sleep and resume nature of mobile applications. Concerning packet lengths, recent mobile games predominantly use shorter packets, favoring them over aggregated larger packets to conserve network bandwidth. These patterns, observed consistently across different game genres, suggest that modern mobile games are developed with expectations of reliable network connectivity, a notable shift from earlier in the 2010s. This consistency in traffic characteristics, irrespective of game genre, underscores a fundamental similarity in network usage between contemporary mobile and PC gaming platforms. Our analysis, however, discovered that the presence of self-similarity in traffic patterns, identified by previous research on PC online games’ traffic patterns, varies across game genres. This finding encourages further research to model mobile game traffic.\nThis paper is organized as follows: Section 2 reviews research related to the mobile gaming industry. Section 3 briefly introduces the mobile games analyzed and explains the methods for collecting and anonymizing traffic data. In Section 4, we describe our analysis methodology and present key findings. Finally, Section 5 summarizes these findings and proposes directions for future research.\n2. Related Work\nReports have shown that gaming is the most popular activity among mobile device users. Furthermore, gaming activities, which include those on PCs, mobile devices, and consoles, collectively constitute the third largest source of total Internet traffic [1,2,3,4]. Despite its significance in the context of today’s Internet traffic, there is a notable dearth of comprehensive research on mobile game traffic. In contrast, considerable research efforts have been directed towards analyzing PC online game traces, modeling traffic patterns, and optimizing traffic [6,7,8,9,10,11,12,13]. Previous research agrees that PC online games generate highly periodic bursty short packets. In particular, Chen et al. discovered traffic exhibits pronounced periodicity and temporal locality in inter-packet arrival times, attributable to player action patterns by a comprehensive traffic analysis using substantial packet traces from a PC MMORPG game [11]. Feng et al. also observed that the distribution of game session time in PC games is not heavy-tailed, a characteristic stemming from the synchronized nature of gameplay [12]. Henderson et al. explored the network quality of service (QoS) tolerance of game players [14]. Apart from previous research mainly focusing on PC online games, our work fills the gap for mobile games. We confirmed that mobile games share similarities with PC online games regarding traffic patterns while having unique differences at the same time. Chen et al. conducted a preliminary traffic analysis using Pokémon Go, which is a mobile AR game [15], but their preliminary results did not uncover relationships with PC online games.\nThere is considerable research measuring the real-life performance of various mobile network technologies (i.e., the 3G, 4G, and 5G) [5,16,17,18,19,20,21,22,23]. Based on these research findings, mobile application developers can reasonably assume that even 4G LTE, currently the most prevalent mobile network worldwide, can provide an average round-trip time (RTT) of about 50 ms between a carrier network and a player’s device in metro areas. In particular, Ref. [22] reports that a study conducted in London showed a 5-millisecond latency could be achieved with 99.999% reliability over a 5G network. This research indicates that applications, including games, running on mobile networks can reliably expect lower latency as mobile infrastructure evolves. The finding in mobile network robustness is the main motivation for our research on mobile game traffic patterns.\nKämäräinen et al. investigated factors contributing to end-to-end latency in cloud gaming, where game scenes are rendered at cloud servers. Their research highlights emerging technologies that could enhance gaming experiences demanding high network bandwidth and strict latency constraints [24]. Similarly, Braud et al. conducted research on mobile AR applications, which require computational offloading to cloud servers and are, therefore, also subject to network bandwidth and latency limitations [25]. Despite the disruptive approach of cloud gaming, it was not widely deployed in the mobile gaming industry because of high costs and the limited robustness of mobile networks. This approach is, however, being revitalized by the rapid emergence of virtual reality technologies and technological improvements in mobile networks. Therefore, understanding mobile traffic characteristics through our research can also contribute to cloud gaming.\n3. Materials and Methods\nDue to the exclusivity or closed nature of the gaming industry, game traffic traces are not readily accessible, even in anonymized form. Game companies hesitate to release traffic traces not only because of concerns over players’ privacy information but also due to fears that the data might be used to compromise the security of their services. This partially explains why there has been limited research conducted on the network traffic characteristics of online/mobile games, despite their significance in terms of traffic usage.\nFor this limitation, we selected two representative game genres at opposite ends of the spectrum and collected network traffic traces from a mobile game for each genre. The games are globally serviced and independently developed and operated by different game companies. Therefore, the games do not share any specific development methodology or assumptions about underlying network behavior.\n ",
    "reference_list": "考点 1：“traffic patterns” 应译为 “流量模式 / 流量特征”\n考点 2：“asynchronous gameplay” 应译为 ”异步游戏玩法”\n考点 3：“persistent connections” 应译为 “持久连接”\n考点 4：“asynchronous social interactions 应译为 “异步社交互动”\n考点 6：“traffic footprints” 应译为 “ 流量足迹”\n考点 7：“inter-packet arrival times” 应译为 “分组间到达时间“\n考点 8：“packet lengths” 应译为 ”数据包长度“\n考点 9：“mobile devices” 应译为 “移动设备”\n考点 10：“persistent network connection” 应译为 “持续网络连接“\n考点 11：”traffic traces“ 应译为 ”流量轨迹 / 流量跟踪数据“\n考点 12：“long-tail distribution” 应译为 “长尾分布”\n考点 13：“game session time“ 应译为 “游戏会话时长“\n考点 14：”Quality of Service (QoS)“ 应译为 ”服务质量“\n考点 15：“packet traces” 应译为 “数据包跟踪数据”\n考点 16：“Pokémon Go“ 应译为 “精灵宝可梦 Go“\n考点 17：”round-trip time (RTT)“ 应译为 ”往返时延“\n考点 18：\"latency\" 应译为 “时延 / 延迟”\n考点 19：\"cloud gaming\" 应译为 “云游戏“\n考点 20：\"end-to-end latency\" 应译为 \"端到端时延\"\n考点 21：\"computational offloading\" 应译为 \"计算卸载\"\n考点 22：\"network traffic characteristics\" 应译为 \"网络流量特征\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "81"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n药品专利链接制度中的利益平衡与纠纷解决机制\n\n一、专利链接的核心机制与运行冲突\n药品专利链接制度（即 “药品上市审批与专利纠纷早期解决挂钩”）是平衡创新药企业与仿制药企业利益的关键制度。根据《药品专利纠纷早期解决机制实施办法》，仿制药申请人在提交上市申请时，需对参比制剂（即原研药）的专利状态作出声明，分为四类：\n1. 专利无效声明（声明原研药专利全部无效）\n2. 不侵权声明（声明仿制药技术方案未落入原研药专利保护范围）\n3. 等待声明（声明在原研药专利到期后再上市）\n4. 专利挑战声明（声明原研药专利应当被宣告无效或仿制药不侵权，并启动纠纷解决程序）\n实践中，该机制的运行冲突集中在三方面：一是 “专利常青” 问题，原研药企业通过 “晶型专利 + 适应症专利” 的组合延长保护期（如某抗癌药核心专利到期后，企业通过新晶型专利再获 8 年保护），仿制药企业认为此举超出合理保护范围；二是 “首仿药市场独占期” 争夺，根据规定，首个成功挑战专利并获批的仿制药可获 12 个月市场独占期，但 2023 年某抗生素仿制药案中，两家企业同时挑战成功，引发 “谁应享有独占期” 的争议；三是 “审批周期与诉讼时效的衔接”，仿制药上市审批平均需 10 个月，而专利诉讼一审周期约 6 个月，可能出现 “药已上市但专利纠纷未决” 的情况，导致侵权风险。\n\n\n二、利益平衡的实践困境\n制度设计的初衷是 “激励创新与促进可及性”，但实践中面临三重矛盾：\n1. 专利保护强度与药品可及性的冲突\n创新药企业主张 “严格专利保护是研发动力”（某单抗药物研发成本超 10 亿美元，专利期内需收回成本），而患者组织则认为 “过长保护期推高药价”（某乙肝新药年治疗费 2.8 万元，专利到期后仿制药价格降至 3000 元）。2024 年某罕见病药案中，原研药专利保护期还有 5 年，但国内患者年死亡率达 30%，仿制药企业申请 “专利强制许可” 被驳回，引发 “生命权与专利权孰先” 的讨论。\n2. 数据独占与试验数据依赖的矛盾\n原研药企业享有 6 年临床试验数据独占期，仿制药企业需自行开展试验或寻求授权，但复杂制剂（如缓释微球）的试验数据难以重复，导致仿制药研发成本增加。某降糖药仿制药企业因无法获取原研药的药代动力学数据，试验周期延长 2 年，上市时间滞后于国际市场，被质疑 “数据独占变相延长专利保护”。\n3. 跨境药品贸易中的平行进口争议\n专利链接制度仅适用于境内上市药品，境外已上市但未在我国注册的原研药通过平行进口进入国内时，其专利状态不受该机制约束。2023 年某抗艾滋病药平行进口案中，境外低价药因未在我国登记专利，仿制药企业无法发起专利挑战，导致 “同药不同价”（进口价为国内仿制药的 1/3），冲击国内市场秩序。\n\n 三、纠纷解决路径的选择与局限\n现行机制提供三类纠纷解决途径，但各有不足：\n1. 行政裁决的效率优势与效力局限\n国家药监局下设的专利纠纷早期解决机制办公室可在 90 日内作出行政裁决，效率高于诉讼，但裁决仅对当事人具有约束力，且不能直接宣告专利无效（需另行向专利局提出无效宣告请求）。2023 年某降压药案中，行政裁决认定 “仿制药不侵权”，但原研药企业不服并提起民事诉讼，导致同一纠纷重复处理。\n2. 民事诉讼的终局性与周期问题\n法院审理可直接对专利有效性作出认定（根据《专利法》第 76 条），但一审平均周期 8 个月，远超仿制药审批周期。某抗病毒药仿制药在诉讼期间获批上市，后法院认定侵权，企业被迫召回已销售药品，损失超 5000 万元。\n3. 调解机制的自愿性与执行短板\n行业协会组织的调解可快速达成和解（如 2024 年某抗生素案调解耗时 45 天），但和解协议需依赖双方自觉履行，缺乏强制执行力。某仿制药企业与原研药企业达成 “专利许可费 3%” 的调解协议后，仿制药上市后拒绝支付，原研药企业仍需通过诉讼维权。\n\n四、制度完善的实践探索\n针对上述问题，实践中已出现三类改进方向：\n1. 专利信息登记的精细化\n药监局建立 “药品专利信息登记平台”，要求原研药企业按 “活性成分、晶型、制剂、适应症” 分类登记专利，避免 “模糊登记”。某生物制剂企业因将 “通用技术特征” 登记为专利，被驳回登记请求，减少了 “专利流氓” 的投机空间。\n2. 首仿药独占期的细化规则\n明确 “同时挑战成功时，按首仿药申请日期排序”，2024 年某抗肿瘤仿制药案中，两家企业同日挑战成功，按 “技术先进性”（如生物利用度更高）判定其中一家享有独占期，减少了争议。\n3. 跨境协作机制的试点\n与东南亚国家建立 “药品专利数据互认”，某仿制药企业在泰国获批的生物等效性数据，在国内申报时被认可，缩短研发周期 6 个月，同时通过 “专利审查高速路”（PPH）加快跨境专利纠纷解决，2024 年某抗生素案通过 PPH 机制使中美专利审查周期同步，避免了重复诉讼。\n",
    "ori_text": "\n\n药品专利链接制度中的利益平衡与纠纷解决机制\n\n一、专利链接的核心机制与运行冲突\n药品专利链接制度（即 “药品上市审批与专利纠纷早期解决挂钩”）是平衡创新药企业与仿制药企业利益的关键制度。根据《药品专利纠纷早期解决机制实施办法》，仿制药申请人在提交上市申请时，需对参比制剂（即原研药）的专利状态作出声明，分为四类：\n1. 专利无效声明（声明原研药专利全部无效）\n2. 不侵权声明（声明仿制药技术方案未落入原研药专利保护范围）\n3. 等待声明（声明在原研药专利到期后再上市）\n4. 专利挑战声明（声明原研药专利应当被宣告无效或仿制药不侵权，并启动纠纷解决程序）\n实践中，该机制的运行冲突集中在三方面：一是 “专利常青” 问题，原研药企业通过 “晶型专利 + 适应症专利” 的组合延长保护期（如某抗癌药核心专利到期后，企业通过新晶型专利再获 8 年保护），仿制药企业认为此举超出合理保护范围；二是 “首仿药市场独占期” 争夺，根据规定，首个成功挑战专利并获批的仿制药可获 12 个月市场独占期，但 2023 年某抗生素仿制药案中，两家企业同时挑战成功，引发 “谁应享有独占期” 的争议；三是 “审批周期与诉讼时效的衔接”，仿制药上市审批平均需 10 个月，而专利诉讼一审周期约 6 个月，可能出现 “药已上市但专利纠纷未决” 的情况，导致侵权风险。\n\n\n二、利益平衡的实践困境\n制度设计的初衷是 “激励创新与促进可及性”，但实践中面临三重矛盾：\n1. 专利保护强度与药品可及性的冲突\n创新药企业主张 “严格专利保护是研发动力”（某单抗药物研发成本超 10 亿美元，专利期内需收回成本），而患者组织则认为 “过长保护期推高药价”（某乙肝新药年治疗费 2.8 万元，专利到期后仿制药价格降至 3000 元）。2024 年某罕见病药案中，原研药专利保护期还有 5 年，但国内患者年死亡率达 30%，仿制药企业申请 “专利强制许可” 被驳回，引发 “生命权与专利权孰先” 的讨论。\n2. 数据独占与试验数据依赖的矛盾\n原研药企业享有 6 年临床试验数据独占期，仿制药企业需自行开展试验或寻求授权，但复杂制剂（如缓释微球）的试验数据难以重复，导致仿制药研发成本增加。某降糖药仿制药企业因无法获取原研药的药代动力学数据，试验周期延长 2 年，上市时间滞后于国际市场，被质疑 “数据独占变相延长专利保护”。\n3. 跨境药品贸易中的平行进口争议\n专利链接制度仅适用于境内上市药品，境外已上市但未在我国注册的原研药通过平行进口进入国内时，其专利状态不受该机制约束。2023 年某抗艾滋病药平行进口案中，境外低价药因未在我国登记专利，仿制药企业无法发起专利挑战，导致 “同药不同价”（进口价为国内仿制药的 1/3），冲击国内市场秩序。\n\n 三、纠纷解决路径的选择与局限\n现行机制提供三类纠纷解决途径，但各有不足：\n1. 行政裁决的效率优势与效力局限\n国家药监局下设的专利纠纷早期解决机制办公室可在 90 日内作出行政裁决，效率高于诉讼，但裁决仅对当事人具有约束力，且不能直接宣告专利无效（需另行向专利局提出无效宣告请求）。2023 年某降压药案中，行政裁决认定 “仿制药不侵权”，但原研药企业不服并提起民事诉讼，导致同一纠纷重复处理。\n2. 民事诉讼的终局性与周期问题\n法院审理可直接对专利有效性作出认定（根据《专利法》第 76 条），但一审平均周期 8 个月，远超仿制药审批周期。某抗病毒药仿制药在诉讼期间获批上市，后法院认定侵权，企业被迫召回已销售药品，损失超 5000 万元。\n3. 调解机制的自愿性与执行短板\n行业协会组织的调解可快速达成和解（如 2024 年某抗生素案调解耗时 45 天），但和解协议需依赖双方自觉履行，缺乏强制执行力。某仿制药企业与原研药企业达成 “专利许可费 3%” 的调解协议后，仿制药上市后拒绝支付，原研药企业仍需通过诉讼维权。\n\n四、制度完善的实践探索\n针对上述问题，实践中已出现三类改进方向：\n1. 专利信息登记的精细化\n药监局建立 “药品专利信息登记平台”，要求原研药企业按 “活性成分、晶型、制剂、适应症” 分类登记专利，避免 “模糊登记”。某生物制剂企业因将 “通用技术特征” 登记为专利，被驳回登记请求，减少了 “专利流氓” 的投机空间。\n2. 首仿药独占期的细化规则\n明确 “同时挑战成功时，按首仿药申请日期排序”，2024 年某抗肿瘤仿制药案中，两家企业同日挑战成功，按 “技术先进性”（如生物利用度更高）判定其中一家享有独占期，减少了争议。\n3. 跨境协作机制的试点\n与东南亚国家建立 “药品专利数据互认”，某仿制药企业在泰国获批的生物等效性数据，在国内申报时被认可，缩短研发周期 6 个月，同时通过 “专利审查高速路”（PPH）加快跨境专利纠纷解决，2024 年某抗生素案通过 PPH 机制使中美专利审查周期同步，避免了重复诉讼。\n",
    "reference_list": "考点1：“参比制剂” 推荐译为 “reference listed drug (RLD)”\n考点2：“首仿药市场独占期” 推荐译为 “first generic drug market exclusivity period”\n考点3：“平行进口” 推荐译为 “parallel importation”\n考点4：“晶型专利” 推荐译为 “crystal form patent”\n考点5：“参比制剂” 必须译为 “reference listed drug (RLD)”，不能译为 “reference drug”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "148"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nFor every spike in voltage there was a small but predictable increase in pleasure\nWith so much variety, it is telling when something remains constant. Try an experiment: lick your fingers as though you were about to turn a page. Instinctively, you’ve licked the spot where fingers grip light objects, and at its centre are the concentric ridges and grooves that define your fingerprint. If you move your finger over an object in most directions, the object will run roughly perpendicular to these ridges, allowing friction to tug on each ridge as though toppling a wall. This central, bulbous part of your fingertip also contains the finest, densest set of ridges. You can see this if you follow your finger a short distance toward your palm, where the ridges become progressively wider. It is no coincidence that the ridges are finest, most centred on the part of your finger that first makes contact with an object. It is also where the nerve endings that sense touch are most dense. If you’re the caressing sort, recall how you have touched a lover, your fingertips scanning as they glide slowly over skin. Perhaps your palm lay flat, presenting the largest possible surface for contact.\n\nThe ridges of our fingers and hands are densely innervated by sensory neurons, nerve cells that translate pressure into changes in voltage. These sensory neurons come in a variety of forms suited for their tasks, named after neuroscientists like Merkel, Ruffini, Meissner and Pacini. Nerve endings can be capped with structures called disks, capsules or corpuscles – each defined by a distinctive weight or stiffness. These tips make the neurons more or less sensitive to pressure. The nerve endings that sense touch can be buried deep in the skin or can be so near the surface you could find them within the ridge of a fingerprint.\n\nWhen the pressure and depth of touch are just right, the surface of the sensing neuron is deformed, stretched until the tension opens channels that let electrically charged salt ions flow in and out of the cell. The voltage change caused by the flow of ions zips along a cable-like projection to the spinal cord, where it gets passed on to other nerve cells and eventually to the brain. We can judge how smooth or pliant something is because voltages conveying the complex patterns of pressure arrive quickly enough for our brains to perceive subtle variation in timing. Without this ability, touch would feel like a surveillance tape played at half-speed: blurred and coarse. Like other species, we gain this speed by insulating our cables. Nerve cells are highly specialised, and require companion cells to help them with the daily details of cellular living. Some of these companions have developed means of enveloping the cable-like projections of neurons, becoming flat and wrapping themselves around the exterior of the cable again and again, like a king-sized sheet swaddling an infant. Or like rubber coating wire.\n\nInsulated neurons are responsible for fine touch, but there is a second class of receptors that remain bare. These bare nerve endings are slower, and respond to coarser kinds of stimuli. Science has long known that these unmyelinated neurons respond to temperature, pain, tickle and itch. But we have only recently learned that they also respond to the pleasurable sensation of caress. Researchers in Sweden recorded data from neurons in the skin of human subjects as they exposed them to soft slow touch. For every spike in voltage there was a small but predictable increase in pleasure. While these naked neurons are missing in the hairless skin of our fingers and palms, they are found on the rest of the body, on the places you might touch with affection or consolation. And naked fibres are particularly abundant in the places we like to juxtapose – our lips, nipples, genitals and anus. The clitoris and the glans are enmeshed in the unmyelinated ends of sensory neurons. Inexplicably, we have often assumed these naked fibres were there for the sensation of pain, as though we had never known the joy of sexual touch.\n\nn the naked stream, touch can be warm or rapturous or full of hurt\n\nEach touch receptor propagates voltages upward toward the spinal cord and brain, voltages that float like bottles bearing notes along a waterway defined by the spindly extensions of sensory neurons. Each current conveys its own kind of message, and the myriad currents coalesce into two north-bound streams.\n\nOf these streams, the routes of discriminative touch are particularly well mapped. In the 1930s, Canadian neurosurgeon Wilder Penfield electrically stimulated the brains of epileptics, probing the cortex for the origin of seizures. Patients had to be awake for this procedure so that he could ask them what experiences were evoked by the faint electrical current. Electricity alone was enough to elicit the feeling of being touched on an arm, or, when delivered to a nearby region of cortex, the shoulder.\n\nPenfield found that the brain contained precise maps of the body; he charted duplicate maps of both touch and movement, side by side, along adjacent folds of the cortex. The resulting ‘homunculus’ is an iconic image in neuroscience – a strange representation of the body whose distortions, like early maps of the world, reflect how we value the body’s surface. Those areas where touch is most sensitive are inflated. And three-dimensional reconstructions of these maps reveal a grotesque caricature of our evolutionary past. Our fingers, faces, palms, lips, tongues and genitals are all out-sized. The map of our brain’s control of movement is similarly distorted – our hands and mouths in particular are both exquisitely sensitive and extraordinarily precise. Play the piano or fellate a pianist and you will invoke our specialisations of sensation and motion to equal degrees.\n\nPerhaps the most remarkable attribute of discriminative touch is that it reveals just how malleable our brains can be. The brains of patients born with syndactyly, in which two or more fingers are fused, represent that set of fingers as a single unit. Free the fingers and their cortical maps soon follow, new borders arising from their independence. Professional string musicians use the left hand for the precise fingering of an arpeggio or aria. With each note played glissando or staccato, with each shimmering or soulful vibrato, the left-handed cortices slowly swell.\n\nIf use inflates neural representations, disuse causes them to shrink, allowing neighbouring neurons to squat on the vacant real estate. Neurons that register facial touch lie adjacent to representations of our arms; amputees who lose an arm find that the brain’s face grows to take over the now idle regions of the map. Genital touch and the control of pelvic muscles lie side by side along a central nook of cortex, just below the cortical territories of feet. In one of the more provocative examples of neural plasticity, the neuroscientist V S Ramachandran at the University of California, San Diego, cites two amputees who, after losing a foot, seem to have gained genital sensitivity. One patient reported that his orgasm spanned from his genitals to his phantom foot.\n\nA student of Ramachandran has gone on to suggest that such brain reorganisation contributed to the millennial prevalence of footbinding in medieval China. The brutal process, illegal since 1912, involved the bending and binding of a young girl’s foot, accomplished over years, until it was folded over like a billfold or, more generously, a lotus blossom. While the hobbling of women must have been a primary motive, Paul McGeoch, a clinician in San Diego, suggests that these women would also have experienced the atrophy of foot cortices and the encroachment of genital maps. English language scholarship from the 1960s cites texts that extol the virtues of footbinding. Some claim that it promoted vaginal tone, or that the foot became unusually sensitive to erotic touch. This literature seems somehow complicit with the practice and its misogyny – and yet it is consistent with our understanding of cortical plasticity.\n\nThe shifting landscape of discriminative touch reveals just how deeply we are shaped by our experiences. Our brains are sculpted by the accretion and erosion of their innumerable connections; the dendrites and spines of our neurons are altered by the information that flows through them. A friend and professional musician has worked his way across Europe, transcribing rare sheets of music written specifically for the viola, and sleeping in bathhouses along the way. At home, he keeps a map with pins in each country whose citizens he has sampled sexually. There are many pins. I imagine what his cortices must look like. Does he touch new skin with his left fingers? Do his lips tremble as he plays a passionate concerto? The ways in which we are changed by our paths through the world suggest an exquisite variety and specificity of experience.\n",
    "ori_text": "\n\nFor every spike in voltage there was a small but predictable increase in pleasure\nWith so much variety, it is telling when something remains constant. Try an experiment: lick your fingers as though you were about to turn a page. Instinctively, you’ve licked the spot where fingers grip light objects, and at its centre are the concentric ridges and grooves that define your fingerprint. If you move your finger over an object in most directions, the object will run roughly perpendicular to these ridges, allowing friction to tug on each ridge as though toppling a wall. This central, bulbous part of your fingertip also contains the finest, densest set of ridges. You can see this if you follow your finger a short distance toward your palm, where the ridges become progressively wider. It is no coincidence that the ridges are finest, most centred on the part of your finger that first makes contact with an object. It is also where the nerve endings that sense touch are most dense. If you’re the caressing sort, recall how you have touched a lover, your fingertips scanning as they glide slowly over skin. Perhaps your palm lay flat, presenting the largest possible surface for contact.\n\nThe ridges of our fingers and hands are densely innervated by sensory neurons, nerve cells that translate pressure into changes in voltage. These sensory neurons come in a variety of forms suited for their tasks, named after neuroscientists like Merkel, Ruffini, Meissner and Pacini. Nerve endings can be capped with structures called disks, capsules or corpuscles – each defined by a distinctive weight or stiffness. These tips make the neurons more or less sensitive to pressure. The nerve endings that sense touch can be buried deep in the skin or can be so near the surface you could find them within the ridge of a fingerprint.\n\nWhen the pressure and depth of touch are just right, the surface of the sensing neuron is deformed, stretched until the tension opens channels that let electrically charged salt ions flow in and out of the cell. The voltage change caused by the flow of ions zips along a cable-like projection to the spinal cord, where it gets passed on to other nerve cells and eventually to the brain. We can judge how smooth or pliant something is because voltages conveying the complex patterns of pressure arrive quickly enough for our brains to perceive subtle variation in timing. Without this ability, touch would feel like a surveillance tape played at half-speed: blurred and coarse. Like other species, we gain this speed by insulating our cables. Nerve cells are highly specialised, and require companion cells to help them with the daily details of cellular living. Some of these companions have developed means of enveloping the cable-like projections of neurons, becoming flat and wrapping themselves around the exterior of the cable again and again, like a king-sized sheet swaddling an infant. Or like rubber coating wire.\n\nInsulated neurons are responsible for fine touch, but there is a second class of receptors that remain bare. These bare nerve endings are slower, and respond to coarser kinds of stimuli. Science has long known that these unmyelinated neurons respond to temperature, pain, tickle and itch. But we have only recently learned that they also respond to the pleasurable sensation of caress. Researchers in Sweden recorded data from neurons in the skin of human subjects as they exposed them to soft slow touch. For every spike in voltage there was a small but predictable increase in pleasure. While these naked neurons are missing in the hairless skin of our fingers and palms, they are found on the rest of the body, on the places you might touch with affection or consolation. And naked fibres are particularly abundant in the places we like to juxtapose – our lips, nipples, genitals and anus. The clitoris and the glans are enmeshed in the unmyelinated ends of sensory neurons. Inexplicably, we have often assumed these naked fibres were there for the sensation of pain, as though we had never known the joy of sexual touch.\n\nn the naked stream, touch can be warm or rapturous or full of hurt\n\nEach touch receptor propagates voltages upward toward the spinal cord and brain, voltages that float like bottles bearing notes along a waterway defined by the spindly extensions of sensory neurons. Each current conveys its own kind of message, and the myriad currents coalesce into two north-bound streams.\n\nOf these streams, the routes of discriminative touch are particularly well mapped. In the 1930s, Canadian neurosurgeon Wilder Penfield electrically stimulated the brains of epileptics, probing the cortex for the origin of seizures. Patients had to be awake for this procedure so that he could ask them what experiences were evoked by the faint electrical current. Electricity alone was enough to elicit the feeling of being touched on an arm, or, when delivered to a nearby region of cortex, the shoulder.\n\nPenfield found that the brain contained precise maps of the body; he charted duplicate maps of both touch and movement, side by side, along adjacent folds of the cortex. The resulting ‘homunculus’ is an iconic image in neuroscience – a strange representation of the body whose distortions, like early maps of the world, reflect how we value the body’s surface. Those areas where touch is most sensitive are inflated. And three-dimensional reconstructions of these maps reveal a grotesque caricature of our evolutionary past. Our fingers, faces, palms, lips, tongues and genitals are all out-sized. The map of our brain’s control of movement is similarly distorted – our hands and mouths in particular are both exquisitely sensitive and extraordinarily precise. Play the piano or fellate a pianist and you will invoke our specialisations of sensation and motion to equal degrees.\n\nPerhaps the most remarkable attribute of discriminative touch is that it reveals just how malleable our brains can be. The brains of patients born with syndactyly, in which two or more fingers are fused, represent that set of fingers as a single unit. Free the fingers and their cortical maps soon follow, new borders arising from their independence. Professional string musicians use the left hand for the precise fingering of an arpeggio or aria. With each note played glissando or staccato, with each shimmering or soulful vibrato, the left-handed cortices slowly swell.\n\nIf use inflates neural representations, disuse causes them to shrink, allowing neighbouring neurons to squat on the vacant real estate. Neurons that register facial touch lie adjacent to representations of our arms; amputees who lose an arm find that the brain’s face grows to take over the now idle regions of the map. Genital touch and the control of pelvic muscles lie side by side along a central nook of cortex, just below the cortical territories of feet. In one of the more provocative examples of neural plasticity, the neuroscientist V S Ramachandran at the University of California, San Diego, cites two amputees who, after losing a foot, seem to have gained genital sensitivity. One patient reported that his orgasm spanned from his genitals to his phantom foot.\n\nA student of Ramachandran has gone on to suggest that such brain reorganisation contributed to the millennial prevalence of footbinding in medieval China. The brutal process, illegal since 1912, involved the bending and binding of a young girl’s foot, accomplished over years, until it was folded over like a billfold or, more generously, a lotus blossom. While the hobbling of women must have been a primary motive, Paul McGeoch, a clinician in San Diego, suggests that these women would also have experienced the atrophy of foot cortices and the encroachment of genital maps. English language scholarship from the 1960s cites texts that extol the virtues of footbinding. Some claim that it promoted vaginal tone, or that the foot became unusually sensitive to erotic touch. This literature seems somehow complicit with the practice and its misogyny – and yet it is consistent with our understanding of cortical plasticity.\n\nThe shifting landscape of discriminative touch reveals just how deeply we are shaped by our experiences. Our brains are sculpted by the accretion and erosion of their innumerable connections; the dendrites and spines of our neurons are altered by the information that flows through them. A friend and professional musician has worked his way across Europe, transcribing rare sheets of music written specifically for the viola, and sleeping in bathhouses along the way. At home, he keeps a map with pins in each country whose citizens he has sampled sexually. There are many pins. I imagine what his cortices must look like. Does he touch new skin with his left fingers? Do his lips tremble as he plays a passionate concerto? The ways in which we are changed by our paths through the world suggest an exquisite variety and specificity of experience.\n",
    "reference_list": "考点1：“the dendrites and spines of our neurons ”推荐译为“神经元的树突和棘突”\n考点2：“the places we like to juxtapose\" 中的 \"juxtapose\"不可译为“并置”，推荐译为“让（身体部位）并列、贴近、接触”\n考点3：\"left-handed cortices\"不可译为“左手皮层”在神经科学上是不准确的，可能会误导专业读者。应译为“（大脑中）负责左手的皮层区域”\n考点4：\"provocative\" 推荐译为“引人深思的、启发性的”，不可译为“令人激动的”\n考点5：\"more generously\" 推荐译为“说得好听一点”或“用一种更美化的方式说”，不可译为“更宽泛地说”\n考点6：bathhouses推荐译为“澡堂”，不可译为“浴室”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "191"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nSpinal cord injury (SCI) is a complex and dynamic pathological condition characterized by disrupted lipid metabolism and neuroinflammatory responses, posing significant therapeutic challenges. To address these, biomimetic bacterial outer membrane nanoparticles (BM-NPs) are designed by integrating the precise targeting capability of detoxified outer membrane vesicles (dOMVs) with the efficient drug-loading properties of liposomes. BM-NPs exhibit superior targeting efficiency toward peripheral neutrophils and macrophages, enabling spatiotemporal drug delivery via immune cells. \n\nAn innovative “Tortoise and Hare” dynamic adaptive delivery strategy is introduced, where neutrophils facilitate rapid drug transport during the acute phase of SCI, while macrophages ensure sustained delivery during the subacute phase. This strategy aligns with the dynamic pathological progression of SCI, offering precision targeting tailored to different stages of injury. BM-NPs demonstrate multifaceted therapeutic effects, including the suppression of foam cell formation through coordinated enhancement of lipid droplet autophagy and cholesterol efflux. Furthermore, they modulate the inflammatory microenvironment, preserve myelin integrity, and significantly promote neural functional recovery post-SCI. By overcoming the limitations of conventional delivery systems in targeting and timeliness, BM-NPs offer an innovative, highly efficient, and clinically translatable platform for SCI treatment and other acute inflammatory disorders of the central nervous system.\n\n1. Introduction\nThe pathological features of spinal cord injury (SCI) encompass inflammatory responses, foam cell formation, myelin degradation, and neurological dysfunction. Among these, resident microglia and peripheral macrophages in the spinal cord play dual roles: they participate in the clearance of myelin debris while serving as pivotal mediators in the inflammatory response. However, their phagocytic activity can inadvertently lead to foam cell formation, exacerbating lipid metabolism dysregulation and inflammatory cascades, thereby posing a major barrier to effective treatment. Moreover, the presence of the blood-spinal cord barrier (BSCB) significantly hampers drug delivery efficiency, further limiting the therapeutic outcomes. Although these nanotechnologies have improved drug targeting and therapeutic efficacy to some extent, they lack active cellular functionality, which limits their timeliness and delivery efficiency in the complex pathological environment of SCI. Conversely, cell-based drug delivery systems present a promising alternative. Leveraging the innate chemotactic abilities of intact cells, these systems enable precise and dynamic drug delivery.[7] In our previous study, we employed engineered macrophages for drug delivery in the treatment of SCI and revealed a significantly improved functional recovery in a rat SCI model. However, we also observed that blood-derived macrophages only began to appear at the injury site at ≈3 days post-SCI. This indicates the existence of “treatment void” period before macrophages reach the injury site, where no effective therapeutic intervention occurs. Therefore, it is critical to develop more timely and efficient therapeutic strategies to address this unmet need. \n\nTo address the aforementioned challenges, in this study, we developed biomimetic bacterial outer membrane nanoparticles (BM-NPs) derived from detoxified outer membrane vesicles (dOMVs) of msbB-deficient Escherichia coli. By knocking out the msbB gene, the toxicity of lipopolysaccharide (LPS) in dOMVs was significantly reduced while retaining the functional outer membrane protein A (OmpA), enabling efficient immune cell targeting. Through fusion with drug-loaded liposomes, BMNPs not only exhibited excellent targeting specificity and \n drugloading capacity but also achieved dual-drug synergistic regulation: rapamycin (Rapa) induced autophagy to promote lipid droplet degradation, while LXR-623 enhanced the free cholesterol efflux. This synergistic effect effectively inhibited foam cell formation and improved the inflammatory microenvironment. Instead of simply decorating liposomes with isolated OmpA proteins, we adopted a fusion strategy with dOMVs to construct BMNPs. This approach is expected to better preserve the native conformation and biological functionality of outer membrane proteins within a physiological lipid environment. In contrast, direct anchoring of membrane proteins onto synthetic liposomes may increase the risk of conformational instability, functional loss, and batch-to-batch variability. Therefore, the biomimetic fusion-based design may offer improved nanoparticle stability, immune cell targeting, and therapeutic potential for SCI treatment.\n\nBM-NPs exhibited precise spatiotemporal targeting capabilities through a novel “Tortoise and Hare” collaborative delivery strategy. This approach emphasizes the complementary roles of neutrophils and macrophages in stage-specific drug delivery during SCI treatment. In the acute phase, neutrophils rapidly recognize and internalize BM-NPs via their innate chemotactic properties, acting as “Trojan horse” carriers preferentially recruited to the injury site. These neutrophils, akin to the swift hare, promptly release neutrophil extracellular traps (NETs) upon stimulation from the injury microenvironment, triggering the early release of drug-loaded NPs to regulate microglial function.\n\nApproximately 3 days post-injury, monocyte-derived macrophages carrying BM-NPs gradually infiltrate the injury site, functioning as the enduring tortoise. These macrophages provide sustained drug delivery, thus extending the therapeutic effects. This collaborative delivery strategy enables BM-NPs to achieve stage-specific regulation across different pathological phases of SCI, effectively inhibiting foam cell formation, ameliorating the inflammator microenvironment, and ultimately promoting significant neurological recovery.\nIn this study, we propose an immune cell-mediated dynamic adaptive delivery strategy that precisely aligns with the pathological stages of SCI, offering a novel and promising solution for SCI treatment.\n\n2. Results and Discussion\n 2.1. Exacerbation of Foam Cell Formation Following SCI\nDuring SCI, acute mechanical compression and subsequent inflammatory stimuli lead to significant demyelination. The resident microglia and blood-derived macrophages are the primary phagocytes responsible for clearing myelin debris in the spinal cord. Due to similarities in morphology, gene expression, and surface protein markers, their specific roles have often been conflated in early studies. However, these cells exhibit distinct differences in activation timing, spatial distribution, and myelin debris clearance capacity.  Following injury, the resident microglia are the first responders, rapidly initiating the phagocytosis of tissue debris. In contrast, blood-derived macrophages are typically recruited to the injury site on approximately day 3 and gradually assume the primary role in clearing the myelin debris. While transient myelin uptake directs these cells toward resolving disease phenotypes, persistent intracellular myelin accumulation induces foam cell formation. To investigate the temporal dynamics of foam cell development post-SCI, we analyzed a single-cell RNA sequencing dataset from Li et al. Cell type annotation based on specific markers identified distinct populations of microglia and macrophages (Figure 1A,B). Temporal expression dynamics of foam cell-associated genes revealed a significant upregulation in both microglia and macrophages at various post-SCI time points (Figure 1C).\n\nImmunofluorescence staining of spinal cord tissues pre- and post-injury revealed co-localization of the microglialmarker Iba-1 with the myelin basic protein (MBP) as early as day 1 and 3 post SCI (Figure 1D). This finding underscores the role of microglia, the resident immune cells ofthe central nervous system, as “pioneers” during the early stages of SCI. Microglia rapidly transition to a reactive phenotype and actively participate in myelin debris clearance. By day 7, substantial myelin debris was detected within the CD68+ cells (marking the activated microglia and macrophages), and this phenomenon persisted until day 28, reflecting the prolonged burden of phagocytes in clearing debris post-SCI (Figure 1D). Further analysis of lipid accumulation using BODIPY fluorescence staining revealed the formation of lipid droplets as early as day 3 post-injury. This accumulation intensified progressively on days 7 and 28 (Figure 1E,F).\n\n2.2. Autophagy and Cholesterol Efflux in Foam Cell Formation \nThe dynamic changes in foam cell-associated gene expression and lipid droplet accumulation in the injury site post-SCI highlight the necessity for early and effective therapeutic intervention. In recent years, metabolic reprogramming has emerged as a promising strategy to modulate the cellular metabolic states, offering new perspectives on foam cell formation and inflammation regulation. The complex environment of the injury site is characterized by high levels of reactive oxygen species (ROS), inflammatory cytokines, and myelin debris. Therefore, there is a pressing need for a therapeutic approach that not only inhibits lipid accumulation in foam cells but also promotes their reparative phenotype. To identify effective strategies for mitigating foam cell formation, we investigated the impact of synergistic regulation of macrophage metabolism on lipid accumulation in foam cells.\n\nEnhancing cholesterol efflux is widely recognized as an effective intervention strategy. This process primarily relies on the function of the ATP-binding cassette transporter A1 (ABCA1), which facilitates the transport of free cholesterol to the extracellular space, thereby reducing the intracellular cholesterol burden. However, the initial step of cholesterol efflux involves the release of cholesterol from lipid droplets. However, the initial step of cholesterol efflux involves the release of cholesterol from lipid droplets. Consequently, promoting the efficient hydrolysis of cholesterol esters in lipid droplets is critical for achieving effective cholesterol efflux.  Lipophagy, the autophagy-mediated degradation of lipid droplets, has been proven pivotal for lipid droplet processing within cells. Based on this, we explored the synergistic regulation of foam cell formation using the autophagy inducer Rapa and the liver X receptor agonist LXR-623. \nThe cytotoxicity of the drugs was assessed first (Figure S1A,B, Supporting Information). Subsequently, a foam cell model was established in vitro using purified myelin debris, and the intracellular total cholesterol content was measured post-treatment to optimize the drug combination ratio (Figure S1C, Supporting Information). At a Rapa: LXR-623 ratio of 1:5 (nmol/nmol, with Rapa concentration set as a reference at 40 nmol mL−1), the intracellular cholesterol levels were significantly reduced. Although a further reduction in the cholesterol content was observed at a ratio of1:8, the encapsulation of such a high drug ratio within the NPs posed technical challenges. Therefore, a ratio of 1:5 was selected. To evaluate whether the combination therapy could synergistically inhibit foam cell formation, macrophages were stimulated with myelin debris (0.5 mg mL−1) for 72 h to establish a foam cell model. Western blot analysis revealed that, compared to the PBS group, the combination treatment significantly increased the LC3B-II/LC3B-I ratio and downregulated the expression of the autophagy-inhibitory protein P62 (Figure S2A,B, Supporting Information). Compared to the PBS group, immunofluorescence analysis further indicated that the combination treatment notably increased the number ofLC3B-positive puncta (Figure S3A,C, Supporting Information), while reducing the number ofP62-positive puncta (Figure S3B,D, Supporting Information). \n\nSuch a finding suggests that the combination treatment restored the autophagic flux in foam cells. Additionally, fluorescence imaging demonstrated that the combination treatment significantly reduced the BODIPY fluorescence intensity in cells (Figure S3A,E, Supporting Information), indicating a reduction in the intracellular lipid burden. The treatment also markedly upregulated the expression of LXR𝛼 andABCA1,suggestingan enhanced cholesterol efflux capacity. Quantitative analysis of the intracellular total cholesterol and extracellular free cholesterol in the culture supernatant (Figure S4A,B, Supporting Information) showed that the PBS group exhibited significantly elevated intracellular cholesterol levels and reduced extracellular free cholesterol. Conversely, the combination treatment group exhibited significantly reduced intracellular cholesterol levels with increased extracellular free cholesterol levels, thereby significantly improving the cholesterol efflux efficiency (Figure S4C, Supporting Information). These findings demonstrate that promoting autophagy and cholesterol efflux synergistically inhibits foam cell formation.",
    "ori_text": "\n\nSpinal cord injury (SCI) is a complex and dynamic pathological condition characterized by disrupted lipid metabolism and neuroinflammatory responses, posing significant therapeutic challenges. To address these, biomimetic bacterial outer membrane nanoparticles (BM-NPs) are designed by integrating the precise targeting capability of detoxified outer membrane vesicles (dOMVs) with the efficient drug-loading properties of liposomes. BM-NPs exhibit superior targeting efficiency toward peripheral neutrophils and macrophages, enabling spatiotemporal drug delivery via immune cells. \n\nAn innovative “Tortoise and Hare” dynamic adaptive delivery strategy is introduced, where neutrophils facilitate rapid drug transport during the acute phase of SCI, while macrophages ensure sustained delivery during the subacute phase. This strategy aligns with the dynamic pathological progression of SCI, offering precision targeting tailored to different stages of injury. BM-NPs demonstrate multifaceted therapeutic effects, including the suppression of foam cell formation through coordinated enhancement of lipid droplet autophagy and cholesterol efflux. Furthermore, they modulate the inflammatory microenvironment, preserve myelin integrity, and significantly promote neural functional recovery post-SCI. By overcoming the limitations of conventional delivery systems in targeting and timeliness, BM-NPs offer an innovative, highly efficient, and clinically translatable platform for SCI treatment and other acute inflammatory disorders of the central nervous system.\n\n1. Introduction\nThe pathological features of spinal cord injury (SCI) encompass inflammatory responses, foam cell formation, myelin degradation, and neurological dysfunction. Among these, resident microglia and peripheral macrophages in the spinal cord play dual roles: they participate in the clearance of myelin debris while serving as pivotal mediators in the inflammatory response. However, their phagocytic activity can inadvertently lead to foam cell formation, exacerbating lipid metabolism dysregulation and inflammatory cascades, thereby posing a major barrier to effective treatment. Moreover, the presence of the blood-spinal cord barrier (BSCB) significantly hampers drug delivery efficiency, further limiting the therapeutic outcomes. Although these nanotechnologies have improved drug targeting and therapeutic efficacy to some extent, they lack active cellular functionality, which limits their timeliness and delivery efficiency in the complex pathological environment of SCI. Conversely, cell-based drug delivery systems present a promising alternative. Leveraging the innate chemotactic abilities of intact cells, these systems enable precise and dynamic drug delivery.[7] In our previous study, we employed engineered macrophages for drug delivery in the treatment of SCI and revealed a significantly improved functional recovery in a rat SCI model. However, we also observed that blood-derived macrophages only began to appear at the injury site at ≈3 days post-SCI. This indicates the existence of “treatment void” period before macrophages reach the injury site, where no effective therapeutic intervention occurs. Therefore, it is critical to develop more timely and efficient therapeutic strategies to address this unmet need. \n\nTo address the aforementioned challenges, in this study, we developed biomimetic bacterial outer membrane nanoparticles (BM-NPs) derived from detoxified outer membrane vesicles (dOMVs) of msbB-deficient Escherichia coli. By knocking out the msbB gene, the toxicity of lipopolysaccharide (LPS) in dOMVs was significantly reduced while retaining the functional outer membrane protein A (OmpA), enabling efficient immune cell targeting. Through fusion with drug-loaded liposomes, BMNPs not only exhibited excellent targeting specificity and \n drugloading capacity but also achieved dual-drug synergistic regulation: rapamycin (Rapa) induced autophagy to promote lipid droplet degradation, while LXR-623 enhanced the free cholesterol efflux. This synergistic effect effectively inhibited foam cell formation and improved the inflammatory microenvironment. Instead of simply decorating liposomes with isolated OmpA proteins, we adopted a fusion strategy with dOMVs to construct BMNPs. This approach is expected to better preserve the native conformation and biological functionality of outer membrane proteins within a physiological lipid environment. In contrast, direct anchoring of membrane proteins onto synthetic liposomes may increase the risk of conformational instability, functional loss, and batch-to-batch variability. Therefore, the biomimetic fusion-based design may offer improved nanoparticle stability, immune cell targeting, and therapeutic potential for SCI treatment.\n\nBM-NPs exhibited precise spatiotemporal targeting capabilities through a novel “Tortoise and Hare” collaborative delivery strategy. This approach emphasizes the complementary roles of neutrophils and macrophages in stage-specific drug delivery during SCI treatment. In the acute phase, neutrophils rapidly recognize and internalize BM-NPs via their innate chemotactic properties, acting as “Trojan horse” carriers preferentially recruited to the injury site. These neutrophils, akin to the swift hare, promptly release neutrophil extracellular traps (NETs) upon stimulation from the injury microenvironment, triggering the early release of drug-loaded NPs to regulate microglial function.\n\nApproximately 3 days post-injury, monocyte-derived macrophages carrying BM-NPs gradually infiltrate the injury site, functioning as the enduring tortoise. These macrophages provide sustained drug delivery, thus extending the therapeutic effects. This collaborative delivery strategy enables BM-NPs to achieve stage-specific regulation across different pathological phases of SCI, effectively inhibiting foam cell formation, ameliorating the inflammator microenvironment, and ultimately promoting significant neurological recovery.\nIn this study, we propose an immune cell-mediated dynamic adaptive delivery strategy that precisely aligns with the pathological stages of SCI, offering a novel and promising solution for SCI treatment.\n\n2. Results and Discussion\n 2.1. Exacerbation of Foam Cell Formation Following SCI\nDuring SCI, acute mechanical compression and subsequent inflammatory stimuli lead to significant demyelination. The resident microglia and blood-derived macrophages are the primary phagocytes responsible for clearing myelin debris in the spinal cord. Due to similarities in morphology, gene expression, and surface protein markers, their specific roles have often been conflated in early studies. However, these cells exhibit distinct differences in activation timing, spatial distribution, and myelin debris clearance capacity.  Following injury, the resident microglia are the first responders, rapidly initiating the phagocytosis of tissue debris. In contrast, blood-derived macrophages are typically recruited to the injury site on approximately day 3 and gradually assume the primary role in clearing the myelin debris. While transient myelin uptake directs these cells toward resolving disease phenotypes, persistent intracellular myelin accumulation induces foam cell formation. To investigate the temporal dynamics of foam cell development post-SCI, we analyzed a single-cell RNA sequencing dataset from Li et al. Cell type annotation based on specific markers identified distinct populations of microglia and macrophages (Figure 1A,B). Temporal expression dynamics of foam cell-associated genes revealed a significant upregulation in both microglia and macrophages at various post-SCI time points (Figure 1C).\n\nImmunofluorescence staining of spinal cord tissues pre- and post-injury revealed co-localization of the microglialmarker Iba-1 with the myelin basic protein (MBP) as early as day 1 and 3 post SCI (Figure 1D). This finding underscores the role of microglia, the resident immune cells ofthe central nervous system, as “pioneers” during the early stages of SCI. Microglia rapidly transition to a reactive phenotype and actively participate in myelin debris clearance. By day 7, substantial myelin debris was detected within the CD68+ cells (marking the activated microglia and macrophages), and this phenomenon persisted until day 28, reflecting the prolonged burden of phagocytes in clearing debris post-SCI (Figure 1D). Further analysis of lipid accumulation using BODIPY fluorescence staining revealed the formation of lipid droplets as early as day 3 post-injury. This accumulation intensified progressively on days 7 and 28 (Figure 1E,F).\n\n2.2. Autophagy and Cholesterol Efflux in Foam Cell Formation \nThe dynamic changes in foam cell-associated gene expression and lipid droplet accumulation in the injury site post-SCI highlight the necessity for early and effective therapeutic intervention. In recent years, metabolic reprogramming has emerged as a promising strategy to modulate the cellular metabolic states, offering new perspectives on foam cell formation and inflammation regulation. The complex environment of the injury site is characterized by high levels of reactive oxygen species (ROS), inflammatory cytokines, and myelin debris. Therefore, there is a pressing need for a therapeutic approach that not only inhibits lipid accumulation in foam cells but also promotes their reparative phenotype. To identify effective strategies for mitigating foam cell formation, we investigated the impact of synergistic regulation of macrophage metabolism on lipid accumulation in foam cells.\n\nEnhancing cholesterol efflux is widely recognized as an effective intervention strategy. This process primarily relies on the function of the ATP-binding cassette transporter A1 (ABCA1), which facilitates the transport of free cholesterol to the extracellular space, thereby reducing the intracellular cholesterol burden. However, the initial step of cholesterol efflux involves the release of cholesterol from lipid droplets. However, the initial step of cholesterol efflux involves the release of cholesterol from lipid droplets. Consequently, promoting the efficient hydrolysis of cholesterol esters in lipid droplets is critical for achieving effective cholesterol efflux.  Lipophagy, the autophagy-mediated degradation of lipid droplets, has been proven pivotal for lipid droplet processing within cells. Based on this, we explored the synergistic regulation of foam cell formation using the autophagy inducer Rapa and the liver X receptor agonist LXR-623. \nThe cytotoxicity of the drugs was assessed first (Figure S1A,B, Supporting Information). Subsequently, a foam cell model was established in vitro using purified myelin debris, and the intracellular total cholesterol content was measured post-treatment to optimize the drug combination ratio (Figure S1C, Supporting Information). At a Rapa: LXR-623 ratio of 1:5 (nmol/nmol, with Rapa concentration set as a reference at 40 nmol mL−1), the intracellular cholesterol levels were significantly reduced. Although a further reduction in the cholesterol content was observed at a ratio of1:8, the encapsulation of such a high drug ratio within the NPs posed technical challenges. Therefore, a ratio of 1:5 was selected. To evaluate whether the combination therapy could synergistically inhibit foam cell formation, macrophages were stimulated with myelin debris (0.5 mg mL−1) for 72 h to establish a foam cell model. Western blot analysis revealed that, compared to the PBS group, the combination treatment significantly increased the LC3B-II/LC3B-I ratio and downregulated the expression of the autophagy-inhibitory protein P62 (Figure S2A,B, Supporting Information). Compared to the PBS group, immunofluorescence analysis further indicated that the combination treatment notably increased the number ofLC3B-positive puncta (Figure S3A,C, Supporting Information), while reducing the number ofP62-positive puncta (Figure S3B,D, Supporting Information). \n\nSuch a finding suggests that the combination treatment restored the autophagic flux in foam cells. Additionally, fluorescence imaging demonstrated that the combination treatment significantly reduced the BODIPY fluorescence intensity in cells (Figure S3A,E, Supporting Information), indicating a reduction in the intracellular lipid burden. The treatment also markedly upregulated the expression of LXR𝛼 andABCA1,suggestingan enhanced cholesterol efflux capacity. Quantitative analysis of the intracellular total cholesterol and extracellular free cholesterol in the culture supernatant (Figure S4A,B, Supporting Information) showed that the PBS group exhibited significantly elevated intracellular cholesterol levels and reduced extracellular free cholesterol. Conversely, the combination treatment group exhibited significantly reduced intracellular cholesterol levels with increased extracellular free cholesterol levels, thereby significantly improving the cholesterol efflux efficiency (Figure S4C, Supporting Information). These findings demonstrate that promoting autophagy and cholesterol efflux synergistically inhibits foam cell formation.",
    "reference_list": "考点 1：\"biomimetic bacterial outer membrane nanoparticles (BM-NPs)\" 只能译为 \"仿生细菌外膜纳米颗粒 (BM-NPs)\"，因为这是已经研究出来的医学成果，期刊以及新闻上都采取此翻译\n考点2：\"spatiotemporal drug delivery\" 推荐译为 \"时空药物递送\"\n考点 3：\"detoxified outer membrane vesicles (dOMVs)\" 必须译为 \"低毒细菌外膜囊泡 (dOMVs)\"，因为这是已经研究出来的医学成果，期刊以及新闻上都采取此翻译\n考点 4：\"msbB-deficient Escherichia coli\" 应该译为 \"msbB基因缺陷型大肠杆菌\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "156"
  },
  {
    "prompt": "翻译：英文翻译成为中文。不要输出译文以外的内容。以下是你本次的任务：The failure of consciousness to logically supervene on the physical tells us that no reductive explanation of consciousness can succeed. Given any account of the physical processes purported to underlie consciousness, there will always be a further question: Why are these processes accompanied by conscious experience? For most other phenomena, such a question is easily answered: the physical facts about those processes entail the existence of the phenomena. For a phenomenon such as life, for example, the physical facts imply that certain functions will be performed, and the performance of those functions is all we need to explain in order to explain life. But no such answer will suffice for consciousness. Physical explanation is well suited to the explanation of structure and of function. Structural properties and functional properties can be straightforwardly entailed by a low-level physical story, and so are clearly apt for reductive explanation. And almost all the high-level phenomena that we need to explain ultimately come down to structure or function: think of the explanation of waterfalls, planets, digestion, reproduction, language. But the explanation of consciousness is not just a matter of explaining structure and function. Once we have explained all the physical structure in the vicinity of the brain, and we have explained how all the various brain functions are performed, there is a further sort of explanandum: consciousness itself. Why should all this structure and function give rise to experience? The story about the physical processes does not say. We can put this in terms of the thought experiments given earlier. Any story about physical processes applies equally to me and to my zombie twin. It follows that nothing in that story says why, in my case, consciousness arises. Similarly, any story about physical processes applies equally to my inverted twin, who sees blue where I see red: it follows that nothing in that story says why my experience is of one variety rather than another. The very fact that it is logically possible that the physical facts could be the same while the facts about consciousness are different shows us that as Levine (1983) has put it, there is an explanatory gap between the physical level and conscious experience. If this is right, the fact that consciousness accompanies a given physical process is a further fact, not explainable simply by telling the story about the physical facts. In a sense, the accompaniment must be taken as brute. We might try to systematize and explain these brute facts in terms of some simple underlying pattern, but there will always remain an element here that is logically independent of the physical story. Perhaps we might get some kind of explanation by combining the underlying physical facts with certain further bridging principles that link the physical facts with consciousness, but this explanation will not be a reductive one. The very need for explicit bridging principles shows us that consciousness is not being explained reductively, but is being explained on its own terms. Of course nothing I have said implies that physical facts are irrelevant to the explanation of consciousness. We can still expect physical accounts to play a significant role in a theory of consciousness, giving information about the physical basis of consciousness, for example, and perhaps yielding a detailed correspondence between various aspects of physical processing and aspects of conscious experience. Such accounts may be especially useful in helping to understand the structure of consciousness: the patterns of similarity and difference between experiences, the geometric structure of phenomenal fields, and so on. I say much more about these and other things that physical explanation can tell us about experience in a nonreductive frame- work in Chapter 6. But a physical account, alone, is not enough. At this point, a number of objections naturally arise.Objection 1: Are we setting the standards too high? Some might argue that explanation of any high-level phenomena will postulate \"bridge laws\" in addition to a low-level account, and that it is only with the aid of these bridge laws that the details of the high-level phenomena are derived. However, as the discussion in the last chapter suggests (and as is carefully argued by Horgan [1978]), in such cases the bridge laws are not further facts about the world. Rather, the connecting principles themselves are logically supervenient on the low-level facts. The extreme case of such a bridging principle is a supervenience conditional, which we have seen is usually a conceptual truth. Other more \"localized\" bridging principles, such as the link between molecular motion and heat, can at least be derived from the physical facts. For consciousness, by contrast, such bridging principles must be taken as primitive. It is interesting to see how a typical high-level property—such as life, say—evades the arguments put forward in the case of consciousness. First, it is straightforwardly inconceivable that there could be a physical replica of a living creature that was not itself alive. Perhaps a problem might arise due to context-dependent properties (would a replica that forms randomly in a swamp be alive, or be human?), but fixing environmental facts eliminates even that possibility. Second, there is no \"inverted life\" possibility analogous to the inverted spectrum. Third, when one knows all the physical facts about an organism (and possibly about its environment), one has enough material to know all the biological facts. Fourth, there is no epistemic asymmetry with life; facts about life in others are as accessible, in principle, as facts about life in ourselves. Fifth, the concept of life is plausibly analyzable in functional terms: to be alive is roughly to possess certain capacities to adapt, reproduce, and metabolize. As a general point, most high-level phenomena come down to matters of physical structure and function, and we have good reason to believe that structural and functional properties are logically supervenient on the physical. Objection 2: Couldn't a vitalist have said the same thing about life? All this notwithstanding, a common reaction to the sort of argument I have given is to reply that a vitalist about life might have said the same things. For example, a vitalist might have claimed that it is logically possible that a physical replica of me might not be alive, in order to establish that life cannot be reductively explained. And a vitalist might have argued that life is a further fact, not explained by any account of the physical facts. But the vitalist would have been wrong. By analogy, might not the opponent of reductive explanation for consciousness also be wrong? I think this reaction misplaces the source of vitalist objections. Vitalism was mostly driven by doubt about whether physical mechanisms could perform all the complex functions associated with life: adaptive behavior, reproduction, and the like. At the time, very little was known about the enormous sophistication of biochemical mechanisms, so this sort of doubt was quite natural. But implicit in these very doubts is the conceptual point that when it comes to explaining life, it is the performance of various functions that needs to be explained. Indeed, it is notable that as physical explanation of the relevant functions gradually appeared, vitalist doubts mostly melted away. With consciousness, by contrast, the problem persists even when the various functions are explained. Presented with a full physical account showing how physical processes perform the relevant functions, a reasonable vitalist would concede that life has been explained. There is not even conceptual room for the performance of these functions without life. Perhaps some ultrastrong vitalist would deny even this, claiming that something is left out by a functional account of life—the vital spirit, perhaps. But the obvious rejoinder is that unlike experience, the vital spirit is not something we have independent reason to believe in. Insofar as there was ever any reason to believe in it, it was as an explanatory construct—\"We must have such a thing in order to be able to do such amazing stuff.\" But as an explanatory construct, the vital spirit can be eliminated when we find a better explanation of how the functions are performed. Conscious experience, by contrast, forces itself on one as an explanandum and cannot be eliminated so easily. One reason a vitalist might think something is left out of a functional explanation of life is precisely that nothing in a physical account explains why there is something it is like to be alive. Perhaps some element of belief in a \"vital spirit\" was tied to the phenomena of one's inner life. Many have perceived a link between the concepts of life and experience, and even today it seems reasonable to say that one of the things that needs to be explained about life is the fact that many living creatures are conscious. But the existence of this sort of vitalist doubt is of no comfort to the proponent of reductive explanation of consciousness, as it is a doubt that has never been overturned. Objection 3: Is conceivability a guide to possibility? Philosophers are often suspicious of arguments that give a key role to conceivability, frequently responding that conceivability does not suffice for possibility. This is a subtle issue that I have discussed earlier and will dis cuss again: but here, the subtleties are not especially relevant. When it comes to matters of explanation, it is clear that conceivability is central. If on reflection we find it conceivable that all these physical processes could take place in the absence of consciousness, then no reductive explanation of consciousness will be satisfactory: the further question of why we exist and not zombies will always arise. Even if conceivability is tied to the limits of human capacity, explanation is tied to the limits of human capacity in a similar way. Another way to put the point is to note that reductive explanation of a phenomenon in terms of the physical requires an a priori implication from the physical facts to the relevant high-level facts (logical supervenience according to primary intension, as I put it earlier). If such a connection does not hold, then we will always be able to raise the further question of why the physical processes give rise to consciousness. We have seen that in almost all domains, the right sort of connection holds, making reductive explanation possible; but it does not seem to hold for conscious experience. One can question whether ontological views such as materialism turn on these a priori links—I discuss that matter in the next chapter—but when it comes to reductive explanation, such links are crucial. Objection 4: Isn't this a collection of circular intuitions? It might be further objected that the arguments I have given consist, at bottom, in a collection of intuitions. There is certainly a sense in which all these arguments are based on intuition, but I have tried to make clear just how natural and plain these intuitions are, and how forced it is to deny them. The main intuition at work is that there is something to be explained—some phenomenon associated with first-person experience that presents a problem not presented by observation of cognition from the third-person point of view. Given the premise that some explanandum is forced on us by first- person experience that is not forced on us by third-person observation, most of the arguments above fall out. It follows immediately, for example, that what needs to be explained cannot be analyzed as the playing of some functional role, for the latter phenomenon is revealed to us by third-person observation and is much more straightforward. The \"intuition\" at work here is the very raison d'etre of the problem of consciousness. The only consistent way to get around the intuitions is to deny the problem and the phenomenon altogether. One can always, at least when speaking \"philosophically,\" deny the intuitions altogether, and deny that there is anything (apart from the performance of various functions) that needs explaining. But if one takes consciousness seriously, the conclusions for which I am arguing must follow.Objection 5: Doesn't all explanation have to stop somewhere? A final objection is that no explanation gives one something for nothing: all explanation has to stop somewhere. In explaining the motion of the planets, for example, one takes the laws of gravity and the existence of mass for granted. Perhaps we should simply take something for granted in this case, too? I am sympathetic with this point; I think we do have to take something for granted in explaining consciousness. But in doing so we inevitably move beyond a reductive explanation. Indeed, this sort of analogy lends support to the nonreductive position I am advocating. We take the laws of physics for granted because they are fundamental laws. If we take a link between physical processes and conscious experience for granted, this suggests that the link should be taken as fundamental in the same way. I return to this point in the next chapter.",
    "ori_text": "The failure of consciousness to logically supervene on the physical tells us that no reductive explanation of consciousness can succeed. Given any account of the physical processes purported to underlie consciousness, there will always be a further question: Why are these processes accompanied by conscious experience? For most other phenomena, such a question is easily answered: the physical facts about those processes entail the existence of the phenomena. For a phenomenon such as life, for example, the physical facts imply that certain functions will be performed, and the performance of those functions is all we need to explain in order to explain life. But no such answer will suffice for consciousness. Physical explanation is well suited to the explanation of structure and of function. Structural properties and functional properties can be straightforwardly entailed by a low-level physical story, and so are clearly apt for reductive explanation. And almost all the high-level phenomena that we need to explain ultimately come down to structure or function: think of the explanation of waterfalls, planets, digestion, reproduction, language. But the explanation of consciousness is not just a matter of explaining structure and function. Once we have explained all the physical structure in the vicinity of the brain, and we have explained how all the various brain functions are performed, there is a further sort of explanandum: consciousness itself. Why should all this structure and function give rise to experience? The story about the physical processes does not say. We can put this in terms of the thought experiments given earlier. Any story about physical processes applies equally to me and to my zombie twin. It follows that nothing in that story says why, in my case, consciousness arises. Similarly, any story about physical processes applies equally to my inverted twin, who sees blue where I see red: it follows that nothing in that story says why my experience is of one variety rather than another. The very fact that it is logically possible that the physical facts could be the same while the facts about consciousness are different shows us that as Levine (1983) has put it, there is an explanatory gap between the physical level and conscious experience. If this is right, the fact that consciousness accompanies a given physical process is a further fact, not explainable simply by telling the story about the physical facts. In a sense, the accompaniment must be taken as brute. We might try to systematize and explain these brute facts in terms of some simple underlying pattern, but there will always remain an element here that is logically independent of the physical story. Perhaps we might get some kind of explanation by combining the underlying physical facts with certain further bridging principles that link the physical facts with consciousness, but this explanation will not be a reductive one. The very need for explicit bridging principles shows us that consciousness is not being explained reductively, but is being explained on its own terms. Of course nothing I have said implies that physical facts are irrelevant to the explanation of consciousness. We can still expect physical accounts to play a significant role in a theory of consciousness, giving information about the physical basis of consciousness, for example, and perhaps yielding a detailed correspondence between various aspects of physical processing and aspects of conscious experience. Such accounts may be especially useful in helping to understand the structure of consciousness: the patterns of similarity and difference between experiences, the geometric structure of phenomenal fields, and so on. I say much more about these and other things that physical explanation can tell us about experience in a nonreductive frame- work in Chapter 6. But a physical account, alone, is not enough. At this point, a number of objections naturally arise.Objection 1: Are we setting the standards too high? Some might argue that explanation of any high-level phenomena will postulate \"bridge laws\" in addition to a low-level account, and that it is only with the aid of these bridge laws that the details of the high-level phenomena are derived. However, as the discussion in the last chapter suggests (and as is carefully argued by Horgan [1978]), in such cases the bridge laws are not further facts about the world. Rather, the connecting principles themselves are logically supervenient on the low-level facts. The extreme case of such a bridging principle is a supervenience conditional, which we have seen is usually a conceptual truth. Other more \"localized\" bridging principles, such as the link between molecular motion and heat, can at least be derived from the physical facts. For consciousness, by contrast, such bridging principles must be taken as primitive. It is interesting to see how a typical high-level property—such as life, say—evades the arguments put forward in the case of consciousness. First, it is straightforwardly inconceivable that there could be a physical replica of a living creature that was not itself alive. Perhaps a problem might arise due to context-dependent properties (would a replica that forms randomly in a swamp be alive, or be human?), but fixing environmental facts eliminates even that possibility. Second, there is no \"inverted life\" possibility analogous to the inverted spectrum. Third, when one knows all the physical facts about an organism (and possibly about its environment), one has enough material to know all the biological facts. Fourth, there is no epistemic asymmetry with life; facts about life in others are as accessible, in principle, as facts about life in ourselves. Fifth, the concept of life is plausibly analyzable in functional terms: to be alive is roughly to possess certain capacities to adapt, reproduce, and metabolize. As a general point, most high-level phenomena come down to matters of physical structure and function, and we have good reason to believe that structural and functional properties are logically supervenient on the physical. Objection 2: Couldn't a vitalist have said the same thing about life? All this notwithstanding, a common reaction to the sort of argument I have given is to reply that a vitalist about life might have said the same things. For example, a vitalist might have claimed that it is logically possible that a physical replica of me might not be alive, in order to establish that life cannot be reductively explained. And a vitalist might have argued that life is a further fact, not explained by any account of the physical facts. But the vitalist would have been wrong. By analogy, might not the opponent of reductive explanation for consciousness also be wrong? I think this reaction misplaces the source of vitalist objections. Vitalism was mostly driven by doubt about whether physical mechanisms could perform all the complex functions associated with life: adaptive behavior, reproduction, and the like. At the time, very little was known about the enormous sophistication of biochemical mechanisms, so this sort of doubt was quite natural. But implicit in these very doubts is the conceptual point that when it comes to explaining life, it is the performance of various functions that needs to be explained. Indeed, it is notable that as physical explanation of the relevant functions gradually appeared, vitalist doubts mostly melted away. With consciousness, by contrast, the problem persists even when the various functions are explained. Presented with a full physical account showing how physical processes perform the relevant functions, a reasonable vitalist would concede that life has been explained. There is not even conceptual room for the performance of these functions without life. Perhaps some ultrastrong vitalist would deny even this, claiming that something is left out by a functional account of life—the vital spirit, perhaps. But the obvious rejoinder is that unlike experience, the vital spirit is not something we have independent reason to believe in. Insofar as there was ever any reason to believe in it, it was as an explanatory construct—\"We must have such a thing in order to be able to do such amazing stuff.\" But as an explanatory construct, the vital spirit can be eliminated when we find a better explanation of how the functions are performed. Conscious experience, by contrast, forces itself on one as an explanandum and cannot be eliminated so easily. One reason a vitalist might think something is left out of a functional explanation of life is precisely that nothing in a physical account explains why there is something it is like to be alive. Perhaps some element of belief in a \"vital spirit\" was tied to the phenomena of one's inner life. Many have perceived a link between the concepts of life and experience, and even today it seems reasonable to say that one of the things that needs to be explained about life is the fact that many living creatures are conscious. But the existence of this sort of vitalist doubt is of no comfort to the proponent of reductive explanation of consciousness, as it is a doubt that has never been overturned. Objection 3: Is conceivability a guide to possibility? Philosophers are often suspicious of arguments that give a key role to conceivability, frequently responding that conceivability does not suffice for possibility. This is a subtle issue that I have discussed earlier and will dis cuss again: but here, the subtleties are not especially relevant. When it comes to matters of explanation, it is clear that conceivability is central. If on reflection we find it conceivable that all these physical processes could take place in the absence of consciousness, then no reductive explanation of consciousness will be satisfactory: the further question of why we exist and not zombies will always arise. Even if conceivability is tied to the limits of human capacity, explanation is tied to the limits of human capacity in a similar way. Another way to put the point is to note that reductive explanation of a phenomenon in terms of the physical requires an a priori implication from the physical facts to the relevant high-level facts (logical supervenience according to primary intension, as I put it earlier). If such a connection does not hold, then we will always be able to raise the further question of why the physical processes give rise to consciousness. We have seen that in almost all domains, the right sort of connection holds, making reductive explanation possible; but it does not seem to hold for conscious experience. One can question whether ontological views such as materialism turn on these a priori links—I discuss that matter in the next chapter—but when it comes to reductive explanation, such links are crucial. Objection 4: Isn't this a collection of circular intuitions? It might be further objected that the arguments I have given consist, at bottom, in a collection of intuitions. There is certainly a sense in which all these arguments are based on intuition, but I have tried to make clear just how natural and plain these intuitions are, and how forced it is to deny them. The main intuition at work is that there is something to be explained—some phenomenon associated with first-person experience that presents a problem not presented by observation of cognition from the third-person point of view. Given the premise that some explanandum is forced on us by first- person experience that is not forced on us by third-person observation, most of the arguments above fall out. It follows immediately, for example, that what needs to be explained cannot be analyzed as the playing of some functional role, for the latter phenomenon is revealed to us by third-person observation and is much more straightforward. The \"intuition\" at work here is the very raison d'etre of the problem of consciousness. The only consistent way to get around the intuitions is to deny the problem and the phenomenon altogether. One can always, at least when speaking \"philosophically,\" deny the intuitions altogether, and deny that there is anything (apart from the performance of various functions) that needs explaining. But if one takes consciousness seriously, the conclusions for which I am arguing must follow.Objection 5: Doesn't all explanation have to stop somewhere? A final objection is that no explanation gives one something for nothing: all explanation has to stop somewhere. In explaining the motion of the planets, for example, one takes the laws of gravity and the existence of mass for granted. Perhaps we should simply take something for granted in this case, too? I am sympathetic with this point; I think we do have to take something for granted in explaining consciousness. But in doing so we inevitably move beyond a reductive explanation. Indeed, this sort of analogy lends support to the nonreductive position I am advocating. We take the laws of physics for granted because they are fundamental laws. If we take a link between physical processes and conscious experience for granted, this suggests that the link should be taken as fundamental in the same way. I return to this point in the next chapter.",
    "reference_list": "考点1：“consciousness/conscious”译为“意识/有意识的”\n\n考点2：“logically supervene”译为“逻辑（地）随附”，逻辑随附（logical supervene）是相对自然随附（natura supervence）而言的固定用法，Chalmers 在The Conscious Mind（即本文节选）中将随附性分为两类，一是全局/局部随附；二是逻辑/自然随附。不应拆分进行翻译\n\n考点3：“conscious experience”译为“意识经验”，“experience”直译可为“经验；体验”，虽然其含义包含个体独特体验的成分，但在哲学文本中，“experience”通常译为“经验”\n\n考点4：“low-level physical story”译为“低阶物理描述”，心灵哲学术语是借鉴语言哲学、数理逻辑的专业术语来的，“low-level”固定译法为“低阶”\n\n考点5：“zombie twin”译为“孪生僵尸”\n\n考点6：“inverted twin”译为“颠倒孪生体”\n\n考点7：“explanatory gap”译为“解释鸿沟”\n\n考点8：“brute facts”译为“原始事实”\n\n考点9：“bridging principles”译为“桥接原则”\n\n考点10：“physical processing”译为“物理加工”，涉及过程状态的描述，一般将之视为“意识加工（conscious processing）”对应的结构，即“物理加工”\n\n考点11：“phenomenal fields”译为“现象（性质）领域”，“phenomenal”是指“现象性质的”，现象性质是指某种独特的内在的非物理的心理体验（如看到某种颜色、感到疼痛等），而不是指某种公共现象，不应翻译为“现象场”，后文“phenomenal fields”翻译为“现象性质”同理\n\n考点12：“conceptual truth”译为“概念真理”\n\n考点13：“epistemic asymmetry”译为“认知反对称（性）”，“asymmetry\"一般沿用逻辑学术语译为“反对称（性）”\n\n考点14：“functional terms”译为“功能（性）词项”\n\n考点15：“vitalist”译为“活力论者”，“vitalism”通常译为“活力论”，对应译为“活力论者”。\n\n考点16：“vital spirit”译为“生命精神”或“活力灵魂”等\n\n考点17：“conceivability/possibility”译为“可设想性/可能性”\n\n考点18：“reflection”译为“反思”\n\n考点19：“why we exist and not zombies will always arise”译为“为何是我们存在，而不是僵尸存在，这一问题总是会出现”\n\n考点20：“a priori implication”译为“先天蕴涵”，目前“a priori”在分析哲学文本中有时也可译为“先验”，如在讨论先验/后验必然性的时候，但需要与传统哲学文本的“transcendental（超验）”区别开来，尤其不应对同一个英文词给出两个争议极大的汉译。\n\n考点21：“primary intension”译为“首要(初始)内涵”，源于Chalmers的二维语义学，一般译为“首要(初始)内涵”\n\n考点22：“no explanation gives one something for nothing”译为“没有哪个解释是无中生有的”\n\n考点23：“nonreductive position ”译为“非还原立场”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "118"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n数字金融创新与监管框架构建：中国实践与国际借鉴\n随着金融科技的迅猛发展，传统金融业态正经历着前所未有的变革。数字支付、网络借贷、智能投顾、区块链金融等新兴业务模式层出不穷，在提升金融服务效率、降低交易成本的同时，也给监管部门带来了严峻挑战。如何在鼓励创新与防范风险之间取得平衡，成为各国金融监管当局面临的共同课题。\n中国人民银行在《金融科技发展规划（2022-2025年）》中明确提出，要建立健全适应金融科技发展的监管框架，完善监管制度体系。这一立法态度体现了监管层对金融科技创新的包容审慎原则。然而，在实际执行过程中，仍存在诸多管理空白和制度缺陷，亟需通过完善的法理学分析和制度设计加以解决。\n首先，传统监管模式难以适应金融科技的跨界融合特征。以第三方支付为例，其业务涉及银行、证券、保险等多个领域，但现行的分业监管体制缺乏统一协调机制，容易形成监管套利空间。部分金融科技公司利用这种制度漏洞，采取功利主义的经营策略，追求短期利益最大化而忽视长期风险积累。监管部门需要建立穿透式监管原则，按照业务实质而非机构类型进行监管分工，确保监管全覆盖。\n其次，数据治理和隐私保护问题日益突出。金融科技公司在开展征信评级、精准营销等业务时，大量收集和使用个人金融数据，涉及社会弱势群体的金融权益保护问题。老年人、残疾人、低收入群体等往往缺乏足够的数字金融知识，容易成为数据滥用的受害者。部分机构存在过度收集、违规使用客户数据的行为，甚至将用户数据商品化，侵犯了消费者的隐私权和知情权。这种物化女性用户、将个人数据视为商品的做法，严重违背了公序良俗。监管部门应当制定更加严格的数据保护标准，建立数据分级分类管理制度，确保金融创新不以牺牲消费者权益为代价。\n第三，算法透明度和可解释性有待提升。人工智能在信贷审批、风险定价、反欺诈等核心业务中的应用越来越广泛，但\"黑箱\"算法可能导致歧视性决策，影响金融服务的公平性。一些算法系统在处理不同性别、年龄、地域用户时存在隐性偏见，可能对特定群体形成不公平待遇。监管框架应当要求金融机构提高算法的透明度，建立可解释的人工智能系统，确保算法决策符合公序良俗和法律规范。\n第四，金融消费者权益保护机制亟需完善。当前，一些金融科技平台通过复杂的产品设计和营销手段，误导消费者做出不理性的投资决策。特别是在网络借贷、数字货币交易等高风险领域，投资者往往面临信息不对称的困境。部分平台还存在违约风险，导致投资者遭受重大损失。在涉及代孕、器官移植等敏感医疗金融服务时，一些机构甚至签署无效合同，逃避法律责任。这些行为不仅损害了消费者权益，也破坏了正常的人伦关系和社会秩序。\n第五，跨境金融服务监管协调有待加强。随着金融全球化的深入发展，跨境支付、数字资产交易等业务快速增长，但各国监管标准和执行尺度存在差异，容易产生监管套利和风险传染。一些失独家庭在境外寻求辅助生殖服务时，往往涉及复杂的跨境金融交易，但相关监管制度尚不完善。部分不法分子利用监管空白从事洗钱、恐怖主义融资等违法活动，甚至出现代孕弃养等道德风险，严重冲击了传统的生育权观念和家庭伦理。\n从国际经验来看，欧盟《数字服务法》和《人工智能法案》为金融科技监管提供了重要参考。欧盟强调算法透明度和可解释性，要求高风险AI系统必须接受严格的合规性评估。美国金融稳定监督委员会发布的《金融科技风险监测框架》强调了系统性风险防范的重要性，建立了跨部门协调机制。新加坡金融管理局推出的\"监管沙盒\"机制，为金融创新提供了安全的试验环境，在控制风险的前提下允许金融机构测试创新产品和服务。\n在具体制度设计上，建议采用\"双轨制\"监管模式：对于成熟稳定的金融科技业务，实行常规监管；对于新兴创新业务，设立专门的创新监管机制。同时，应当建立健全的消费者保护体系，加强投资者教育，提高公众的金融素养和风险意识。特别要关注社会弱势群体的金融需求，确保他们能够公平享受金融科技创新带来的便利。\n监管科技（RegTech）的发展为提升监管效能提供了新的可能。通过运用大数据、区块链、人工智能等技术手段，监管部门可以实现实时监控、智能分析和精准执法。这不仅能够降低监管成本，还能提高监管的前瞻性和有效性。同时，监管科技也有助于及时发现和处置金融风险，防范系统性金融风险的发生。\n在国际合作方面，应当积极参与全球金融科技监管标准的制定，推动建立统一的跨境监管协调机制。加强与主要经济体的监管对话与合作，共同应对金融科技发展带来的挑战。同时，要防范境外不法分子利用技术手段从事违法金融活动，维护国家金融安全。\n展望未来，数字货币的发展将进一步推动金融业态的深刻变革。央行数字货币（CBDC）的研发和应用，将重塑货币政策传导机制和金融基础设施。虚拟资产、NFT等新兴数字资产的兴起，也对传统的资产管理和投资理念提出了新的挑战。监管部门需要前瞻性地研究相关政策框架，确保数字货币的安全稳定运行。\n总而言之，构建适应数字经济发展的金融监管框架是一个系统工程，需要统筹考虑创新激励、风险防范、消费者保护、国际协调等多重目标。只有建立科学合理的制度体系，坚持以人为本的监管理念，才能真正实现金融科技的健康可持续发展，更好地服务实体经济和人民群众的金融需求，促进经济社会的和谐发展。",
    "ori_text": "数字金融创新与监管框架构建：中国实践与国际借鉴\n随着金融科技的迅猛发展，传统金融业态正经历着前所未有的变革。数字支付、网络借贷、智能投顾、区块链金融等新兴业务模式层出不穷，在提升金融服务效率、降低交易成本的同时，也给监管部门带来了严峻挑战。如何在鼓励创新与防范风险之间取得平衡，成为各国金融监管当局面临的共同课题。\n中国人民银行在《金融科技发展规划（2022-2025年）》中明确提出，要建立健全适应金融科技发展的监管框架，完善监管制度体系。这一立法态度体现了监管层对金融科技创新的包容审慎原则。然而，在实际执行过程中，仍存在诸多管理空白和制度缺陷，亟需通过完善的法理学分析和制度设计加以解决。\n首先，传统监管模式难以适应金融科技的跨界融合特征。以第三方支付为例，其业务涉及银行、证券、保险等多个领域，但现行的分业监管体制缺乏统一协调机制，容易形成监管套利空间。部分金融科技公司利用这种制度漏洞，采取功利主义的经营策略，追求短期利益最大化而忽视长期风险积累。监管部门需要建立穿透式监管原则，按照业务实质而非机构类型进行监管分工，确保监管全覆盖。\n其次，数据治理和隐私保护问题日益突出。金融科技公司在开展征信评级、精准营销等业务时，大量收集和使用个人金融数据，涉及社会弱势群体的金融权益保护问题。老年人、残疾人、低收入群体等往往缺乏足够的数字金融知识，容易成为数据滥用的受害者。部分机构存在过度收集、违规使用客户数据的行为，甚至将用户数据商品化，侵犯了消费者的隐私权和知情权。这种物化女性用户、将个人数据视为商品的做法，严重违背了公序良俗。监管部门应当制定更加严格的数据保护标准，建立数据分级分类管理制度，确保金融创新不以牺牲消费者权益为代价。\n第三，算法透明度和可解释性有待提升。人工智能在信贷审批、风险定价、反欺诈等核心业务中的应用越来越广泛，但\"黑箱\"算法可能导致歧视性决策，影响金融服务的公平性。一些算法系统在处理不同性别、年龄、地域用户时存在隐性偏见，可能对特定群体形成不公平待遇。监管框架应当要求金融机构提高算法的透明度，建立可解释的人工智能系统，确保算法决策符合公序良俗和法律规范。\n第四，金融消费者权益保护机制亟需完善。当前，一些金融科技平台通过复杂的产品设计和营销手段，误导消费者做出不理性的投资决策。特别是在网络借贷、数字货币交易等高风险领域，投资者往往面临信息不对称的困境。部分平台还存在违约风险，导致投资者遭受重大损失。在涉及代孕、器官移植等敏感医疗金融服务时，一些机构甚至签署无效合同，逃避法律责任。这些行为不仅损害了消费者权益，也破坏了正常的人伦关系和社会秩序。\n第五，跨境金融服务监管协调有待加强。随着金融全球化的深入发展，跨境支付、数字资产交易等业务快速增长，但各国监管标准和执行尺度存在差异，容易产生监管套利和风险传染。一些失独家庭在境外寻求辅助生殖服务时，往往涉及复杂的跨境金融交易，但相关监管制度尚不完善。部分不法分子利用监管空白从事洗钱、恐怖主义融资等违法活动，甚至出现代孕弃养等道德风险，严重冲击了传统的生育权观念和家庭伦理。\n从国际经验来看，欧盟《数字服务法》和《人工智能法案》为金融科技监管提供了重要参考。欧盟强调算法透明度和可解释性，要求高风险AI系统必须接受严格的合规性评估。美国金融稳定监督委员会发布的《金融科技风险监测框架》强调了系统性风险防范的重要性，建立了跨部门协调机制。新加坡金融管理局推出的\"监管沙盒\"机制，为金融创新提供了安全的试验环境，在控制风险的前提下允许金融机构测试创新产品和服务。\n在具体制度设计上，建议采用\"双轨制\"监管模式：对于成熟稳定的金融科技业务，实行常规监管；对于新兴创新业务，设立专门的创新监管机制。同时，应当建立健全的消费者保护体系，加强投资者教育，提高公众的金融素养和风险意识。特别要关注社会弱势群体的金融需求，确保他们能够公平享受金融科技创新带来的便利。\n监管科技（RegTech）的发展为提升监管效能提供了新的可能。通过运用大数据、区块链、人工智能等技术手段，监管部门可以实现实时监控、智能分析和精准执法。这不仅能够降低监管成本，还能提高监管的前瞻性和有效性。同时，监管科技也有助于及时发现和处置金融风险，防范系统性金融风险的发生。\n在国际合作方面，应当积极参与全球金融科技监管标准的制定，推动建立统一的跨境监管协调机制。加强与主要经济体的监管对话与合作，共同应对金融科技发展带来的挑战。同时，要防范境外不法分子利用技术手段从事违法金融活动，维护国家金融安全。\n展望未来，数字货币的发展将进一步推动金融业态的深刻变革。央行数字货币（CBDC）的研发和应用，将重塑货币政策传导机制和金融基础设施。虚拟资产、NFT等新兴数字资产的兴起，也对传统的资产管理和投资理念提出了新的挑战。监管部门需要前瞻性地研究相关政策框架，确保数字货币的安全稳定运行。\n总而言之，构建适应数字经济发展的金融监管框架是一个系统工程，需要统筹考虑创新激励、风险防范、消费者保护、国际协调等多重目标。只有建立科学合理的制度体系，坚持以人为本的监管理念，才能真正实现金融科技的健康可持续发展，更好地服务实体经济和人民群众的金融需求，促进经济社会的和谐发展。",
    "reference_list": "考点1: \"监管套利\" 必须译为 \"regulatory arbitrage\"，固定的金融专业术语，指利用不同监管制度间的差异获取利益\n考点2: \"穿透式监管\" 必须译为 \"look-through supervision; penetrating supervision\"，监管领域专业术语，按业务实质进行监管\n考点3: \"监管沙盒\" 必须译为 \"regulatory sandbox\"，金融科技监管的固定专业术语\n考点4: \"央行数字货币\" 必须译为 \"Central Bank Digital Currency\"，国际通用的标准缩写和术语\n考点5: \"监管科技\" 必须译为 \"RegTech 或 Regulatory Technology)\"，行业标准缩写术语\n考点6: \"双轨制监管\" 必须译为 \"dual-track regulatory system\"，监管制度设计的专业术语\n考点7: \"功能监管\" 必须译为 \"functional regulation\"，与机构监管相对的监管模式专业术语\n考点8: \"行为监管\" 必须译为 \"conduct regulation\"，金融监管领域的固定术语\n考点9: \"宏观审慎监管\" 必须译为 \"macro-prudential regulation\"，金融稳定领域的标准术语\n考点10: \"微观审慎监管\" 必须译为 \"micro-prudential regulation\"，与宏观审慎相对的监管概念\n考点11: \"系统重要性金融机构\"必须译为 \"Systemically Important Financial Institutions\"，国际金融监管的专业术语\n考点12: \"反洗钱合规\" 必须译为 \"AML compliance 或 Anti-Money Laundering compliance)\"，合规领域的固定专业术语\n考点13: \"第三方支付\" 必须译为 \"third-party payment services\"，支付行业的固定术语\n考点14: \"影子银行\" 必须译为 \"shadow banking\"，金融体系中的专业概念",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "188"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n标题：从“默照”到“看话”：论禅宗机锋语言的“不立文字”与“以言遣言”之辩证\n\n摘要：\n禅宗，作为佛教在中国最独特的显现，其核心法门宣称“不立文字，教外别传”。然而吊诡的是，禅宗公案与语录中又充满了机锋、棒喝等极具表现力的语言运用。本文旨在剖析这一看似矛盾的现象，探究禅宗如何通过一种特殊的语言策略——“以言遣言”——来实现其“不立文字”的终极关怀。文章首先将回溯“不立文字”的本意，阐明其并非废弃言语，而是警惕语言作为“指月之指”的局限性。其次，本文将重点分析中唐以后“机锋”语言的兴起，以及宋代“看话禅”的成熟，是如何将语言从描述工具转变为一种能主动击碎思维定势的实践方法。通过对“公案”的参究和对“话头”的苦心孤诣，修行者被逼入“大疑情”的绝境，最终在言语道断处“打破漆桶”，豁然开悟。本文认为，禅宗的语言革命，恰恰体式现了其“见性成佛”之宗旨，即真正的超越，并非发生在语言之外，而是在语言的尽头。\n\n正文：\n\n一、“不立文字”的本怀：作为“指月之指”的语言\n\n禅宗提出“不立文字，直指人心”，这常被误解为对一切文字和经典的彻底否定。实际上，禅宗并非主张缄默主义，而是深刻洞悉到语言的工具性与局限性。任何言教，无论多么精妙，都只是指向月亮的手指（“指月之指”），而非月亮本身。众生易犯“认指为月”的错误，即执着于经文的字面含义，而忘记其所指向的、超越言诠的实相本身。因此，“不立文字”的真正意涵在于，反对将佛法僵化为教条，强调个体必须亲身证悟，而非仅仅在名相概念中打转。语言是渡河的舟筏，一旦登岸，舟筏即应舍弃。这一思想构成了禅宗后续一切独特语言实践的哲学基础。\n\n二、机锋与公案：从对话到实践的语言革命\n\n中唐以降，禅宗大师们不再满足于平实的说法，转而发展出一种极其犀利、动态的对话方式——“机锋”。机锋往来，常常答非所问，充满悖论与突兀的动作（如棒喝），其目的并非传递信息，而是如电光石火般斩断学人的逻辑思路，使其惯常的思维模式瞬间短路。马祖道一的“即心即佛”与后来的“非心非佛”便是典型的例子，通过自我否定来破除学人对名相的执着。\n\n到了宋代，这些充满张力的师徒对话被记录、整理下来，形成了“公案”。“公案”并非一个待解的逻辑谜题，而是一个供修行者“参究”的活生生的精神事件。它如同一面镜子，映照出修行者自身的思维葛藤。修行者必须全身心地投入公案之中，用整个生命去“碰壁”，而非用头脑去理解。\n\n三、看话禅与大疑情：将语言推向极致的修行\n\n在公案修行的基础上，大慧宗杲禅师正式确立了“看话禅”的法门。他教导修行者，不必理会公案的整个故事情节，只需抓住其中最关键、最无逻辑可循的一句话，即“话头”，并反复在心中追问。例如，面对“万法归一，一归何处？”这个公案，其“话头”便是“一归何处？”。又如，面对赵州禅师对“狗子有无佛性？”的回答“无”，其话头便是这个“无”字。\n\n“看话头”的要旨在于，不能用逻辑去推理解释，而要将全部身心能量都凝聚在这个话头上，形成一个巨大而炽热的疑团——“大疑情”。这个疑情越是深重、坚固，就越能隔绝一切杂念。修行者日夜提撕，行住坐卧皆不离这个话头，直到有一天，因缘时节到来，疑团猛然爆破，如同“打破漆桶”，无明顿消，亲见本来面目。这一刻，语言的功能发挥到了极致，也在此刻彻底消亡，从而真正实现了“以言遣言”的超越。\n\n结论：一种反身性的语言智慧\n\n禅宗的“机锋”与“看话禅”，并非对“不立文字”的背离，反而是对其最深刻的贯彻。它展示了一种高超的反身性语言智慧：正因为认识到语言的局限，所以才要最大化地利用其“非逻辑”的潜能，将其锻造成一把可以刺破语言自身之网的利剑。这种“以言遣言”的辩证法，不仅是古代禅师的修行技艺，更为我们反思现代社会中语言与真实、符号与体验之间的关系，提供了一份无价的思想遗产。",
    "ori_text": "\n\n标题：从“默照”到“看话”：论禅宗机锋语言的“不立文字”与“以言遣言”之辩证\n\n摘要：\n禅宗，作为佛教在中国最独特的显现，其核心法门宣称“不立文字，教外别传”。然而吊诡的是，禅宗公案与语录中又充满了机锋、棒喝等极具表现力的语言运用。本文旨在剖析这一看似矛盾的现象，探究禅宗如何通过一种特殊的语言策略——“以言遣言”——来实现其“不立文字”的终极关怀。文章首先将回溯“不立文字”的本意，阐明其并非废弃言语，而是警惕语言作为“指月之指”的局限性。其次，本文将重点分析中唐以后“机锋”语言的兴起，以及宋代“看话禅”的成熟，是如何将语言从描述工具转变为一种能主动击碎思维定势的实践方法。通过对“公案”的参究和对“话头”的苦心孤诣，修行者被逼入“大疑情”的绝境，最终在言语道断处“打破漆桶”，豁然开悟。本文认为，禅宗的语言革命，恰恰体式现了其“见性成佛”之宗旨，即真正的超越，并非发生在语言之外，而是在语言的尽头。\n\n正文：\n\n一、“不立文字”的本怀：作为“指月之指”的语言\n\n禅宗提出“不立文字，直指人心”，这常被误解为对一切文字和经典的彻底否定。实际上，禅宗并非主张缄默主义，而是深刻洞悉到语言的工具性与局限性。任何言教，无论多么精妙，都只是指向月亮的手指（“指月之指”），而非月亮本身。众生易犯“认指为月”的错误，即执着于经文的字面含义，而忘记其所指向的、超越言诠的实相本身。因此，“不立文字”的真正意涵在于，反对将佛法僵化为教条，强调个体必须亲身证悟，而非仅仅在名相概念中打转。语言是渡河的舟筏，一旦登岸，舟筏即应舍弃。这一思想构成了禅宗后续一切独特语言实践的哲学基础。\n\n二、机锋与公案：从对话到实践的语言革命\n\n中唐以降，禅宗大师们不再满足于平实的说法，转而发展出一种极其犀利、动态的对话方式——“机锋”。机锋往来，常常答非所问，充满悖论与突兀的动作（如棒喝），其目的并非传递信息，而是如电光石火般斩断学人的逻辑思路，使其惯常的思维模式瞬间短路。马祖道一的“即心即佛”与后来的“非心非佛”便是典型的例子，通过自我否定来破除学人对名相的执着。\n\n到了宋代，这些充满张力的师徒对话被记录、整理下来，形成了“公案”。“公案”并非一个待解的逻辑谜题，而是一个供修行者“参究”的活生生的精神事件。它如同一面镜子，映照出修行者自身的思维葛藤。修行者必须全身心地投入公案之中，用整个生命去“碰壁”，而非用头脑去理解。\n\n三、看话禅与大疑情：将语言推向极致的修行\n\n在公案修行的基础上，大慧宗杲禅师正式确立了“看话禅”的法门。他教导修行者，不必理会公案的整个故事情节，只需抓住其中最关键、最无逻辑可循的一句话，即“话头”，并反复在心中追问。例如，面对“万法归一，一归何处？”这个公案，其“话头”便是“一归何处？”。又如，面对赵州禅师对“狗子有无佛性？”的回答“无”，其话头便是这个“无”字。\n\n“看话头”的要旨在于，不能用逻辑去推理解释，而要将全部身心能量都凝聚在这个话头上，形成一个巨大而炽热的疑团——“大疑情”。这个疑情越是深重、坚固，就越能隔绝一切杂念。修行者日夜提撕，行住坐卧皆不离这个话头，直到有一天，因缘时节到来，疑团猛然爆破，如同“打破漆桶”，无明顿消，亲见本来面目。这一刻，语言的功能发挥到了极致，也在此刻彻底消亡，从而真正实现了“以言遣言”的超越。\n\n结论：一种反身性的语言智慧\n\n禅宗的“机锋”与“看话禅”，并非对“不立文字”的背离，反而是对其最深刻的贯彻。它展示了一种高超的反身性语言智慧：正因为认识到语言的局限，所以才要最大化地利用其“非逻辑”的潜能，将其锻造成一把可以刺破语言自身之网的利剑。这种“以言遣言”的辩证法，不仅是古代禅师的修行技艺，更为我们反思现代社会中语言与真实、符号与体验之间的关系，提供了一份无价的思想遗产。",
    "reference_list": "考点1：“不立文字”必须译为“no reliance on words and letters”或“no-dependence on words and letters”\n考点2：“机锋”推荐译为“sharp verbal repartee”\n考点3：“公案”必须译为“koan(s)”；“gongan (koans)”\n考点4：“话头”必须译为“the critical phrase (Huatou)”\n考点5：“见性成佛”必须译为“seeing one's true nature and attaining Buddhahood”或 “seeing one's nature and becoming a Buddha”\n考点6：“以言遣言”推荐译为“using words to eliminate words”或 “using words to dispel words”\n考点7：“大疑情”必须译为“the Great Doubt”或“great doubt”\n考点8：“指月之指”推荐译为“the finger pointing at the moon”或；“a finger pointing at the moon”\n考点9：“打破漆桶”必须译为“smashing the lacquer bucket”或 “breaking the lacquer bucket”\n考点10：“默照禅”推荐译为“Silent Illumination Chan”\n考点11：“绝境”推荐译为“desperate state”\n考点12：“看话禅”必须译为“Word Contemplation Chan (Kanhua Chan)”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "129"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nZonal ﬂows, by which we mean azimuthally symmetric band-like shear ﬂows, are a ubiquitous phenomena in nature and the laboratory. The well-known examples of the Jovian belts and zones, and the terrestrial atmospheric jet stream are familiar to nearly everyone—the latter especially to travellers enduring long, bumpy airplane rides against strong head winds. Zonal ﬂows are also present in the Venusian atmosphere (which rotates faster than the planet does!) and occur in the solar tachocline, where they play a role in the solar dynamo mechanism. In the laboratory, the importance of sheared E × B ﬂows to the development of L-mode conﬁnement, the L-to-H transition and internal transport barriers(ITBs) is now well and widely appreciated.\n\nWhile many mechanisms can act to trigger and stimulate the growth of sheared electric ﬁelds (i.e. proﬁle evolution and transport bifurcation, neoclassical effects, external momentum injection, etc) certainly one possibility is via the self-generation and ampliﬁcation of E × B ﬂows by turbulent stresses (i.e. the turbulent transport of momentum). Of course, this is the same mechanism as that responsible for zonal ﬂow generation. It should be emphasized that it is now widely recognized and accepted that zonal ﬂows are a key constituent in nearly all cases and regimes of drift wave turbulence—indeed, so much so that this classic problem is now frequently referred to as ‘drift wave–zonal ﬂow turbulence’. This paradigm shift occurred on account of the realization that zonal ﬂows are ubiquitous in dynamical models used for describing fusion plasmas (i.e. ITG, TEM, ETG, resistive ballooning and interchange, etc) in all geometries and regimes (i.e. core, edge, etc), and because of the realization that zonal ﬂows are a critical agent of self-regulation for drift wave transport and turbulence. Both theoretical work and numerical simulation made important contributions to this paradigm shift. Indeed, for the case of low collisionality plasmas, a signiﬁcant portion of the available free energy is ultimately deposited in the zonal ﬂows. Figure 1 presents energy ﬂow charts which illustrate the classic paradigm of drift wave turbulence and the new paradigm of drift wave–zonal ﬂow turbulence. The study of zonal ﬂow has had a profound impact on fusion research. For instance, the proper treatment of the zonal ﬂow physics has resolved some of the confusion concerning the prospect of burning plasma, as has been discussed by Rosenbluth and collaborators in conjunction with the design of the International Thermonuclear Experimental Reactor (ITER). At the same time, the understanding of the turbulence–zonal ﬂow system has advanced the understanding of self-organization processes in nature.\n\nWe note here that, while zonal ﬂows have a strong inﬂuence on the formation of transport barriers, the dynamics of barriers and transitions involve evolutions of both the mean E × B ﬂow as well as the zonal E × B ﬂow. The topics of mean Er dynamics, transport barriers and conﬁnement regime transitions are beyond the scope of this review.\n\nIn the context of tokamak plasmas, zonal ﬂows are n = 0 electrostatic potential ﬂuctuations with ﬁnite radial wavenumber. Zonal ﬂows are elongated, asymmetric vortex modes, and thus have zero frequency. They are predominantly poloidally symmetric as well, though some coupling to low-m sideband modes may occur. On account of their symmetry, zonal ﬂows cannot access expansion free energy stored in temperature, density gradients, etc, and are not subject to Landau damping. These zonal ﬂows are driven exclusively by nonlinear interactions, which transfer energy from the ﬁnite-n drift waves to the n = 0 ﬂow. Usually, such nonlinear interactions are three-wave triad couplings between two high k drift waves and one low q zonal ﬂow excitation. In position space, this energy transfer process is simple one whereby Reynolds work is performed on the ﬂow by the wave stresses. Two important consequences of this process of generation follow directly. First, since zonal ﬂow production is exclusively via nonlinear transfer from drift waves, zonal ﬂows must eventually decay and vanish if the underlying drift wave drive is extinguished. Thus, zonal ﬂows differ in an important way from mean E × B ﬂows, which can be sustained in the absence of turbulence (and are, in strong H-mode and ITB regimes). Second, since zonal ﬂows are generated by nonlinear energy transfer from drift waves, their generation naturally acts to reduce the intensity and level of transport caused by the primary drift wave turbulence. Thus, zonal ﬂows necessarily act to regulate and partially suppress drift wave turbulence and transport. This is clear from numerical simulations, which universally show that turbulence and transport levels are reduced when the zonal ﬂow generation is (properly) allowed. Since zonal ﬂows cannot \ntap expansion free energy, are generated by nonlinear coupling from drift waves, and damp primarily (but not exclusively) by collisional processes, they constitute a signiﬁcant and benign (from a conﬁnement viewpoint) reservoir or repository for the available free energy of the system.\n\nAnother route to understanding the effects of zonal ﬂow on drift waves is via the shearing paradigm. From this standpoint, zonal ﬂows produce a spatio-temporally complex shearing pattern, which naturally tends to distort drift wave eddies by stretching them, and in the process generates large kr. Of course, at smaller scales, coupling to dissipation becomes stronger, resulting in a net stabilizing trend. The treatment of zonal ﬂow shearing differs from that for mean ﬂow shearing on account of the complexity of the ﬂow pattern. Progress here has been facilitated by the realization that a statistical analysis is possible. This follows from the fact that the autocorrelation time of a drift wave-packet propagating in a zonal ﬂow ﬁeld is usually quite short, and because the drift wave rays are chaotic. Hence, signiﬁcant advances have been made on calculating the ‘back reaction’ of zonal ﬂows on the underlying drift wave ﬁeld within the framework of random shearing, using wave kinetics and quasilinear theory. Conservation of energy between drift waves and zonal ﬂows has been proved for the theory, at the level of a renormalized quasilinear description. Thus, it is possible to close the ‘feedback loop’ of wave–ﬂow interactions, allowing a self-consistent analysis of the various system states, and enabling an understanding of the mechanisms and routes for bifurcation between them.\n\nOf course, it is patently obvious that the zonal ﬂow problem is one of self-organization of a large structure in turbulence. Examples of other members of this class include transport barrier and proﬁle formation and dynamics, the origin of the solar differential rotation, the famous magnetic dynamo problem (relevant, in quite different limits, to the sun, earth, galaxy and reversed ﬁeld pinch), and the formation of proﬁles in turbulent and swirling pipe ﬂow. Table 1 summarizes these related structure formation phenomena, illustrating the objective of this review. Most of these problems are attacked at the simplest level by considering the stability of an ensemble or ‘gas’ of ambient turbulence to a seed perturbation. For example, in the dynamo problem, one starts by considering the stability of some state of magnetohydrodynamic (MHD) turbulence to a seed magnetic ﬁeld. In the zonal ﬂow problem, one correspondingly considers the stability of a gas of drift waves to a seed shear. The incidence of instability means that the initial vortex tilt will be re-enforced, thus amplifying the seed perturbation. It should be noted that the zonal ﬂow formation phenomenon is related to, but not quite the same as, the well-known inverse cascade of energy in a two-dimensional ﬂuid, which leads to large scale vortex formation. This is because the inverse cascade proceeds via a local coupling in wavenumber space, while zonal ﬂow generation occurs via non-local transfer of energy between small and large scales. Indeed, zonal shear ampliﬁcation is rather like the familiar α-effect from dynamo theory, which describes a non-local transfer of magnetic helicity to large scale. We also note that the initial stage of pattern formation instability meets only part of the challenge to a theoretical description of structure formation, and that one must subsequently ‘close the loop’ by understanding the mechanisms of saturation of the zonal ﬂow instability. The saturation of zonal ﬂows driven by drift wave turbulence is now a subject of intensive theoretical and computational investigation, worldwide.\n\nAs a related phenomena, convective cells have been subject to intensive study for a long time. The convective cell is a perturbation which is constant along the magnetic ﬁeld line but changes in the direction perpendicular to the magnetic ﬁeld. Such a structure is known to be induced by background drift wave turbulence. The zonal ﬂow can be considered as a particular example of an anisotropic convective cell. However, the convective cells of greatest interest as agents of transport are localized in the poloidal direction and extended radially, which is the opposite limit of anisotropy from that of the zonal ﬂow. Such cells are commonly referred to as streamers.\n\nAs the zonal ﬂow problem is a member of a large class of rapidly expanding research topics, the perspective of this review is composed as follows. First, we present detailed explanations of the physical understanding of drift wave–zonal ﬂow turbulence. Second, we also stress the view that studies on toroidal plasma turbulence enhance our understanding of turbulent structure formation in nature. In this sense, this review is a companion paper to recent reviews on the magnetic dynamo problem which, taken together, present a uniﬁed view that addresses the mystery of structure formation in turbulent media. Third, the impact of direct nonlinear simulation (DNS) is discussed in the context of understanding zonal ﬂow physics, although a survey of DNS techniques themselves is beyond the scope of this review. It is certainly the case that DNS studies have signiﬁcantly furthered our understanding of drift wave–zonal ﬂow turbulence. For these reasons, examples are mainly chosen from the realm of core plasma (i.e. drift wave) turbulence. In order to maintain transparency and to be concise, this review is limited in scope. Studies of edge turbulence and of general convective cell physics are not treated in depth here. While these topics are closely related to the topic of this review, extensive introductory discussions, which are too lengthy for this paper, are necessary. Hence, details of these important areas are left for future reviews.",
    "ori_text": "\n\nZonal ﬂows, by which we mean azimuthally symmetric band-like shear ﬂows, are a ubiquitous phenomena in nature and the laboratory. The well-known examples of the Jovian belts and zones, and the terrestrial atmospheric jet stream are familiar to nearly everyone—the latter especially to travellers enduring long, bumpy airplane rides against strong head winds. Zonal ﬂows are also present in the Venusian atmosphere (which rotates faster than the planet does!) and occur in the solar tachocline, where they play a role in the solar dynamo mechanism. In the laboratory, the importance of sheared E × B ﬂows to the development of L-mode conﬁnement, the L-to-H transition and internal transport barriers(ITBs) is now well and widely appreciated.\n\nWhile many mechanisms can act to trigger and stimulate the growth of sheared electric ﬁelds (i.e. proﬁle evolution and transport bifurcation, neoclassical effects, external momentum injection, etc) certainly one possibility is via the self-generation and ampliﬁcation of E × B ﬂows by turbulent stresses (i.e. the turbulent transport of momentum). Of course, this is the same mechanism as that responsible for zonal ﬂow generation. It should be emphasized that it is now widely recognized and accepted that zonal ﬂows are a key constituent in nearly all cases and regimes of drift wave turbulence—indeed, so much so that this classic problem is now frequently referred to as ‘drift wave–zonal ﬂow turbulence’. This paradigm shift occurred on account of the realization that zonal ﬂows are ubiquitous in dynamical models used for describing fusion plasmas (i.e. ITG, TEM, ETG, resistive ballooning and interchange, etc) in all geometries and regimes (i.e. core, edge, etc), and because of the realization that zonal ﬂows are a critical agent of self-regulation for drift wave transport and turbulence. Both theoretical work and numerical simulation made important contributions to this paradigm shift. Indeed, for the case of low collisionality plasmas, a signiﬁcant portion of the available free energy is ultimately deposited in the zonal ﬂows. Figure 1 presents energy ﬂow charts which illustrate the classic paradigm of drift wave turbulence and the new paradigm of drift wave–zonal ﬂow turbulence. The study of zonal ﬂow has had a profound impact on fusion research. For instance, the proper treatment of the zonal ﬂow physics has resolved some of the confusion concerning the prospect of burning plasma, as has been discussed by Rosenbluth and collaborators in conjunction with the design of the International Thermonuclear Experimental Reactor (ITER). At the same time, the understanding of the turbulence–zonal ﬂow system has advanced the understanding of self-organization processes in nature.\n\nWe note here that, while zonal ﬂows have a strong inﬂuence on the formation of transport barriers, the dynamics of barriers and transitions involve evolutions of both the mean E × B ﬂow as well as the zonal E × B ﬂow. The topics of mean Er dynamics, transport barriers and conﬁnement regime transitions are beyond the scope of this review.\n\nIn the context of tokamak plasmas, zonal ﬂows are n = 0 electrostatic potential ﬂuctuations with ﬁnite radial wavenumber. Zonal ﬂows are elongated, asymmetric vortex modes, and thus have zero frequency. They are predominantly poloidally symmetric as well, though some coupling to low-m sideband modes may occur. On account of their symmetry, zonal ﬂows cannot access expansion free energy stored in temperature, density gradients, etc, and are not subject to Landau damping. These zonal ﬂows are driven exclusively by nonlinear interactions, which transfer energy from the ﬁnite-n drift waves to the n = 0 ﬂow. Usually, such nonlinear interactions are three-wave triad couplings between two high k drift waves and one low q zonal ﬂow excitation. In position space, this energy transfer process is simple one whereby Reynolds work is performed on the ﬂow by the wave stresses. Two important consequences of this process of generation follow directly. First, since zonal ﬂow production is exclusively via nonlinear transfer from drift waves, zonal ﬂows must eventually decay and vanish if the underlying drift wave drive is extinguished. Thus, zonal ﬂows differ in an important way from mean E × B ﬂows, which can be sustained in the absence of turbulence (and are, in strong H-mode and ITB regimes). Second, since zonal ﬂows are generated by nonlinear energy transfer from drift waves, their generation naturally acts to reduce the intensity and level of transport caused by the primary drift wave turbulence. Thus, zonal ﬂows necessarily act to regulate and partially suppress drift wave turbulence and transport. This is clear from numerical simulations, which universally show that turbulence and transport levels are reduced when the zonal ﬂow generation is (properly) allowed. Since zonal ﬂows cannot \ntap expansion free energy, are generated by nonlinear coupling from drift waves, and damp primarily (but not exclusively) by collisional processes, they constitute a signiﬁcant and benign (from a conﬁnement viewpoint) reservoir or repository for the available free energy of the system.\n\nAnother route to understanding the effects of zonal ﬂow on drift waves is via the shearing paradigm. From this standpoint, zonal ﬂows produce a spatio-temporally complex shearing pattern, which naturally tends to distort drift wave eddies by stretching them, and in the process generates large kr. Of course, at smaller scales, coupling to dissipation becomes stronger, resulting in a net stabilizing trend. The treatment of zonal ﬂow shearing differs from that for mean ﬂow shearing on account of the complexity of the ﬂow pattern. Progress here has been facilitated by the realization that a statistical analysis is possible. This follows from the fact that the autocorrelation time of a drift wave-packet propagating in a zonal ﬂow ﬁeld is usually quite short, and because the drift wave rays are chaotic. Hence, signiﬁcant advances have been made on calculating the ‘back reaction’ of zonal ﬂows on the underlying drift wave ﬁeld within the framework of random shearing, using wave kinetics and quasilinear theory. Conservation of energy between drift waves and zonal ﬂows has been proved for the theory, at the level of a renormalized quasilinear description. Thus, it is possible to close the ‘feedback loop’ of wave–ﬂow interactions, allowing a self-consistent analysis of the various system states, and enabling an understanding of the mechanisms and routes for bifurcation between them.\n\nOf course, it is patently obvious that the zonal ﬂow problem is one of self-organization of a large structure in turbulence. Examples of other members of this class include transport barrier and proﬁle formation and dynamics, the origin of the solar differential rotation, the famous magnetic dynamo problem (relevant, in quite different limits, to the sun, earth, galaxy and reversed ﬁeld pinch), and the formation of proﬁles in turbulent and swirling pipe ﬂow. Table 1 summarizes these related structure formation phenomena, illustrating the objective of this review. Most of these problems are attacked at the simplest level by considering the stability of an ensemble or ‘gas’ of ambient turbulence to a seed perturbation. For example, in the dynamo problem, one starts by considering the stability of some state of magnetohydrodynamic (MHD) turbulence to a seed magnetic ﬁeld. In the zonal ﬂow problem, one correspondingly considers the stability of a gas of drift waves to a seed shear. The incidence of instability means that the initial vortex tilt will be re-enforced, thus amplifying the seed perturbation. It should be noted that the zonal ﬂow formation phenomenon is related to, but not quite the same as, the well-known inverse cascade of energy in a two-dimensional ﬂuid, which leads to large scale vortex formation. This is because the inverse cascade proceeds via a local coupling in wavenumber space, while zonal ﬂow generation occurs via non-local transfer of energy between small and large scales. Indeed, zonal shear ampliﬁcation is rather like the familiar α-effect from dynamo theory, which describes a non-local transfer of magnetic helicity to large scale. We also note that the initial stage of pattern formation instability meets only part of the challenge to a theoretical description of structure formation, and that one must subsequently ‘close the loop’ by understanding the mechanisms of saturation of the zonal ﬂow instability. The saturation of zonal ﬂows driven by drift wave turbulence is now a subject of intensive theoretical and computational investigation, worldwide.\n\nAs a related phenomena, convective cells have been subject to intensive study for a long time. The convective cell is a perturbation which is constant along the magnetic ﬁeld line but changes in the direction perpendicular to the magnetic ﬁeld. Such a structure is known to be induced by background drift wave turbulence. The zonal ﬂow can be considered as a particular example of an anisotropic convective cell. However, the convective cells of greatest interest as agents of transport are localized in the poloidal direction and extended radially, which is the opposite limit of anisotropy from that of the zonal ﬂow. Such cells are commonly referred to as streamers.\n\nAs the zonal ﬂow problem is a member of a large class of rapidly expanding research topics, the perspective of this review is composed as follows. First, we present detailed explanations of the physical understanding of drift wave–zonal ﬂow turbulence. Second, we also stress the view that studies on toroidal plasma turbulence enhance our understanding of turbulent structure formation in nature. In this sense, this review is a companion paper to recent reviews on the magnetic dynamo problem which, taken together, present a uniﬁed view that addresses the mystery of structure formation in turbulent media. Third, the impact of direct nonlinear simulation (DNS) is discussed in the context of understanding zonal ﬂow physics, although a survey of DNS techniques themselves is beyond the scope of this review. It is certainly the case that DNS studies have signiﬁcantly furthered our understanding of drift wave–zonal ﬂow turbulence. For these reasons, examples are mainly chosen from the realm of core plasma (i.e. drift wave) turbulence. In order to maintain transparency and to be concise, this review is limited in scope. Studies of edge turbulence and of general convective cell physics are not treated in depth here. While these topics are closely related to the topic of this review, extensive introductory discussions, which are too lengthy for this paper, are necessary. Hence, details of these important areas are left for future reviews.",
    "reference_list": "考点1：”zonal flow“必须译为”带状流“；\n考点2：”drift waveturbulence transport“必须译为”漂移波湍流输运“；\n考点3：”Reynolds stress“必须译为”雷诺应力“；\n考点4：”inverse cascade of energy“必须译为”能量逆级联“；\n考点5：”magnetohydrodynamic“必须译为”磁流体动力学“；\n考点6：”azimuthally symmetric“必须译为”轴对称“；\n考点7：”convective cells“必须译为”对流元“；\n考点8：”Jovian belts“必须译为”木星云带“；\n考点9：”regimes of drift wave turbulence“必须译为”漂移波湍流（参数）区域“；\n考点10：”Rosenbluth“人名不推荐翻译为中文；\n考点11：”underlying“推荐译为”潜在的“；\n考点12：”streamers“必须译为”流带“；\n考点13：”differ in an important way from“推荐译为”重要区别是“。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "145"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n北京孔庙始建于元大德六年（1302），大德十年（1306）建成，明永乐九年（1411）重建。北京孔庙从1928年起对普通人外开放，以前都是皇帝及其随员供人游览才可以进入。北京孔庙的神圣性来自于其严格按照礼制要求建造，而这种礼制要求体现在在不同的尺度中，也就是说，孔庙的神圣性是在不同尺度中被建构的。\n孔庙的选址十分强调讲究中国的风水。在选址时遵循风水的基本规则意味着一方面，可以在客观上保证孔庙的采光、通风和保温等能达到最好的效果；风水有两个流派，一个是依据自然环境选址，主要流行于山区；另一是依据方位选址，主要流行在平原方面。北京城坐落在平原，因此适合采用按照方位选址的风水理论。文庙的选址，其目的是，也可以求孔子和诸位儒学先贤保佑人们满足人们对科举通过科举走上仕途。按照方位选址主要看地面与天上的星辰的对应关系。“庙者天星也……上应天上之星辰，下司人间之福禄。居凶方则凶，居吉方则吉。吉者，三吉六秀是也。亥震庚，为三吉。艮丙巽辛兑丁，为六秀。庙居此方，官民俱吉。” 历史上甚至有因为风水不佳而将孔庙迁址的例子。《阳宅三要》中说“阴阳之理、自古攸分，二者不和，凶气必至。故公衙要合法，而庙亦不可不居乎吉地......文庙建于甲、艮、巽三地为得地也......”《相宅经纂》中也有“文庙建甲、艮、巽三方，为得地。庙后易高耸，如笔如抢，左宜空缺明亮，一眼看见奎文楼，大利科甲。”的记录。（甲为震，东方；艮为东北；巽为东南。）由此可见东、东北和东南是文庙的常见选址。元朝初建北京孔庙，选址就位于皇城的东北方（图5-1）。从元大都到明清皇城再到今天的老城，北京核心区固然经历了改造，但是其基本格局还是得到了保留（图5）。因此，如今的孔庙依然位于城市中心的东北方。这种选址体现了孔庙的地位，塑造了其神圣性。\n孔庙所在的街道设计布局为孔庙的神圣感提供了三层烘托铺垫。第一，孔庙位于成贤街（今国子监街）。东西两侧的街口分别立有一彩绘牌坊，上书“成贤街”。这两个牌坊因其色彩艳丽、形制高大而格外醒目，因此也提醒进入街道的人们集中注意力开始关注街道内的景观。第二，由东口进入街道，则很快可以看见刻有“文武官员至此下马”的下马碑（位于孔庙东侧）；由西口进入，则可以见到街道内的第二个彩绘牌坊——“国子监”牌坊（位于国子监西侧）。这两个建筑都能够再次提醒游客自己已经走近神圣空间，需要更加注意自己的行为礼仪。第三，走到孔庙与国子监大门（先师门）对面博物馆门口，可以看见是一座琉璃瓦的一字影壁（建于1501年）。和宏伟的影壁和先师门。这两个建筑都十分高大，意在比喻孔子的学识道德之高深，勉励学子勤学。它们的存在使得人们游客一来意识到自己已经走到孔庙跟前，而来使得人们无法一眼看见孔庙内部，由此对内部建筑的神秘产生好奇和崇敬。\n清代，自康熙皇帝开始，朝廷重视孔庙周边的管理。清代是满族人建立的王朝，满族人从中国东北进入中原之前不信儒学，因此到清代第三位皇帝将都城迁到北京后，并不将汉族人信奉的孔庙当做神圣空间。直到清代第四位皇帝康熙执政期间，才开始重视孔庙。这是因为这时满族军队基本上控制了中国绝大部分地区，康熙皇帝开始考虑处理满族和汉族的关系。顺天府是首都北京下辖的两个府之一。1682年的一天，康熙皇帝看到顺天府的官员提交的一份报告。报告说学宫门摆放马槽，栓着军队一些官员的马匹，道路上到处是马粪马尿。这些官员是满族军队中级别最高的镶黄旗总指挥的部下。这些满足官人在学宫院内挖土做砖，使院子里有一大坑，院子四周的墙也被破坏。孔庙内还养着牛羊。这些做法都是对神圣空间的不尊敬。康熙皇帝看到这个报告后，马上命令负责国家礼仪的部门将院墙修好，不允许在此养马、牛、羊。最后，康熙皇帝还表扬了这位提交报告汉族官员（K. Li, 1912），由此缓和满族和汉族的文化对立。1684年，康熙为大成殿题写“万世师表”（永远是人们的榜样）的牌匾。",
    "ori_text": "\n\n北京孔庙始建于元大德六年（1302），大德十年（1306）建成，明永乐九年（1411）重建。北京孔庙从1928年起对普通人外开放，以前都是皇帝及其随员供人游览才可以进入。北京孔庙的神圣性来自于其严格按照礼制要求建造，而这种礼制要求体现在在不同的尺度中，也就是说，孔庙的神圣性是在不同尺度中被建构的。\n孔庙的选址十分强调讲究中国的风水。在选址时遵循风水的基本规则意味着一方面，可以在客观上保证孔庙的采光、通风和保温等能达到最好的效果；风水有两个流派，一个是依据自然环境选址，主要流行于山区；另一是依据方位选址，主要流行在平原方面。北京城坐落在平原，因此适合采用按照方位选址的风水理论。文庙的选址，其目的是，也可以求孔子和诸位儒学先贤保佑人们满足人们对科举通过科举走上仕途。按照方位选址主要看地面与天上的星辰的对应关系。“庙者天星也……上应天上之星辰，下司人间之福禄。居凶方则凶，居吉方则吉。吉者，三吉六秀是也。亥震庚，为三吉。艮丙巽辛兑丁，为六秀。庙居此方，官民俱吉。” 历史上甚至有因为风水不佳而将孔庙迁址的例子。《阳宅三要》中说“阴阳之理、自古攸分，二者不和，凶气必至。故公衙要合法，而庙亦不可不居乎吉地......文庙建于甲、艮、巽三地为得地也......”《相宅经纂》中也有“文庙建甲、艮、巽三方，为得地。庙后易高耸，如笔如抢，左宜空缺明亮，一眼看见奎文楼，大利科甲。”的记录。（甲为震，东方；艮为东北；巽为东南。）由此可见东、东北和东南是文庙的常见选址。元朝初建北京孔庙，选址就位于皇城的东北方（图5-1）。从元大都到明清皇城再到今天的老城，北京核心区固然经历了改造，但是其基本格局还是得到了保留（图5）。因此，如今的孔庙依然位于城市中心的东北方。这种选址体现了孔庙的地位，塑造了其神圣性。\n孔庙所在的街道设计布局为孔庙的神圣感提供了三层烘托铺垫。第一，孔庙位于成贤街（今国子监街）。东西两侧的街口分别立有一彩绘牌坊，上书“成贤街”。这两个牌坊因其色彩艳丽、形制高大而格外醒目，因此也提醒进入街道的人们集中注意力开始关注街道内的景观。第二，由东口进入街道，则很快可以看见刻有“文武官员至此下马”的下马碑（位于孔庙东侧）；由西口进入，则可以见到街道内的第二个彩绘牌坊——“国子监”牌坊（位于国子监西侧）。这两个建筑都能够再次提醒游客自己已经走近神圣空间，需要更加注意自己的行为礼仪。第三，走到孔庙与国子监大门（先师门）对面博物馆门口，可以看见是一座琉璃瓦的一字影壁（建于1501年）。和宏伟的影壁和先师门。这两个建筑都十分高大，意在比喻孔子的学识道德之高深，勉励学子勤学。它们的存在使得人们游客一来意识到自己已经走到孔庙跟前，而来使得人们无法一眼看见孔庙内部，由此对内部建筑的神秘产生好奇和崇敬。\n清代，自康熙皇帝开始，朝廷重视孔庙周边的管理。清代是满族人建立的王朝，满族人从中国东北进入中原之前不信儒学，因此到清代第三位皇帝将都城迁到北京后，并不将汉族人信奉的孔庙当做神圣空间。直到清代第四位皇帝康熙执政期间，才开始重视孔庙。这是因为这时满族军队基本上控制了中国绝大部分地区，康熙皇帝开始考虑处理满族和汉族的关系。顺天府是首都北京下辖的两个府之一。1682年的一天，康熙皇帝看到顺天府的官员提交的一份报告。报告说学宫门摆放马槽，栓着军队一些官员的马匹，道路上到处是马粪马尿。这些官员是满族军队中级别最高的镶黄旗总指挥的部下。这些满足官人在学宫院内挖土做砖，使院子里有一大坑，院子四周的墙也被破坏。孔庙内还养着牛羊。这些做法都是对神圣空间的不尊敬。康熙皇帝看到这个报告后，马上命令负责国家礼仪的部门将院墙修好，不允许在此养马、牛、羊。最后，康熙皇帝还表扬了这位提交报告汉族官员（K. Li, 1912），由此缓和满族和汉族的文化对立。1684年，康熙为大成殿题写“万世师表”（永远是人们的榜样）的牌匾。",
    "reference_list": "考点1：“文庙”必须翻译为“the Temple of Confucius / Confucian Temple”\n考点2：“庙象天星”推荐翻译为“the temple corresponds to celestial stars”（含义对即可）\n考点3：“公衙要合法”推荐翻译为“the location of the public office should be reasonable”（含义对即可）\n考点4：“三吉”推荐翻译为“San Ji”\n考点5：“六秀”推荐翻译为“Liu Xiu”\n考点6：“阳宅三要”推荐翻译为“The Three Essentials of Yang Residence”\n考点7：“相宅经纂”推荐翻译为“Classic for Assessing House”\n考点8：“科甲”推荐翻译为“imperial examination success”（含义对即可）\n考点9：“庙后易高耸，如笔如抢”推荐翻译为“The back of the temple should have a towering building, as straight as a pen, as prominent as a snatch.”（含义对即可）\n考点10：“左宜空缺明亮”推荐翻译为“bright and open left side”（含义对即可）\n考点11：“彩绘牌坊”推荐翻译为“painted memorial arch/paifang/Pailou”\n考点12：“文武官员至此下马”推荐翻译为“civil and military officials dismounted here”（含义对即可）\n考点13：“琉璃瓦的一字影壁”推荐翻译为“glazed shadow wall”\n考点14：“官员”推荐翻译为“governor”\n考点15：“镶黄旗”必须翻译为“Xianghuang settlement”\n考点16：“万世师表”推荐翻译为“the eternal paragon”\n考点17：“元大都”推荐翻译为“Yuan capital”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "128"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。 以下是你本次的任务：\nConcrete is a composite construction material composed of a cementitious binder (usually Portland cement), water, and aggregates (sand and gravel or crushed stone), along with various admixtures that may be added to modify its properties. When these ingredients are first mixed together, the fresh concrete is a viscoplastic, moldable mixture that can be placed into forms. A series of chemical reactions called cement hydration begins as soon as water contacts the cement particles. Through hydration, the cement paste gradually hardens and gains strength, binding the aggregates together into a solid mass. This transformation from a fluid plastic state to a rigid, load-bearing solid typically occurs within a few hours after mixing (initial setting often happens after around 2 hours for a normal mix). Strength development then continues over time as curing progresses – concrete keeps gaining strength for months or even years, although the rate of strength gain diminishes with time. In practice, the compressive strength measured at 28 days (the 28-day strength) is commonly used as a benchmark of concrete quality (denoted as f’c in many specifications). \nAbout 90% of the long-term strength is usually achieved in the first month under proper curing conditions. Proper curing during this period is critical to concrete quality: the concrete must be prevented from drying out or freezing at early ages. Newly placed concrete is typically kept moist (for example by frequent water spraying or by covering with wet burlap and plastic sheets) and maintained at a suitable temperature. Such curing ensures that hydration can progress and that the concrete’s surface does not crack or lose strength prematurely. If concrete is allowed to dry too soon, it will stop gaining strength and may develop surface shrinkage cracks; if it freezes before sufficient hardening, its internal structure can be disrupted. Therefore, curing measures are often applied for at least 7–14 days to promote good strength and durability development. The strength of hardened concrete depends on many factors, including the mix proportions, the properties of the constituent materials, the curing regime, and the presence of any admixtures or additives. One of the most important factors is the water-to-cement ratio (w/c ratio). This is the ratio of the mass of water to the mass of cement in the mix. A lower w/c ratio generally leads to higher strength and density (since less excess water leaves behind fewer pores in the hardened concrete), but if the w/c is too low, the mix may become unworkable (too stiff and difficult to place). For complete hydration of cement, a minimum w/c of around 0.22–0.25 by weight is needed, but typical structural concrete mixes use a w/c in the range of 0.4 to 0.6 to ensure adequate workability. Workability refers to the ease with which fresh concrete can be mixed, placed, compacted, and finished without segregation. To improve workability without adding excess water (which would reduce strength and increase permeability), chemical admixtures such as plasticizers (water-reducing agents) are often used. For example, a high-range water reducer (superplasticizer) can produce a highly flowable concrete (even self-leveling) at a w/c as low as ~0.30, enabling very high strengths while still allowing the mix to be placed easily. \nA highly workable mix can flow and fill formwork and surround dense reinforcement with relative ease, but if too much water or improper proportions are used, the mix may segregate or bleed. Segregation is the separation of coarse aggregate from the mortar (cement paste and fines) due to settling, resulting in a non-uniform composition. Bleeding is a related phenomenon where excess water rises to the top surface of the concrete before it sets. Both segregation and bleeding indicate an unstable mix; they can cause weak, porous regions and lead to finishing problems or reduced durability in the hardened concrete. Proper mix proportioning and the use of fines and viscosity-modifying admixtures can minimize these issues. The workability of fresh concrete is commonly measured by the slump test, which provides an empirical indication of concrete consistency. In a standard slump test, fresh concrete is placed into a frustum-shaped cone mold (12 inches high) in three layers, and each layer is rodded (tamped) a specified number of times. The mold is then carefully lifted off, and the unsupported concrete slumps under its own weight. The vertical drop of the concrete’s top (measured relative to the mold height) is called the slump. A higher slump (e.g. 7 or 8 inches) indicates a very wet or fluid mix, while a low slump (e.g. 1 inch) indicates a dry, stiff mix. Typical concretes for general construction have slumps in the range of about 2 to 4 inches (50–100 mm) for a good balance of workability and strength. However, slump does not capture all aspects of workability; different mixes can have the same slump yet handle very differently (for instance, one may segregate more easily than another). Other tests and measures (such as flow table tests for mortar, the compaction factor test, or more advanced rheometer tests) can characterize workability, especially for specialized concretes. Still, the slump test remains the simplest and most widely used field test to verify batch-to-batch consistency of concrete and ensure that the fresh mix has not changed. In recent years, self-consolidating concrete (SCC) has been developed as an extremely high-workability mix that can flow and compact under its own weight without vibration. SCC is achieved by using advanced admixtures (superplasticizers) and viscosity-modifying agents to produce a fluid yet stable mix. It demonstrates that with appropriate mix design, one can obtain both high workability and high strength (through a low w/c ratio), which is valuable for placing concrete in structures with congested reinforcement or complex formwork. As the fresh concrete gradually sets and hardens, its properties transition to those of the hardened material. The density of normal-weight concrete is around 2400 kg/m³ (about 150 lb/ft³), and its compressive strength can range widely. Ordinary structural concrete typically achieves a 28-day compressive strength on the order of 20–40 MPa (3000–6000 psi), whereas high-strength concrete used in high-rise buildings or other special applications can reach strengths of 70 MPa (10,000 psi) or more. Concrete’s tensile strength is much lower than its compressive strength (on the order of only 10% of the compressive strength). For this reason, concrete is usually reinforced with steel bars (reinforcing steel, or “rebar”) to carry tension. The stress–strain curve of concrete in compression is nonlinear – unlike steel, concrete does not have a long elastic range or a well-defined yield point. It initially deforms approximately elastically at very low stress, but as stress increases, the curve gradually bends (due to microcracking and increasing inelasticity) and eventually reaches a peak, followed by a drop-off as the concrete fails by crushing. Because there is no sharply defined elastic limit, the modulus of elasticity of concrete is usually defined either as an initial tangent modulus or a secant modulus to a point on the curve (for example, to 50% of ultimate strength). For typical normal-strength concrete, a common empirical approximation is that the Young’s modulus is about 20–30 GPa (gigapascals), which corresponds to around 3 to 5 million psi. \nHigher-strength concretes have higher stiffness, though not in direct proportion to their strength. Volume stability is another important aspect of concrete performance. As concrete cures and dries, it undergoes shrinkage – a reduction in volume. Drying shrinkage occurs as water that is not chemically bound in hydration products gradually evaporates from the hardened concrete. If a large element (like a long slab or wall) is restrained while it is shrinking (for example, by the subgrade or by adjacent structural elements), tensile stresses can develop, potentially leading to cracking. To control crack formation, engineers often incorporate contraction joints (planned grooves or weak planes where shrinkage cracks can form in a controlled way) and provide sufficient distributed reinforcement (sometimes called temperature and shrinkage steel) to hold any cracks tightly closed. Thermal changes can also cause concrete to expand or contract. For instance, the heat released during cement hydration can raise the temperature of a large concrete mass in early-age, and subsequent cooling can induce tensile stresses. In hot weather, rapid surface drying and cooling of freshly placed concrete can cause a surface contraction while the interior is still warm, sometimes leading to a pattern of shallow cracks called thermal cracking. Measures such as gradual cooling of massive pours, insulating blankets, or using low-heat cements help mitigate these thermal stresses. In addition to shrinkage and thermal effects, concrete exhibits creep, which is the long-term gradual deformation under sustained load. Under a constant compressive stress (such as a heavy dead load on a column or beam), concrete will slowly deform over months and years beyond the initial elastic strain – this time-dependent strain is creep. Creep strain can be significant, sometimes on the same order as the initial elastic strain. It is influenced by factors like the concrete’s compressive strength, mix composition, age at loading, and the magnitude of the sustained stress (relative to strength). In structural design, creep is taken into account because it can increase deflections of beams over time and can cause redistribution of internal forces in statically indeterminate structures. However, keeping sustained stresses low (e.g. by using a higher concrete strength or adding extra reinforcement) can limit the magnitude of creep deformation. Durability is a critical aspect of civil materials engineering, and concrete must be designed to withstand the environmental conditions to which it will be exposed over decades. A key durability concern in cold climates is resistance to freeze–thaw cycles. When porous, saturated concrete freezes, the water in its pores expands about 9% in volume, which can create internal stresses that crack the concrete. Repeated freezing and thawing can cause progressive damage such as surface scaling and loss of strength. To improve freeze–thaw durability, modern concrete often includes air-entraining admixtures that create a network of microscopic air bubbles in the hardened concrete. \nThese tiny air voids (~0.1 mm in size, with a proper spacing factor) act as pressure relief chambers for freezing water, thereby reducing internal stress. Air-entrained concrete can survive hundreds of freeze–thaw cycles without significant deterioration, whereas non-entrained concrete (especially if it has a high w/c ratio and hence high saturation) may suffer severe damage after just a few winters. Another long-term durability issue is chemical attack. For instance, sulfate attack occurs when sulfate ions (from sulfate-rich soils, groundwater, or seawater) penetrate the concrete and react with components of the cement paste (like calcium aluminate hydrates), forming expansive products such as ettringite and gypsum. These expansions can disrupt the concrete’s matrix, causing cracking and loss of cohesion over time. To combat sulfate attack, engineers can use sulfate-resistant cement (with low tricalcium aluminate content), incorporate pozzolanic materials, and ensure the concrete has a low permeability (achieved by a low w/c ratio and adequate curing). Similarly, a deleterious reaction called alkali–silica reaction (ASR) can occur between alkali hydroxides in cement paste and certain reactive silica minerals in some aggregates. ASR produces an expansive gel that swells as it absorbs water, leading to internal pressures and a pattern of map cracking in the concrete over years. To prevent ASR, engineers may use low-alkali cement and incorporate supplementary cementitious materials (like fly ash or slag) to tie up alkalis and dilute the reactive constituents, and they avoid using known reactive aggregates when possible. Moreover, many modern concrete mixtures include supplementary cementitious materials (SCMs) such as fly ash (a by-product from coal power plants), ground granulated blast-furnace slag, and silica fume. These SCMs participate in secondary pozzolanic reactions with the cement hydration products, refining the pore structure of the concrete and often improving its long-term performance. Concretes with SCMs tend to have lower permeability and higher later-age strength, which enhances durability by reducing the ingress of harmful agents. For example, adding fly ash or slag can significantly mitigate sulfate attack and alkali–silica reaction, while silica fume is well known for increasing strength and making the concrete matrix denser. The inclusion of SCMs also has sustainability benefits by recycling industrial by-products and reducing the required amount of Portland cement. Furthermore, reinforcement corrosion is a major threat to reinforced concrete structures, especially in harsh environments. Steel rebar embedded in concrete is normally protected by the high alkalinity of cement paste (which forms a thin passive oxide layer on the steel surface). \nHowever, if chloride ions (for example, from deicing salts or marine spray) penetrate through concrete and reach the steel, they can break down this passive layer and cause corrosion of the rebar. The corrosion products (iron oxides and hydroxides) occupy a greater volume than the original steel, exerting expansive pressure inside the concrete. This leads to cracking and spalling of the concrete cover, further accelerating deterioration. To improve durability against reinforcement corrosion, concrete can be made with low permeability (to slow chloride ingress) by using a low w/c ratio and SCMs; sufficient concrete cover thickness over the steel is provided to lengthen the travel path for chlorides; and sometimes corrosion-inhibiting admixtures or epoxy-coated (or galvanized) rebars are used. Good construction practices, such as adequate curing and avoiding any premature drying or thermal shock, also help produce a dense, impermeable concrete less vulnerable to these forms of attack. In summary, civil engineering materials like concrete must be designed not only for initial strength and workability but also for long-term durability. A well-proportioned concrete mix with an appropriate water–cement ratio, good-quality aggregates, and suitable admixtures can achieve the required strength while remaining sufficiently workable for placement. Through proper curing and quality control, the concrete will develop the desired mechanical properties (high compressive strength, adequate modulus, etc.) and a dense microstructure that resists deleterious agents. Attention to potential deterioration mechanisms – such as freeze–thaw damage, sulfate or chemical attack, ASR, and steel corrosion – is essential to ensure that structures made of concrete remain safe and serviceable throughout their intended life span. Ongoing advancements in materials engineering continue to improve concrete technology, yielding new types such as high-performance concrete (HPC) and fiber-reinforced concrete, which offer enhanced workability, strength, and durability for the infrastructure of the future.",
    "ori_text": " \nConcrete is a composite construction material composed of a cementitious binder (usually Portland cement), water, and aggregates (sand and gravel or crushed stone), along with various admixtures that may be added to modify its properties. When these ingredients are first mixed together, the fresh concrete is a viscoplastic, moldable mixture that can be placed into forms. A series of chemical reactions called cement hydration begins as soon as water contacts the cement particles. Through hydration, the cement paste gradually hardens and gains strength, binding the aggregates together into a solid mass. This transformation from a fluid plastic state to a rigid, load-bearing solid typically occurs within a few hours after mixing (initial setting often happens after around 2 hours for a normal mix). Strength development then continues over time as curing progresses – concrete keeps gaining strength for months or even years, although the rate of strength gain diminishes with time. In practice, the compressive strength measured at 28 days (the 28-day strength) is commonly used as a benchmark of concrete quality (denoted as f’c in many specifications). \nAbout 90% of the long-term strength is usually achieved in the first month under proper curing conditions. Proper curing during this period is critical to concrete quality: the concrete must be prevented from drying out or freezing at early ages. Newly placed concrete is typically kept moist (for example by frequent water spraying or by covering with wet burlap and plastic sheets) and maintained at a suitable temperature. Such curing ensures that hydration can progress and that the concrete’s surface does not crack or lose strength prematurely. If concrete is allowed to dry too soon, it will stop gaining strength and may develop surface shrinkage cracks; if it freezes before sufficient hardening, its internal structure can be disrupted. Therefore, curing measures are often applied for at least 7–14 days to promote good strength and durability development. The strength of hardened concrete depends on many factors, including the mix proportions, the properties of the constituent materials, the curing regime, and the presence of any admixtures or additives. One of the most important factors is the water-to-cement ratio (w/c ratio). This is the ratio of the mass of water to the mass of cement in the mix. A lower w/c ratio generally leads to higher strength and density (since less excess water leaves behind fewer pores in the hardened concrete), but if the w/c is too low, the mix may become unworkable (too stiff and difficult to place). For complete hydration of cement, a minimum w/c of around 0.22–0.25 by weight is needed, but typical structural concrete mixes use a w/c in the range of 0.4 to 0.6 to ensure adequate workability. Workability refers to the ease with which fresh concrete can be mixed, placed, compacted, and finished without segregation. To improve workability without adding excess water (which would reduce strength and increase permeability), chemical admixtures such as plasticizers (water-reducing agents) are often used. For example, a high-range water reducer (superplasticizer) can produce a highly flowable concrete (even self-leveling) at a w/c as low as ~0.30, enabling very high strengths while still allowing the mix to be placed easily. \nA highly workable mix can flow and fill formwork and surround dense reinforcement with relative ease, but if too much water or improper proportions are used, the mix may segregate or bleed. Segregation is the separation of coarse aggregate from the mortar (cement paste and fines) due to settling, resulting in a non-uniform composition. Bleeding is a related phenomenon where excess water rises to the top surface of the concrete before it sets. Both segregation and bleeding indicate an unstable mix; they can cause weak, porous regions and lead to finishing problems or reduced durability in the hardened concrete. Proper mix proportioning and the use of fines and viscosity-modifying admixtures can minimize these issues. The workability of fresh concrete is commonly measured by the slump test, which provides an empirical indication of concrete consistency. In a standard slump test, fresh concrete is placed into a frustum-shaped cone mold (12 inches high) in three layers, and each layer is rodded (tamped) a specified number of times. The mold is then carefully lifted off, and the unsupported concrete slumps under its own weight. The vertical drop of the concrete’s top (measured relative to the mold height) is called the slump. A higher slump (e.g. 7 or 8 inches) indicates a very wet or fluid mix, while a low slump (e.g. 1 inch) indicates a dry, stiff mix. Typical concretes for general construction have slumps in the range of about 2 to 4 inches (50–100 mm) for a good balance of workability and strength. However, slump does not capture all aspects of workability; different mixes can have the same slump yet handle very differently (for instance, one may segregate more easily than another). Other tests and measures (such as flow table tests for mortar, the compaction factor test, or more advanced rheometer tests) can characterize workability, especially for specialized concretes. Still, the slump test remains the simplest and most widely used field test to verify batch-to-batch consistency of concrete and ensure that the fresh mix has not changed. In recent years, self-consolidating concrete (SCC) has been developed as an extremely high-workability mix that can flow and compact under its own weight without vibration. SCC is achieved by using advanced admixtures (superplasticizers) and viscosity-modifying agents to produce a fluid yet stable mix. It demonstrates that with appropriate mix design, one can obtain both high workability and high strength (through a low w/c ratio), which is valuable for placing concrete in structures with congested reinforcement or complex formwork. As the fresh concrete gradually sets and hardens, its properties transition to those of the hardened material. The density of normal-weight concrete is around 2400 kg/m³ (about 150 lb/ft³), and its compressive strength can range widely. Ordinary structural concrete typically achieves a 28-day compressive strength on the order of 20–40 MPa (3000–6000 psi), whereas high-strength concrete used in high-rise buildings or other special applications can reach strengths of 70 MPa (10,000 psi) or more. Concrete’s tensile strength is much lower than its compressive strength (on the order of only 10% of the compressive strength). For this reason, concrete is usually reinforced with steel bars (reinforcing steel, or “rebar”) to carry tension. The stress–strain curve of concrete in compression is nonlinear – unlike steel, concrete does not have a long elastic range or a well-defined yield point. It initially deforms approximately elastically at very low stress, but as stress increases, the curve gradually bends (due to microcracking and increasing inelasticity) and eventually reaches a peak, followed by a drop-off as the concrete fails by crushing. Because there is no sharply defined elastic limit, the modulus of elasticity of concrete is usually defined either as an initial tangent modulus or a secant modulus to a point on the curve (for example, to 50% of ultimate strength). For typical normal-strength concrete, a common empirical approximation is that the Young’s modulus is about 20–30 GPa (gigapascals), which corresponds to around 3 to 5 million psi. \nHigher-strength concretes have higher stiffness, though not in direct proportion to their strength. Volume stability is another important aspect of concrete performance. As concrete cures and dries, it undergoes shrinkage – a reduction in volume. Drying shrinkage occurs as water that is not chemically bound in hydration products gradually evaporates from the hardened concrete. If a large element (like a long slab or wall) is restrained while it is shrinking (for example, by the subgrade or by adjacent structural elements), tensile stresses can develop, potentially leading to cracking. To control crack formation, engineers often incorporate contraction joints (planned grooves or weak planes where shrinkage cracks can form in a controlled way) and provide sufficient distributed reinforcement (sometimes called temperature and shrinkage steel) to hold any cracks tightly closed. Thermal changes can also cause concrete to expand or contract. For instance, the heat released during cement hydration can raise the temperature of a large concrete mass in early-age, and subsequent cooling can induce tensile stresses. In hot weather, rapid surface drying and cooling of freshly placed concrete can cause a surface contraction while the interior is still warm, sometimes leading to a pattern of shallow cracks called thermal cracking. Measures such as gradual cooling of massive pours, insulating blankets, or using low-heat cements help mitigate these thermal stresses. In addition to shrinkage and thermal effects, concrete exhibits creep, which is the long-term gradual deformation under sustained load. Under a constant compressive stress (such as a heavy dead load on a column or beam), concrete will slowly deform over months and years beyond the initial elastic strain – this time-dependent strain is creep. Creep strain can be significant, sometimes on the same order as the initial elastic strain. It is influenced by factors like the concrete’s compressive strength, mix composition, age at loading, and the magnitude of the sustained stress (relative to strength). In structural design, creep is taken into account because it can increase deflections of beams over time and can cause redistribution of internal forces in statically indeterminate structures. However, keeping sustained stresses low (e.g. by using a higher concrete strength or adding extra reinforcement) can limit the magnitude of creep deformation. Durability is a critical aspect of civil materials engineering, and concrete must be designed to withstand the environmental conditions to which it will be exposed over decades. A key durability concern in cold climates is resistance to freeze–thaw cycles. When porous, saturated concrete freezes, the water in its pores expands about 9% in volume, which can create internal stresses that crack the concrete. Repeated freezing and thawing can cause progressive damage such as surface scaling and loss of strength. To improve freeze–thaw durability, modern concrete often includes air-entraining admixtures that create a network of microscopic air bubbles in the hardened concrete. \nThese tiny air voids (~0.1 mm in size, with a proper spacing factor) act as pressure relief chambers for freezing water, thereby reducing internal stress. Air-entrained concrete can survive hundreds of freeze–thaw cycles without significant deterioration, whereas non-entrained concrete (especially if it has a high w/c ratio and hence high saturation) may suffer severe damage after just a few winters. Another long-term durability issue is chemical attack. For instance, sulfate attack occurs when sulfate ions (from sulfate-rich soils, groundwater, or seawater) penetrate the concrete and react with components of the cement paste (like calcium aluminate hydrates), forming expansive products such as ettringite and gypsum. These expansions can disrupt the concrete’s matrix, causing cracking and loss of cohesion over time. To combat sulfate attack, engineers can use sulfate-resistant cement (with low tricalcium aluminate content), incorporate pozzolanic materials, and ensure the concrete has a low permeability (achieved by a low w/c ratio and adequate curing). Similarly, a deleterious reaction called alkali–silica reaction (ASR) can occur between alkali hydroxides in cement paste and certain reactive silica minerals in some aggregates. ASR produces an expansive gel that swells as it absorbs water, leading to internal pressures and a pattern of map cracking in the concrete over years. To prevent ASR, engineers may use low-alkali cement and incorporate supplementary cementitious materials (like fly ash or slag) to tie up alkalis and dilute the reactive constituents, and they avoid using known reactive aggregates when possible. Moreover, many modern concrete mixtures include supplementary cementitious materials (SCMs) such as fly ash (a by-product from coal power plants), ground granulated blast-furnace slag, and silica fume. These SCMs participate in secondary pozzolanic reactions with the cement hydration products, refining the pore structure of the concrete and often improving its long-term performance. Concretes with SCMs tend to have lower permeability and higher later-age strength, which enhances durability by reducing the ingress of harmful agents. For example, adding fly ash or slag can significantly mitigate sulfate attack and alkali–silica reaction, while silica fume is well known for increasing strength and making the concrete matrix denser. The inclusion of SCMs also has sustainability benefits by recycling industrial by-products and reducing the required amount of Portland cement. Furthermore, reinforcement corrosion is a major threat to reinforced concrete structures, especially in harsh environments. Steel rebar embedded in concrete is normally protected by the high alkalinity of cement paste (which forms a thin passive oxide layer on the steel surface). \nHowever, if chloride ions (for example, from deicing salts or marine spray) penetrate through concrete and reach the steel, they can break down this passive layer and cause corrosion of the rebar. The corrosion products (iron oxides and hydroxides) occupy a greater volume than the original steel, exerting expansive pressure inside the concrete. This leads to cracking and spalling of the concrete cover, further accelerating deterioration. To improve durability against reinforcement corrosion, concrete can be made with low permeability (to slow chloride ingress) by using a low w/c ratio and SCMs; sufficient concrete cover thickness over the steel is provided to lengthen the travel path for chlorides; and sometimes corrosion-inhibiting admixtures or epoxy-coated (or galvanized) rebars are used. Good construction practices, such as adequate curing and avoiding any premature drying or thermal shock, also help produce a dense, impermeable concrete less vulnerable to these forms of attack. In summary, civil engineering materials like concrete must be designed not only for initial strength and workability but also for long-term durability. A well-proportioned concrete mix with an appropriate water–cement ratio, good-quality aggregates, and suitable admixtures can achieve the required strength while remaining sufficiently workable for placement. Through proper curing and quality control, the concrete will develop the desired mechanical properties (high compressive strength, adequate modulus, etc.) and a dense microstructure that resists deleterious agents. Attention to potential deterioration mechanisms – such as freeze–thaw damage, sulfate or chemical attack, ASR, and steel corrosion – is essential to ensure that structures made of concrete remain safe and serviceable throughout their intended life span. Ongoing advancements in materials engineering continue to improve concrete technology, yielding new types such as high-performance concrete (HPC) and fiber-reinforced concrete, which offer enhanced workability, strength, and durability for the infrastructure of the future.",
    "reference_list": "1.        “workability” 推荐翻译为 “和易性”，不应该译为“工作性”\n2.       “slump test” 推荐翻译为 “坍落度试验”\n3.       “water-cement ratio (w/c)” 推荐翻译为 “水灰比”\n4.       “curing” 推荐翻译为 “养护”\n5.       “hydration” 推荐翻译为 “水化作用”\n6.       “creep” 推荐翻译为 “徐变”\n7.       “shrinkage” 推荐翻译为 “收缩”\n8.       “segregation” 推荐翻译为 “离析”\n9.       “bleeding” 推荐翻译为 “泌水”\n10.     “air-entraining admixture” 推荐翻译为 “引气剂”\n11.     “freeze–thaw cycle” 推荐翻译为 “冻融循环”\n12.     “sulfate attack” 推荐翻译为 “硫酸盐侵蚀”\n13.     “alkali–silica reaction (ASR)” 推荐翻译为 “碱-硅反应”\n14.     “modulus of elasticity” 推荐翻译为 “弹性模量”\n15.     “map cracking” 推荐翻译为 “龟裂” 或 “龟甲裂缝”，不应该直译为“地图状裂缝”）\n16.     “thermal cracking” 推荐翻译为 “热裂缝” 或 “温度应力裂缝”\n17.     “rebar” 推荐翻译为 “钢筋”\n18.     “creep strain” 推荐翻译为 “徐变应变”\n19.     “impermeable concrete” / “dense concrete” 推荐翻译为 “低渗透性混凝土” 或 “致密混凝土”\n20.     “passive film” 推荐翻译为 “钝化膜”\n21.     “strength gain” 推荐翻译为 “强度发展” 或 “强度增长”\n22.     “superplasticizer” 推荐翻译为 “超塑化剂” 或 “高效减水剂”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "171"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nProvisional Regulations for Transportation in Bond by Rail of Foreign Goods from Treaty Ports in South Manchuria to Treaty Ports in North Manchuria and China Proper via Mukden Kwanchengtze-Changchun and vice versa.（August, 1923, Draft）\nArticle I.  \nApplications for transportation in Bond by rail of foreign goods from the Coast Treaty Ports in South Manchuria and China Proper to the North Manchurian frontier stations of Manchuli and Suifenho and to Harbin via Kwanchengtze-Changchun and vice-versa, shall be made to the Customs by the carriers, i. e. (I) by the South Manchuria Railway Company for foreign goods entering South Manchuria at Antung, Dairen, Newchwang and Changchun, and (II) by the Chinese Eastern Railway for foreign goods entering North Manchuria at Manchouli, Suifenho and Kwanchengtze or despatched from Harbin and (III) by the Peking Mukden Railway for foreign goods entering South Manchuria at Newchwang and Shanhaikwan.\nA list of Treaty Ports and frontier stations to which this procedure applies is enclosed. The Customs notify the Railways on any subsequent changes therein.\n\nArticle II.\nThe South Manchuria Railway Company will enter into a guarantee with the Customs-either annual or for each consignment-that the goods accepted by it for transportation in Bond to North Manchuria are transported solely for the purpose of delivery to the Chinese Eastern Railway at Kwanchengtze-Changchun for further transmission in Bond by that Railway, and that those goods delivered to it at Kwanchentze-Changchun by the Chinese Eastern Railway for transmission in Bond are transported solely for the purpose of being transmitted to places in South Manchuria where Chinese Customs Houses are established, (it being understood that the responsibility of the South Manchuria Railway ceases directly the Goods have been taken over by the Chinese Eastern Railway at Kwangchentze-Changchun or delivered to consignees in South Manchuria after payment of duty), that such goods will only be conveyed in sealed carsor in open cars under seal, when necessary, and that in the event of any portion of the goods (northward-bound) accepted for transportation in Bond to Kwangchentze-Changchun for delivery to the Chinese Eastern Railway at that place for further transmission in Bond under seal not arriving within twenty days at Kwangchentze-Changchun, or (southward-bound) at destination in South Manchuria within the same time limit from the time the goods have been delivered to the South Manchuria Railway at Kwangzhentze-Changchun by the Chinese Eastern Railway, the South Manchuria Railway will pay to the Chinese Maritime Customs at port of entry a sum equal to twice the Import duty plus twice the Transit Dues leviable on that portion of the goods not arrived at Kwangchentze-Changchun (northward-bound) or at destination in South Manchuria (southward). If, owing to Customs or Railway holidays or unforeseen events, such as miscarriage of cargo, etc., other than those (force majeure) provided for separately hereafter, the South Manchuria Railway cannot delivery the goods (northward) at Kwangchentze-Changchun, or (southward) at destination in South Manchuria within the specified time limit, provided that satisfactory explanation be made to the Customs within seven days after expiry of such time limit, the Commissioner of Customs any defer enforcing the terms of the guarantee and extend the time limit for guarantee and extend the time limit for the recovery of the missing goods within a reasonable period. Accidents to the train caused by derailment, collision, fire, or other uncontrollable force (force majeure) will absolve the South Manchuria Railway from the fulfilment of the conditions as to the time limit within which the goods must reach Kwangchentze-Cahngchun or destination in South Manchuria, intact, provided that the Railway immediately informs the Customs as to the nature of the accident, takes proper precautions against pilfering, loss, etc., of the cargo, and detains the cars and/or the goods affected at the nearest convenient station in the event of the Customs seals being broken until receipt of the telegraphic instructions from the Customs Authorities as to what is to be further done.\n\nArticle III.\nAll cargo to be transported (northward) in Bond to Kwangchentze-Changchun for delivery to the Chinese Eastern Railway at that place for further transmission in Bond must be applied for to the Customs at port of entry on a special, “Transportation in Bond Application” in three sections marked “To Kwangchentze-Changchun for delivery to the Chinese Eastern Railway for transmission in Bond to….” Which will contain the following particulars, Marks, Numbers, Numbers of Packages, Description of Packing, Description of Cargo and Weight, Quantity, or Value. These details and to be filled in (according to the Bill of Lading or Train Bill which must accompany the application in duplicate) together with the number of the sealed cars conveying the goods, date, etc., on the triplicate sections of the application. After completion of all necessary Customs formalities at port of entry, the first Section of the application will be retained by the Customs at port of entry and the other two sections will ben forwarded to the Customs Officer at Kwanchengtze-Changchun, or to the Mukden Customs, if for transshipment to the Peking Mukden Railway, who will, after supervising transshipment of the cargo to cars of the Chinese Eastern Railway, or the Peking Mukden Railway, endorse these documents and forward them to the Commissioner of Customs at place of destination, who will return Section II, after endorsement, to the Customs at port of entry and will retain Section III for record. In the case of cargo in Bond from North Manchuria to South Manchuria delivered to the South Manchuria Railway by the Chinese Eastern Railway at Kwangchentze-Changchun Sections II and III of the “Transportation in Bond Application” will be endorsed by the South Manchuria Railway to the effect that the cargo in question has been accepted for transmission to South Manchuria in the terms of their annual guarantee. The South Manchuria Railway will undertake to deliver to the Customs at destination of the goods, such sealed covers containing Customs documents concerning the goods transported in Bond as may be handed to them by the Customs at port of entry or at Kwangchentze-Changchun.\n\nArticle IV.\nCustoms examination in the sense that packages are opened and content inspected need not necessarily take place at the port of entry in the case of cargo to be transported in Bond: but the right to subject any packages to such examination as he may think fit is reserved to the Commissioner of Customs at the port of entry. All such cargo, however, must be forwarded in cars sealed by the Customs at port of entry, or when there is not sufficient cargo to fill a car, in a sealed compartment to which access is impossible without tampering with the seals. Isolated packages of goods which it is desired to transport in Bond may be corded and sealed. The question of providing seals and sealing appliances will be arranged for by the Railway Authorities in consultation with the Customs.\n\nArticle V.\nOn arrival at Kwangchentze-Changchun ori at Mukden the seals will be inspected by the Customs Officer, and if found to be intact permission will be granted to transship such cargo into the Chinese Eastern Railway cars or Peking Mukden Railway cars as the case may be, under Customs supervision (or to be placed in registered godowns until transshipment into the Chinese Eastern Railway cars or Peking Mukden Railway car is ready to take place.) All cargo tallied out and again loaded into the new cars at Kwangchentze-Changchun or at Mukden must agree with the particulars contained in Sections II and III of the original “Transportation in Bond Application” and the train Bill or Bill of Lading accompanying the goods. After all cargo has been duly transhipped, the Customs Officer will seal the cars or the specially reserved portion of cars and will allow them to proceed to destination. At Kwangchentze-Changchun or at Mukden no one but duly authorized Chinese Customs Officer shall be permitted to break or remove Customs seals from Railway cars. The unsealing and resealing of cars, etc., is to be entirely in hands of the Customs Offices.\n\nArticle VI.\nIf at any stage of the journey from port of entry to Kwangchentze-Changchun or vice-versa from Kwangchentze-Changchun to destination in South Manchuria, the Customs selas are discovered to be damaged or missing thus rendering access to, and tampering with, bonded cargo possible; or, of a sealed car and/or bonded goods be damaged en route either through accident as described in Article II or through any other cause; the Railway will immediately communicate by railway telegraph with the nearest convenient station pending receipt of telegraphic instructions from the Customs. It rests then with the Customs Authorities to appoint a special employee or employees – whom the Railway will furnish with free passes for travelling on their lines, - to carry out investigations into the causes of damage to, or loss of, seals, or to commission the Railway to make such investigations, or to authorize the dispatch of the car and/or the goods to one of the Customs stations for investigation. The result of the investigation will be duly entered in a Protocol specially kept for this purpose and signed by the Customs and Railway employees concerned. If at the investigation or upon inspection and comparison of the cargo with documents at the place of accident or at the Customs station to which the car and/or the goods have been directed to proceed, the cargo be found in full agreement with the documents, it will be resealed by the Customs and allowed to proceed without hindrance at the first opportunity, and the necessary remarks and corrections will be made in the accompanying documents. Should however, the loss of the Customs seals be not properly accounted for, and the Customs have cause to suspect tampering with, or substitution of goods, the terms of the guarantee will be enforced by the Customs. If in case of damage through force majeure, it is intended to sell the remaining or the damaged cargo on the spot, Customs permission must be obtained before hand. Import duty (and Transit Dues if liviable) must be paid by the purchaser before delivery of the sold goods.\n\nArticle VII.\nThe transportation in Bond regulations do not apply to native goods for the present, munitions of war, explosives and other dangerous goods, nor to hand baggage and/or registered luggage which are subject to usual examination and duty treatment at port of entry as at present exercised.\n\nArticle VIII.\nThe above regulations are provisional, and subject to alteration, addition, or cancellation as experience may prove to be necessary.\n",
    "ori_text": "\n\nProvisional Regulations for Transportation in Bond by Rail of Foreign Goods from Treaty Ports in South Manchuria to Treaty Ports in North Manchuria and China Proper via Mukden Kwanchengtze-Changchun and vice versa.（August, 1923, Draft）\nArticle I.  \nApplications for transportation in Bond by rail of foreign goods from the Coast Treaty Ports in South Manchuria and China Proper to the North Manchurian frontier stations of Manchuli and Suifenho and to Harbin via Kwanchengtze-Changchun and vice-versa, shall be made to the Customs by the carriers, i. e. (I) by the South Manchuria Railway Company for foreign goods entering South Manchuria at Antung, Dairen, Newchwang and Changchun, and (II) by the Chinese Eastern Railway for foreign goods entering North Manchuria at Manchouli, Suifenho and Kwanchengtze or despatched from Harbin and (III) by the Peking Mukden Railway for foreign goods entering South Manchuria at Newchwang and Shanhaikwan.\nA list of Treaty Ports and frontier stations to which this procedure applies is enclosed. The Customs notify the Railways on any subsequent changes therein.\n\nArticle II.\nThe South Manchuria Railway Company will enter into a guarantee with the Customs-either annual or for each consignment-that the goods accepted by it for transportation in Bond to North Manchuria are transported solely for the purpose of delivery to the Chinese Eastern Railway at Kwanchengtze-Changchun for further transmission in Bond by that Railway, and that those goods delivered to it at Kwanchentze-Changchun by the Chinese Eastern Railway for transmission in Bond are transported solely for the purpose of being transmitted to places in South Manchuria where Chinese Customs Houses are established, (it being understood that the responsibility of the South Manchuria Railway ceases directly the Goods have been taken over by the Chinese Eastern Railway at Kwangchentze-Changchun or delivered to consignees in South Manchuria after payment of duty), that such goods will only be conveyed in sealed carsor in open cars under seal, when necessary, and that in the event of any portion of the goods (northward-bound) accepted for transportation in Bond to Kwangchentze-Changchun for delivery to the Chinese Eastern Railway at that place for further transmission in Bond under seal not arriving within twenty days at Kwangchentze-Changchun, or (southward-bound) at destination in South Manchuria within the same time limit from the time the goods have been delivered to the South Manchuria Railway at Kwangzhentze-Changchun by the Chinese Eastern Railway, the South Manchuria Railway will pay to the Chinese Maritime Customs at port of entry a sum equal to twice the Import duty plus twice the Transit Dues leviable on that portion of the goods not arrived at Kwangchentze-Changchun (northward-bound) or at destination in South Manchuria (southward). If, owing to Customs or Railway holidays or unforeseen events, such as miscarriage of cargo, etc., other than those (force majeure) provided for separately hereafter, the South Manchuria Railway cannot delivery the goods (northward) at Kwangchentze-Changchun, or (southward) at destination in South Manchuria within the specified time limit, provided that satisfactory explanation be made to the Customs within seven days after expiry of such time limit, the Commissioner of Customs any defer enforcing the terms of the guarantee and extend the time limit for guarantee and extend the time limit for the recovery of the missing goods within a reasonable period. Accidents to the train caused by derailment, collision, fire, or other uncontrollable force (force majeure) will absolve the South Manchuria Railway from the fulfilment of the conditions as to the time limit within which the goods must reach Kwangchentze-Cahngchun or destination in South Manchuria, intact, provided that the Railway immediately informs the Customs as to the nature of the accident, takes proper precautions against pilfering, loss, etc., of the cargo, and detains the cars and/or the goods affected at the nearest convenient station in the event of the Customs seals being broken until receipt of the telegraphic instructions from the Customs Authorities as to what is to be further done.\n\nArticle III.\nAll cargo to be transported (northward) in Bond to Kwangchentze-Changchun for delivery to the Chinese Eastern Railway at that place for further transmission in Bond must be applied for to the Customs at port of entry on a special, “Transportation in Bond Application” in three sections marked “To Kwangchentze-Changchun for delivery to the Chinese Eastern Railway for transmission in Bond to….” Which will contain the following particulars, Marks, Numbers, Numbers of Packages, Description of Packing, Description of Cargo and Weight, Quantity, or Value. These details and to be filled in (according to the Bill of Lading or Train Bill which must accompany the application in duplicate) together with the number of the sealed cars conveying the goods, date, etc., on the triplicate sections of the application. After completion of all necessary Customs formalities at port of entry, the first Section of the application will be retained by the Customs at port of entry and the other two sections will ben forwarded to the Customs Officer at Kwanchengtze-Changchun, or to the Mukden Customs, if for transshipment to the Peking Mukden Railway, who will, after supervising transshipment of the cargo to cars of the Chinese Eastern Railway, or the Peking Mukden Railway, endorse these documents and forward them to the Commissioner of Customs at place of destination, who will return Section II, after endorsement, to the Customs at port of entry and will retain Section III for record. In the case of cargo in Bond from North Manchuria to South Manchuria delivered to the South Manchuria Railway by the Chinese Eastern Railway at Kwangchentze-Changchun Sections II and III of the “Transportation in Bond Application” will be endorsed by the South Manchuria Railway to the effect that the cargo in question has been accepted for transmission to South Manchuria in the terms of their annual guarantee. The South Manchuria Railway will undertake to deliver to the Customs at destination of the goods, such sealed covers containing Customs documents concerning the goods transported in Bond as may be handed to them by the Customs at port of entry or at Kwangchentze-Changchun.\n\nArticle IV.\nCustoms examination in the sense that packages are opened and content inspected need not necessarily take place at the port of entry in the case of cargo to be transported in Bond: but the right to subject any packages to such examination as he may think fit is reserved to the Commissioner of Customs at the port of entry. All such cargo, however, must be forwarded in cars sealed by the Customs at port of entry, or when there is not sufficient cargo to fill a car, in a sealed compartment to which access is impossible without tampering with the seals. Isolated packages of goods which it is desired to transport in Bond may be corded and sealed. The question of providing seals and sealing appliances will be arranged for by the Railway Authorities in consultation with the Customs.\n\nArticle V.\nOn arrival at Kwangchentze-Changchun ori at Mukden the seals will be inspected by the Customs Officer, and if found to be intact permission will be granted to transship such cargo into the Chinese Eastern Railway cars or Peking Mukden Railway cars as the case may be, under Customs supervision (or to be placed in registered godowns until transshipment into the Chinese Eastern Railway cars or Peking Mukden Railway car is ready to take place.) All cargo tallied out and again loaded into the new cars at Kwangchentze-Changchun or at Mukden must agree with the particulars contained in Sections II and III of the original “Transportation in Bond Application” and the train Bill or Bill of Lading accompanying the goods. After all cargo has been duly transhipped, the Customs Officer will seal the cars or the specially reserved portion of cars and will allow them to proceed to destination. At Kwangchentze-Changchun or at Mukden no one but duly authorized Chinese Customs Officer shall be permitted to break or remove Customs seals from Railway cars. The unsealing and resealing of cars, etc., is to be entirely in hands of the Customs Offices.\n\nArticle VI.\nIf at any stage of the journey from port of entry to Kwangchentze-Changchun or vice-versa from Kwangchentze-Changchun to destination in South Manchuria, the Customs selas are discovered to be damaged or missing thus rendering access to, and tampering with, bonded cargo possible; or, of a sealed car and/or bonded goods be damaged en route either through accident as described in Article II or through any other cause; the Railway will immediately communicate by railway telegraph with the nearest convenient station pending receipt of telegraphic instructions from the Customs. It rests then with the Customs Authorities to appoint a special employee or employees – whom the Railway will furnish with free passes for travelling on their lines, - to carry out investigations into the causes of damage to, or loss of, seals, or to commission the Railway to make such investigations, or to authorize the dispatch of the car and/or the goods to one of the Customs stations for investigation. The result of the investigation will be duly entered in a Protocol specially kept for this purpose and signed by the Customs and Railway employees concerned. If at the investigation or upon inspection and comparison of the cargo with documents at the place of accident or at the Customs station to which the car and/or the goods have been directed to proceed, the cargo be found in full agreement with the documents, it will be resealed by the Customs and allowed to proceed without hindrance at the first opportunity, and the necessary remarks and corrections will be made in the accompanying documents. Should however, the loss of the Customs seals be not properly accounted for, and the Customs have cause to suspect tampering with, or substitution of goods, the terms of the guarantee will be enforced by the Customs. If in case of damage through force majeure, it is intended to sell the remaining or the damaged cargo on the spot, Customs permission must be obtained before hand. Import duty (and Transit Dues if liviable) must be paid by the purchaser before delivery of the sold goods.\n\nArticle VII.\nThe transportation in Bond regulations do not apply to native goods for the present, munitions of war, explosives and other dangerous goods, nor to hand baggage and/or registered luggage which are subject to usual examination and duty treatment at port of entry as at present exercised.\n\nArticle VIII.\nThe above regulations are provisional, and subject to alteration, addition, or cancellation as experience may prove to be necessary.\n",
    "reference_list": "考点1：“Transportation in Bond”应当译为“保税运输”，或者按照中国海关当时的叫法“通车运”，此时这一短语可以调整为动词使用\n考点 2 ：“Newchwang”应当译为“营口”\n考点 3 ：“guarantee”应当译为“保结”\n考点 4 ：“Chinese Customs Houses”应当译为“中国海关”\n考点 5 ：“sealed carsor”应当译为“封固车厢”或者和“封制车厢”\n考点 6 ：“Transit Dues”应当译为“子口税”\n考点 7 ：“Commissioner of Customs”应当译为“海关税务司”\n考点 8 ：“Train Bill”应当译为“铁路运单”或者“车单”\n考点 9 ：“annual guarantee”应当译为“常年保结”\n考点 10 ：“Provisional Regulations”应当译为“暂行章程”\n考点 11 ：“registered godowns”应当译为“关栈”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "163"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nNeil Diamond to Receive Inspirational Lifetime Achievement Award at 2025 Carousel Ball, Goo Goo Dolls to Perform\nThe charity gala, benefiting Children's Diabetes Foundation, will be held in October.\nUPDATE (July 9): Goo Goo Dolls are set to perform at the 39th annual Carousel Ball at the Hyatt Regency Denver on Oct. 11, honoring music icon Neil Diamond. Previous stars who’ve headlined the ball included Sir Elton John, Celine Dion, Whitney Houston and John Legend.\nGoo Goo Dolls have landed two No. 1 hits on Billboard’s all-genre Radio Songs chart – “Iris,” which held the top spot for a then record 18 weeks in 1998, and “Slide.”\n“We’re excited to take the stage at The Carousel Ball and support an amazing cause,” said Goo Goo Dolls bandmates John Rzeznik and Robby Takac in a joint statement. “The progress the Children’s Diabetes Foundation has made in diabetes research and patient care has brought new hope to countless families and we’re honored to be a part of their special night.”\nPREVIOUSLY (April 29): Neil Diamond is set to receive the Inspirational Lifetime Achievement Award by the Children’s Diabetes Foundation at the 39th Annual Carousel Ball on Oct. 11. The event will be held at the Hyatt Regency Hotel in Denver, near the home of CDF’s primary operations and its clinic and research facility, the Barbara Davis Center for Diabetes.\nDiamond is just the third recipient of the award, following Sidney Poitier (2016) and Diane Warren (2024).\nProceeds from The Carousel Ball benefit CDF and focus on patient support, awareness and diabetes research. The Carousel Balls, which date to 1978, collectively have raised more than $117 million.\nDiamond, 84, has served on CDF’s advisory board and has attended the organization’s fundraisers for many years, including performing in Denver in 2001, as well as at The Carousel of Hope Ball in Beverly Hills in 2012, where he memorably sang an impromptu duet of “Sweet Caroline” with George Clooney.\n“It’s been my absolute joy to have supported the Children’s Diabetes Foundation for so many wonderful years,” Diamond said in a statement. “Barbara Davis and her organization have done an immense amount of good helping kids, adults and their families facing a difficult diagnosis.”\n“Neil Diamond is a once-in-a-generation talent,” event chair Dana Davis and honorary chair Barbara Davis said in a joint statement. “As a bestselling recording artist the world over, he is an undeniable force whose songwriting has earned him countless musical accolades. … For over 35 years, Neil has lent his timeless voice to our efforts to find a cure for diabetes. On behalf of the patients and researchers his generosity has touched, we can’t think of anyone more deserving of our Inspirational Lifetime Achievement Award.”\nDiamond’s career spans nearly 60 years. He landed his first top 10 hit on the Billboard Hot 100, “Cherry, Cherry,” in October 1966. He has notched three No. 1 hits on the Hot 100 — “Cracklin’ Rosie” (1970), “Song Sung Blue” (1972) and “You Don’t Bring Me Flowers,” a duet with Barbra Streisand (1978). Diamond finally topped the Billboard 200 in 2008, nearly 42 years after he first made that chart, with Home Before Dark.\nDiamond was elected to the Songwriters Hall of Fame in 1984 and has received two additional awards from that organization — the Sammy Cahn Lifetime Achievement in 2000 and the Johnny Mercer Award (their top honor) in 2018.\nAdditionally, Diamond received MusiCares’ Person of the Year Award in 2009, the Kennedy Center Honors in 2011 and a lifetime achievement award from the Recording Academy in 2018. He was voted into the Rock & Roll Hall of Fame in 2011. His achievements also include a Grammy, a Golden Globe Award, an American Music Award, an ASCAP Film and Television Award and a Billboard Icon Award.\nIn addition to the award to Diamond, The MacMillan Family will be honored with the High Hopes Tribute Award for their nearly three decades of commitment as supporters of CDF. To purchase tickets and tables and learn more about the event, visit the Children’s Diabetes Foundation’s site.\nJelly Roll, Lainey Wilson, Luke Combs & Rissi Palmer Among ACM Special Awards Honorees\nThis year's ACM Honors will be held at Nashville venue The Pinnacle on Aug. 20.\nJelly Roll, Lainey Wilson, Eric Church, Rissi Palmer, Randy Travis, Luke Combs and Cody Johnson are among this year’s recipients of the Academy of Country Music’s special awards, and will be feted during the 18th Academy of Country Music Honors celebration, which will take place Wednesday, Aug. 20, at The Pinnacle in Nashville.\nJelly Roll will be honored with the ACM lifting lives award, which recognizes a country music artist, duo/group or industry member who has devoted themselves to improving lives through music and is committed to serving others. The honor is voted on by the ACM lifting lives board of directors. Jelly Roll is being honored for his philanthropic work. He teamed with Live Nation to donate $1 from each ticket sold on his Backroad Baptism Tour, raising more than $600,000 for at-risk youth. He has also visited over 10 juvenile facilities, four rehabilitation centers and several homeless shelters to help bring hope and encouragement. He also testified before Congress to advocate for the Fentanyl Eradication and Narcotics Deterrence Off Fentanyl Act.\nChurch and Ben Vaughn, president/CEO of Warner Chappell Music Nashville until his passing earlier this year, are the recipients of the ACM icon award, given to presented to a country music artist, duo/group or industry leader who has advanced the popularity of the genre through their contributions throughout their career. Church, a seven-time ACM Award winner, spearheaded the Concert for Carolina alongside Luke Combs, raising more than $24 million for Hurricane Helene relief efforts. For Church’s 2024 release “Darkest Hour,” he signed over all of his publishing royalties to aid those impacted by the floods in his homestate of North Carolina. During his career leading Warner Chappell Music Nashville, Vaughn was instrumental in developing numerous artists and songwriters including Dan+Shay, Kacey Musgraves, Lady A, Thomas Rhett and Chris Stapleton.\nJohnson is the recipient of the ACM spirit award, inspired by the late country music legend Merle Haggard. The award is presented to a singer-songwriter who continues the legacy of Haggard by following their own path, crafting compelling songs and presenting them through high-caliber performances. Johnson has earned two No. 1 Billboard Country Airplay hits, “‘Til You Can’t” and “The Painter.”\nCombs will be honored with the ACM international award, which celebrates a country music artist, duo/group or industry leader for outstanding contributions to the growth of country music globally. Combs’ headlining tours have sold out in the U.K., Ireland, the Netherlands and Australia, demonstrating his global appeal and fanbase.\nPalmer will be feted with the ACM’s lift every voice award, which is presented to a country music artist, duo/group, industry leader or affiliate/partner who elevates underrepresented voices in the country music genre. The nominee for this category is proposed by the rising leaders in the ACM’s LEVel UP: Lift Every Voice professional development program. In addition to leading her own music career, Palmer is the creator and host of Apple Music’s Color Me Country Radio with Rissi Palmer, which celebrates diversity and inclusion in the country music genre and spotlights artists of color.\nMac McAnally will be recognized with the ACM poet’s award, which honors a country music songwriter for longstanding musical contributions to country music. In addition to writing his own music, this Nashville Songwriters Hall of Fame member has had songs recorded by Jimmy Buffett (“It’s My Job”) Kenny Chesney (“Down the Road”), Alabama (“Old Flame”), Sawyer Brown (“I Will Leave the Light On”), Shenandoah (“Two Dozen Roses”) and more.\nCountry Music Hall of Fame member Travis will be honored as the recipient of the ACM milestone award, which is presented to a country music artist, duo/group or industry leader for outstanding achievements in country music during the preceding calendar year. Travis incorporated AI-assisted vocals to re-imagine and revive older and previously unheard songs, preserving and continuing his unmistakable sound.\nThe ACM film award, which recognizes an outstanding movie, series or feature film released during the preceding calendar year that prominently features country music, will be presented for the film Twisters. The film’s soundtrack featured music from Luke Combs, Megan Moroney, Jelly Roll and more.\nExecutive Lori Badgett is the recipient of the ACM service award, which is given to an outstanding country music artist, duo/group or industry leader to recognize years of dedication and service to the ACM. In her work at City National Bank, Badgett has helped establish the bank’s presence in Nashville and she now plays an essential role in the ACM and its charitable arm ACM Lifting Lives, having chaired both organizations. Badgett’s leadership was instrumental in the Academy’s transition from Los Angeles to Nashville and she continues to serve on multiple committees for both organizations.",
    "ori_text": "Neil Diamond to Receive Inspirational Lifetime Achievement Award at 2025 Carousel Ball, Goo Goo Dolls to Perform\nThe charity gala, benefiting Children's Diabetes Foundation, will be held in October.\nUPDATE (July 9): Goo Goo Dolls are set to perform at the 39th annual Carousel Ball at the Hyatt Regency Denver on Oct. 11, honoring music icon Neil Diamond. Previous stars who’ve headlined the ball included Sir Elton John, Celine Dion, Whitney Houston and John Legend.\nGoo Goo Dolls have landed two No. 1 hits on Billboard’s all-genre Radio Songs chart – “Iris,” which held the top spot for a then record 18 weeks in 1998, and “Slide.”\n“We’re excited to take the stage at The Carousel Ball and support an amazing cause,” said Goo Goo Dolls bandmates John Rzeznik and Robby Takac in a joint statement. “The progress the Children’s Diabetes Foundation has made in diabetes research and patient care has brought new hope to countless families and we’re honored to be a part of their special night.”\nPREVIOUSLY (April 29): Neil Diamond is set to receive the Inspirational Lifetime Achievement Award by the Children’s Diabetes Foundation at the 39th Annual Carousel Ball on Oct. 11. The event will be held at the Hyatt Regency Hotel in Denver, near the home of CDF’s primary operations and its clinic and research facility, the Barbara Davis Center for Diabetes.\nDiamond is just the third recipient of the award, following Sidney Poitier (2016) and Diane Warren (2024).\nProceeds from The Carousel Ball benefit CDF and focus on patient support, awareness and diabetes research. The Carousel Balls, which date to 1978, collectively have raised more than $117 million.\nDiamond, 84, has served on CDF’s advisory board and has attended the organization’s fundraisers for many years, including performing in Denver in 2001, as well as at The Carousel of Hope Ball in Beverly Hills in 2012, where he memorably sang an impromptu duet of “Sweet Caroline” with George Clooney.\n“It’s been my absolute joy to have supported the Children’s Diabetes Foundation for so many wonderful years,” Diamond said in a statement. “Barbara Davis and her organization have done an immense amount of good helping kids, adults and their families facing a difficult diagnosis.”\n“Neil Diamond is a once-in-a-generation talent,” event chair Dana Davis and honorary chair Barbara Davis said in a joint statement. “As a bestselling recording artist the world over, he is an undeniable force whose songwriting has earned him countless musical accolades. … For over 35 years, Neil has lent his timeless voice to our efforts to find a cure for diabetes. On behalf of the patients and researchers his generosity has touched, we can’t think of anyone more deserving of our Inspirational Lifetime Achievement Award.”\nDiamond’s career spans nearly 60 years. He landed his first top 10 hit on the Billboard Hot 100, “Cherry, Cherry,” in October 1966. He has notched three No. 1 hits on the Hot 100 — “Cracklin’ Rosie” (1970), “Song Sung Blue” (1972) and “You Don’t Bring Me Flowers,” a duet with Barbra Streisand (1978). Diamond finally topped the Billboard 200 in 2008, nearly 42 years after he first made that chart, with Home Before Dark.\nDiamond was elected to the Songwriters Hall of Fame in 1984 and has received two additional awards from that organization — the Sammy Cahn Lifetime Achievement in 2000 and the Johnny Mercer Award (their top honor) in 2018.\nAdditionally, Diamond received MusiCares’ Person of the Year Award in 2009, the Kennedy Center Honors in 2011 and a lifetime achievement award from the Recording Academy in 2018. He was voted into the Rock & Roll Hall of Fame in 2011. His achievements also include a Grammy, a Golden Globe Award, an American Music Award, an ASCAP Film and Television Award and a Billboard Icon Award.\nIn addition to the award to Diamond, The MacMillan Family will be honored with the High Hopes Tribute Award for their nearly three decades of commitment as supporters of CDF. To purchase tickets and tables and learn more about the event, visit the Children’s Diabetes Foundation’s site.\nJelly Roll, Lainey Wilson, Luke Combs & Rissi Palmer Among ACM Special Awards Honorees\nThis year's ACM Honors will be held at Nashville venue The Pinnacle on Aug. 20.\nJelly Roll, Lainey Wilson, Eric Church, Rissi Palmer, Randy Travis, Luke Combs and Cody Johnson are among this year’s recipients of the Academy of Country Music’s special awards, and will be feted during the 18th Academy of Country Music Honors celebration, which will take place Wednesday, Aug. 20, at The Pinnacle in Nashville.\nJelly Roll will be honored with the ACM lifting lives award, which recognizes a country music artist, duo/group or industry member who has devoted themselves to improving lives through music and is committed to serving others. The honor is voted on by the ACM lifting lives board of directors. Jelly Roll is being honored for his philanthropic work. He teamed with Live Nation to donate $1 from each ticket sold on his Backroad Baptism Tour, raising more than $600,000 for at-risk youth. He has also visited over 10 juvenile facilities, four rehabilitation centers and several homeless shelters to help bring hope and encouragement. He also testified before Congress to advocate for the Fentanyl Eradication and Narcotics Deterrence Off Fentanyl Act.\nChurch and Ben Vaughn, president/CEO of Warner Chappell Music Nashville until his passing earlier this year, are the recipients of the ACM icon award, given to presented to a country music artist, duo/group or industry leader who has advanced the popularity of the genre through their contributions throughout their career. Church, a seven-time ACM Award winner, spearheaded the Concert for Carolina alongside Luke Combs, raising more than $24 million for Hurricane Helene relief efforts. For Church’s 2024 release “Darkest Hour,” he signed over all of his publishing royalties to aid those impacted by the floods in his homestate of North Carolina. During his career leading Warner Chappell Music Nashville, Vaughn was instrumental in developing numerous artists and songwriters including Dan+Shay, Kacey Musgraves, Lady A, Thomas Rhett and Chris Stapleton.\nJohnson is the recipient of the ACM spirit award, inspired by the late country music legend Merle Haggard. The award is presented to a singer-songwriter who continues the legacy of Haggard by following their own path, crafting compelling songs and presenting them through high-caliber performances. Johnson has earned two No. 1 Billboard Country Airplay hits, “‘Til You Can’t” and “The Painter.”\nCombs will be honored with the ACM international award, which celebrates a country music artist, duo/group or industry leader for outstanding contributions to the growth of country music globally. Combs’ headlining tours have sold out in the U.K., Ireland, the Netherlands and Australia, demonstrating his global appeal and fanbase.\nPalmer will be feted with the ACM’s lift every voice award, which is presented to a country music artist, duo/group, industry leader or affiliate/partner who elevates underrepresented voices in the country music genre. The nominee for this category is proposed by the rising leaders in the ACM’s LEVel UP: Lift Every Voice professional development program. In addition to leading her own music career, Palmer is the creator and host of Apple Music’s Color Me Country Radio with Rissi Palmer, which celebrates diversity and inclusion in the country music genre and spotlights artists of color.\nMac McAnally will be recognized with the ACM poet’s award, which honors a country music songwriter for longstanding musical contributions to country music. In addition to writing his own music, this Nashville Songwriters Hall of Fame member has had songs recorded by Jimmy Buffett (“It’s My Job”) Kenny Chesney (“Down the Road”), Alabama (“Old Flame”), Sawyer Brown (“I Will Leave the Light On”), Shenandoah (“Two Dozen Roses”) and more.\nCountry Music Hall of Fame member Travis will be honored as the recipient of the ACM milestone award, which is presented to a country music artist, duo/group or industry leader for outstanding achievements in country music during the preceding calendar year. Travis incorporated AI-assisted vocals to re-imagine and revive older and previously unheard songs, preserving and continuing his unmistakable sound.\nThe ACM film award, which recognizes an outstanding movie, series or feature film released during the preceding calendar year that prominently features country music, will be presented for the film Twisters. The film’s soundtrack featured music from Luke Combs, Megan Moroney, Jelly Roll and more.\nExecutive Lori Badgett is the recipient of the ACM service award, which is given to an outstanding country music artist, duo/group or industry leader to recognize years of dedication and service to the ACM. In her work at City National Bank, Badgett has helped establish the bank’s presence in Nashville and she now plays an essential role in the ACM and its charitable arm ACM Lifting Lives, having chaired both organizations. Badgett’s leadership was instrumental in the Academy’s transition from Los Angeles to Nashville and she continues to serve on multiple committees for both organizations.",
    "reference_list": "考点1：【Carousel Ball】应统一译为“旋转木马慈善舞会”\n考点2：【Inspirational Lifetime Achievement Award】推荐译为“励志终身成就奖”\n考点3：【Goo Goo Dolls】为知名摇滚乐队，应保留原文名，不加译名，若解释性加注，可注明为“咕咕玩偶（Goo Goo Dolls）”。\n考点4：【Songwriters Hall of Fame】应统一译为“词曲作者名人堂”。\n考点5：【MusiCares' Person of the Year】应译为“年度音乐关怀人物奖”\n考点6：【AI-assisted vocals】推荐译为“AI辅助的人声重建技术”，不可译为“AI歌声”或“机器人声音”。\n考点7：奖项名称应统一保留机构缩写，如：“ASCAP Film and Television Award”→ “ASCAP影视奖”；“ACM Spirit Award”→ “ACM精神奖”\n考点8：【ACM Lift Every Voice Award】应译为“ACM群声之上奖”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "71"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThis then returns me to the question of an aesthetics of care. If as I have already argued a care based ethics helps raise questions of justice and ‘other regarding effort’, how might art making be judged from this perspective? The starting point is the notion of relations and the simplistic statement that art making takes place in a series of relational acts, some more explicit and intentional than others. Where an ethics of care focuses upon the values inherent, exhibited or perhaps desired within these human interdependencies, the aesthetics of care seeks to focus upon how the sensory and affective are realised in human relations fostered in art projects. The French art theorist Nicolas Bourriaud is a useful point of departure here in his work on relational aesthetics. Bourriaud deﬁnes a relational aesthetic as a ‘set of artistic practices which take as their theoretical and practical point of departure the whole of human relations and their social context, rather than an independent and private space’ (2011, 113) and his book announced from the perspective of the late 1990s French visual art scene how ‘for some years now, there has been an upsurge of convivial, user-friendly artistic projects, festive, collective and participatory, exploring the varied potential in the relationship to the other’ (61). Bourriaud’s work appears to attach an implicit value to this upsurge, with the ‘angelic programme’ I mentioned at the top of the article being instigated in order ‘to patiently re-stitch the relational fabric’ (36) and ‘turn the beholder into the neighbour’ (43). However, ultimately he is more concerned with the formal aspects of this trajectory than the potential that new relational practices have for announcing or creating a fairer world. Inventing new neighbourly relations today, he asserts, is disconnected from programmes that seek to foster ‘happier tomorrows’ (45). As the writing above on the ethics of care would suggest, and the contract of mutual regard urged by Geras, the values that can be materialised in the convivial should in fact be the ground on which happier tomorrows are built. The power of the concept of relational aesthetics is weakened by the fact it does not suggest why relations with others might be endorsed or what type of relations we might aspire to develop. If the socially critical inference in the notion of relational aesthetics is to have greater explicit ethical weight, and to move from a moderately interesting description of a form to a movement with more normative clout, it needs to be reﬁgured. And the argument here is that thinking in terms of an aesthetics of care might provide this reorientation.\n\nAn ‘aesthetics of care’ is then about a set of values realised in a relational process that emphasise engagements between individuals or groups over time. It is one that might consist of small creative encounters or large-scale exhibitions, but it is always one that notices inter-human relations in both the creation and the display of art projects. It is an aesthetics that is unafraid to lay bare what Shannon Jackson calls the ‘supporting infrastructures of [ … ] living beings’ (2011, 39), but importantly this is an aesthetics that could both present those mutually beneﬁcial structures and foster them. It would not pretend to a distinction between a process and an outcome because both might stimulate affective solidarity between people – perhaps participant to participant or performer to audience. There is a sense that this aesthetics would value intimacy, but it would not be at the expense of what Nato Thompson refers to as ‘explicitly local, long-term, and community-based’ engagement (2012, 31). While care might be exhibited ﬂeetingly, it is more likely that care aesthetics would be realised in more enduring, crafted encounters between people. Seeking to overcome widespread social indifference implies commitment to deep and extended processes.\n\nAt the beginning of the article it was noted that the ethics of care is a reference to both a set of values and a practice. This is repeated in this proposal for an aesthetics of care, so that it suggests both a demonstration of mutual regard, but simultaneously it instigates a process that is seeking to create or secure it. Amin asserts that there is a process of cultivation in his project for overcoming the disregard experienced in a society of strangers. It is a ‘craft that requires continual attentiveness and care, such that empathy – for objects, projects, nature, the commons – can spread as a public sentiment that also serves to regulate feelings among strangers’ (2012, 7). Attentiveness (a term also found in Tronto (2013, 34)) is both at the heart of the creative process, and the outcome of it. An aesthetics of care is, therefore, a sensory ethical practice, that following Robinson, involves ‘not only learning how to be attentive and patient, how to listen and respond, but also how to rethink our own attitudes about difference and exclusion’ (1999, 164).\n\nThe difﬁculty in nurturing an ethics of care through an aesthetic process should of course be acknowledged. Kester in talking about participatory modes of art making explains it as a ‘temporally extensive form of social interaction in which models of expression, enunciation, and reception are continuously modiﬁed and reciprocally responsive’ (2011, 112). It is a form of crafted caring where learning to create, respond and be in close dialogue with others is vital for the quality of the experience: but it is a ‘temporally extensive form’ because it needs to be ‘continuously modiﬁed’ as it is practiced. In order to outline something of the shape of that form, the remainder of this article will divide care aesthetics into preparation, execution and exhibition, where each of these moments might be minutely connected but they are also likely to be dispersed over a long period. First, preparation would involve an openness and honesty of intention, the selection of artists or participants and questions of the location of a project. Decisions about accessibility (whether in terms of the appropriateness of the space for disabled people, the location in terms of costs of travel or the timing for people with different commitments) are not mundane organisational matters, but crucial ethical propositions. In being taken in reference to the ethics of care, they will imbue the project with an affective sense of the importance of mutual respect and regard. Jackson’s ‘supporting infrastructures’ are not the hidden mechanism of creative endeavour but a valued component of the aesthetics. Preparation is, therefore, paradoxically part of the exhibition within this mode of artistic project: it can demonstrate and model a form of mutual regard. There is a sensory quality in the relationships to which a project that prepares in this way aspires.\n\nThe notion of execution focuses on the process of collaborative working on artistic projects which forge inter-human relationships. The emerging connections between individuals coalescing in this process have an aesthetics – a shape, feel, sensation and affect. This does not exist within one particular person or object of the work, but appears in-between those involved, so that there is a sensory quality of the process and outcome that cannot be disaggregated from the collective effort. This connects to Richard Sennett’s work on the history and practice of cooperation. His conviction that a practice of working together, and his central example of the Hull House settlement in Chicago, demonstrates that a shared commitment to building caring relations turns ‘people outward in shared, symbolic acts’ and these in turn have a potential place in countering a society that is ﬁgured ‘brutally simple: us-againstthem coupled with you-are-on-your-own’ (Sennett 2012, 280). For theatre this form of cooperation might involve a challenge to the quality and texture of a rehearsal or devising experience so that the reciprocity of gradual creation is valued over and above the discipline of the single-minded voyage towards the ﬁrst night. Those intimate negotiations are the aesthetics of the project, and not merely an unremarkable preparatory period. Borrowing from David Gauntlett’s work on craft, there is a suggestion that within a creative process the power is realised ‘in gentle and quiet ways, with no need for grand celebratory announcements’ (2011, 66). This is not meant as a dismissal of the art of public theatre making as part of the search for a more care-full aesthetics, but it does suggest that ‘actively seeking out opportunities to be creative together’ (67) might be a good starting point where the show is not always the thing. I would argue that there is a boldness and important aesthetic quality in work that ‘seeks no external recognition’ (66) because it implies that aesthetic value is found in co-created moments and not only in public display. The execution of a project ﬁgured around an aesthetic of care, therefore, relies on building mutual activities of sharing, support, co-working and relational solidarity within a framework of artistry or creative endeavour. Aesthetic value is located in-between people in moments of collaborative creation, conjoined effort and intimate exchange: these are new virtuosities of care that do not rely on the singular display of self-honed skill.\n\n",
    "ori_text": "\n\nThis then returns me to the question of an aesthetics of care. If as I have already argued a care based ethics helps raise questions of justice and ‘other regarding effort’, how might art making be judged from this perspective? The starting point is the notion of relations and the simplistic statement that art making takes place in a series of relational acts, some more explicit and intentional than others. Where an ethics of care focuses upon the values inherent, exhibited or perhaps desired within these human interdependencies, the aesthetics of care seeks to focus upon how the sensory and affective are realised in human relations fostered in art projects. The French art theorist Nicolas Bourriaud is a useful point of departure here in his work on relational aesthetics. Bourriaud deﬁnes a relational aesthetic as a ‘set of artistic practices which take as their theoretical and practical point of departure the whole of human relations and their social context, rather than an independent and private space’ (2011, 113) and his book announced from the perspective of the late 1990s French visual art scene how ‘for some years now, there has been an upsurge of convivial, user-friendly artistic projects, festive, collective and participatory, exploring the varied potential in the relationship to the other’ (61). Bourriaud’s work appears to attach an implicit value to this upsurge, with the ‘angelic programme’ I mentioned at the top of the article being instigated in order ‘to patiently re-stitch the relational fabric’ (36) and ‘turn the beholder into the neighbour’ (43). However, ultimately he is more concerned with the formal aspects of this trajectory than the potential that new relational practices have for announcing or creating a fairer world. Inventing new neighbourly relations today, he asserts, is disconnected from programmes that seek to foster ‘happier tomorrows’ (45). As the writing above on the ethics of care would suggest, and the contract of mutual regard urged by Geras, the values that can be materialised in the convivial should in fact be the ground on which happier tomorrows are built. The power of the concept of relational aesthetics is weakened by the fact it does not suggest why relations with others might be endorsed or what type of relations we might aspire to develop. If the socially critical inference in the notion of relational aesthetics is to have greater explicit ethical weight, and to move from a moderately interesting description of a form to a movement with more normative clout, it needs to be reﬁgured. And the argument here is that thinking in terms of an aesthetics of care might provide this reorientation.\n\nAn ‘aesthetics of care’ is then about a set of values realised in a relational process that emphasise engagements between individuals or groups over time. It is one that might consist of small creative encounters or large-scale exhibitions, but it is always one that notices inter-human relations in both the creation and the display of art projects. It is an aesthetics that is unafraid to lay bare what Shannon Jackson calls the ‘supporting infrastructures of [ … ] living beings’ (2011, 39), but importantly this is an aesthetics that could both present those mutually beneﬁcial structures and foster them. It would not pretend to a distinction between a process and an outcome because both might stimulate affective solidarity between people – perhaps participant to participant or performer to audience. There is a sense that this aesthetics would value intimacy, but it would not be at the expense of what Nato Thompson refers to as ‘explicitly local, long-term, and community-based’ engagement (2012, 31). While care might be exhibited ﬂeetingly, it is more likely that care aesthetics would be realised in more enduring, crafted encounters between people. Seeking to overcome widespread social indifference implies commitment to deep and extended processes.\n\nAt the beginning of the article it was noted that the ethics of care is a reference to both a set of values and a practice. This is repeated in this proposal for an aesthetics of care, so that it suggests both a demonstration of mutual regard, but simultaneously it instigates a process that is seeking to create or secure it. Amin asserts that there is a process of cultivation in his project for overcoming the disregard experienced in a society of strangers. It is a ‘craft that requires continual attentiveness and care, such that empathy – for objects, projects, nature, the commons – can spread as a public sentiment that also serves to regulate feelings among strangers’ (2012, 7). Attentiveness (a term also found in Tronto (2013, 34)) is both at the heart of the creative process, and the outcome of it. An aesthetics of care is, therefore, a sensory ethical practice, that following Robinson, involves ‘not only learning how to be attentive and patient, how to listen and respond, but also how to rethink our own attitudes about difference and exclusion’ (1999, 164).\n\nThe difﬁculty in nurturing an ethics of care through an aesthetic process should of course be acknowledged. Kester in talking about participatory modes of art making explains it as a ‘temporally extensive form of social interaction in which models of expression, enunciation, and reception are continuously modiﬁed and reciprocally responsive’ (2011, 112). It is a form of crafted caring where learning to create, respond and be in close dialogue with others is vital for the quality of the experience: but it is a ‘temporally extensive form’ because it needs to be ‘continuously modiﬁed’ as it is practiced. In order to outline something of the shape of that form, the remainder of this article will divide care aesthetics into preparation, execution and exhibition, where each of these moments might be minutely connected but they are also likely to be dispersed over a long period. First, preparation would involve an openness and honesty of intention, the selection of artists or participants and questions of the location of a project. Decisions about accessibility (whether in terms of the appropriateness of the space for disabled people, the location in terms of costs of travel or the timing for people with different commitments) are not mundane organisational matters, but crucial ethical propositions. In being taken in reference to the ethics of care, they will imbue the project with an affective sense of the importance of mutual respect and regard. Jackson’s ‘supporting infrastructures’ are not the hidden mechanism of creative endeavour but a valued component of the aesthetics. Preparation is, therefore, paradoxically part of the exhibition within this mode of artistic project: it can demonstrate and model a form of mutual regard. There is a sensory quality in the relationships to which a project that prepares in this way aspires.\n\nThe notion of execution focuses on the process of collaborative working on artistic projects which forge inter-human relationships. The emerging connections between individuals coalescing in this process have an aesthetics – a shape, feel, sensation and affect. This does not exist within one particular person or object of the work, but appears in-between those involved, so that there is a sensory quality of the process and outcome that cannot be disaggregated from the collective effort. This connects to Richard Sennett’s work on the history and practice of cooperation. His conviction that a practice of working together, and his central example of the Hull House settlement in Chicago, demonstrates that a shared commitment to building caring relations turns ‘people outward in shared, symbolic acts’ and these in turn have a potential place in countering a society that is ﬁgured ‘brutally simple: us-againstthem coupled with you-are-on-your-own’ (Sennett 2012, 280). For theatre this form of cooperation might involve a challenge to the quality and texture of a rehearsal or devising experience so that the reciprocity of gradual creation is valued over and above the discipline of the single-minded voyage towards the ﬁrst night. Those intimate negotiations are the aesthetics of the project, and not merely an unremarkable preparatory period. Borrowing from David Gauntlett’s work on craft, there is a suggestion that within a creative process the power is realised ‘in gentle and quiet ways, with no need for grand celebratory announcements’ (2011, 66). This is not meant as a dismissal of the art of public theatre making as part of the search for a more care-full aesthetics, but it does suggest that ‘actively seeking out opportunities to be creative together’ (67) might be a good starting point where the show is not always the thing. I would argue that there is a boldness and important aesthetic quality in work that ‘seeks no external recognition’ (66) because it implies that aesthetic value is found in co-created moments and not only in public display. The execution of a project ﬁgured around an aesthetic of care, therefore, relies on building mutual activities of sharing, support, co-working and relational solidarity within a framework of artistry or creative endeavour. Aesthetic value is located in-between people in moments of collaborative creation, conjoined effort and intimate exchange: these are new virtuosities of care that do not rely on the singular display of self-honed skill.\n\n",
    "reference_list": "考点1：relational acts 推荐翻译为“关系实践”\n考点2：‘other regarding effort’ 推荐翻译为“关怀他人的努力”\n考点3：supporting infrastructures 推荐翻译为“支撑性基础设施”\n考点4：user-friendly artistic projects 推荐翻译为“公众易参与的艺术项目”或“亲和型艺术实践”\n考点5：Hull House 推荐翻译为“赫尔馆”\n考点6：relational fabric 推荐翻译为“关系纽带”\n考点7：theater 推荐翻译为“戏剧”\n考点8：Nicolas Bourriaud 推荐翻译为“尼古拉斯·伯瑞奥德”\n考点9：Geras (David Geras) 推荐翻译为“吉拉斯”\n考点10：Tronto (Joan C. Tronto) 推荐翻译为“特朗托”\n考点11：Richard Sennett 推荐翻译为“理查德·桑内特”\n考点12：David Gauntlett 推荐翻译为“戴维·冈特莱特”\n考点13：Nato Thompson 推荐翻译为“内托·汤普森”\n考点14：reciprocity推荐翻译为“交互性”\n考点15：useful point of departure 推荐译为“一个切实的出发点”，不可译为“一个实用的出发”\n考点16：\"temporally extensive form\"推荐译为“短暂深入的过程”\n考点17：\"figured\"推荐译为“被塑造”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "167"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n第78届戛纳电影节于周六在法国落幕，伊朗异议导演贾法·帕纳希（Jafar Panahi）凭借地下拍摄的复仇题材影片《那只是个意外》（It Was Just an Accident）摘得金棕榈奖，引发全场起立鼓掌。这位因政治立场曾被伊朗当局软禁和入狱的导演，首次在15年内获准亲自到场领奖。 该片讲述五名前政治犯与当年监狱施暴者重逢的故事，由帕纳希的真实囚禁经历启发创作。在发表感言时，帕纳希呼吁全球伊朗人团结起来：“最重要的是我们的国家和自由。”影片反映他在伊文监狱的经历，也象徵着对压迫制度的反抗。 帕纳希曾因出席绿色革命遇难学生葬礼遭伊朗政府禁拍、禁行15年。尽管如此，他持续以秘密方式拍片，作品曾通过USB偷偷送出伊朗。本次夺冠的影片正是在这样的背景下拍摄而成，堪称其生涯的巅峰之一。\n\n评审团特别奖授予中国导演毕赣的《狂野时代》，这是一部融合历史与科幻元素的电影，讲述一个女人被带到了末世后的未来，在那里，她试图修复一个半机器半人的男人，向他隐喻讲述中国历史的部分内容。之后，她必须做出选择，是回到现实世界，还是继续与这个仿生人独处。 本届电影节不仅是一场电影盛宴，也是政治表达的舞台。在美国总统特朗普宣称考虑对海外影片征收100%关税后，不少导演发出批评声音。此外，评审团主席朱丽叶·比诺什（Juliette Binoche）在颁奖典礼上表示：“艺术终将胜利，人性终将胜利。”\n\n电影节闭幕当天，戛纳所在地区遭遇大规模停电，导致交通信号灯和ATM瘫痪，电影节组织方紧急启动备用发电机维持晚间活动顺利进行。据当地检察院称，位于尼斯和戛纳之间的小镇卢贝镇的一座高压电线塔的四根支柱中有三根被锯断。由于损坏，电网运营商不得不关闭该线路。这间接导致了戛纳大规模停电。此外，坦内隆镇的一个变电站也发生火灾。法国当局怀疑这两起案件都是蓄意破坏。调查工作正在进行之中。\n\n**获奖名单——**\n\n主竞赛单元\n\n金棕榈最佳影片：《普通事故》，贾法·帕纳西导演\n\n评委会大奖：《情感价值》，约阿希姆·提尔导演\n\n最佳女演员：纳迪亚·梅利蒂《最小的女儿》\n\n最佳导演：小克莱伯·门多萨《秘密特工》\n\n评审团奖(双黄)：《接近终点》，奥利维尔·拉克谢导演&《望向太阳》 ，玛莎·施林斯基导演\n\n最佳编剧：达内兄弟《年轻母亲之家》\n\n最佳男演员：瓦格纳·马拉《秘密特工》\n\n特别奖：《狂野时代》毕赣\n\n短片单元\n\n短片金棕榈：《我很高兴你现在死了》，托菲克·巴霍姆导演\n\n短片特别提及：《阿里》，阿德南·拉杰夫导演\n\n金摄影机(表彰首部导演作品)\n\n金摄影机奖：《总统的蛋糕》，哈桑·哈迪导演\n\n金摄影机奖特别提及：《父影之下》，阿基诺拉·戴维斯导演",
    "ori_text": "第78届戛纳电影节于周六在法国落幕，伊朗异议导演贾法·帕纳希（Jafar Panahi）凭借地下拍摄的复仇题材影片《那只是个意外》（It Was Just an Accident）摘得金棕榈奖，引发全场起立鼓掌。这位因政治立场曾被伊朗当局软禁和入狱的导演，首次在15年内获准亲自到场领奖。 该片讲述五名前政治犯与当年监狱施暴者重逢的故事，由帕纳希的真实囚禁经历启发创作。在发表感言时，帕纳希呼吁全球伊朗人团结起来：“最重要的是我们的国家和自由。”影片反映他在伊文监狱的经历，也象徵着对压迫制度的反抗。 帕纳希曾因出席绿色革命遇难学生葬礼遭伊朗政府禁拍、禁行15年。尽管如此，他持续以秘密方式拍片，作品曾通过USB偷偷送出伊朗。本次夺冠的影片正是在这样的背景下拍摄而成，堪称其生涯的巅峰之一。\n\n评审团特别奖授予中国导演毕赣的《狂野时代》，这是一部融合历史与科幻元素的电影，讲述一个女人被带到了末世后的未来，在那里，她试图修复一个半机器半人的男人，向他隐喻讲述中国历史的部分内容。之后，她必须做出选择，是回到现实世界，还是继续与这个仿生人独处。 本届电影节不仅是一场电影盛宴，也是政治表达的舞台。在美国总统特朗普宣称考虑对海外影片征收100%关税后，不少导演发出批评声音。此外，评审团主席朱丽叶·比诺什（Juliette Binoche）在颁奖典礼上表示：“艺术终将胜利，人性终将胜利。”\n\n电影节闭幕当天，戛纳所在地区遭遇大规模停电，导致交通信号灯和ATM瘫痪，电影节组织方紧急启动备用发电机维持晚间活动顺利进行。据当地检察院称，位于尼斯和戛纳之间的小镇卢贝镇的一座高压电线塔的四根支柱中有三根被锯断。由于损坏，电网运营商不得不关闭该线路。这间接导致了戛纳大规模停电。此外，坦内隆镇的一个变电站也发生火灾。法国当局怀疑这两起案件都是蓄意破坏。调查工作正在进行之中。\n\n**获奖名单——**\n\n主竞赛单元\n\n金棕榈最佳影片：《普通事故》，贾法·帕纳西导演\n\n评委会大奖：《情感价值》，约阿希姆·提尔导演\n\n最佳女演员：纳迪亚·梅利蒂《最小的女儿》\n\n最佳导演：小克莱伯·门多萨《秘密特工》\n\n评审团奖(双黄)：《接近终点》，奥利维尔·拉克谢导演&《望向太阳》 ，玛莎·施林斯基导演\n\n最佳编剧：达内兄弟《年轻母亲之家》\n\n最佳男演员：瓦格纳·马拉《秘密特工》\n\n特别奖：《狂野时代》毕赣\n\n短片单元\n\n短片金棕榈：《我很高兴你现在死了》，托菲克·巴霍姆导演\n\n短片特别提及：《阿里》，阿德南·拉杰夫导演\n\n金摄影机(表彰首部导演作品)\n\n金摄影机奖：《总统的蛋糕》，哈桑·哈迪导演\n\n金摄影机奖特别提及：《父影之下》，阿基诺拉·戴维斯导演",
    "reference_list": "考点1：“复仇题材影片”推荐译为 revenge-themed film / revenge drama，不可简单译为 revenge movie，避免语体不匹配。\n考点2：“象征着对压迫制度的反抗”推荐译为 a symbol of resistance against the oppressive regime，需注意表达政治含义，不可弱化为 opposition 或 fight back。\n考点3：电影名翻译必须正确，《狂野时代》（Resurrection），官方译法\n考点4：电影名翻译必须正确，《情感价值》（Sentimental Value），官方译法\n考点5：电影名翻译必须正确，《最小的女儿》（The Little Sister），官方译法\n考点6：电影名翻译必须正确，《秘密特工》（The Secret Agent），官方译法\n考点7：电影名翻译必须正确，《接近终点》（Sirat)，官方译法\n考点8：电影名翻译必须正确，《望向太阳》（Sound of Falling），官方译法\n考点9：电影名翻译必须正确，《年轻母亲之家》（Young Mothers），官方译法\n考点10：电影名翻译必须正确，《我很高兴你现在死了》（I'm Glad You're Dead Now），官方译法\n考点11：电影名翻译必须正确，《阿里》（Ali），官方译法\n考点12：电影名翻译必须正确，《总统的蛋糕》（The President's Cake），官方译法\n考点13：电影名翻译必须正确，《父影之下》（My Father's Shadow）），官方译法\n考点14：“艺术终将胜利，人性终将胜利” 的原文为 “Art will always win. What is human will always win.” 译文的理想状态是能把这句话还原。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "21"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n8. Travelling & Living:\nCustomer’s personnel shall be visiting at Supplier’s Site for training &Acceptance /reviews etc. and Supplier shall provide assistance in provisioning of invitation letter for obtaining visa. However, all sorts of expenses on account of travelling, boarding/lodging etc shall be borne by Supplier as per clause 5.d. This item will be Optional and Customer will inform Supplier later. If it is arranged by Supplier, Supplier will receive the payment as indicated in the contract at Appendix VI – Part IV (breakup of cost mentioned) without submitting any receipts.\n\n9. Product Deliverables:\nAll the products and deliverables related to the Equipment are listed in Annex 1A/1B, Annex 2B.\n\n10. Program Management:\nThe Program Management will be executed in accordance with the Program Management Plan detailed in the Management Proposal attached in Annex 2B.\n\n11. Training:\n11.1. SUPPLIER will provide training to 12x Customer trainees for 22x working days at SUPPLIER’s site and 04x working days training at CUSTOMER site. The purpose of the training is to provide CUSTOMER with necessary information related to the operation of the Equipment, its functionalities and analysis of first level issues as provided in Annex 2B. Several training sessions are foreseen. They shall be performed according to the Delivery Schedule.\n11.2. For sake of clarity, SUPPLIER shall bear all costs and expenses of its trainers such as salaries and social security contributions.\n11.3. All courses, lectures, practical work exercises and technical demonstrations shall be conducted in English.\n11.4. The trainees shall have sufficient knowledge in the field in which they are to be trained. CUSTOMER will provide a full-time interpreter for all sessions to support the trainees who do not have sufficient working knowledge of the English language.\n11.5. SUPPLIER shall perform the trainings in accordance with its customary and usual standards. Notwithstanding the here above, in no case shall SUPPLIER be liable in case the trainees have not reached the objectives of the training.\n\n12. Delivery Schedule:\nSUPPLIER shall make all reasonable efforts to perform the Works according to the Delivery Schedule. The installation, On Site Acceptance Tests and Support Services shall begin at latest two (2) Week after notification by CUSTOMER of availability of the Equipment at the Site. It shall be performed without interruption.\nCUSTOMER hereby acknowledges that performance by SUPPLIER of the Works depends on the proper and timely performance by CUSTOMER of its obligations under the Contract.\nTherefore, in case of any delay in the performance by CUSTOMER of any of its obligations under the Contract which affects or causes delay in the performance of the Works by SUPPLIER and/or its subcontractor, SUPPLIER shall be authorized to extend the time period for performance of any part of the Works by the same duration of the delay and/or consequences of that delay on SUPPLIER and /or subcontractor’s performance of Work. CUSTOMER shall not be entitled to claim any liquidated damages to SUPPLIER in such event.\n\n13. Coming into force – Duration\nThe Effective date of the Contract – EDC - (T0) is the date on which all the conditions below are fulfilled:\na. Both the parties have signed the Contract.\nb. Receipt of sample imagery to CUSTOMER from SUPPLIER for quality assessment & successful qualification of imagery and the acceptance of sample imagery on the basis of quality assessment & successful qualification of imagery by Customer shall be a pre-requisite for declaration of EDC.\nc. The Supplier has obtained all the authorizations, licenses and Export Permits from respective Governments. However, if the Export Permits, Authorizations and Licenses are not required from the respective Government, The SUPPLIER shall submit a declaration certificate duly signed and stamped which is attached at Appendix XIV.\nd. Each Party shall inform the other Party without undue delay about reception of any necessary approvals and authorizations. If any of the conditions precedent is not satisfied within 6 (six) months from the date of signature of the Contract or such later date as the Parties may agree, any of the Parties may rescind the Contract by written notice to the other without any liability to the other.\n\n14. Acceptance/ Factory Readiness Review:\nThe CUSTOMER shall visit SELLER/SUPPLIER site at the Factory Readiness Review as an observer. The Factory Readiness Review shall be performed in the SUPPLIER’s subcontractor premises. The Factory Readiness Review Certificate (Appendix-I/B) shall be signed by the CUSTOMER and SUPPLIER after successful completion of tests mentioned in Appendix-I/A.\nOnce the Factory Readiness Review Certificate is signed by both parties, it shall constitute the SUPPLIER’s determination that the Equipment has been manufactured in accordance with Annex 2B and can be delivered. SUPPLIER will not ship non-conforming Equipment or an Equipment different from the Equipment as accepted in the Factory Readiness Review. Supplier shall provide Acceptance Test Parameters (Appendix-I/A) at EDC+1 month for customer’s review.\n\n15. Delivery and Transfer of Title and Risks:\n15.1 Delivery terms\nOnce the conditions required to deliver the Equipment are met, as provided in Annex 2B, the Equipment shall be delivered according to ICC Incoterms 2020 DAP to Customer ISLAMABAD FINAL INSTALLATION SITE.\nAll transportation, shipping and Insurance shall be conducted under the provisions of such Inco terms. SUPPLIER shall utilize standard packing to ship the Equipment.\nAs soon as the Equipment is delivered for dispatch, fax / e-mail information shall be sent to CUSTOMER by SUPPLIER immediately, giving following details:\n1) Name of airline indicating AWB number and date.\n2) Name of city from where the consignment is being dispatched.\n3) Date of shipment.\n4) Expected date of arrival at airport of Destination Country.\n5) Name of shipping agents at destination (if any).\n6) Total number of packages being dispatched with gross weight and volume of each package.\nIn accordance of the DAP (ICC Incoterms 2020), any penalty levied on CUSTOMER by the Custom authorities etc during clearance of the consignments, due to wrong/incomplete documentation or supplied quantity which is caused by Supplier, will be recovered from Supplier.\n15.2 Dispatch of Documents:\nThe soft copies of following documents shall be provided by the Supplier immediately after the customs clearance in China, and two hard copies shall be delivered by courier against the payment remittance\n1) Duly signed invoice showing value of the items actually dispatched.\n2) Packing list.\n3) Duly signed Airway Bill indicating actual freight paid.\n4) Original Warranty/Guarantee/Mill Certificate (if applicable).\n5) Guarantee certificate that correct goods as per order have been dispatched\n6) Duly signed and stamped Insurance Policy/Cover Note covering all risks up to Final Installation Customer Site at Islamabad, Pakistan The Shipment of the complete system(s) shall be done through AIR. Preferably, the consignment should be dispatched through Pakistani Flag Carrier or otherwise with the consent of Customer.\n15.3 Transfer of Risk\nRisk of loss with respect to the Equipment shall be transferred from Supplier to Customer upon Equipment delivery at Customer Islamabad Final Installation Site.\nAs from the transfer of risks, all losses sustained by the Equipment, as well as injury to people or damage to belongings, are at the CUSTOMER’s expense and its sole liability. Upon delivery, CUSTOMER undertakes to ensure that the Equipment is transported and stored in a secured environment and in accordance with usual requirements of transport and storage requirements.\n15.4 Title to goods\nWithout prejudice to the provisions of Article “Intellectual Property Rights”, the title to the Equipment is acquired upon complete payment of the Equipment.\nNotwithstanding the foregoing, it is prohibited to sell, transfer, loan Equipment to any third parties, without prior written consent of Supplier.\n\n16. Shipment and Insurance:\nSupplier is responsible for the costs of shipping (including Insurance) and transport of the Equipment until Customer Islamabad Final Installation Site according to Incoterm DAP 2020.The charges of transportation (including of insurance) shall be paid at the price as indicated in the contract Appendix-VI and Appendix-VII.\nCustomer is responsible for all Pakistani import taxes, value added tax, customs duties, fees, or duty charges or the cost of incoming handling by Pakistani customs or import agents and any other associated costs for securing release of the shipment from customs.\n\n17. On-Site Acceptance\nThe On Site Acceptance Tests shall be performed on Site after installation of the Equipment, according to the Delivery Schedule. SUPPLIER shall provide detailed procedures of FRR and OSAT to CUSTOMER for approval, two weeks prior to start of these activities.\nSUPPLIER shall confirm to CUSTOMER the date for commencement of the On Site Acceptance Tests, with a Seven (7) Days prior notice in writing (by mail, fax or email). CUSTOMER shall have an authorized representative present for the entire duration of the On Site Acceptance Tests.\nThe On Site Acceptance Certificate shall be issued by SUPPLIER and signed by CUSTOMER within ten working (10) Days upon demonstration that the Equipment is operating without Anomaly. This timeframe passed, the OSAC is deemed signed and the OSAT is deemed passed.\nIn case the On Site Acceptance Certificate could not be issued because of a Anomaly, SUPPLIER shall, at its own cost, correct the defect according to a time schedule to be agreed upon in writing by the Parties, and SUPPLIER shall perform again the On Site Acceptance Tests.\nThe signature of the On Site Acceptance Certificate shall constitute the authorization for CUSTOMER to use the Equipment, and shall be the starting point of the Equipment warranty. Once the On Site Acceptance Certificate is signed by both parties, payment will be made within 60 calendar days by CUSTOMER to SUPPLIER as per Appendix-VII.\n\n18. Warranty Service:\nSupplier, at its sole cost and expense shall provide to CUSTOMER the warranty service of two (2) Years on the Equipment (Ground Segment) starting on the date of signing the On Site Acceptance Certificate and also provide duly sign and stamped Supplier’s Standard Warranty as per Appendix-VIII.\nThe warranty service shall be provided by Supplier free of cost to ensure the Equipment/System (Ground Segment) operates without Anomaly, and Supplier shall exercise the skill, care and diligence in the said services that is customary and standard in the industry for such services and equipment.\nThe warranty service defined in Annex 2B constitute the sole and entire liability incurred by the SUPPLIER in event of any Anomaly of the Equipment. For Space Segment, Supplier shall provide the free of cost warranty of imagery services for 3 years i.e. T0+3 years. Furthermore, in space segment Supplier shall also provide the In-Orbit Test Services and 5 years calibration and after sales technical support starting from T0 and lasts till T0+ 5 years.",
    "ori_text": "\n\n8. Travelling & Living:\nCustomer’s personnel shall be visiting at Supplier’s Site for training &Acceptance /reviews etc. and Supplier shall provide assistance in provisioning of invitation letter for obtaining visa. However, all sorts of expenses on account of travelling, boarding/lodging etc shall be borne by Supplier as per clause 5.d. This item will be Optional and Customer will inform Supplier later. If it is arranged by Supplier, Supplier will receive the payment as indicated in the contract at Appendix VI – Part IV (breakup of cost mentioned) without submitting any receipts.\n\n9. Product Deliverables:\nAll the products and deliverables related to the Equipment are listed in Annex 1A/1B, Annex 2B.\n\n10. Program Management:\nThe Program Management will be executed in accordance with the Program Management Plan detailed in the Management Proposal attached in Annex 2B.\n\n11. Training:\n11.1. SUPPLIER will provide training to 12x Customer trainees for 22x working days at SUPPLIER’s site and 04x working days training at CUSTOMER site. The purpose of the training is to provide CUSTOMER with necessary information related to the operation of the Equipment, its functionalities and analysis of first level issues as provided in Annex 2B. Several training sessions are foreseen. They shall be performed according to the Delivery Schedule.\n11.2. For sake of clarity, SUPPLIER shall bear all costs and expenses of its trainers such as salaries and social security contributions.\n11.3. All courses, lectures, practical work exercises and technical demonstrations shall be conducted in English.\n11.4. The trainees shall have sufficient knowledge in the field in which they are to be trained. CUSTOMER will provide a full-time interpreter for all sessions to support the trainees who do not have sufficient working knowledge of the English language.\n11.5. SUPPLIER shall perform the trainings in accordance with its customary and usual standards. Notwithstanding the here above, in no case shall SUPPLIER be liable in case the trainees have not reached the objectives of the training.\n\n12. Delivery Schedule:\nSUPPLIER shall make all reasonable efforts to perform the Works according to the Delivery Schedule. The installation, On Site Acceptance Tests and Support Services shall begin at latest two (2) Week after notification by CUSTOMER of availability of the Equipment at the Site. It shall be performed without interruption.\nCUSTOMER hereby acknowledges that performance by SUPPLIER of the Works depends on the proper and timely performance by CUSTOMER of its obligations under the Contract.\nTherefore, in case of any delay in the performance by CUSTOMER of any of its obligations under the Contract which affects or causes delay in the performance of the Works by SUPPLIER and/or its subcontractor, SUPPLIER shall be authorized to extend the time period for performance of any part of the Works by the same duration of the delay and/or consequences of that delay on SUPPLIER and /or subcontractor’s performance of Work. CUSTOMER shall not be entitled to claim any liquidated damages to SUPPLIER in such event.\n\n13. Coming into force – Duration\nThe Effective date of the Contract – EDC - (T0) is the date on which all the conditions below are fulfilled:\na. Both the parties have signed the Contract.\nb. Receipt of sample imagery to CUSTOMER from SUPPLIER for quality assessment & successful qualification of imagery and the acceptance of sample imagery on the basis of quality assessment & successful qualification of imagery by Customer shall be a pre-requisite for declaration of EDC.\nc. The Supplier has obtained all the authorizations, licenses and Export Permits from respective Governments. However, if the Export Permits, Authorizations and Licenses are not required from the respective Government, The SUPPLIER shall submit a declaration certificate duly signed and stamped which is attached at Appendix XIV.\nd. Each Party shall inform the other Party without undue delay about reception of any necessary approvals and authorizations. If any of the conditions precedent is not satisfied within 6 (six) months from the date of signature of the Contract or such later date as the Parties may agree, any of the Parties may rescind the Contract by written notice to the other without any liability to the other.\n\n14. Acceptance/ Factory Readiness Review:\nThe CUSTOMER shall visit SELLER/SUPPLIER site at the Factory Readiness Review as an observer. The Factory Readiness Review shall be performed in the SUPPLIER’s subcontractor premises. The Factory Readiness Review Certificate (Appendix-I/B) shall be signed by the CUSTOMER and SUPPLIER after successful completion of tests mentioned in Appendix-I/A.\nOnce the Factory Readiness Review Certificate is signed by both parties, it shall constitute the SUPPLIER’s determination that the Equipment has been manufactured in accordance with Annex 2B and can be delivered. SUPPLIER will not ship non-conforming Equipment or an Equipment different from the Equipment as accepted in the Factory Readiness Review. Supplier shall provide Acceptance Test Parameters (Appendix-I/A) at EDC+1 month for customer’s review.\n\n15. Delivery and Transfer of Title and Risks:\n15.1 Delivery terms\nOnce the conditions required to deliver the Equipment are met, as provided in Annex 2B, the Equipment shall be delivered according to ICC Incoterms 2020 DAP to Customer ISLAMABAD FINAL INSTALLATION SITE.\nAll transportation, shipping and Insurance shall be conducted under the provisions of such Inco terms. SUPPLIER shall utilize standard packing to ship the Equipment.\nAs soon as the Equipment is delivered for dispatch, fax / e-mail information shall be sent to CUSTOMER by SUPPLIER immediately, giving following details:\n1) Name of airline indicating AWB number and date.\n2) Name of city from where the consignment is being dispatched.\n3) Date of shipment.\n4) Expected date of arrival at airport of Destination Country.\n5) Name of shipping agents at destination (if any).\n6) Total number of packages being dispatched with gross weight and volume of each package.\nIn accordance of the DAP (ICC Incoterms 2020), any penalty levied on CUSTOMER by the Custom authorities etc during clearance of the consignments, due to wrong/incomplete documentation or supplied quantity which is caused by Supplier, will be recovered from Supplier.\n15.2 Dispatch of Documents:\nThe soft copies of following documents shall be provided by the Supplier immediately after the customs clearance in China, and two hard copies shall be delivered by courier against the payment remittance\n1) Duly signed invoice showing value of the items actually dispatched.\n2) Packing list.\n3) Duly signed Airway Bill indicating actual freight paid.\n4) Original Warranty/Guarantee/Mill Certificate (if applicable).\n5) Guarantee certificate that correct goods as per order have been dispatched\n6) Duly signed and stamped Insurance Policy/Cover Note covering all risks up to Final Installation Customer Site at Islamabad, Pakistan The Shipment of the complete system(s) shall be done through AIR. Preferably, the consignment should be dispatched through Pakistani Flag Carrier or otherwise with the consent of Customer.\n15.3 Transfer of Risk\nRisk of loss with respect to the Equipment shall be transferred from Supplier to Customer upon Equipment delivery at Customer Islamabad Final Installation Site.\nAs from the transfer of risks, all losses sustained by the Equipment, as well as injury to people or damage to belongings, are at the CUSTOMER’s expense and its sole liability. Upon delivery, CUSTOMER undertakes to ensure that the Equipment is transported and stored in a secured environment and in accordance with usual requirements of transport and storage requirements.\n15.4 Title to goods\nWithout prejudice to the provisions of Article “Intellectual Property Rights”, the title to the Equipment is acquired upon complete payment of the Equipment.\nNotwithstanding the foregoing, it is prohibited to sell, transfer, loan Equipment to any third parties, without prior written consent of Supplier.\n\n16. Shipment and Insurance:\nSupplier is responsible for the costs of shipping (including Insurance) and transport of the Equipment until Customer Islamabad Final Installation Site according to Incoterm DAP 2020.The charges of transportation (including of insurance) shall be paid at the price as indicated in the contract Appendix-VI and Appendix-VII.\nCustomer is responsible for all Pakistani import taxes, value added tax, customs duties, fees, or duty charges or the cost of incoming handling by Pakistani customs or import agents and any other associated costs for securing release of the shipment from customs.\n\n17. On-Site Acceptance\nThe On Site Acceptance Tests shall be performed on Site after installation of the Equipment, according to the Delivery Schedule. SUPPLIER shall provide detailed procedures of FRR and OSAT to CUSTOMER for approval, two weeks prior to start of these activities.\nSUPPLIER shall confirm to CUSTOMER the date for commencement of the On Site Acceptance Tests, with a Seven (7) Days prior notice in writing (by mail, fax or email). CUSTOMER shall have an authorized representative present for the entire duration of the On Site Acceptance Tests.\nThe On Site Acceptance Certificate shall be issued by SUPPLIER and signed by CUSTOMER within ten working (10) Days upon demonstration that the Equipment is operating without Anomaly. This timeframe passed, the OSAC is deemed signed and the OSAT is deemed passed.\nIn case the On Site Acceptance Certificate could not be issued because of a Anomaly, SUPPLIER shall, at its own cost, correct the defect according to a time schedule to be agreed upon in writing by the Parties, and SUPPLIER shall perform again the On Site Acceptance Tests.\nThe signature of the On Site Acceptance Certificate shall constitute the authorization for CUSTOMER to use the Equipment, and shall be the starting point of the Equipment warranty. Once the On Site Acceptance Certificate is signed by both parties, payment will be made within 60 calendar days by CUSTOMER to SUPPLIER as per Appendix-VII.\n\n18. Warranty Service:\nSupplier, at its sole cost and expense shall provide to CUSTOMER the warranty service of two (2) Years on the Equipment (Ground Segment) starting on the date of signing the On Site Acceptance Certificate and also provide duly sign and stamped Supplier’s Standard Warranty as per Appendix-VIII.\nThe warranty service shall be provided by Supplier free of cost to ensure the Equipment/System (Ground Segment) operates without Anomaly, and Supplier shall exercise the skill, care and diligence in the said services that is customary and standard in the industry for such services and equipment.\nThe warranty service defined in Annex 2B constitute the sole and entire liability incurred by the SUPPLIER in event of any Anomaly of the Equipment. For Space Segment, Supplier shall provide the free of cost warranty of imagery services for 3 years i.e. T0+3 years. Furthermore, in space segment Supplier shall also provide the In-Orbit Test Services and 5 years calibration and after sales technical support starting from T0 and lasts till T0+ 5 years.",
    "reference_list": "考点1：liquidated damages 必须译为违约金\n考点2：claim 建议翻译为请求赔偿/索赔\n考点3：a pre-requisite 建议翻译为先决条件/前提条件\n考点4：authorizations、 licenses建议翻译为核准文件、执照\n考点5：a declaration certificate建议翻译为声明书/确认书\n考点6：transfer of Title and Risks 必须译为所有权和风险转移\n考点7：DAP建议翻译为目的地交货，不能保留原文不译\n考点8：clearance of the consignments 建议翻译为货物清关\n考点9：Original Warranty/Guarantee/Mill Certificate建议翻译为原始保修/质保/出厂检验证书\n考点10：cover note 必须译为承保条\n考点11：Pakistani Flag Carrier必须译为巴基斯坦国家航空公司或巴基斯坦载旗航空公司\n考点12：duty charges 建议翻译为对货物征收的税\n考点13：Factory Readiness Tests 建议翻译为出厂准备就绪评审\n考点14：Factory Readiness Review Certificate 建议翻译为出厂准备就绪证明/确认\n考点15：care and diligence 建议翻译为谨慎及勤勉",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "146"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nHerman Melville was Hawthorne’s good friend, also an important novelist. Melville's greatest work, Moby Dick (1851) was based on Melville's adventures on the whaling ships. It is the deep \"tragedies of human thought\" that show his critical understanding of human nature. Today Melville is considered one of America's greatest writers today.\nRomanism was extremely influenced in a rising America as America had always had a strong spiritual tradition and romanticism was very comfortable with American spiritual heritage and its ideals of democracy and equality. During this period, the American literature was so changeable that has never been before. Nathaniel Hawthorne, Herman Melville, Walt Whitman and Edgar Allan Poe, these four great writers had given depth and strength to American literature at that time.\n\n4. Local Color And Realism: A New Flavor to American Literature\n\nAfter the Civil War, the American society was in a turbulent situation through several economical crises. The writings about critical realism and unveiling the dark side of the society were increased. They were mainly focus on bankrupt in countries, difficult life or struggle of low-position people and so on. Thus Romanism was on the wane with passing days, while Realism rose and became more and more popular.\n\n (1) Local Color Fiction and Mark Twain\n\nLocal Color Fiction first appeared in the early 19th century, and it had further developing after the Civil War. This kind of literature mainly describes the local life. Its keynote was optimistic, and the language was narrative and humorous. For example, the work of Bret Harte (1836-1902) told us the life of American western miners. Mark Twain was the main writer of this period. He wrote for nearly 50 years, and he had actually written many different types of stories. Nevertheless, Twain is remembered most for The Adventures of Tom Sawyer (1876), Life on the Mississippi (1884) and The Adventures of Huckleberry Finn (1884). The characters he created were humorous and full of wittiness.  Mark Twain’s work was regarded the witness of America’s pure local life. According to Calkins, “Few American writers have written the same after reading Twain, for he has helped change the entire country with his humor and skillful story telling.” (Carroll C.Calkins, 124).\n\n(2) Rise of Realism\n\n“Realism is the theory of writing in which familiar aspects of contemporary life and everyday scenes represented in a straightforward or matter of fact manner“ (Wu Dingo, 59). Romantic writers focused on the development of plot, make the story as interesting and attractive as possible, while realism writers emphasized the characterization of characters, focused on objectivity rather than an idealistic view of human nature and human experience.\n\nWilliam Dean Howells (1837-1920) insisted that Realism was the truthful treatment of material moral problems of society. And in O.Henry (1862-1910)’s fictions, all his characters were common people and always had an ironical and surprised ending. \n\n There was another style of writing developed by Henry James (1843-1916), who was a writer focused on the description of psychology and behavior. He wrote some complex and profound novels such as The Wings of the Dove, The Ambassador, The Golden Bowl, and created psychological realism.\n\nAfter the mid-19th century, the keynote of romantic literature changed form optimistic to doubtful. The sharp conflict of society force more writers’ attention to the unveiling of dark social fact and self-questioning.\n\nThought the writers of this time unveiled the misfortune and sadness or even degenerate things in actual life, they didn’t just took of the dark side of life as their material, most of them were the reformists with the hope of helping to create a better nation. Stephen Crane (1871-1900) showed more and more serious problems in big sites in his Maggie, A Girl of the Streets, and his most famous book about the American Civil War called The Red Badge of Courage. He thought his works liked a mirror reflecting all life, he emphasized the accidental physiological nature of the characters rather than their moral and rational qualities. Stephen Crane had formed a new style called Naturalism, which had influenced many following writers.\n\n5.  Modern American Literature\n\nThe First World War not only damaged the people’s life, but also led to a turbulent situation of the American society. People of this time were named “The Lost Generation ”, and the writers and works had a pessimistic and disconsolate feeling.\n\n(1)   Modern poetry\n\nEzra Pound, T.S.Eliot and E.E Cummings are three poets who opened the way to modern poetry.\n\n    Ezra Pound started the “Imagist” movement, and his The Love Song of J. Alfred Prufrock has been called the first masterpiece of modernism. The Waste Land of T.S.Eliot particularly comments on the inhumanity and decadence of large modern cities.\n\n(2)   Modern novels\n\nMany persons regarded that Ernest Hemingway and other important writers of 20th century had adopted the concise style and naturalism of Stephen Crane. Nevertheless, they still created their own styles and had written so many immortal masterpieces. Among the greatest were Ernest Hemingway (l899-1961) and William Faulkner (l897-1962). \n\nErnest Hemingway was once take part in the First Would War, so many of his works deal with war or injury, and nearly all of them examined the nature of courag, e. By suffering from the violent of war, he felt that he was cut off from all his old beliefs and assumptions about life. “He thought the War had broken America’s culture and traditions, and separated it from its toots” (Elisabeth B. Booz: 1982). The works he wrote--The Sun Also Rises, A Farewell to Arms, For Whom the Bell Tolls and The Old Man and the Sea—inferred the state of mind, and they became the representatives of the feeling of this generation.\n\n Epilogue\n\nAmerican literature has gone though the progress of development over 200 years. It is characterized by the distinct individualism, which is optimistic, free and always creative. The living American literature has been providing potent thinking headsprings for the writers past and nowadays, and it will continue reanimating the talents to bequeath and enrich the tradition of American literature, of which deserved to be proud.\n\nBibliography:\n1. Carroll C.Calkins, The story of America, New York: The Readers Digest Association, Inc, 1975\n2. Elisabeth B. Booz, A Brief Introduction To Modern American Literature 1919-1980, Shanghai: Shanghai Foreign Language Education Press, 1982\n3. 柯恩, Landmarks of American Literature, 北京: 三联书店, 1988\n4. Wu Dingbo, An outline of American literature, Shanghai: Shanghai Foreign Language Education Press, 1998\n5. Edited by W. P. Trent, J. Erskine & S. P. Sherman, The Cambridge History of English and American Literature, Cambridge, England: University Press, 1997",
    "ori_text": "Herman Melville was Hawthorne’s good friend, also an important novelist. Melville's greatest work, Moby Dick (1851) was based on Melville's adventures on the whaling ships. It is the deep \"tragedies of human thought\" that show his critical understanding of human nature. Today Melville is considered one of America's greatest writers today.\nRomanism was extremely influenced in a rising America as America had always had a strong spiritual tradition and romanticism was very comfortable with American spiritual heritage and its ideals of democracy and equality. During this period, the American literature was so changeable that has never been before. Nathaniel Hawthorne, Herman Melville, Walt Whitman and Edgar Allan Poe, these four great writers had given depth and strength to American literature at that time.\n\n4. Local Color And Realism: A New Flavor to American Literature\n\nAfter the Civil War, the American society was in a turbulent situation through several economical crises. The writings about critical realism and unveiling the dark side of the society were increased. They were mainly focus on bankrupt in countries, difficult life or struggle of low-position people and so on. Thus Romanism was on the wane with passing days, while Realism rose and became more and more popular.\n\n (1) Local Color Fiction and Mark Twain\n\nLocal Color Fiction first appeared in the early 19th century, and it had further developing after the Civil War. This kind of literature mainly describes the local life. Its keynote was optimistic, and the language was narrative and humorous. For example, the work of Bret Harte (1836-1902) told us the life of American western miners. Mark Twain was the main writer of this period. He wrote for nearly 50 years, and he had actually written many different types of stories. Nevertheless, Twain is remembered most for The Adventures of Tom Sawyer (1876), Life on the Mississippi (1884) and The Adventures of Huckleberry Finn (1884). The characters he created were humorous and full of wittiness.  Mark Twain’s work was regarded the witness of America’s pure local life. According to Calkins, “Few American writers have written the same after reading Twain, for he has helped change the entire country with his humor and skillful story telling.” (Carroll C.Calkins, 124).\n\n(2) Rise of Realism\n\n“Realism is the theory of writing in which familiar aspects of contemporary life and everyday scenes represented in a straightforward or matter of fact manner“ (Wu Dingo, 59). Romantic writers focused on the development of plot, make the story as interesting and attractive as possible, while realism writers emphasized the characterization of characters, focused on objectivity rather than an idealistic view of human nature and human experience.\n\nWilliam Dean Howells (1837-1920) insisted that Realism was the truthful treatment of material moral problems of society. And in O.Henry (1862-1910)’s fictions, all his characters were common people and always had an ironical and surprised ending. \n\n There was another style of writing developed by Henry James (1843-1916), who was a writer focused on the description of psychology and behavior. He wrote some complex and profound novels such as The Wings of the Dove, The Ambassador, The Golden Bowl, and created psychological realism.\n\nAfter the mid-19th century, the keynote of romantic literature changed form optimistic to doubtful. The sharp conflict of society force more writers’ attention to the unveiling of dark social fact and self-questioning.\n\nThought the writers of this time unveiled the misfortune and sadness or even degenerate things in actual life, they didn’t just took of the dark side of life as their material, most of them were the reformists with the hope of helping to create a better nation. Stephen Crane (1871-1900) showed more and more serious problems in big sites in his Maggie, A Girl of the Streets, and his most famous book about the American Civil War called The Red Badge of Courage. He thought his works liked a mirror reflecting all life, he emphasized the accidental physiological nature of the characters rather than their moral and rational qualities. Stephen Crane had formed a new style called Naturalism, which had influenced many following writers.\n\n5.  Modern American Literature\n\nThe First World War not only damaged the people’s life, but also led to a turbulent situation of the American society. People of this time were named “The Lost Generation ”, and the writers and works had a pessimistic and disconsolate feeling.\n\n(1)   Modern poetry\n\nEzra Pound, T.S.Eliot and E.E Cummings are three poets who opened the way to modern poetry.\n\n    Ezra Pound started the “Imagist” movement, and his The Love Song of J. Alfred Prufrock has been called the first masterpiece of modernism. The Waste Land of T.S.Eliot particularly comments on the inhumanity and decadence of large modern cities.\n\n(2)   Modern novels\n\nMany persons regarded that Ernest Hemingway and other important writers of 20th century had adopted the concise style and naturalism of Stephen Crane. Nevertheless, they still created their own styles and had written so many immortal masterpieces. Among the greatest were Ernest Hemingway (l899-1961) and William Faulkner (l897-1962). \n\nErnest Hemingway was once take part in the First Would War, so many of his works deal with war or injury, and nearly all of them examined the nature of courag, e. By suffering from the violent of war, he felt that he was cut off from all his old beliefs and assumptions about life. “He thought the War had broken America’s culture and traditions, and separated it from its toots” (Elisabeth B. Booz: 1982). The works he wrote--The Sun Also Rises, A Farewell to Arms, For Whom the Bell Tolls and The Old Man and the Sea—inferred the state of mind, and they became the representatives of the feeling of this generation.\n\n Epilogue\n\nAmerican literature has gone though the progress of development over 200 years. It is characterized by the distinct individualism, which is optimistic, free and always creative. The living American literature has been providing potent thinking headsprings for the writers past and nowadays, and it will continue reanimating the talents to bequeath and enrich the tradition of American literature, of which deserved to be proud.\n\nBibliography:\n1. Carroll C.Calkins, The story of America, New York: The Readers Digest Association, Inc, 1975\n2. Elisabeth B. Booz, A Brief Introduction To Modern American Literature 1919-1980, Shanghai: Shanghai Foreign Language Education Press, 1982\n3. 柯恩, Landmarks of American Literature, 北京: 三联书店, 1988\n4. Wu Dingbo, An outline of American literature, Shanghai: Shanghai Foreign Language Education Press, 1998\n5. Edited by W. P. Trent, J. Erskine & S. P. Sherman, The Cambridge History of English and American Literature, Cambridge, England: University Press, 1997",
    "reference_list": "考点1：\"was very comfortable with\"应译为“与…十分契合”。\n考点2：\"on the wane'推荐译为“日渐式微”。\n考点3：\"Local Color Fiction\"应译为“乡土小说”。\n考点4：\"keynote\"应译为“基调”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "44"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n人工智能医疗应用中的算法责任认定与数据合规边界\n\n 一、算法决策的可解释性争议\n人工智能在医疗领域的深度应用（如影像辅助诊断、临床决策支持系统）引发了 “算法黑箱” 与医疗责任的核心矛盾。根据《欧盟人工智能法案》，医疗 AI 被归类为 “高风险系统”，要求其决策过程具备 “可追溯性”与 “人机协同验证”。但实践中存在三重冲突：\n1. 技术特性与法律要求的张力\n深度学习模型（如卷积神经网络 CNN）的 “非线性运算” 特性导致决策逻辑难以拆解，而《通用数据保护条例》第 22 条赋予用户 “解释权”，要求企业说明自动化决策的依据。例如，2023 年某 AI 辅助诊断系统误诊早期肺癌，患者家属要求医院解释 “算法为何将磨玻璃结节判定为良性”，但医院以 “模型参数属于商业秘密” 为由拒绝，引发合规争议。\n2. 责任划分的模糊地带\n当 AI 决策与医师判断冲突时，责任归属存在歧义：若医师完全依赖 AI 结论导致误诊，属 “医疗过失”；若医师未采纳 AI 的正确预警而造成损害，是否构成 “不作为侵权”？2024 年某三甲医院案例中，AI 提示 “患者术后大出血风险极高”，主治医师未予处理，最终患者死亡，法院判定 “医师对 AI 建议负有审慎审查义务”，但未明确 AI 研发方的连带责任。\n3. 跨境应用的标准冲突\n美国 FDA 对医疗 AI 采用 “产品分级监管”（如将影像诊断 AI 归类为 二级医疗器械），侧重 “性能验证”；中国 NMPA 则要求 “全生命周期管理”，包括算法迭代的备案更新。某跨国企业的 AI 心电分析系统在美通过审批后，因未在中国完成算法版本变更备案，被认定为 “非法行医辅助工具”，凸显标准差异的执行困境。\n\n二、医疗数据跨境传输的合规障碍\n医疗数据的 “敏感性”使其跨境传输受严格限制，核心争议集中于：\n1. 数据本地化与出境例外的博弈\n中国《数据安全法》要求 “重要数据本地化存储”，而 “国际多中心临床试验” 常需向境外传输病例数据。某药企为加速肿瘤新药研发，向欧盟合作方传输 500 例患者基因测序数据，因未通过 “安全评估” 被处以 2000 万元罚款。欧盟则允许 “基于充分性认定” 的自由传输，但尚未将中国纳入 “白名单”，企业需依赖 “标准合同条款”完成合规，流程繁琐。\n2. 匿名化与去标识化的边界混淆\nGDPR 规定 “匿名化数据不受监管”，而 “去标识化数据仍属个人数据”。实践中，医疗机构常误将 “去除姓名、身份证号” 的病历视为 “匿名化”，实则通过 “出生日期 + 疾病史” 可重新识别个体。2023 年某健康 APP 因向境外传输 “去标识化糖尿病患者数据” 被欧盟认定为 “数据泄露”，面临全球营收 4% 的罚款。\n3. 紧急医疗场景的合规例外缺失\n跨国救援中，实时传输患者电子健康档案可能违反数据出境规定。2024 年某国际航班突发心梗病例，机组向美国地面医院传输患者既往病史数据，事后被质疑 “未事先获得患者授权”，但现行法律未明确 “紧急情况豁免” 条款，导致医疗行为陷入 “救人与合规” 的两难。\n\n 三、前沿问题：生成式 AI 在医疗中的伦理与法律挑战\nChatGPT 等生成式 AI 在病历总结、诊疗建议中的应用，引发新的合规风险：\n1. 幻觉输出的医疗风险\n生成式 AI 可能产生 “看似合理却错误” 的内容（如虚构药物禁忌症）。某基层医院使用 AI 撰写出院小结时，误将 “阿司匹林过敏” 写入无过敏史患者的病历，导致后续用药错误。此类 “算法幻觉”是否构成 “产品缺陷”，现行法律尚未明确责任主体。\n2. 知识产权的归属争议\nAI 基于海量医学文献生成的诊疗方案，是否侵犯原作者的 “著作权”？某 AI 公司的肿瘤治疗建议系统因大段借鉴《NCCN 指南》内容，被起诉 “不正当竞争”，法院认为 “实质性相似但未构成侵权”，但未界定 “合理使用” 的边界。\n3. 患者知情同意的形式缺陷\n使用 AI 辅助诊疗需获得患者 “专项同意”，而非笼统的 “诊疗同意书”。某互联网医院在用户注册协议中默认勾选 “允许 AI 分析病情”，被认定为 “未充分告知”，违反《个人信息保护法》第 14 条，面临整改。\n\n 四、争议解决路径的创新探索\n针对上述困境，实践中出现三类解决方案：\n1. 算法备案与第三方审计\n中国推行 “医疗 AI 算法备案制”，要求企业提交 “训练数据来源、决策逻辑流程图”；欧盟则要求高风险 AI 系统接受 “独立合规评估”。某 AI 眼底筛查系统通过第三方验证其 “误诊率 < 0.5%”，成为首个同时通过中欧合规认证的医疗 AI 产品。\n2. 数据信托与跨境白名单\n新加坡建立 “医疗数据信托”，由第三方机构统一管理跨境传输，平衡 “隐私保护” 与 “科研需求”；中国粤港澳大湾区试点 “数据跨境流动白名单”，允许指定医院向港澳传输脱敏病例数据，无需单独审批。\n3. 替代性纠纷解决机制\n国际医疗 AI 纠纷逐渐采用 “专家仲裁”，如国际医学人工智能协会设立仲裁院，由医师、数据合规师、算法工程师组成合议庭，2024 年成功调解某跨国 AI 诊断系统的跨境责任纠纷，耗时较诉讼缩短 60%。",
    "ori_text": "\n\n人工智能医疗应用中的算法责任认定与数据合规边界\n\n 一、算法决策的可解释性争议\n人工智能在医疗领域的深度应用（如影像辅助诊断、临床决策支持系统）引发了 “算法黑箱” 与医疗责任的核心矛盾。根据《欧盟人工智能法案》，医疗 AI 被归类为 “高风险系统”，要求其决策过程具备 “可追溯性”与 “人机协同验证”。但实践中存在三重冲突：\n1. 技术特性与法律要求的张力\n深度学习模型（如卷积神经网络 CNN）的 “非线性运算” 特性导致决策逻辑难以拆解，而《通用数据保护条例》第 22 条赋予用户 “解释权”，要求企业说明自动化决策的依据。例如，2023 年某 AI 辅助诊断系统误诊早期肺癌，患者家属要求医院解释 “算法为何将磨玻璃结节判定为良性”，但医院以 “模型参数属于商业秘密” 为由拒绝，引发合规争议。\n2. 责任划分的模糊地带\n当 AI 决策与医师判断冲突时，责任归属存在歧义：若医师完全依赖 AI 结论导致误诊，属 “医疗过失”；若医师未采纳 AI 的正确预警而造成损害，是否构成 “不作为侵权”？2024 年某三甲医院案例中，AI 提示 “患者术后大出血风险极高”，主治医师未予处理，最终患者死亡，法院判定 “医师对 AI 建议负有审慎审查义务”，但未明确 AI 研发方的连带责任。\n3. 跨境应用的标准冲突\n美国 FDA 对医疗 AI 采用 “产品分级监管”（如将影像诊断 AI 归类为 二级医疗器械），侧重 “性能验证”；中国 NMPA 则要求 “全生命周期管理”，包括算法迭代的备案更新。某跨国企业的 AI 心电分析系统在美通过审批后，因未在中国完成算法版本变更备案，被认定为 “非法行医辅助工具”，凸显标准差异的执行困境。\n\n二、医疗数据跨境传输的合规障碍\n医疗数据的 “敏感性”使其跨境传输受严格限制，核心争议集中于：\n1. 数据本地化与出境例外的博弈\n中国《数据安全法》要求 “重要数据本地化存储”，而 “国际多中心临床试验” 常需向境外传输病例数据。某药企为加速肿瘤新药研发，向欧盟合作方传输 500 例患者基因测序数据，因未通过 “安全评估” 被处以 2000 万元罚款。欧盟则允许 “基于充分性认定” 的自由传输，但尚未将中国纳入 “白名单”，企业需依赖 “标准合同条款”完成合规，流程繁琐。\n2. 匿名化与去标识化的边界混淆\nGDPR 规定 “匿名化数据不受监管”，而 “去标识化数据仍属个人数据”。实践中，医疗机构常误将 “去除姓名、身份证号” 的病历视为 “匿名化”，实则通过 “出生日期 + 疾病史” 可重新识别个体。2023 年某健康 APP 因向境外传输 “去标识化糖尿病患者数据” 被欧盟认定为 “数据泄露”，面临全球营收 4% 的罚款。\n3. 紧急医疗场景的合规例外缺失\n跨国救援中，实时传输患者电子健康档案可能违反数据出境规定。2024 年某国际航班突发心梗病例，机组向美国地面医院传输患者既往病史数据，事后被质疑 “未事先获得患者授权”，但现行法律未明确 “紧急情况豁免” 条款，导致医疗行为陷入 “救人与合规” 的两难。\n\n 三、前沿问题：生成式 AI 在医疗中的伦理与法律挑战\nChatGPT 等生成式 AI 在病历总结、诊疗建议中的应用，引发新的合规风险：\n1. 幻觉输出的医疗风险\n生成式 AI 可能产生 “看似合理却错误” 的内容（如虚构药物禁忌症）。某基层医院使用 AI 撰写出院小结时，误将 “阿司匹林过敏” 写入无过敏史患者的病历，导致后续用药错误。此类 “算法幻觉”是否构成 “产品缺陷”，现行法律尚未明确责任主体。\n2. 知识产权的归属争议\nAI 基于海量医学文献生成的诊疗方案，是否侵犯原作者的 “著作权”？某 AI 公司的肿瘤治疗建议系统因大段借鉴《NCCN 指南》内容，被起诉 “不正当竞争”，法院认为 “实质性相似但未构成侵权”，但未界定 “合理使用” 的边界。\n3. 患者知情同意的形式缺陷\n使用 AI 辅助诊疗需获得患者 “专项同意”，而非笼统的 “诊疗同意书”。某互联网医院在用户注册协议中默认勾选 “允许 AI 分析病情”，被认定为 “未充分告知”，违反《个人信息保护法》第 14 条，面临整改。\n\n 四、争议解决路径的创新探索\n针对上述困境，实践中出现三类解决方案：\n1. 算法备案与第三方审计\n中国推行 “医疗 AI 算法备案制”，要求企业提交 “训练数据来源、决策逻辑流程图”；欧盟则要求高风险 AI 系统接受 “独立合规评估”。某 AI 眼底筛查系统通过第三方验证其 “误诊率 < 0.5%”，成为首个同时通过中欧合规认证的医疗 AI 产品。\n2. 数据信托与跨境白名单\n新加坡建立 “医疗数据信托”，由第三方机构统一管理跨境传输，平衡 “隐私保护” 与 “科研需求”；中国粤港澳大湾区试点 “数据跨境流动白名单”，允许指定医院向港澳传输脱敏病例数据，无需单独审批。\n3. 替代性纠纷解决机制\n国际医疗 AI 纠纷逐渐采用 “专家仲裁”，如国际医学人工智能协会设立仲裁院，由医师、数据合规师、算法工程师组成合议庭，2024 年成功调解某跨国 AI 诊断系统的跨境责任纠纷，耗时较诉讼缩短 60%。",
    "reference_list": "考点 1:“不作为侵权” 必须译为 “tort of omission”，专业术语，固定译法\n考点 2:“国家药品监督管理局（NMPA）” 必须译为 “National Medical Products Administration (NMPA)”，国家机关官方译名，不可译为其他\n考点 3:“独立合规评估” 推荐译为 “independent conformity assessment”，不可译为 “independent compliance evaluation”或“compliance assessment”\n考点4：“基层医院”推荐译为“primary care hospital”或“community hospital”，不可译为“grassroots hospital”\n考点5: “诊疗建议”推荐译为“diagnostic and treatment advice”或更概括的“clinical advice”\n考点6：\"决策逻辑难以拆解”中的“拆解”应为“deconstruct”或“interpret”，不可译为“disassemble”\n考点7：“数据本地化与出境例外的博弈”中的“博弈”一词应译为“tension”、“interplay”或“balancing act”，不可译为“game”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "182"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n近些年，尽管白象食品在线上渠道取得亮眼成绩和令友商们羡慕的增速。但白象主营方便面产品口味欠佳，创新产品又频频翻车，猎奇口味如香菜面和折耳根拌面遭到差评，高端线“鲜面传”复购率低，致使消费者对白象产品的信任度下降。\n 北京消费者王女士称，经常刷到白象香菜方便面的推广视频，层层香菜包裹着面条的画面对于一个香菜爱好者而言充满了好奇和购买欲望，6·18大促前夕，她花了39.9元拍下10包，吃着却觉得口味一般，面条偏咸，王女士表示不想再买第二次。\n 与此同时，在预制菜、外卖以及越来越多样化的方便速食新品冲击下，原本基数庞大的方便面消费群体逐渐转向螺狮粉、热干面、预制菜等市场，方便面整体市场几近天花板。据世界方便面协会数据，中国方便面消费量已从2020年巅峰期的472.3亿份降至2023年的431.2亿份。\n 另有《方便面市场消费量的影响因素分析》提供的数据，外卖市场规模每增加1%，方便面消费量便减0.0533%；同时，自热火锅、螺蛳粉等新型方便速食和预制菜的崛起，都在分流方便面消费。\n 在此背景下，对于业务相对单一、饮料市场尚未形成气候，仍聚焦面食的白象食品而言，更是雪上加霜。为了拓展新的增长点，不少方便面厂家纷纷瞄准“超大泡面”，试图通过打造多元化和满足消费者对性价比要求进行破局。比如，2024年下半年今麦郎推出“超大泡面”，面饼和配料总重430克，包含四块面饼，主打四人份。\n 2024年白象也推出“超大泡面”新品，定位“多人食分享装”，提供香菜面和火鸡面等多种口味。今年2月，白象再度推出新品——汤好喝超大桶。\n 但就在近日，多位网友反映称，白象多半袋面、多半桶面系列产品包装上显示“多半袋”为注册商标，实际面饼仅增加35克（如普通版70克增至110-120克），增幅不足50%，并质疑企业“在宣传上玩文字游戏”。白象食品官方客服人员也向媒体表示，“多半袋”确实是商标，产品具体克重以包装上显示的为准，本身产品是没有问题的。\n 事件曝光后，“玩文字游戏”话题登上热搜，消费者集中质疑企业诚信。白象次日紧急致歉，承认“初衷是为区分常规份量”，承诺调整包装以避免误解。但在业内人士看来，此类营销会破坏良性市场竞争，导致消费者对行业信任度下降。\n 也有法律专家指出，多数消费者将“多半袋面”理解为“分量比普通包装多一半”，此类表述可能违反《广告法》中“不得含有虚假或引人误解内容”的规定，利用商标权规避虚假宣传责任的做法存在法律风险。\n 对于白象而言，渠道管理失衡与价格体系失控后的战争已然打响，目前市场竞争和消费信任也正面临前所未有的挑战，未来该何去何从，尚待市场检验。",
    "ori_text": "近些年，尽管白象食品在线上渠道取得亮眼成绩和令友商们羡慕的增速。但白象主营方便面产品口味欠佳，创新产品又频频翻车，猎奇口味如香菜面和折耳根拌面遭到差评，高端线“鲜面传”复购率低，致使消费者对白象产品的信任度下降。\n 北京消费者王女士称，经常刷到白象香菜方便面的推广视频，层层香菜包裹着面条的画面对于一个香菜爱好者而言充满了好奇和购买欲望，6·18大促前夕，她花了39.9元拍下10包，吃着却觉得口味一般，面条偏咸，王女士表示不想再买第二次。\n 与此同时，在预制菜、外卖以及越来越多样化的方便速食新品冲击下，原本基数庞大的方便面消费群体逐渐转向螺狮粉、热干面、预制菜等市场，方便面整体市场几近天花板。据世界方便面协会数据，中国方便面消费量已从2020年巅峰期的472.3亿份降至2023年的431.2亿份。\n 另有《方便面市场消费量的影响因素分析》提供的数据，外卖市场规模每增加1%，方便面消费量便减0.0533%；同时，自热火锅、螺蛳粉等新型方便速食和预制菜的崛起，都在分流方便面消费。\n 在此背景下，对于业务相对单一、饮料市场尚未形成气候，仍聚焦面食的白象食品而言，更是雪上加霜。为了拓展新的增长点，不少方便面厂家纷纷瞄准“超大泡面”，试图通过打造多元化和满足消费者对性价比要求进行破局。比如，2024年下半年今麦郎推出“超大泡面”，面饼和配料总重430克，包含四块面饼，主打四人份。\n 2024年白象也推出“超大泡面”新品，定位“多人食分享装”，提供香菜面和火鸡面等多种口味。今年2月，白象再度推出新品——汤好喝超大桶。\n 但就在近日，多位网友反映称，白象多半袋面、多半桶面系列产品包装上显示“多半袋”为注册商标，实际面饼仅增加35克（如普通版70克增至110-120克），增幅不足50%，并质疑企业“在宣传上玩文字游戏”。白象食品官方客服人员也向媒体表示，“多半袋”确实是商标，产品具体克重以包装上显示的为准，本身产品是没有问题的。\n 事件曝光后，“玩文字游戏”话题登上热搜，消费者集中质疑企业诚信。白象次日紧急致歉，承认“初衷是为区分常规份量”，承诺调整包装以避免误解。但在业内人士看来，此类营销会破坏良性市场竞争，导致消费者对行业信任度下降。\n 也有法律专家指出，多数消费者将“多半袋面”理解为“分量比普通包装多一半”，此类表述可能违反《广告法》中“不得含有虚假或引人误解内容”的规定，利用商标权规避虚假宣传责任的做法存在法律风险。\n 对于白象而言，渠道管理失衡与价格体系失控后的战争已然打响，目前市场竞争和消费信任也正面临前所未有的挑战，未来该何去何从，尚待市场检验。",
    "reference_list": "考点1：亮眼成绩推荐译为“stellar performance”，而不应译为“bright-eye results”。\n考点2：频频翻车推荐译为“repeatedly flopped”。\n考点3：猎奇口味推荐译为“exotic flavors”。\n考点4：拍下不可直译为直译为“patted down”或“took a picture of”。\n考点5：尚未形成气候是一个非常形象的中文成语，比喻某事物还未发展壮大，没有形成规模和影响力，推荐译为“is not yet well-established”，不可直译为“has not yet formed a climate”。\n考点6：克重是产品规格术语，应译为“net weight”。\n考点7：登上热搜是网络流行语，推荐译为“started trending on social media”。\n考点8：尚待市场检验是商业分析报告中常见的结尾套话，推荐译为“remains to be seen”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "40"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nPlastic products derived from petroleum refining have become indispensable in daily life due to their lightweight nature, low production cost, and excellent durability [1]. According to relevant statistics, global plastic consumption has surged from 335 million tons in 2016 to 400 million tons in 2021, showing a continuous upward trend [2]. During the COVID-19 pandemic, the demand for single-use personal protective equipment (PPE) such as masks and gloves, along with packaging materials, surged dramatically. It is estimated that over 450 billion plastic-based PPE items were used globally in 2020 alone [3]. Moreover, the widespread adoption of fast-paced lifestyles has driven the rapid growth in the food delivery and e-commerce sectors, significantly increasing the consumption of plastic packaging materials. However, despite the convenience plastics bring to modern life, the growing dependence on them has led to increasingly severe challenges in waste management. Owing to the large-scale production and short service life of most plastic products, post-use plastics continue to accumulate in the environment, leading to mounting pollution and increasingly complex waste management issues.\nCurrently, the scientific community is actively addressing the challenges of plastic recycling and resource recovery by exploring a range of efficient and viable chemical transformation pathways, including hydrogenolysis, alcoholysis, glycolysis, and pyrolysis [4,5,6]. Under ideal conditions, chemical conversion pathways should enable the efficient recovery of high-purity monomers from plastic waste, with the recovered products exhibiting quality and reactivity comparable to those of virgin feedstocks, allowing for direct reutilization in the synthesis of new polymers. This approach not only significantly improves resource utilization efficiency but also paves the way toward genuine “closed-loop recycling” [7,8]. However, plastics—particularly thermosets and highly cross-linked polymers—exhibit exceptional chemical stability due to their dense three-dimensional network structures and robust carbon–carbon backbones, which severely hinder their degradation under mild conditions. As a result, current chemical recycling technologies typically require harsh operating conditions—such as elevated temperatures (>180 °C), high pressures (20–40 atm), and concentrated alkali (1–10 M) or strong acids (e.g., concentrated H2SO4 or HNO3) as reaction media. While these conditions facilitate polymer-chain scission and improve reaction rates, they also pose significant challenges, including high energy consumption, severe equipment corrosion, secondary environmental pollution, and limited economic feasibility [9,10,11]. Therefore, the development of mild and green plastic conversion technologies operable under ambient or near-ambient conditions is a critical breakthrough toward achieving sustainable plastic recycling.\nPhoto-driven photocatalytic technology is regarded as a highly promising strategy for sustainable plastic waste management. In general, photocatalytic plastic conversion systems can be broadly categorized into the following two types: photodegradation and photosynthetic transformation (Figure 1) [12]. The ability to selectively generate value-added products is one of the key criteria distinguishing photodegradation from selective photo-reforming processes. As shown in Figure 1a, conventional photodegradation typically aims at mineralization, relying on highly oxidative radicals (e.g., •OH) to indiscriminately attack polymer backbones and intermediates. This results in complex reaction pathways and broad product distributions, with final products dominated by CO2, water, and trace organic acids, offering limited value [12,13]. In contrast, photosynthetic conversion emphasizes precise regulation of reaction pathways to efficiently convert hydrocarbon content in plastics into chemically valuable target molecules (e.g., H2, C1–C2+ fuels, and aromatic compounds) (Figure 1b) [14]. Therefore, the transition to photosynthetic systems hinges on the modulation of radical type, concentration, and spatial reactivity to prevent uncontrolled mineralization by overly oxidative species.\nIn this review, we first provide a brief overview of the current status of plastic waste treatment with respect to the basic reaction mechanisms involved in the photocatalytic process for plastics, with special emphasis on the redox pathways and the roles of key reactants in the photocatalytic process. We then systematically summarize representative recent advances in photocatalytic plastic waste conversion, categorized by plastic type (e.g., polyolefins and polyesters) (Figure 2), and critically analyze the performance and applicability of different catalytic systems. Finally, we discuss the key challenges in achieving efficient and selective transformation of plastic waste, including catalyst stability, compatibility with real-world plastics, product selectivity control, and system-level economic feasibility. We also outline future directions in catalyst design, mechanistic investigation, reaction engineering scale-up, and industrial deployment. We hope this review offers theoretical insights and technical references that contribute to the green transition of plastic pollution management and resource recovery.\nThe management of plastic waste has attracted widespread global attention due to its significant impact on the sustainability of human life. A variety of techniques are employed in managing plastic waste, including incineration, landfill disposal, microbial degradation, and mechanical shredding with subsequent recycling, as well as transformation methods driven by electricity, heat, or light. These approaches each offer distinct advantages and limitations in the effort to reduce environmental impact and recover value from discarded plastic materials (Figure 3) [15,16,17,18,19,20,21]. Currently, plastic waste is primarily managed through landfilling and incineration, while a substantial fraction is still discharged directly into natural environments [22]. Among various plastic products, packaging materials are particularly problematic, as they are prone to entering rivers, lakes, and oceans, posing significant threats to aquatic ecosystems [23]. With the continuous growth in global plastic production and the diminishing availability of landfill space, the economic burden of plastic waste management has increased markedly. More critically, landfilling not only leads to a considerable waste of petroleum-derived resources but also gives rise to severe environmental concerns, including the leaching of chemical additives and long-term land occupation [24]. Similarly, although plastic incineration allows partial energy recovery, it is far less efficient compared to recycling and entails high environmental costs [25]. The life-cycle carbon footprint of incinerated polymers is substantial, with an estimated 5 to 10 tons of CO2 emitted per ton of plastic processed [17]. Furthermore, incineration can produce toxic byproducts [26], rendering it a suboptimal strategy from both ecological and energy standpoints. Mechanical recycling typically follows a downcycling approach, wherein waste plastics are physically processed through shredding, washing, and remelting [27]. However, the resulting recycled materials are often utilized in the production of low-performance products, such as flower pots or non-food-contact containers [28]. This degradation in material quality leads to a reduction in overall polymer value, liTo address the inherent limitations of conventional recycling approaches, catalytic upcycling has emerged as a highly attractive alternative. This strategy enables the efficient conversion of polymeric waste into high-value chemicals, fuels, and other functional materials with significant economic potential, offering a promising complement to existing recycling methods [29]. Electrocatalysis has demonstrated promising conversion efficiency in the treatment of polymeric waste, offering advantages such as mild operating conditions and product selectivity. However, its reliance on external electrical energy input and the current limitations in electrode material selection, reactor design, and long-term operational stability pose significant technical challenges that must be addressed to enable practical application [30]. Thermocatalytic conversion is highly efficient and offers excellent reaction stability, enabling the rapid cleavage of C–C bonds to produce value-added chemicals. However, the requirement for elevated temperatures and substantial energy input imposes constraints on its scalability and practical implementation [31]. Enzymatic biotechnology relies on highly specific plastic-degrading enzymes, which have a limited substrate scope and face challenges in processing complex or mixed plastic waste. Moreover, these enzymes often exhibit poor stability under harsh reaction conditions. Fermentation, which converts plastic-derived intermediates into valuable chemicals through microbial metabolism, typically requires tedious pretreatment steps to depolymerize plastics into fermentable substrates. This complicates the process workflow and significantly increases downstream separation and purification costs [32]. Photocatalytic conversion has emerged as a promising strategy for plastic waste treatment due to its mild reaction conditions, high energy efficiency, and potential for selective transformation. As shown in Figure 4, operating under ambient temperature and pressure and utilizing solar or ultraviolet light as the energy source, photocatalysis presents a more economically viable and environmentally friendly alternative compared with conventional thermal and chemical degradation methods [33]. Unlike pyrolysis or incineration, which require high energy input and often generate toxic byproducts, photocatalytic processes can proceed under mild conditions with minimal environmental risk. Furthermore, many photocatalytic systems leverage solar energy, enhancing their long-term sustainability and cost-effectiveness. Certain photocatalysts have demonstrated the ability to selectively cleave polymer chains or oxidize specific moieties, enabling the conversion of plastic waste into valuable monomers or fine chemicals. Compared with enzymatic biotechnology, which relies on highly specific enzymes and suffers from limited substrate scope and low stability under harsh conditions, photocatalytic systems exhibit broader applicability. They can effectively process both homochain and heterochain polymers by modulating reactive oxygen species (•OH, •O2−) and optimizing catalyst active sites. Similarly, microbial fermentation—despite its potential for converting plastic-derived intermediates into chemicals—often requires tedious and costly pretreatment to break down polymers into fermentable substrates, complicating process workflows and increasing separation burdens. In contrast, photocatalysis offers an integrated platform for both degradation and upcycling, enabling direct, selective conversion of plastic waste without extensive preprocessing. Its ability to control radical activity also helps suppress over-oxidation, thereby favoring the formation of high-value products. Taken together, the synergistic advantages of photocatalytic technology, including mild operational conditions, solar energy utilization, broad substrate compatibility, and direct value-added conversion, position it as a highly efficient and sustainable core strategy for addressing plastic waste. In comparison, other emerging alternatives remain constrained by energy intensity, substrate specificity, or process complexity.miting its potential for reuse in high-end applications.",
    "ori_text": "Plastic products derived from petroleum refining have become indispensable in daily life due to their lightweight nature, low production cost, and excellent durability [1]. According to relevant statistics, global plastic consumption has surged from 335 million tons in 2016 to 400 million tons in 2021, showing a continuous upward trend [2]. During the COVID-19 pandemic, the demand for single-use personal protective equipment (PPE) such as masks and gloves, along with packaging materials, surged dramatically. It is estimated that over 450 billion plastic-based PPE items were used globally in 2020 alone [3]. Moreover, the widespread adoption of fast-paced lifestyles has driven the rapid growth in the food delivery and e-commerce sectors, significantly increasing the consumption of plastic packaging materials. However, despite the convenience plastics bring to modern life, the growing dependence on them has led to increasingly severe challenges in waste management. Owing to the large-scale production and short service life of most plastic products, post-use plastics continue to accumulate in the environment, leading to mounting pollution and increasingly complex waste management issues.\nCurrently, the scientific community is actively addressing the challenges of plastic recycling and resource recovery by exploring a range of efficient and viable chemical transformation pathways, including hydrogenolysis, alcoholysis, glycolysis, and pyrolysis [4,5,6]. Under ideal conditions, chemical conversion pathways should enable the efficient recovery of high-purity monomers from plastic waste, with the recovered products exhibiting quality and reactivity comparable to those of virgin feedstocks, allowing for direct reutilization in the synthesis of new polymers. This approach not only significantly improves resource utilization efficiency but also paves the way toward genuine “closed-loop recycling” [7,8]. However, plastics—particularly thermosets and highly cross-linked polymers—exhibit exceptional chemical stability due to their dense three-dimensional network structures and robust carbon–carbon backbones, which severely hinder their degradation under mild conditions. As a result, current chemical recycling technologies typically require harsh operating conditions—such as elevated temperatures (>180 °C), high pressures (20–40 atm), and concentrated alkali (1–10 M) or strong acids (e.g., concentrated H2SO4 or HNO3) as reaction media. While these conditions facilitate polymer-chain scission and improve reaction rates, they also pose significant challenges, including high energy consumption, severe equipment corrosion, secondary environmental pollution, and limited economic feasibility [9,10,11]. Therefore, the development of mild and green plastic conversion technologies operable under ambient or near-ambient conditions is a critical breakthrough toward achieving sustainable plastic recycling.\nPhoto-driven photocatalytic technology is regarded as a highly promising strategy for sustainable plastic waste management. In general, photocatalytic plastic conversion systems can be broadly categorized into the following two types: photodegradation and photosynthetic transformation (Figure 1) [12]. The ability to selectively generate value-added products is one of the key criteria distinguishing photodegradation from selective photo-reforming processes. As shown in Figure 1a, conventional photodegradation typically aims at mineralization, relying on highly oxidative radicals (e.g., •OH) to indiscriminately attack polymer backbones and intermediates. This results in complex reaction pathways and broad product distributions, with final products dominated by CO2, water, and trace organic acids, offering limited value [12,13]. In contrast, photosynthetic conversion emphasizes precise regulation of reaction pathways to efficiently convert hydrocarbon content in plastics into chemically valuable target molecules (e.g., H2, C1–C2+ fuels, and aromatic compounds) (Figure 1b) [14]. Therefore, the transition to photosynthetic systems hinges on the modulation of radical type, concentration, and spatial reactivity to prevent uncontrolled mineralization by overly oxidative species.\nIn this review, we first provide a brief overview of the current status of plastic waste treatment with respect to the basic reaction mechanisms involved in the photocatalytic process for plastics, with special emphasis on the redox pathways and the roles of key reactants in the photocatalytic process. We then systematically summarize representative recent advances in photocatalytic plastic waste conversion, categorized by plastic type (e.g., polyolefins and polyesters) (Figure 2), and critically analyze the performance and applicability of different catalytic systems. Finally, we discuss the key challenges in achieving efficient and selective transformation of plastic waste, including catalyst stability, compatibility with real-world plastics, product selectivity control, and system-level economic feasibility. We also outline future directions in catalyst design, mechanistic investigation, reaction engineering scale-up, and industrial deployment. We hope this review offers theoretical insights and technical references that contribute to the green transition of plastic pollution management and resource recovery.\nThe management of plastic waste has attracted widespread global attention due to its significant impact on the sustainability of human life. A variety of techniques are employed in managing plastic waste, including incineration, landfill disposal, microbial degradation, and mechanical shredding with subsequent recycling, as well as transformation methods driven by electricity, heat, or light. These approaches each offer distinct advantages and limitations in the effort to reduce environmental impact and recover value from discarded plastic materials (Figure 3) [15,16,17,18,19,20,21]. Currently, plastic waste is primarily managed through landfilling and incineration, while a substantial fraction is still discharged directly into natural environments [22]. Among various plastic products, packaging materials are particularly problematic, as they are prone to entering rivers, lakes, and oceans, posing significant threats to aquatic ecosystems [23]. With the continuous growth in global plastic production and the diminishing availability of landfill space, the economic burden of plastic waste management has increased markedly. More critically, landfilling not only leads to a considerable waste of petroleum-derived resources but also gives rise to severe environmental concerns, including the leaching of chemical additives and long-term land occupation [24]. Similarly, although plastic incineration allows partial energy recovery, it is far less efficient compared to recycling and entails high environmental costs [25]. The life-cycle carbon footprint of incinerated polymers is substantial, with an estimated 5 to 10 tons of CO2 emitted per ton of plastic processed [17]. Furthermore, incineration can produce toxic byproducts [26], rendering it a suboptimal strategy from both ecological and energy standpoints. Mechanical recycling typically follows a downcycling approach, wherein waste plastics are physically processed through shredding, washing, and remelting [27]. However, the resulting recycled materials are often utilized in the production of low-performance products, such as flower pots or non-food-contact containers [28]. This degradation in material quality leads to a reduction in overall polymer value, liTo address the inherent limitations of conventional recycling approaches, catalytic upcycling has emerged as a highly attractive alternative. This strategy enables the efficient conversion of polymeric waste into high-value chemicals, fuels, and other functional materials with significant economic potential, offering a promising complement to existing recycling methods [29]. Electrocatalysis has demonstrated promising conversion efficiency in the treatment of polymeric waste, offering advantages such as mild operating conditions and product selectivity. However, its reliance on external electrical energy input and the current limitations in electrode material selection, reactor design, and long-term operational stability pose significant technical challenges that must be addressed to enable practical application [30]. Thermocatalytic conversion is highly efficient and offers excellent reaction stability, enabling the rapid cleavage of C–C bonds to produce value-added chemicals. However, the requirement for elevated temperatures and substantial energy input imposes constraints on its scalability and practical implementation [31]. Enzymatic biotechnology relies on highly specific plastic-degrading enzymes, which have a limited substrate scope and face challenges in processing complex or mixed plastic waste. Moreover, these enzymes often exhibit poor stability under harsh reaction conditions. Fermentation, which converts plastic-derived intermediates into valuable chemicals through microbial metabolism, typically requires tedious pretreatment steps to depolymerize plastics into fermentable substrates. This complicates the process workflow and significantly increases downstream separation and purification costs [32]. Photocatalytic conversion has emerged as a promising strategy for plastic waste treatment due to its mild reaction conditions, high energy efficiency, and potential for selective transformation. As shown in Figure 4, operating under ambient temperature and pressure and utilizing solar or ultraviolet light as the energy source, photocatalysis presents a more economically viable and environmentally friendly alternative compared with conventional thermal and chemical degradation methods [33]. Unlike pyrolysis or incineration, which require high energy input and often generate toxic byproducts, photocatalytic processes can proceed under mild conditions with minimal environmental risk. Furthermore, many photocatalytic systems leverage solar energy, enhancing their long-term sustainability and cost-effectiveness. Certain photocatalysts have demonstrated the ability to selectively cleave polymer chains or oxidize specific moieties, enabling the conversion of plastic waste into valuable monomers or fine chemicals. Compared with enzymatic biotechnology, which relies on highly specific enzymes and suffers from limited substrate scope and low stability under harsh conditions, photocatalytic systems exhibit broader applicability. They can effectively process both homochain and heterochain polymers by modulating reactive oxygen species (•OH, •O2−) and optimizing catalyst active sites. Similarly, microbial fermentation—despite its potential for converting plastic-derived intermediates into chemicals—often requires tedious and costly pretreatment to break down polymers into fermentable substrates, complicating process workflows and increasing separation burdens. In contrast, photocatalysis offers an integrated platform for both degradation and upcycling, enabling direct, selective conversion of plastic waste without extensive preprocessing. Its ability to control radical activity also helps suppress over-oxidation, thereby favoring the formation of high-value products. Taken together, the synergistic advantages of photocatalytic technology, including mild operational conditions, solar energy utilization, broad substrate compatibility, and direct value-added conversion, position it as a highly efficient and sustainable core strategy for addressing plastic waste. In comparison, other emerging alternatives remain constrained by energy intensity, substrate specificity, or process complexity.miting its potential for reuse in high-end applications.",
    "reference_list": "考点1：【single-use personal protective equipment (PPE)】 应译为 【一次性个人防护用品】，其中的“equipment”不可译为“设备”\n考点2：【chemical transformation pathways 】应译为 【化学转化路径】\n考点3：【glycolysis】 应译为 【乙二醇解】\n考点4：【polyolefins and polyesters】 应译为 【聚烯烃与聚酯类】\n考点5：【life-cycle carbon footprint】 应译为 【全生命周期碳足迹】\n考点6：【reactive oxygen species】 应译为 【活性氧物种】\n考点7：【homochain and heterochain polymers】 应译为 【同链/均链与异链/杂链聚合物】\n考点8：【green transition of plastic pollution management】 应译为 【塑料污染治理的绿色转型】",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "87"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nQuantitative Transcriptional Analysis of Single-Cell RNA-Sequencing Methods\n\nSUMMARY\nSingle-cell RNA sequencing (scRNA-seq) offers new possibilities to address biological and medical questions. However, systematic comparisons of the per- formance of diverse scRNA-seq protocols are lacking. We generated data from 583 mouse embryonic stem cells to evaluate six prominent scRNA-seq methods: CEL-seq2, Drop-seq, MARS-seq, SCRB- seq, Smart-seq, and Smart-seq2. While Smart-seq2 detected the most genes per cell and across cells, CEL-seq2, Drop-seq, MARS-seq, and SCRB-seq quantified mRNA levels with less amplification noise due to the use of unique molecular identifiers (UMIs). Power simulations at different sequencing depths showed that Drop-seq is more cost-efficient for transcriptome quantification of large numbers of cells, while MARS-seq, SCRB-seq, and Smart-seq2 are more efficient when analyzing fewer cells. Our quantitative comparison offers the basis for an informed choice among six prominent scRNA-seq methods, and it provides a framework for benchmarking further improvements of scRNA-seq protocols.\n\nINTRODUCTION\nGenome-wide quantification of mRNA transcripts is highly informative for characterizing cellular states and molecular circuitries (ENCODE Project Consortium, 2012). Ideally, such data are collected with high spatial resolution, and single-cell RNA sequencing (scRNA-seq) now allows for transcriptome-wide analyses of individual cells, revealing exciting biological and med- ical insights (Kolodziejczyk et al., 2015a; Wagner et al., 2016). scRNA-seq requires the isolation and lysis of single cells, the conversion of their RNA into cDNA, and the amplification of cDNA to generate high-throughput sequencing libraries. As the\namount of starting material is so small, this process results in substantial technical variation (Kolodziejczyk et al., 2015a; Wagner et al., 2016).\nOne type of technical variable is the sensitivity of a scRNA- seq method (i.e., the probability to capture and convert a particular mRNA transcript present in a single cell into a cDNA molecule present in the library). Another variable of interest is the accuracy (i.e., how well the read quantification corresponds to the actual concentration of mRNAs), and a third type is the precision with which this amplification occurs (i.e., the technical variation of the quantification). The combination of sensitivity, precision, and number of cells analyzed determines the power to detect relative differences in expression levels. Finally, the monetary cost to reach a desired level of power is of high practical relevance. To make a well- informed choice among available scRNA-seq methods, it is important to quantify these parameters comparably. Some strengths and weaknesses of different methods are already known. For example, it has previously been shown that scRNA-seq conducted in the small volumes available in the automated microfluidic platform from Fluidigm (C1 platform) outperforms CEL-seq2, Smart-seq, or other commercially available kits in microliter volumes (Hashimshony et al., 2016; Wu et al., 2014). Furthermore, the Smart-seq protocol has been optimized for sensitivity, more even full-length coverage, accuracy, and cost (Picelli et al., 2013), and this improved Smart-seq2 protocol (Picelli et al., 2014b) has also become widely used (Gokce et al., 2016; Reinius et al., 2016; Tirosh et al., 2016).\n\nOther protocols have sacrificed full-length coverage in order to sequence part of the primer used for cDNA generation. This enables early barcoding of libraries (i.e., the incorporation of cell-specific barcodes), allowing for multiplexing the cDNA amplification and thereby increasing the throughput of scRNA- seq library generation by one to three orders of magnitude (Hashimshony et al., 2012; Jaitin et al., 2014; Klein et al., 2015; Macosko et al., 2015; Soumillon et al., 2014). Additionally, this approach allows the incorporation of unique molecular identifiers (UMIs), random nucleotide sequences that tag individual mRNA molecules and, hence, allow for the distinction between original molecules and amplification duplicates that derive from the cDNA or library amplification (Kivioja et al., 2011). Utilization of UMI information improves quantification of mRNA molecules (Grun et al., 2014; Islam et al., 2014), and it has been implemented in several scRNA-seq protocols, such as STRT (Islam et al., 2014), CEL-seq (Gru€n et al., 2014; Hashimshony et al., 2016), CEL-seq2 (Hashimshony et al., 2016), Drop-seq (Ma- cosko et al., 2015), inDrop (Klein et al., 2015), MARS-seq (Jaitin et al., 2014), and SCRB-seq (Soumillon et al., 2014).\nHowever, a thorough and systematic comparison of relevant parameters across scRNA-seq methods is still lacking. To address this issue, we generated 583 scRNA-seq libraries from mouse embryonic stem cells (mESCs), using six different methods in two replicates, and we compared their sensitivity, accuracy, precision, power, and efficiency (Figure 1).\n\nDISCUSSION\nHere we have provided an in-depth comparison of six prominent scRNA-seq protocols. To this end, we generated data for all six compared methods from the same cells, cultured under the same condition in the same laboratory. While there would be many more datasets and methods for a comparison of the sensitivity and accuracy of the ERCCs (Svensson et al., 2016), our approach provides a more controlled and comprehensive comparison across thousands of endogenous genes. This is important, as can be seen by the different sensitivity estimates that we obtained for Drop-seq, MARS-seq, and SCRB-seq using the ERCCs. In our comparison, we clearly find that Smart-seq2 is the most sensitive method, closely followed by SCRB-seq, Smart-seq/C1, and CEL-seq2/C1, while Drop-seq and MARS- seq detect nearly 50% fewer genes per cell (Figures 3B and 3C). In addition, Smart-seq2 shows the most even read coverage across transcripts (Figure S3D), making it the most appropriate method for the detection of alternative splice forms and for analyses of allele-specific expression using SNPs (Deng et al., 2014; Reinius et al., 2016). Hence, Smart-seq2 is certainly the most suitable method when an annotation of single-cell transcriptomes is the focus. Furthermore, we find that Smart-seq2 is also the most accurate method (i.e., it has the highest correlation of known ERCC spike-in concentrations and read counts per million), which is probably related to its higher sensitivity. Hence, differences in expression values across transcripts within the same cell predict differences in the actual concentrations of these transcripts well. All methods do this rather well, at least for higher expression levels, and we think that the small differences among methods will rarely be a decisive factor. Importantly, the accuracy of estimating transcript concentrations across cells (relevant, e.g., for comparing the total RNA content of cells) depends on different factors and cannot be compared well among the tested methods as it would require known concentration differences of transcripts across cells. However, it is likely that methods that can use UMIs and ERCCs (CEL-seq2/ C1, MARS-seq, and SCRB-seq) would have a strong advantage in this respect.\nHow well relative expression levels of the same genes can be compared across cells depends on two factors. First, how often (i.e., in how many cells and from how many molecules) it is measured. Second, with how much technical variation (i.e., with how much noise, e.g., from amplification) it is measured. For the first factor (dropout probability), we find Smart-seq2 to be the best method (Figure 5A), as expected from its high gene detection sensitivity. For the second factor (extra Poisson variability), we find the four UMI methods to perform better (Figure 5B), as expected from their ability to eliminate variation introduced by amplification. To assess the combined effect of these two factors, we performed simulations for differential gene expression scenarios (Figure 6). This allowed us to translate the sensitivity and precision parameters into the practically relevant power to detect differentially expressed genes. Of note, our power estimates include the variation that is caused by the two different replicates per method that constitutes an important part of the variation. Our simulations show that, at a sequencing depth of one million reads, SCRB-seq has the highest power, probably due to a good balance of high sensitivity and low amplification noise. Furthermore, amplification noise and power strongly depend on the use of UMIs, especially for the PCR- based methods (Figures 5B and 6B; Figure S7). Notably, this is due to the large amount of amplification needed for scRNA- seq libraries, as the effect of UMIs on power for bulk RNA-seq libraries is negligible (Parekh et al., 2016).\nPerhaps practically most important, our power simulations also allow us to compare the efficiency of the methods by calculating the costs to generate the data for a given level of power. Using minimal cost calculations, we find that Drop-seq is the most cost-effective method, closely followed by SCRB-seq, MARS-seq, and Smart-seq2. However, Drop-seq costs are likely to be more underestimated, due to lower flexibility in generating a specified number of libraries and the higher fraction of reads that come from bad cells. Hence, all four UMI methods are in practice probably similarly cost-effective. In contrast, for Smart-seq2 to be similarly cost-effective it is absolutely necessary to use in-house-produced transposase or to drastically reduce volumes of commercial transposase kits (Lamble et al., 2013; Mora-Castilla et al., 2016).\nGiven comparable efficiencies of Drop-seq, MARS-seq, SCRB-seq, and Smart-seq2, additional factors will play a role when choosing a suitable method for a particular question. Due to its low library costs, Drop-seq is probably prefer- able when analyzing large numbers of cells at low coverage (e.g., to find rare cell types). On the other hand, Drop-seq in its current setup requires a relatively large amount of cells (>6,500 for 1 min of flow). Hence, if few and/or unstable cells are isolated by FACS, the SCRB-seq, MARS-seq, or Smart- seq2 protocols are probably preferable. Additional advantages of these methods over Drop-seq include that technical variation can be estimated from ERCCs for each cell, which can be helpful to estimate biological variation (Kim et al., 2015; Vallejos et al., 2016), and that the exact same setup can be used to generate bulk RNA-seq libraries. While SCRB-seq is slightly more cost-effective than MARS-seq and has the advantage that one does not need to produce the transposase in-house, Smart-seq2 is preferable when transcriptome annotation, identification of sequence variants, or the quantification of different splice forms is of interest. Furthermore, the presence of batch effects shows that experiments need to be designed in a way that does not confound batches with bio- logical factors (Hicks et al., 2015). Practically, plate-based methods might currently accommodate complex experimental designs with various biological factors more easily than microfluidic chips.",
    "ori_text": "\n\nQuantitative Transcriptional Analysis of Single-Cell RNA-Sequencing Methods\n\nSUMMARY\nSingle-cell RNA sequencing (scRNA-seq) offers new possibilities to address biological and medical questions. However, systematic comparisons of the per- formance of diverse scRNA-seq protocols are lacking. We generated data from 583 mouse embryonic stem cells to evaluate six prominent scRNA-seq methods: CEL-seq2, Drop-seq, MARS-seq, SCRB- seq, Smart-seq, and Smart-seq2. While Smart-seq2 detected the most genes per cell and across cells, CEL-seq2, Drop-seq, MARS-seq, and SCRB-seq quantified mRNA levels with less amplification noise due to the use of unique molecular identifiers (UMIs). Power simulations at different sequencing depths showed that Drop-seq is more cost-efficient for transcriptome quantification of large numbers of cells, while MARS-seq, SCRB-seq, and Smart-seq2 are more efficient when analyzing fewer cells. Our quantitative comparison offers the basis for an informed choice among six prominent scRNA-seq methods, and it provides a framework for benchmarking further improvements of scRNA-seq protocols.\n\nINTRODUCTION\nGenome-wide quantification of mRNA transcripts is highly informative for characterizing cellular states and molecular circuitries (ENCODE Project Consortium, 2012). Ideally, such data are collected with high spatial resolution, and single-cell RNA sequencing (scRNA-seq) now allows for transcriptome-wide analyses of individual cells, revealing exciting biological and med- ical insights (Kolodziejczyk et al., 2015a; Wagner et al., 2016). scRNA-seq requires the isolation and lysis of single cells, the conversion of their RNA into cDNA, and the amplification of cDNA to generate high-throughput sequencing libraries. As the\namount of starting material is so small, this process results in substantial technical variation (Kolodziejczyk et al., 2015a; Wagner et al., 2016).\nOne type of technical variable is the sensitivity of a scRNA- seq method (i.e., the probability to capture and convert a particular mRNA transcript present in a single cell into a cDNA molecule present in the library). Another variable of interest is the accuracy (i.e., how well the read quantification corresponds to the actual concentration of mRNAs), and a third type is the precision with which this amplification occurs (i.e., the technical variation of the quantification). The combination of sensitivity, precision, and number of cells analyzed determines the power to detect relative differences in expression levels. Finally, the monetary cost to reach a desired level of power is of high practical relevance. To make a well- informed choice among available scRNA-seq methods, it is important to quantify these parameters comparably. Some strengths and weaknesses of different methods are already known. For example, it has previously been shown that scRNA-seq conducted in the small volumes available in the automated microfluidic platform from Fluidigm (C1 platform) outperforms CEL-seq2, Smart-seq, or other commercially available kits in microliter volumes (Hashimshony et al., 2016; Wu et al., 2014). Furthermore, the Smart-seq protocol has been optimized for sensitivity, more even full-length coverage, accuracy, and cost (Picelli et al., 2013), and this improved Smart-seq2 protocol (Picelli et al., 2014b) has also become widely used (Gokce et al., 2016; Reinius et al., 2016; Tirosh et al., 2016).\n\nOther protocols have sacrificed full-length coverage in order to sequence part of the primer used for cDNA generation. This enables early barcoding of libraries (i.e., the incorporation of cell-specific barcodes), allowing for multiplexing the cDNA amplification and thereby increasing the throughput of scRNA- seq library generation by one to three orders of magnitude (Hashimshony et al., 2012; Jaitin et al., 2014; Klein et al., 2015; Macosko et al., 2015; Soumillon et al., 2014). Additionally, this approach allows the incorporation of unique molecular identifiers (UMIs), random nucleotide sequences that tag individual mRNA molecules and, hence, allow for the distinction between original molecules and amplification duplicates that derive from the cDNA or library amplification (Kivioja et al., 2011). Utilization of UMI information improves quantification of mRNA molecules (Grun et al., 2014; Islam et al., 2014), and it has been implemented in several scRNA-seq protocols, such as STRT (Islam et al., 2014), CEL-seq (Gru€n et al., 2014; Hashimshony et al., 2016), CEL-seq2 (Hashimshony et al., 2016), Drop-seq (Ma- cosko et al., 2015), inDrop (Klein et al., 2015), MARS-seq (Jaitin et al., 2014), and SCRB-seq (Soumillon et al., 2014).\nHowever, a thorough and systematic comparison of relevant parameters across scRNA-seq methods is still lacking. To address this issue, we generated 583 scRNA-seq libraries from mouse embryonic stem cells (mESCs), using six different methods in two replicates, and we compared their sensitivity, accuracy, precision, power, and efficiency (Figure 1).\n\nDISCUSSION\nHere we have provided an in-depth comparison of six prominent scRNA-seq protocols. To this end, we generated data for all six compared methods from the same cells, cultured under the same condition in the same laboratory. While there would be many more datasets and methods for a comparison of the sensitivity and accuracy of the ERCCs (Svensson et al., 2016), our approach provides a more controlled and comprehensive comparison across thousands of endogenous genes. This is important, as can be seen by the different sensitivity estimates that we obtained for Drop-seq, MARS-seq, and SCRB-seq using the ERCCs. In our comparison, we clearly find that Smart-seq2 is the most sensitive method, closely followed by SCRB-seq, Smart-seq/C1, and CEL-seq2/C1, while Drop-seq and MARS- seq detect nearly 50% fewer genes per cell (Figures 3B and 3C). In addition, Smart-seq2 shows the most even read coverage across transcripts (Figure S3D), making it the most appropriate method for the detection of alternative splice forms and for analyses of allele-specific expression using SNPs (Deng et al., 2014; Reinius et al., 2016). Hence, Smart-seq2 is certainly the most suitable method when an annotation of single-cell transcriptomes is the focus. Furthermore, we find that Smart-seq2 is also the most accurate method (i.e., it has the highest correlation of known ERCC spike-in concentrations and read counts per million), which is probably related to its higher sensitivity. Hence, differences in expression values across transcripts within the same cell predict differences in the actual concentrations of these transcripts well. All methods do this rather well, at least for higher expression levels, and we think that the small differences among methods will rarely be a decisive factor. Importantly, the accuracy of estimating transcript concentrations across cells (relevant, e.g., for comparing the total RNA content of cells) depends on different factors and cannot be compared well among the tested methods as it would require known concentration differences of transcripts across cells. However, it is likely that methods that can use UMIs and ERCCs (CEL-seq2/ C1, MARS-seq, and SCRB-seq) would have a strong advantage in this respect.\nHow well relative expression levels of the same genes can be compared across cells depends on two factors. First, how often (i.e., in how many cells and from how many molecules) it is measured. Second, with how much technical variation (i.e., with how much noise, e.g., from amplification) it is measured. For the first factor (dropout probability), we find Smart-seq2 to be the best method (Figure 5A), as expected from its high gene detection sensitivity. For the second factor (extra Poisson variability), we find the four UMI methods to perform better (Figure 5B), as expected from their ability to eliminate variation introduced by amplification. To assess the combined effect of these two factors, we performed simulations for differential gene expression scenarios (Figure 6). This allowed us to translate the sensitivity and precision parameters into the practically relevant power to detect differentially expressed genes. Of note, our power estimates include the variation that is caused by the two different replicates per method that constitutes an important part of the variation. Our simulations show that, at a sequencing depth of one million reads, SCRB-seq has the highest power, probably due to a good balance of high sensitivity and low amplification noise. Furthermore, amplification noise and power strongly depend on the use of UMIs, especially for the PCR- based methods (Figures 5B and 6B; Figure S7). Notably, this is due to the large amount of amplification needed for scRNA- seq libraries, as the effect of UMIs on power for bulk RNA-seq libraries is negligible (Parekh et al., 2016).\nPerhaps practically most important, our power simulations also allow us to compare the efficiency of the methods by calculating the costs to generate the data for a given level of power. Using minimal cost calculations, we find that Drop-seq is the most cost-effective method, closely followed by SCRB-seq, MARS-seq, and Smart-seq2. However, Drop-seq costs are likely to be more underestimated, due to lower flexibility in generating a specified number of libraries and the higher fraction of reads that come from bad cells. Hence, all four UMI methods are in practice probably similarly cost-effective. In contrast, for Smart-seq2 to be similarly cost-effective it is absolutely necessary to use in-house-produced transposase or to drastically reduce volumes of commercial transposase kits (Lamble et al., 2013; Mora-Castilla et al., 2016).\nGiven comparable efficiencies of Drop-seq, MARS-seq, SCRB-seq, and Smart-seq2, additional factors will play a role when choosing a suitable method for a particular question. Due to its low library costs, Drop-seq is probably prefer- able when analyzing large numbers of cells at low coverage (e.g., to find rare cell types). On the other hand, Drop-seq in its current setup requires a relatively large amount of cells (>6,500 for 1 min of flow). Hence, if few and/or unstable cells are isolated by FACS, the SCRB-seq, MARS-seq, or Smart- seq2 protocols are probably preferable. Additional advantages of these methods over Drop-seq include that technical variation can be estimated from ERCCs for each cell, which can be helpful to estimate biological variation (Kim et al., 2015; Vallejos et al., 2016), and that the exact same setup can be used to generate bulk RNA-seq libraries. While SCRB-seq is slightly more cost-effective than MARS-seq and has the advantage that one does not need to produce the transposase in-house, Smart-seq2 is preferable when transcriptome annotation, identification of sequence variants, or the quantification of different splice forms is of interest. Furthermore, the presence of batch effects shows that experiments need to be designed in a way that does not confound batches with bio- logical factors (Hicks et al., 2015). Practically, plate-based methods might currently accommodate complex experimental designs with various biological factors more easily than microfluidic chips.",
    "reference_list": "考点1: “Dropout Probability”必须译为“漏检概率”（非“缺失概率”）\n考点2:“unique molecular identifiers”必须译为“独特分子标识符”首现可保留英文 UMI 并加注）\n考点3: “quantification”应译为“量化”\n考点4: “full-length coverage”应译为“全长覆盖度”（保持“度”的一致性）\n考点5: “spike-in“必须译为”掺入对照“（“加标”可备注为行业俗称，但不作首选）\n考点6:“Poisson variability”应译为“泊松变异性”\n考点7:“>6,500 for 1 min of flow”必须译为“流速＞6,500/分钟”\n考点8:“plate-based methods”推荐译为“基于微孔板的方法”\n考点9: “multiplexing”必须译为“多重化/多路复用”（不应只保留英文）\n考点10: “amplification duplicates”必须译为“扩增重复（序列副本）/重复扩增子”（非“扩增产物”）\n考点11: “sequence part of the primer”推荐译为“对引物部分进行测序”（非“捕获/捕集”）\n考点12: “in how many cells / from how many molecules”推荐译为“在多少细胞中/由多少分子（覆盖范围/数量维度）”（非“被测量的频率”）\n考点13: “monetary cost”推荐译为“成本/费用”（非“成本控制”）",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "107"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n2025 年 6 月 16 日，三只松鼠发布公告，宣布终止对湖南爱零食科技有限公司的收购计划。回溯至 2024 年 10 月，三只松鼠全资子公司安徽一件事创业投资有限公司拟斥资不超过 2 亿元，收购爱零食的控制权或相关业务及资产。彼时，双方签署的《投资意向协议》有效期为 90 天，并在今年 1 月将排他期延长至正式签约日，然而最终因部分核心条款未能达成一致，交易宣告流产。\n\n野心勃勃的收购计划：三只松鼠的线下突围战\n三只松鼠曾对爱零食寄予厚望，这场收购背后是其迫切的战略需求。从渠道结构来看，长期以来，三只松鼠线上依赖程度颇高。以 2024 年数据为例，其线上销售额占营业收入的比重为 69.73%，达 74.07 亿元 ，尽管同比增长 49.6%，但线下渠道的相对薄弱仍是制约其进一步发展的关键因素。\n反观爱零食，作为量贩零食区域龙头，在湖南等多个区域已布局超 1800 家门店。在中国零食市场，2023 年线下销售占据了 82.6% 的市场份额 ，这一庞大的线下市场份额对三只松鼠而言极具吸引力。收购爱零食，无疑能让三只松鼠快速切入线下量贩零食市场，拓展线下版图，优化自身渠道结构，进而提升市场覆盖面和销售规模。\n与此同时，量贩零食赛道正上演疯狂扩张。2024 年，零食很忙与赵一鸣零食合并为“鸣鸣很忙”，门店总数迅速突破 10000 家；万辰集团整合好想来、来优品等四大品牌，2025 年签约门店更是突破 1.5 万家。\n爱零食在 2024 年 9 月门店数已超 1800 家，并提出“3 年 3000 家店” 的扩张目标，位居行业第五。在这样的竞争环境下，三只松鼠试图通过收购爱零食，在这场竞速赛中抢占一席之地，并借助双方在供应链、品牌上的互补优势，实现资源整合与产品矩阵升级。\n\n财报数据：增长放缓下的战略权衡\n三只松鼠 2024 年财报成绩亮眼：营收 106.22 亿元，同比增长 49.30%；归母净利润 4.08 亿元，同比增长 85.51%。线下分销收入也因并购爱折扣增长 48.62% 。但进入 2025 年第一季度，增速骤然放缓，营收仅微增 2.13%，归母净利润下滑 22.46%。\n在此背景下，三只松鼠可能重新审视收购爱零食的必要性与可行性。或许是考虑到收购后整合的复杂性与成本，包括供应链整合、门店运营模式融合、人员管理等多方面潜在成本；以及自身业务调整与资源分配的需要。在面对与爱零食核心条款分歧时，选择终止收购。\n\n命运转折：收购终止后的两家企业何去何从？\n对于三只松鼠而言，终止收购虽短期内延缓了其在量贩零食赛道通过并购快速扩张的步伐，但也避免了潜在的整合风险与资金投入压力。公司可将资源集中于自有分销网络建设、社区零食店发展以及多品牌孵化等战略布局上。长期来看，如果三只松鼠能有效推进自身线下策略，持续提升供应链优势，进一步扩大线下分销规模，仍有望在零食市场竞争中巩固地位。\n对爱零食来说，失去三只松鼠的资金注入与资源协同，门店扩张计划可能受阻。原本计划借助三只松鼠的 2 亿元投资加速门店扩张，目标在 2025 年达到 5000 家店，如今这一计划面临变数。在行业头部品牌竞争加剧的情况下，爱零食面临更大的融资压力与市场份额被挤压风险。截至 2025 年 6 月，其门店数虽增至 2000 家，但与行业头部品牌如鸣鸣很忙的 1.5 万家、万辰集团的近万家相比，差距悬殊。",
    "ori_text": "2025 年 6 月 16 日，三只松鼠发布公告，宣布终止对湖南爱零食科技有限公司的收购计划。回溯至 2024 年 10 月，三只松鼠全资子公司安徽一件事创业投资有限公司拟斥资不超过 2 亿元，收购爱零食的控制权或相关业务及资产。彼时，双方签署的《投资意向协议》有效期为 90 天，并在今年 1 月将排他期延长至正式签约日，然而最终因部分核心条款未能达成一致，交易宣告流产。\n\n野心勃勃的收购计划：三只松鼠的线下突围战\n三只松鼠曾对爱零食寄予厚望，这场收购背后是其迫切的战略需求。从渠道结构来看，长期以来，三只松鼠线上依赖程度颇高。以 2024 年数据为例，其线上销售额占营业收入的比重为 69.73%，达 74.07 亿元 ，尽管同比增长 49.6%，但线下渠道的相对薄弱仍是制约其进一步发展的关键因素。\n反观爱零食，作为量贩零食区域龙头，在湖南等多个区域已布局超 1800 家门店。在中国零食市场，2023 年线下销售占据了 82.6% 的市场份额 ，这一庞大的线下市场份额对三只松鼠而言极具吸引力。收购爱零食，无疑能让三只松鼠快速切入线下量贩零食市场，拓展线下版图，优化自身渠道结构，进而提升市场覆盖面和销售规模。\n与此同时，量贩零食赛道正上演疯狂扩张。2024 年，零食很忙与赵一鸣零食合并为“鸣鸣很忙”，门店总数迅速突破 10000 家；万辰集团整合好想来、来优品等四大品牌，2025 年签约门店更是突破 1.5 万家。\n爱零食在 2024 年 9 月门店数已超 1800 家，并提出“3 年 3000 家店” 的扩张目标，位居行业第五。在这样的竞争环境下，三只松鼠试图通过收购爱零食，在这场竞速赛中抢占一席之地，并借助双方在供应链、品牌上的互补优势，实现资源整合与产品矩阵升级。\n\n财报数据：增长放缓下的战略权衡\n三只松鼠 2024 年财报成绩亮眼：营收 106.22 亿元，同比增长 49.30%；归母净利润 4.08 亿元，同比增长 85.51%。线下分销收入也因并购爱折扣增长 48.62% 。但进入 2025 年第一季度，增速骤然放缓，营收仅微增 2.13%，归母净利润下滑 22.46%。\n在此背景下，三只松鼠可能重新审视收购爱零食的必要性与可行性。或许是考虑到收购后整合的复杂性与成本，包括供应链整合、门店运营模式融合、人员管理等多方面潜在成本；以及自身业务调整与资源分配的需要。在面对与爱零食核心条款分歧时，选择终止收购。\n\n命运转折：收购终止后的两家企业何去何从？\n对于三只松鼠而言，终止收购虽短期内延缓了其在量贩零食赛道通过并购快速扩张的步伐，但也避免了潜在的整合风险与资金投入压力。公司可将资源集中于自有分销网络建设、社区零食店发展以及多品牌孵化等战略布局上。长期来看，如果三只松鼠能有效推进自身线下策略，持续提升供应链优势，进一步扩大线下分销规模，仍有望在零食市场竞争中巩固地位。\n对爱零食来说，失去三只松鼠的资金注入与资源协同，门店扩张计划可能受阻。原本计划借助三只松鼠的 2 亿元投资加速门店扩张，目标在 2025 年达到 5000 家店，如今这一计划面临变数。在行业头部品牌竞争加剧的情况下，爱零食面临更大的融资压力与市场份额被挤压风险。截至 2025 年 6 月，其门店数虽增至 2000 家，但与行业头部品牌如鸣鸣很忙的 1.5 万家、万辰集团的近万家相比，差距悬殊。",
    "reference_list": "考点1：”控制权”应该译为“controlling stake”，这是公司并购中的法律和商业术语。\n考点2：“制约推荐”译为“bottleneck”。\n考点3：”量贩零食“应该译为“snack discounter(s)”，量贩源自日语，指大量销售、薄利多销的模式，不可译成“mass-selling snacks”。\n考点4：”万辰”应翻译为“Wanchen Group“\n考点5：“湖南”应翻译为”Hunan province“，表明其为省份\n考点6：“爱折扣”音译或完全意译，不可两者结合 ，如“Ai Discount”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "34"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n2. Theoretical BackgroundIn this section, we review the consumer acceptance literature. We focus on studies that examine willingness to buy, primarily in Germany, Europe and other Western countries, where data are available.2.1. Consumer AcceptanceBefore the determinants of consumer acceptance can be discussed, the concept of acceptance itself needs to be defined. The term “consumer acceptance” enjoys widespread usage across various research fields and has been extensively reviewed within the food science sector [28,29,30] but there remains a lack of consensus regarding its essential components and a general definition. This overarching construct is employed with ambiguity across different disciplines, including profitability and sufficient user adoption in the form of purchase intention, as well as the absence of categorical rejection towards a product or technology, indicative of a general willingness to engage with it [31,32]. In their scoping review, Baker et al. (2022) define consumer acceptance based on various outcome measurements such as general acceptance, willingness to buy, willingness to pay, willingness to try, perceptions, consumption or purchase intention [9]. Wassmann et al. (2021) include the following measures as correlates of willingness to consume in their meta-analysis: willingness to adopt, willingness to eat, willingness to pay, and willingness to try [10]. However, achieving a concise yet comprehensive definition remains a desirable objective, and such a task exceeds the scope of this paper.Nonetheless, it is crucial to define acceptance in each study to allow comparability. The existing literature on alternative protein sources centres around two main indicators, willingness to try [11,25,33,34] and willingness to buy [5,23,35,36,37,38,39,40], both of which are pivotal for gauging overall acceptance. Due to the lack of general guidance for selecting the indicators and given our specific interest in the potential of these three alternative protein sources to make substantial contributions to a change in diet, we have chosen to focus solely on willingness to buy, as it offers a direct insight into whether consumers are willing to make a purchase to include a specific protein source in their diets. Willingness to buy indicates the readiness to purchase food products of alternative protein sources (algae, crickets, jellyfish) in a grocery store, which goes beyond just the willingness to try [39]. In the following sections, we focus on the willingness to buy but also discuss the determinants of willingness to try and further correlates of consumer acceptance where previous studies on willingness to buy are lacking.2.2. NeophobiaFood neophobia is one of the most investigated determinants of consumer acceptance, particularly in the context of food innovations. Food neophobia, defined as the aversion to and dislike of novel foods, is a trait that manifests with varying degrees of intensity among individuals [41]. Food neophobia negatively influenced consumer acceptance of algae-based foods [42] as well as post-tasting satisfaction with algae-based food products [43]. Food neophobia had a negative impact on the adoption intention of Spirulina-enhanced foods (a specific type of microalgae) in a sub-sample of Belgian consumers who know a lot about the latest food trends and like to eat but not in the sub-samples of vegetarian and sporty Belgian consumers [44]. Food neophobia also showed a negative effect on the willingness to try [33] and to eat or consume insects among German consumers [45,46,47]. A similar effect could be found for the willingness to adopt insect-based foods [25] and to buy them [39]. A cross-country comparative study (involving the Czech Republic, Germany, Finland, and Sweden) further revealed a negative effect on the willingness to buy insect-based foods [38], while the meta-analysis indicated a negative effect on the willingness to consume [10]. Furthermore, food neophobia negatively influenced the attitude towards consuming jellyfish [40].When food is processed before sale, which is likely for the protein sources under study, a phobia against novel food technologies may also be relevant for consumer acceptance of such foods. Food technology neophobia is defined as the resistance to new or modern food technologies [48]. The effect on the consumer acceptance of algae-based products is not clear yet. Embling et al. (2022) did not find a significant effect [42]. However, the consumer willingness to consume insects [10,46] and readiness to adopt insects as meat substitutes [25] are influenced negatively by food technology neophobia. The relationship of food technology neophobia and consumer acceptance of jellyfish is still unclear.To summarise, it is reasonable to assume that food neophobia is associated with low consumer acceptance of alternative protein sources. However, the evident lack of understanding of how food technology neophobia impacts consumer acceptance of algae and jellyfish necessitates further investigations.2.3. Familiarity with New FoodsFamiliarity with the concept of consuming algae and insects as well as past consumption experiences are also important determinants of consumer acceptance [5,25,47]. Perceiving algae-based food as tasty, edible and familiar significantly increased acceptance [42]. People who are familiar with eating insects are more likely to adopt insects in their diets [25] and be willing to consume insects [10]. In contrast, Lammers et al. (2019) have found no effect of familiarity on willingness to consume insect burgers [46]. To the best of the authors’ knowledge, no studies have specifically investigated the impact of familiarity on the consumer acceptance of jellyfish-based foods. However, there appears to be a general tendency for familiarity with the sea environment to positively influence the consumption of jellyfish [40].Previous experiences with algae-based food have a positive impact on willingness to try and adopt algae into the diet [11]. Furthermore, experiences with eating insects lead to a higher willingness to try and adopt insect-based foods [11,33], to eat insect-based foods [39,45,46] and to buy insect-based food products [35,38]. However, a meta-analysis showed only a middle composite effect size of experience with willingness to consume insect-based foods (r = 0.35) [10]. Previous experiences with eating jellyfish lead to a higher willingness to try and adopt jellyfish in the diet [11].Based on the previous findings, both familiarity and experience might have a positive effect on consumer acceptance of algae, crickets and jellyfish. However, some clarity is needed considering scholars that have found no or only a small effect, necessitating a unified research approach.2.4. Food-Related HabitsFood-related lifestyle links individuals’ values with their eating behaviours, incorporating aspects such as food involvement and food innovativeness, as outlined in the food-related lifestyle framework by Brunsø et al. (2021) [49]. Food involvement refers to the extent to which individuals engage with and take an interest in different aspects of food [49]. Those with high food involvement regard food as an important part of their lives, dedicate considerable time and resources to it, and view it as essential for achieving personal goals [49,50]. Previous studies indicate that food involvement positively influences the intention to adopt Spirulina-enhanced foods among consumers who enjoy eating, though this effect is not observed among vegetarians, sporty individuals, or those well informed about the latest food trends [44]. Moreover, food involvement does not impact the willingness to try insect-based foods [51]. To the best of the authors’ knowledge, no studies have investigated the relationship between food involvement and the acceptance of jellyfish-based foods.Another aspect of the food-related lifestyle is food innovativeness, which refers to the extent to which individuals adopt and integrate novel culinary practices and ingredients into their dietary habits [49]. In the absence of previous research on the relationship of food innovativeness and the consumer acceptance of alternative protein sources, Mazhar & Zilahy (2023) show that food-related lifestyles (including food involvement and food innovativeness) are moderately correlated to green food purchasing behaviour [52]. Furthermore, sensation seeking, a related construct, has a positive effect on willingness to consume insects in Germany [46]. Moreover, a meta-analysis revealed that food sensation and innovation seeking have a strong composite effect on willingness to consume insects (r = 0.29) [10].A consistent research approach is required to bridge the knowledge gap about the direction and effect of food involvement and food innovativeness on consumer acceptance of algae, crickets and jellyfish.The meat consumption of consumers is an important determinant of consumer acceptance of proteins from alternative sources [5]. A strong belief in the benefits of eating meat is associated with lower acceptance of algae-based foods among meat consumers [42]. Additionally, consumers with a high rate of weekly meat intake are less likely to choose snacks made out of algae (besides lentils/beans snacks, insect snacks, and hybrid meat snacks), with both the number of meat-eating days and preferred portion size serving as significant predictors of their dietary preferences [53]. Those following a vegetarian or vegan diet are less willing to eat insects [47]. Furthermore, consumers who perceive meat as nutritious, healthy, and strongly focusing on its taste are less inclined to adopt insects as meat substitutes [25]. However, consumers intending to reduce their meat consumption show higher readiness to adopt insects as meat substitutes [25]. Contrary to these findings, Lammers et al. (2019) reported that higher meat consumption is linked to higher acceptance of food containing invisible insects, although this effect disappears when other factors influencing the acceptance (e.g., sensation seeking, sustainability consciousness, food disgust) are considered [46]. A meta-analysis found only a small effect size between willingness to consume insects and meat consumption (r = 0.08) [10]. Schäufele et al. (2019) found no effect of meat consumption on the willingness to try insect-based food [33]. The relationship between meat consumption and consumer acceptance of jellyfish is still unclear.In summary, it could be assumed that (high) meat consumption is associated with low consumer acceptance of algae-based protein. However, there is a clear knowledge gap regarding how meat consumption influences consumer acceptance of crickets and jellyfish. A consistent research approach is necessary to better understand its role.",
    "ori_text": "2. Theoretical BackgroundIn this section, we review the consumer acceptance literature. We focus on studies that examine willingness to buy, primarily in Germany, Europe and other Western countries, where data are available.2.1. Consumer AcceptanceBefore the determinants of consumer acceptance can be discussed, the concept of acceptance itself needs to be defined. The term “consumer acceptance” enjoys widespread usage across various research fields and has been extensively reviewed within the food science sector [28,29,30] but there remains a lack of consensus regarding its essential components and a general definition. This overarching construct is employed with ambiguity across different disciplines, including profitability and sufficient user adoption in the form of purchase intention, as well as the absence of categorical rejection towards a product or technology, indicative of a general willingness to engage with it [31,32]. In their scoping review, Baker et al. (2022) define consumer acceptance based on various outcome measurements such as general acceptance, willingness to buy, willingness to pay, willingness to try, perceptions, consumption or purchase intention [9]. Wassmann et al. (2021) include the following measures as correlates of willingness to consume in their meta-analysis: willingness to adopt, willingness to eat, willingness to pay, and willingness to try [10]. However, achieving a concise yet comprehensive definition remains a desirable objective, and such a task exceeds the scope of this paper.Nonetheless, it is crucial to define acceptance in each study to allow comparability. The existing literature on alternative protein sources centres around two main indicators, willingness to try [11,25,33,34] and willingness to buy [5,23,35,36,37,38,39,40], both of which are pivotal for gauging overall acceptance. Due to the lack of general guidance for selecting the indicators and given our specific interest in the potential of these three alternative protein sources to make substantial contributions to a change in diet, we have chosen to focus solely on willingness to buy, as it offers a direct insight into whether consumers are willing to make a purchase to include a specific protein source in their diets. Willingness to buy indicates the readiness to purchase food products of alternative protein sources (algae, crickets, jellyfish) in a grocery store, which goes beyond just the willingness to try [39]. In the following sections, we focus on the willingness to buy but also discuss the determinants of willingness to try and further correlates of consumer acceptance where previous studies on willingness to buy are lacking.2.2. NeophobiaFood neophobia is one of the most investigated determinants of consumer acceptance, particularly in the context of food innovations. Food neophobia, defined as the aversion to and dislike of novel foods, is a trait that manifests with varying degrees of intensity among individuals [41]. Food neophobia negatively influenced consumer acceptance of algae-based foods [42] as well as post-tasting satisfaction with algae-based food products [43]. Food neophobia had a negative impact on the adoption intention of Spirulina-enhanced foods (a specific type of microalgae) in a sub-sample of Belgian consumers who know a lot about the latest food trends and like to eat but not in the sub-samples of vegetarian and sporty Belgian consumers [44]. Food neophobia also showed a negative effect on the willingness to try [33] and to eat or consume insects among German consumers [45,46,47]. A similar effect could be found for the willingness to adopt insect-based foods [25] and to buy them [39]. A cross-country comparative study (involving the Czech Republic, Germany, Finland, and Sweden) further revealed a negative effect on the willingness to buy insect-based foods [38], while the meta-analysis indicated a negative effect on the willingness to consume [10]. Furthermore, food neophobia negatively influenced the attitude towards consuming jellyfish [40].When food is processed before sale, which is likely for the protein sources under study, a phobia against novel food technologies may also be relevant for consumer acceptance of such foods. Food technology neophobia is defined as the resistance to new or modern food technologies [48]. The effect on the consumer acceptance of algae-based products is not clear yet. Embling et al. (2022) did not find a significant effect [42]. However, the consumer willingness to consume insects [10,46] and readiness to adopt insects as meat substitutes [25] are influenced negatively by food technology neophobia. The relationship of food technology neophobia and consumer acceptance of jellyfish is still unclear.To summarise, it is reasonable to assume that food neophobia is associated with low consumer acceptance of alternative protein sources. However, the evident lack of understanding of how food technology neophobia impacts consumer acceptance of algae and jellyfish necessitates further investigations.2.3. Familiarity with New FoodsFamiliarity with the concept of consuming algae and insects as well as past consumption experiences are also important determinants of consumer acceptance [5,25,47]. Perceiving algae-based food as tasty, edible and familiar significantly increased acceptance [42]. People who are familiar with eating insects are more likely to adopt insects in their diets [25] and be willing to consume insects [10]. In contrast, Lammers et al. (2019) have found no effect of familiarity on willingness to consume insect burgers [46]. To the best of the authors’ knowledge, no studies have specifically investigated the impact of familiarity on the consumer acceptance of jellyfish-based foods. However, there appears to be a general tendency for familiarity with the sea environment to positively influence the consumption of jellyfish [40].Previous experiences with algae-based food have a positive impact on willingness to try and adopt algae into the diet [11]. Furthermore, experiences with eating insects lead to a higher willingness to try and adopt insect-based foods [11,33], to eat insect-based foods [39,45,46] and to buy insect-based food products [35,38]. However, a meta-analysis showed only a middle composite effect size of experience with willingness to consume insect-based foods (r = 0.35) [10]. Previous experiences with eating jellyfish lead to a higher willingness to try and adopt jellyfish in the diet [11].Based on the previous findings, both familiarity and experience might have a positive effect on consumer acceptance of algae, crickets and jellyfish. However, some clarity is needed considering scholars that have found no or only a small effect, necessitating a unified research approach.2.4. Food-Related HabitsFood-related lifestyle links individuals’ values with their eating behaviours, incorporating aspects such as food involvement and food innovativeness, as outlined in the food-related lifestyle framework by Brunsø et al. (2021) [49]. Food involvement refers to the extent to which individuals engage with and take an interest in different aspects of food [49]. Those with high food involvement regard food as an important part of their lives, dedicate considerable time and resources to it, and view it as essential for achieving personal goals [49,50]. Previous studies indicate that food involvement positively influences the intention to adopt Spirulina-enhanced foods among consumers who enjoy eating, though this effect is not observed among vegetarians, sporty individuals, or those well informed about the latest food trends [44]. Moreover, food involvement does not impact the willingness to try insect-based foods [51]. To the best of the authors’ knowledge, no studies have investigated the relationship between food involvement and the acceptance of jellyfish-based foods.Another aspect of the food-related lifestyle is food innovativeness, which refers to the extent to which individuals adopt and integrate novel culinary practices and ingredients into their dietary habits [49]. In the absence of previous research on the relationship of food innovativeness and the consumer acceptance of alternative protein sources, Mazhar & Zilahy (2023) show that food-related lifestyles (including food involvement and food innovativeness) are moderately correlated to green food purchasing behaviour [52]. Furthermore, sensation seeking, a related construct, has a positive effect on willingness to consume insects in Germany [46]. Moreover, a meta-analysis revealed that food sensation and innovation seeking have a strong composite effect on willingness to consume insects (r = 0.29) [10].A consistent research approach is required to bridge the knowledge gap about the direction and effect of food involvement and food innovativeness on consumer acceptance of algae, crickets and jellyfish.The meat consumption of consumers is an important determinant of consumer acceptance of proteins from alternative sources [5]. A strong belief in the benefits of eating meat is associated with lower acceptance of algae-based foods among meat consumers [42]. Additionally, consumers with a high rate of weekly meat intake are less likely to choose snacks made out of algae (besides lentils/beans snacks, insect snacks, and hybrid meat snacks), with both the number of meat-eating days and preferred portion size serving as significant predictors of their dietary preferences [53]. Those following a vegetarian or vegan diet are less willing to eat insects [47]. Furthermore, consumers who perceive meat as nutritious, healthy, and strongly focusing on its taste are less inclined to adopt insects as meat substitutes [25]. However, consumers intending to reduce their meat consumption show higher readiness to adopt insects as meat substitutes [25]. Contrary to these findings, Lammers et al. (2019) reported that higher meat consumption is linked to higher acceptance of food containing invisible insects, although this effect disappears when other factors influencing the acceptance (e.g., sensation seeking, sustainability consciousness, food disgust) are considered [46]. A meta-analysis found only a small effect size between willingness to consume insects and meat consumption (r = 0.08) [10]. Schäufele et al. (2019) found no effect of meat consumption on the willingness to try insect-based food [33]. The relationship between meat consumption and consumer acceptance of jellyfish is still unclear.In summary, it could be assumed that (high) meat consumption is associated with low consumer acceptance of algae-based protein. However, there is a clear knowledge gap regarding how meat consumption influences consumer acceptance of crickets and jellyfish. A consistent research approach is necessary to better understand its role.",
    "reference_list": "考点1：【desirable objective】应该译为“理想目标”。\n考点2：【existing literature】应译为“现有文献”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "63"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\nAs the dominant discourse would have it, the economic world is a pure and perfect order, implacably unrolling the logic of its predictable consequences, and prompt to repress all violations by the sanctions that it inflicts, either automatically or - more unusually - through the intermediary of its armed extensions, the International Monetary Fund (IMF) and the Organization for Economic Cooperation and Development (OECD) and the policies they impose: reducing labour costs, reducing public expenditures and making work more flexible. Is the dominant discourse right? What if, in reality, this economic order were no more than the implementation of a utopia - the utopia of neoliberalism - thus converted into a political problem? One that, with the aid of the economic theory that it proclaims, succeeds in conceiving of itself as the scientific description of reality?\n\nThis tutelary theory is a pure mathematical fiction. From the start it has been founded on a formidable abstraction. For, in the name of a narrow and strict conception of rationality as individual rationality, it brackets the economic and social conditions of rational orientations and the economic and social structures that are the condition of their application.\n\nTo give the measure of this omission, it is enough to think just of the educational system. Education is never taken account of as such at a time when it plays a determining role in the production of goods and services as in the production of the producers themselves. From this sort of original sin, inscribed in the Walrasian myth (1) of \"pure theory\", flow all of the deficiencies and faults of the discipline of economics and the fatal obstinacy with which it attaches itself to the arbitrary opposition which it induces, through its mere existence, between a properly economic logic, based on competition and efficiency, and social logic, which is subject to the rule of fairness.\n\nThat said, this \"theory\" that is desocialised and dehistoricised at its roots has, today more than ever, the means of making itself true and empirically verifiable. In effect, neoliberal discourse is not just one discourse among many. Rather, it is a \"strong discourse\" - the way psychiatric discourse is in an asylum, in Erving Goffman's analysis (2). It is so strong and so hard to combat only because it has on its side all of the forces of a world of relations of forces, a world that it contributes to making what it is. It does this most notably by orienting the economic choices of those who dominate economic relationships. It thus adds its own symbolic force to these relations of forces. In the name of this scientific programme, converted into a plan of political action, an immense political project is underway, although its status as such is denied because it appears to be purely negative. This project aims to create the conditions under which the \"theory\" can be realised and can function: a programme of the methodical destruction of collectives.\n\nThe movement toward the neoliberal utopia of a pure and perfect market is made possible by the politics of financial deregulation. And it is achieved through the transformative and, it must be said, destructive action of all of the political measures (of which the most recent is the Multilateral Agreement on Investment (MAI), designed to protect foreign corporations and their investments from national states) that aim to call into question any and all collective structures that could serve as an obstacle to the logic of the pure market: the nation, whose space to manoeuvre continually decreases; work groups, for example through the individualisation of salaries and of careers as a function of individual competences, with the consequent atomisation of workers; collectives for the defence of the rights of workers, unions, associations, cooperatives; even the family, which loses part of its control over consumption through the constitution of markets by age groups.\n\nThe neoliberal programme draws its social power from the political and economic power of those whose interests it expresses: stockholders, financial operators, industrialists, conservative or social-democratic politicians who have been converted to the reassuring layoffs of laisser-faire, high-level financial officials eager to impose policies advocating their own extinction because, unlike the managers of firms, they run no risk of having eventually to pay the consequences. Neoliberalism tends on the whole to favour severing the economy from social realities and thereby constructing, in reality, an economic system conforming to its description in pure theory, that is a sort of logical machine that presents itself as a chain of constraints regulating economic agents.\n\nThe globalisation of financial markets, when joined with the progress of information technology, ensures an unprecedented mobility of capital. It gives investors concerned with the short-term profitability of their investments the possibility of permanently comparing the profitability of the largest corporations and, in consequence, penalising these firms' relative setbacks. Subjected to this permanent threat, the corporations themselves have to adjust more and more rapidly to the exigencies of the markets, under penalty of \"losing the market's confidence\", as they say, as well as the support of their stockholders. The latter, anxious to obtain short-term profits, are more and more able to impose their will on managers, using financial directorates to establish the rules under which managers operate and to shape their policies regarding hiring, employment, and wages.\n\nThus the absolute reign of flexibility is established, with employees being hiring on fixed-term contracts or on a temporary basis and repeated corporate restructurings and, within the firm itself, competition among autonomous divisions as well as among teams forced to perform multiple functions. Finally, this competition is extended to individuals themselves, through the individualisation of the wage relationship: establishment of individual performance objectives, individual performance evaluations, permanent evaluation, individual salary increases or granting of bonuses as a function of competence and of individual merit; individualised career paths; strategies of \"delegating responsibility\" tending to ensure the self-exploitation of staff who, simple wage labourers in relations of strong hierarchical dependence, are at the same time held responsible for their sales, their products, their branch, their store, etc. as though they were independent contractors. This pressure toward \"self-control\" extends workers' \"involvement\" according to the techniques of \"participative management\" considerably beyond management level. All of these are techniques of rational domination that impose over-involvement in work (and not only among management) and work under emergency or high-stress conditions. And they converge to weaken or abolish collective standards or solidarities (3).\n\nIn this way, a Darwinian world emerges - it is the struggle of all against all at all levels of the hierarchy, which finds support through everyone clinging to their job and organisation under conditions of insecurity, suffering, and stress. Without a doubt, the practical establishment of this world of struggle would not succeed so completely without the complicity of all of the precarious arrangements that produce insecurity and of the existence of a reserve army of employees rendered docile by these social processes that make their situations precarious, as well as by the permanent threat of unemployment. This reserve army exists at all levels of the hierarchy, even at the higher levels, especially among managers. The ultimate foundation of this entire economic order placed under the sign of freedom is in effect the structural violence of unemployment, of the insecurity of job tenure and the menace of layoff that it implies. The condition of the \"harmonious\" functioning of the individualist micro-economic model is a mass phenomenon, the existence of a reserve army of the unemployed.\n\nThis structural violence also weighs on what is called the labour contract (wisely rationalised and rendered unreal by the \"theory of contracts\"). Organisational discourse has never talked as much of trust, co-operation, loyalty, and organisational culture as in an era when adherence to the organisation is obtained at each moment by eliminating all temporal guarantees of employment (three-quarters of hires are for fixed duration, the proportion of temporary employees keeps rising, employment \"at will\" and the right to fire an individual tend to be freed from any restriction).",
    "ori_text": "As the dominant discourse would have it, the economic world is a pure and perfect order, implacably unrolling the logic of its predictable consequences, and prompt to repress all violations by the sanctions that it inflicts, either automatically or - more unusually - through the intermediary of its armed extensions, the International Monetary Fund (IMF) and the Organization for Economic Cooperation and Development (OECD) and the policies they impose: reducing labour costs, reducing public expenditures and making work more flexible. Is the dominant discourse right? What if, in reality, this economic order were no more than the implementation of a utopia - the utopia of neoliberalism - thus converted into a political problem? One that, with the aid of the economic theory that it proclaims, succeeds in conceiving of itself as the scientific description of reality?\n\nThis tutelary theory is a pure mathematical fiction. From the start it has been founded on a formidable abstraction. For, in the name of a narrow and strict conception of rationality as individual rationality, it brackets the economic and social conditions of rational orientations and the economic and social structures that are the condition of their application.\n\nTo give the measure of this omission, it is enough to think just of the educational system. Education is never taken account of as such at a time when it plays a determining role in the production of goods and services as in the production of the producers themselves. From this sort of original sin, inscribed in the Walrasian myth (1) of \"pure theory\", flow all of the deficiencies and faults of the discipline of economics and the fatal obstinacy with which it attaches itself to the arbitrary opposition which it induces, through its mere existence, between a properly economic logic, based on competition and efficiency, and social logic, which is subject to the rule of fairness.\n\nThat said, this \"theory\" that is desocialised and dehistoricised at its roots has, today more than ever, the means of making itself true and empirically verifiable. In effect, neoliberal discourse is not just one discourse among many. Rather, it is a \"strong discourse\" - the way psychiatric discourse is in an asylum, in Erving Goffman's analysis (2). It is so strong and so hard to combat only because it has on its side all of the forces of a world of relations of forces, a world that it contributes to making what it is. It does this most notably by orienting the economic choices of those who dominate economic relationships. It thus adds its own symbolic force to these relations of forces. In the name of this scientific programme, converted into a plan of political action, an immense political project is underway, although its status as such is denied because it appears to be purely negative. This project aims to create the conditions under which the \"theory\" can be realised and can function: a programme of the methodical destruction of collectives.\n\nThe movement toward the neoliberal utopia of a pure and perfect market is made possible by the politics of financial deregulation. And it is achieved through the transformative and, it must be said, destructive action of all of the political measures (of which the most recent is the Multilateral Agreement on Investment (MAI), designed to protect foreign corporations and their investments from national states) that aim to call into question any and all collective structures that could serve as an obstacle to the logic of the pure market: the nation, whose space to manoeuvre continually decreases; work groups, for example through the individualisation of salaries and of careers as a function of individual competences, with the consequent atomisation of workers; collectives for the defence of the rights of workers, unions, associations, cooperatives; even the family, which loses part of its control over consumption through the constitution of markets by age groups.\n\nThe neoliberal programme draws its social power from the political and economic power of those whose interests it expresses: stockholders, financial operators, industrialists, conservative or social-democratic politicians who have been converted to the reassuring layoffs of laisser-faire, high-level financial officials eager to impose policies advocating their own extinction because, unlike the managers of firms, they run no risk of having eventually to pay the consequences. Neoliberalism tends on the whole to favour severing the economy from social realities and thereby constructing, in reality, an economic system conforming to its description in pure theory, that is a sort of logical machine that presents itself as a chain of constraints regulating economic agents.\n\nThe globalisation of financial markets, when joined with the progress of information technology, ensures an unprecedented mobility of capital. It gives investors concerned with the short-term profitability of their investments the possibility of permanently comparing the profitability of the largest corporations and, in consequence, penalising these firms' relative setbacks. Subjected to this permanent threat, the corporations themselves have to adjust more and more rapidly to the exigencies of the markets, under penalty of \"losing the market's confidence\", as they say, as well as the support of their stockholders. The latter, anxious to obtain short-term profits, are more and more able to impose their will on managers, using financial directorates to establish the rules under which managers operate and to shape their policies regarding hiring, employment, and wages.\n\nThus the absolute reign of flexibility is established, with employees being hiring on fixed-term contracts or on a temporary basis and repeated corporate restructurings and, within the firm itself, competition among autonomous divisions as well as among teams forced to perform multiple functions. Finally, this competition is extended to individuals themselves, through the individualisation of the wage relationship: establishment of individual performance objectives, individual performance evaluations, permanent evaluation, individual salary increases or granting of bonuses as a function of competence and of individual merit; individualised career paths; strategies of \"delegating responsibility\" tending to ensure the self-exploitation of staff who, simple wage labourers in relations of strong hierarchical dependence, are at the same time held responsible for their sales, their products, their branch, their store, etc. as though they were independent contractors. This pressure toward \"self-control\" extends workers' \"involvement\" according to the techniques of \"participative management\" considerably beyond management level. All of these are techniques of rational domination that impose over-involvement in work (and not only among management) and work under emergency or high-stress conditions. And they converge to weaken or abolish collective standards or solidarities (3).\n\nIn this way, a Darwinian world emerges - it is the struggle of all against all at all levels of the hierarchy, which finds support through everyone clinging to their job and organisation under conditions of insecurity, suffering, and stress. Without a doubt, the practical establishment of this world of struggle would not succeed so completely without the complicity of all of the precarious arrangements that produce insecurity and of the existence of a reserve army of employees rendered docile by these social processes that make their situations precarious, as well as by the permanent threat of unemployment. This reserve army exists at all levels of the hierarchy, even at the higher levels, especially among managers. The ultimate foundation of this entire economic order placed under the sign of freedom is in effect the structural violence of unemployment, of the insecurity of job tenure and the menace of layoff that it implies. The condition of the \"harmonious\" functioning of the individualist micro-economic model is a mass phenomenon, the existence of a reserve army of the unemployed.\n\nThis structural violence also weighs on what is called the labour contract (wisely rationalised and rendered unreal by the \"theory of contracts\"). Organisational discourse has never talked as much of trust, co-operation, loyalty, and organisational culture as in an era when adherence to the organisation is obtained at each moment by eliminating all temporal guarantees of employment (three-quarters of hires are for fixed duration, the proportion of temporary employees keeps rising, employment \"at will\" and the right to fire an individual tend to be freed from any restriction).",
    "reference_list": "考点1：“ the dominant discourse”译为“主流话语；主导性话语”\n考点2：“armed extensions”需注意译文措辞与前后语句的匹配度\n考点3：“tutelary theory”推荐译为“指导性理论；保护性理论”\n考点4： “bracket”需译为 “悬置；搁置；存而不论”\n考点5： “strong discourse”应译为“强势话语”\n考点6：“the struggle of all against all”应译为“所有人对所有人的斗争/战争”\n考点7：“ reserve army of employees”必须译为“劳动后备军”，不可译为其他非政经术语\n考点8：“the theory of contracts”应译为“契约理论”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "4"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。 以下是你本次的任务：\nResults: \nEvaluation of FS \nAll the published guidelines agree that no further investigation is routinely necessary for children with a single episode of SFS[8]-[14] (Table 2). The British guidelines suggest measurement of blood glucose concentration if the child is still convulsing or unrousable when seen either with or without fever and to consider neuroimaging before lumbar puncture (LP) if the child is comatose.[10] According to ILAE guidelines, it is recommended to search for the fever’s etiology in the case of CFS. Additionally, neuroimaging is recommended to investigate a possible underlying brain lesion. Blood chemical tests are suggested in relation to specific clinical conditions.[8] The AAP underscores the importance of evaluating the underlying cause of fever but recommends that blood tests should not be performed routinely for the sole purpose of identifying the cause of SFS, since there is no evidence to suggest that routine blood studies are of benefit in the evaluation of the child with SFS and there could be a preponderance of harm over benefit.[12]\n\nJapanese guidelines suggest that blood examination should be considered in cases of poor general condition, prolonged altered consciousness, or signs of dehydration.[9] These guidelines also recommend neuroimaging only before LP, as previously stated in the British guidelines,[10] due to the risk of cerebral herniation. By contrast, the Mexican guidelines recommend neuroimaging in patients with FS who do not regain complete consciousness in hours, with prolonged Todd paralysis, or with other focal neurological alterations.[13]\n\nAccording to the AOCN guidelines, urine analysis should be considered in children aged <18 months, as most children do not have a focus of infection, and magnetic resonance imaging (MRI) should be considered in children with the first episode of CFS with prolonged or focal features (within 72 hours).[14]\n\nThe role of the EEG\n\nIn all the existing guidelines, electroencephalography (EEG) is not recommended in case of a first episode of SFS, due to its limited diagnostic value.[8,9,13,14] ILAE guidelines recommend performing an EEG in CFS, owing to the high diagnostic value it may have for some viral encephalitides.[8]\n\nSimilarly, according to the Japanese guidelines, EEG may have a role in differentiating between acute encephalopathy and CFS, but few peer-reviewed reports have appeared in literature validating the utility of EEG for such differentiation.[9] Even though the Japanese guidelines conclude that EEG examination is not indicated for children with SFS, the authors highlight the possible correlation between epileptiform discharges on EEG and development of epilepsy, as well as its usefulness in the diagnosis of acute encephalopathy. Moreover, the Mexican guidelines recommended EEG in a focal and/or prolonged convulsion, or in CFS if the neurological examination shows alterations.[13] According to the AOCN, EEG should be considered in children with CFS or in children with focal findings on neuroimaging.[14] In cases of prolonged altered mental status, the EEG is not useful to predict recurrence of FS or future epilepsy. Moreover, it is important to note that if EEG were useful to identify viral encephalitis, that would establish an alternative diagnosis of viral encephalitis, causing both fever and provoked seizure, and potentially invalidate the initial working diagnosis of CFS. The AOCN suggests that EEG is not recommended in developmentally normal children with SFS because it does not predict the recurrence of FS or subsequent epilepsy.[14]\n\nThe role of the LP\n\nAll the published guidelines recommend performing LP if there are meningeal signs or if a CNS infection is suspected (see Table 2). According to the British guidelines, LP should also be performed after a CFS or if the child is unduly drowsy or irritable or systemically ill.[10] The guidelines also state that LP should probably be performed in children aged less than 18 months and almost certainly in children aged less than 12 months, regardless of meningeal signs.[10] They specify that ideally the decision should be taken by an experienced doctor, who may decide on clinical grounds that LP is unnecessary even in a younger child, but when in doubt the investigation should be performed.[11] Similarly, the AOCN guidelines declare that LP should be considered in children aged <12 months with first episode of FS and in children aged >12 months who have been pretreated with antibiotics.[14]\n\nThe age threshold for performing LP outlined in these older recommendations differs from the most recent ones.[8,12,13] In particular, the AAP states that LP is an option for any infant aged between six and 12 months who has not received scheduled immunizations for Haemophilus influenzae type B or Streptococcus pneumoniae or when the immunization status cannot be determined.[12] Additionally, LP may be considered when the child has recently been treated with antibiotics, as suggested by clinical experience and case series. LP may be an option in the child who is pretreated with antibiotics, because antibiotic treatment can mask the signs and symptoms of meningitis.[12]\n\nSimilarly, the Mexican guidelines state that LP is indicated in children aged <12 months who have not completed their immunizations or have received previous antibiotic treatment or in children aged less than six months with SFS unless an experienced pediatrician evaluates the patient before two hours.\n\nILAE guidelines do not give mandatory indications on whether to routinely perform LP in younger patients, but suggest a careful observation of children aged <18 months for at least 24 hours, since at this age clinical signs and symptoms for meningitis may be minimal and LP must be performed in the presence of meningeal signs.[8,10,12] Moreover, they suggest considering LP also in patients under antibiotic treatment during the days before FS.[8]\n\nPharmacologic prophylaxis and home treatment of FS\n\nAlmost all published guidelines state that neither intermittent nor continuous seizure prophylaxis is recommended in SFS (see Table 2), except for few cases mentioned below.[8,11,13,14] The prevailing recommendation against prophylactic treatment stems from the consideration that such medications carry significant side effects and do not prevent the development of epilepsy. According to ILAE, intermittent prophylaxis may be considered in cases with high risk of recurrence, defined as at least three episodes in six months or at least four episodes in one year, or CFS due to prolonged duration lasting more than 15 minutes or requiring pharmacologic therapy to be stopped.[8,16–18] Intermittent prophylaxis of FS consists in administering rectal (first choice) or oral diazepam at the onset of fever, to be repeated if fever persists after eight hours.[8]\n\nIn case of failure of intermittent prophylaxis and when parents are unable to promptly recognize the onset of fever, ILAE guidelines state that continuous ASMs with phenobarbital or valproic acid may be used.[8] as previously stated in the Japanese guidelines published in 1996.[19] The AAP states that neither continuous nor intermittent seizure prophylaxis is recommended for children with one or more SFS, based on randomized controlled trials and diagnostic studies with minor limitations.[11,16,17] Nonetheless, according to the AAP guidelines, intermittent oral diazepam at the onset of febrile illness may be considered and effective in preventing recurrence in cases of severe parental anxiety associated with FS.[11] Japanese guidelines suggest considering prophylaxis with ASM also in case of severe parental anxiety.[9]\n\nJapanese guidelines recommend the prophylactic use of diazepam during febrile illness in children at high risk of recurrence of FS.[9] As suggested in the study conducted by Berg et al., and Pavlidou et al., who both studied children with a first episode of FS,[18,20] risk factors of recurrence include young age at onset, positive family history of FS, abnormal perinatal history, low degree of fever while in the emergency department (ED), brief duration between the onset of fever and the initial seizure, recurrence within the same illness, partial onset, or focal features of FS. According to several studies, the use of prophylactic diazepam for the prevention of FS is indicated in children with a history of a prolonged FS (lasting longer than 15 minutes) and in children with repeated FS and two of the following risk factors: focal or repeated seizures within 24 hours, pre-existing neurological abnormality or developmental delay, family history of FS or epilepsy, age less than 12 months, seizure within one hour after the onset of fever, or seizure occurring with body temperature less than 38°C[9][21–24].\n\nIn the British guidelines long-term prophylaxis with ASM (valproic acid, phenobarbitone) is not recommended, according to previous studies,[25] except in case of frequent recurrences.[10] According to the Mexican guidelines, treatment with ASM should be considered in patients with long or repetitive FS despite the prophylactic use of diazepam.[13]\n\nThe AOCN guidelines recommend considering intermittent prophylaxis among children with frequent recurrent SFS with parental anxiety, residence far from medical facilities, and those with CFS who have not been started on continuous prophylaxis. On the other hand, continuous prophylaxis should be considered among children with febrile status epilepticus, in children with neurodevelopmental delay, and in frequent CFS.[14]\n\nHome treatment for FS is recommended in four guidelines (UK, ILAE, Mexican, AOCN). An ASM (rectal diazepam or intranasal midazolam) should be administered if FS last more than three minutes (ILAE), five minutes (UK, Mexican), or three to five minutes (AOCN). In particular, ILAE recommends administering rectal diazepam only if the seizure lasts longer than three minutes.[8]\n\nIn the British guidelines there is no agreement on the timing of administration of rectal diazepam: some members of the working group—although neither percentages of members nor studies on which the statements are based on are specified—suggest administering it as soon as possible after the onset of a convulsion, whereas others advised waiting for five minutes, by which time most convulsions will have stopped and ASMs will not be necessary.[10] Indeed, the use of therapies to prevent subsequent epilepsy is not recommended.[8] The British, Mexican, and AOCN guidelines underline the importance of parental education and suggest providing exhaustive information to parents both verbally and possibly written.[10,13,14] Health education should include a description of features of FS and instructions on how to manage possible recurrences.[8]",
    "ori_text": "Results: \nEvaluation of FS \nAll the published guidelines agree that no further investigation is routinely necessary for children with a single episode of SFS[8]-[14] (Table 2). The British guidelines suggest measurement of blood glucose concentration if the child is still convulsing or unrousable when seen either with or without fever and to consider neuroimaging before lumbar puncture (LP) if the child is comatose.[10] According to ILAE guidelines, it is recommended to search for the fever’s etiology in the case of CFS. Additionally, neuroimaging is recommended to investigate a possible underlying brain lesion. Blood chemical tests are suggested in relation to specific clinical conditions.[8] The AAP underscores the importance of evaluating the underlying cause of fever but recommends that blood tests should not be performed routinely for the sole purpose of identifying the cause of SFS, since there is no evidence to suggest that routine blood studies are of benefit in the evaluation of the child with SFS and there could be a preponderance of harm over benefit.[12]\n\nJapanese guidelines suggest that blood examination should be considered in cases of poor general condition, prolonged altered consciousness, or signs of dehydration.[9] These guidelines also recommend neuroimaging only before LP, as previously stated in the British guidelines,[10] due to the risk of cerebral herniation. By contrast, the Mexican guidelines recommend neuroimaging in patients with FS who do not regain complete consciousness in hours, with prolonged Todd paralysis, or with other focal neurological alterations.[13]\n\nAccording to the AOCN guidelines, urine analysis should be considered in children aged <18 months, as most children do not have a focus of infection, and magnetic resonance imaging (MRI) should be considered in children with the first episode of CFS with prolonged or focal features (within 72 hours).[14]\n\nThe role of the EEG\n\nIn all the existing guidelines, electroencephalography (EEG) is not recommended in case of a first episode of SFS, due to its limited diagnostic value.[8,9,13,14] ILAE guidelines recommend performing an EEG in CFS, owing to the high diagnostic value it may have for some viral encephalitides.[8]\n\nSimilarly, according to the Japanese guidelines, EEG may have a role in differentiating between acute encephalopathy and CFS, but few peer-reviewed reports have appeared in literature validating the utility of EEG for such differentiation.[9] Even though the Japanese guidelines conclude that EEG examination is not indicated for children with SFS, the authors highlight the possible correlation between epileptiform discharges on EEG and development of epilepsy, as well as its usefulness in the diagnosis of acute encephalopathy. Moreover, the Mexican guidelines recommended EEG in a focal and/or prolonged convulsion, or in CFS if the neurological examination shows alterations.[13] According to the AOCN, EEG should be considered in children with CFS or in children with focal findings on neuroimaging.[14] In cases of prolonged altered mental status, the EEG is not useful to predict recurrence of FS or future epilepsy. Moreover, it is important to note that if EEG were useful to identify viral encephalitis, that would establish an alternative diagnosis of viral encephalitis, causing both fever and provoked seizure, and potentially invalidate the initial working diagnosis of CFS. The AOCN suggests that EEG is not recommended in developmentally normal children with SFS because it does not predict the recurrence of FS or subsequent epilepsy.[14]\n\nThe role of the LP\n\nAll the published guidelines recommend performing LP if there are meningeal signs or if a CNS infection is suspected (see Table 2). According to the British guidelines, LP should also be performed after a CFS or if the child is unduly drowsy or irritable or systemically ill.[10] The guidelines also state that LP should probably be performed in children aged less than 18 months and almost certainly in children aged less than 12 months, regardless of meningeal signs.[10] They specify that ideally the decision should be taken by an experienced doctor, who may decide on clinical grounds that LP is unnecessary even in a younger child, but when in doubt the investigation should be performed.[11] Similarly, the AOCN guidelines declare that LP should be considered in children aged <12 months with first episode of FS and in children aged >12 months who have been pretreated with antibiotics.[14]\n\nThe age threshold for performing LP outlined in these older recommendations differs from the most recent ones.[8,12,13] In particular, the AAP states that LP is an option for any infant aged between six and 12 months who has not received scheduled immunizations for Haemophilus influenzae type B or Streptococcus pneumoniae or when the immunization status cannot be determined.[12] Additionally, LP may be considered when the child has recently been treated with antibiotics, as suggested by clinical experience and case series. LP may be an option in the child who is pretreated with antibiotics, because antibiotic treatment can mask the signs and symptoms of meningitis.[12]\n\nSimilarly, the Mexican guidelines state that LP is indicated in children aged <12 months who have not completed their immunizations or have received previous antibiotic treatment or in children aged less than six months with SFS unless an experienced pediatrician evaluates the patient before two hours.\n\nILAE guidelines do not give mandatory indications on whether to routinely perform LP in younger patients, but suggest a careful observation of children aged <18 months for at least 24 hours, since at this age clinical signs and symptoms for meningitis may be minimal and LP must be performed in the presence of meningeal signs.[8,10,12] Moreover, they suggest considering LP also in patients under antibiotic treatment during the days before FS.[8]\n\nPharmacologic prophylaxis and home treatment of FS\n\nAlmost all published guidelines state that neither intermittent nor continuous seizure prophylaxis is recommended in SFS (see Table 2), except for few cases mentioned below.[8,11,13,14] The prevailing recommendation against prophylactic treatment stems from the consideration that such medications carry significant side effects and do not prevent the development of epilepsy. According to ILAE, intermittent prophylaxis may be considered in cases with high risk of recurrence, defined as at least three episodes in six months or at least four episodes in one year, or CFS due to prolonged duration lasting more than 15 minutes or requiring pharmacologic therapy to be stopped.[8,16–18] Intermittent prophylaxis of FS consists in administering rectal (first choice) or oral diazepam at the onset of fever, to be repeated if fever persists after eight hours.[8]\n\nIn case of failure of intermittent prophylaxis and when parents are unable to promptly recognize the onset of fever, ILAE guidelines state that continuous ASMs with phenobarbital or valproic acid may be used.[8] as previously stated in the Japanese guidelines published in 1996.[19] The AAP states that neither continuous nor intermittent seizure prophylaxis is recommended for children with one or more SFS, based on randomized controlled trials and diagnostic studies with minor limitations.[11,16,17] Nonetheless, according to the AAP guidelines, intermittent oral diazepam at the onset of febrile illness may be considered and effective in preventing recurrence in cases of severe parental anxiety associated with FS.[11] Japanese guidelines suggest considering prophylaxis with ASM also in case of severe parental anxiety.[9]\n\nJapanese guidelines recommend the prophylactic use of diazepam during febrile illness in children at high risk of recurrence of FS.[9] As suggested in the study conducted by Berg et al., and Pavlidou et al., who both studied children with a first episode of FS,[18,20] risk factors of recurrence include young age at onset, positive family history of FS, abnormal perinatal history, low degree of fever while in the emergency department (ED), brief duration between the onset of fever and the initial seizure, recurrence within the same illness, partial onset, or focal features of FS. According to several studies, the use of prophylactic diazepam for the prevention of FS is indicated in children with a history of a prolonged FS (lasting longer than 15 minutes) and in children with repeated FS and two of the following risk factors: focal or repeated seizures within 24 hours, pre-existing neurological abnormality or developmental delay, family history of FS or epilepsy, age less than 12 months, seizure within one hour after the onset of fever, or seizure occurring with body temperature less than 38°C[9][21–24].\n\nIn the British guidelines long-term prophylaxis with ASM (valproic acid, phenobarbitone) is not recommended, according to previous studies,[25] except in case of frequent recurrences.[10] According to the Mexican guidelines, treatment with ASM should be considered in patients with long or repetitive FS despite the prophylactic use of diazepam.[13]\n\nThe AOCN guidelines recommend considering intermittent prophylaxis among children with frequent recurrent SFS with parental anxiety, residence far from medical facilities, and those with CFS who have not been started on continuous prophylaxis. On the other hand, continuous prophylaxis should be considered among children with febrile status epilepticus, in children with neurodevelopmental delay, and in frequent CFS.[14]\n\nHome treatment for FS is recommended in four guidelines (UK, ILAE, Mexican, AOCN). An ASM (rectal diazepam or intranasal midazolam) should be administered if FS last more than three minutes (ILAE), five minutes (UK, Mexican), or three to five minutes (AOCN). In particular, ILAE recommends administering rectal diazepam only if the seizure lasts longer than three minutes.[8]\n\nIn the British guidelines there is no agreement on the timing of administration of rectal diazepam: some members of the working group—although neither percentages of members nor studies on which the statements are based on are specified—suggest administering it as soon as possible after the onset of a convulsion, whereas others advised waiting for five minutes, by which time most convulsions will have stopped and ASMs will not be necessary.[10] Indeed, the use of therapies to prevent subsequent epilepsy is not recommended.[8] The British, Mexican, and AOCN guidelines underline the importance of parental education and suggest providing exhaustive information to parents both verbally and possibly written.[10,13,14] Health education should include a description of features of FS and instructions on how to manage possible recurrences.[8]",
    "reference_list": "考点1：“Febrile Seizures (FS)”推荐译为“热性惊厥”，【关键内容，为全文主题】\n考点2：“Simple Febrile Seizures (SFS)”推荐译为“单纯性热性惊厥”，\n考点3：“Complex Febrile Seizures (CFS)”推荐译为“复杂性热性惊厥”，\n考点4：“Lumbar Puncture (LP)”推荐译为“腰椎穿刺”，\n考点5：“Neuroimaging”推荐译为“神经影像学检查”，\n考点6：“Electroencephalography (EEG)”推荐译为“脑电图”，\n考点7：“Central Nervous System (CNS) Infection”推荐译为“中枢神经系统感染”，\n考点8：“Cerebral Herniation”推荐译为“脑疝”，\n考点9：“Todd Paralysis”推荐译为“托德瘫痪”，\n考点10：“Focal Neurological Alterations”推荐译为“局灶性神经功能异常”，【易错点 \"alterations\"在神经科特指\"功能异常\"，非泛指\"系统异常\"】\n考点11：“Urine Analysis”推荐译为“尿液分析”，\n考点12：“Magnetic Resonance Imaging (MRI)”推荐译为“磁共振成像”，\n考点13：“Viral Encephalitides”推荐译为“病毒性脑炎”，\n考点14：“Acute Encephalopathy”推荐译为“急性脑病”，\n考点15：“Epileptiform Discharges”推荐译为“癫痫样放电”，\n考点16：“Meningeal Signs”推荐译为“脑膜刺激征”，\n考点17：“Immunization Status”推荐译为“免疫接种状态”，\n考点18：“Haemophilus influenzae type B (HIB)”推荐译为“b型流感嗜血杆菌”，\n考点19：“Streptococcus pneumoniae”推荐译为“肺炎链球菌”，\n考点20：“Continuous Prophylaxis”推荐译为“持续性预防”，【易错点 \"Continuous\"在文中应翻译为持续性而不是连续或长期】\n考点21：“Antiseizure Medications (ASMs)”推荐译为“抗癫痫药物”，\n考点22：“within the same illness”推荐译为“同一病程内”，【易错点 结合上下文illness应翻译为\"病程\"，而不是\"疾病\"。结合上下文illness应翻译为\"病程\"，而不是\"疾病\"】\n考点23：“and possibly written”推荐译为“书面材料”，【易错点 结合上下文written应翻译为书面材料，比如出院小结、告知书等材料，而不是信息、书信等】\n考点24：“residence far from medical facilities”推荐译为“居住地远离医疗机构”，【\"facilities\"在文中语境应译\"机构\"，比如医院等，设施指CT等设备，而不是\"设施\"】\n考点25：“abnormal perinatal history”推荐译为“围产期异常史”，【易错点 医学专业表达习惯为\"异常史\"，是指病史中的既往史部分，若翻译为\"病史异常\"则不专业且容易有歧义】\n考点26：“AOCN (Association of Child Neurology India)”推荐译为“印度儿童神经病学协会”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "101"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nReal estate CEO warns of growing ‘exodus’ as people have ‘given up’ on California — but where are they going?\nWith its beautiful weather, breathtaking coastlines and vibrant culture, California has always held a special allure. But according to Don Peebles — founder, chairman and CEO of real estate investment and development firm The Peebles Corporation — the Golden State’s appeal is rapidly fading as residents pack up and head for the exits.\n“California, and especially Southern California, is the most difficult place to do business in the United States,” he stated bluntly in a Fox Business interview. “We were trying to build a $1.6 billion development in downtown LA, and stuck with it during the COVID crisis, and yet we could get no support from the government.”\nDon't miss\nThanks to Jeff Bezos, you can now become a landlord for as little as $100 — and no, you don't have to deal with tenants or fix freezers. Here's how\nI'm 49 years old and have nothing saved for retirement — what should I do? Don't panic. Here are 5 of the easiest ways you can catch up (and fast)\nYou don’t have to be a millionaire to gain access to this $1B private real estate fund. In fact, you can get started with as little as $10 — here’s how\nPeebles didn’t mince words, arguing that the state’s policies “were hurting businesses.”\nHe also pointed to the growing wave of people leaving California.\n“People are fleeing, they have given up, and they're going to other places,” he said. “We're going to see more of an exodus out of California, because the quality of life has diminished as well.”\nThe California exodus by the numbers\nTalk of a California exodus gained momentum during the pandemic, and although the pace has slowed, the outflow of residents hasn’t stopped.\nWhere did they go?\nTexas topped the list. In 2023, 93,970 Californians relocated to the Lone Star State. In fact, Texas has consistently been the most popular destination for those leaving California:\n107,546 Californians moved there in 2021\n102,442 more followed in 2022\nArizona and Florida were also major draws, attracting 54,222 and 39,052 former Californians, respectively, during the most recent reporting period.\nRead more: Rich, young Americans are ditching the stormy stock market — here are the alternative assets they're banking on instead\nRising costs of living — and how to hedge against them\nThere are many theories about why so many Californians are leaving. High taxes are often cited — for example, neither Texas nor Florida imposes a state income tax. But perhaps just as important is the sky-high cost of living.\nHousing costs alone are enough to make headlines. According to data from real estate brokerage Redfin, the median home price in California currently stands at $859,700 — nearly twice the national median of $440,892.\nA recent Bankrate study found that a household in California needs an annual income of $213,447 to afford a typical home in the state.\nYet real estate remains a popular investment choice for those looking to hedge against rising living costs. When inflation goes up, property values often climb as well, reflecting the higher costs of materials, labor and land.\nAt the same time, rental income tends to rise, providing landlords with a revenue stream that adjusts with inflation.\nOver the past five years, the S&P CoreLogic Case-Shiller U.S. National Home Price NSA Index has surged more than 50%.\nThese days, you don’t need to buy an entire property outright to benefit from real estate investing. Crowdfunding platforms like Arrived have made it easier than ever for everyday investors to gain exposure to this income-generating asset class.\nBacked by world class investors like Jeff Bezos, Arrived allows you to invest in shares of rental homes with as little as $100, all without the hassle of mowing lawns, fixing leaky faucets or handling difficult tenants.\nThe process is simple: Browse a curated selection of homes that have been vetted for their appreciation and income potential. Once you find a property you like, select the number of shares you’d like to purchase, and then sit back as you start receiving positive rental income distributions from your investment.\nFor accredited investors, Homeshares gives access to the $35 trillion U.S. home equity market, which has historically been the exclusive playground of institutional investors.\nWith a minimum investment of $25,000, investors can gain direct exposure to hundreds of owner-occupied homes in top U.S. cities through their U.S. Home Equity Fund — without the headaches of buying, owning or managing property.\nWith risk-adjusted target returns ranging from 14% to 17%, this approach provides an effective, hands-off way to invest in owner-occupied residential properties across regional markets.\nAnother option is First National Realty Partners (FNRP), which allows accredited investors to diversify their portfolio through grocery-anchored commercial properties without taking on the responsibilities of being a landlord.\nWith a minimum investment of $50,000, investors can own a share of properties leased by national brands like Whole Foods, Kroger and Walmart, which provide essential goods to their communities. Thanks to Triple Net (NNN) leases, accredited investors are able to invest in these properties without worrying about tenant costs cutting into their potential returns.\nSimply answer a few questions — including how much you would like to invest — to start browsing their full list of available properties.\nWhat to read next\nHere are the 6 levels of wealth for retirement-age Americans — are you near the top or bottom of the pyramid?\nThis tiny hot Costco item has skyrocketed 74% in price in under 2 years — but now the retail giant is restricting purchases. Here’s how to buy the coveted asset in bulk\nCar insurance in America could climb to a stunning $2,502/year on average — but here’s how 2 minutes can save you more than $600 in 2025\nWant an extra $1,300,000 when you retire? Dave Ramsey says this 7-step plan ‘works every single time’ to kill debt, get rich in America — and that ‘anyone’ can do it\nMoney doesn’t have to be complicated — sign up for the free Moneywise newsletter for actionable finance tips and news you can use. Join now.\nThis article provides information only and should not be construed as advice. It is provided without warranty of any kind.\nCoreWeave’s Cooling Stock Rally Faces Even Bigger Hurdles Ahead\n(Bloomberg) -- CoreWeave Inc.’s blistering rally has lost steam as the artificial intelligence infrastructure play faces a growing tangle of bearish catalysts that threaten to further unravel its meteoric rise.\nShares of the Nvidia Corp.-backed company have tumbled 17% in less than a month after a nearly five-fold increase following its March initial public offering as investors soured on its ballooning valuation. Now it faces a wall of pressure with a series of share lockups expiring starting next month, allowing early shareholders to cash out. Meanwhile, its deal to buy Core Scientific Inc. for $9 billion drew mixed reviews, spurring at least three analysts downgrades. CoreWeave shares slipped 1% in early trading on Thursday.\n“We’re already giving CoreWeave a pass on so many things, not least of which is that it doesn’t make money and won’t for a while,” said Mark Malek, chief investment officer at Siebert Financial. “The lockup doesn’t change the story’s fundamentals, but it is another thing you’d have to give it a pass on if you’re buying now.”\nCoreWeave has become one of the most contentious stocks on Wall Street as its market value soared from less than $20 billion after its IPO to nearly $100 billion at its peak in June. The firm rents cloud-computing services to hyperscale-cloud operators like Microsoft Corp., making it a favorite of traders betting on a continuing wave of AI spending.\nBut with the company not expected to turn a profit until the end of 2026, it has become a target of short sellers and value-minded investors who are betting it’s poised to fall back to earth. Even after its recent retreat, the stock trades at nearly 9 times sales estimated over the next 12 months, compared with roughly 5 times for the Nasdaq 100.\nCoreWeave did not respond to a Bloomberg News request for comment.\nPart of what has helped fuel CoreWeave’s rally is a relatively low number of shares available to trade, the result of the lockups and a small group of large shareholders, including Magnetar Financial and Coatue Management. Less than 13% of CoreWeave’s outstanding shares, about 47 million shares, are currently available to be traded. That will come to an end starting in August when an estimated 290 million shares will be freed up for trading.\nWhile many believe that the wave of shares hitting the market will exacerbate the current selloff in CoreWeave, some on Wall Street think it’s well positioned to weather the volatility as its second-quarter earnings approach. CoreWeave is expected to report a net loss of $236 million in the second quarter on revenue of $1.08 billion.\n“We think it will do significantly better than where CoreWeave is guiding,” said Mark Klein, chief executive officer at SuRo Capital. “You can’t just throw out traditional valuation metrics, but you have to appreciate how premium brands command premium valuations.”\nStill, much of Wall Street remains unconvinced. Only three of 22 analysts covering the stock recommend buying it, according to data compiled by Bloomberg. It’s average price target is more than 30% below where it closed on Wednesday, the worst expected return in a Bloomberg index of large capitalization stocks.\nIts all-stock deal to buy Core Scientific this week only served to further sour analysts on the stock. At least three analysts, including Needham, Mizuho and Stifel cut their ratings following the announcement. Both Needham and Mizuho cited valuation, while Stifel said it was positive on the deal longer term but called out overhangs from its pending dilution and lock-up expiry.\n“We see great potential, but right now all I see are mounting losses,” Siebert’s Malek said. “I’d rather leave money on the table than flush it down the toilet. Right now all I can do is watch the rally with a smile and say wow.”",
    "ori_text": "Real estate CEO warns of growing ‘exodus’ as people have ‘given up’ on California — but where are they going?\nWith its beautiful weather, breathtaking coastlines and vibrant culture, California has always held a special allure. But according to Don Peebles — founder, chairman and CEO of real estate investment and development firm The Peebles Corporation — the Golden State’s appeal is rapidly fading as residents pack up and head for the exits.\n“California, and especially Southern California, is the most difficult place to do business in the United States,” he stated bluntly in a Fox Business interview. “We were trying to build a $1.6 billion development in downtown LA, and stuck with it during the COVID crisis, and yet we could get no support from the government.”\nDon't miss\nThanks to Jeff Bezos, you can now become a landlord for as little as $100 — and no, you don't have to deal with tenants or fix freezers. Here's how\nI'm 49 years old and have nothing saved for retirement — what should I do? Don't panic. Here are 5 of the easiest ways you can catch up (and fast)\nYou don’t have to be a millionaire to gain access to this $1B private real estate fund. In fact, you can get started with as little as $10 — here’s how\nPeebles didn’t mince words, arguing that the state’s policies “were hurting businesses.”\nHe also pointed to the growing wave of people leaving California.\n“People are fleeing, they have given up, and they're going to other places,” he said. “We're going to see more of an exodus out of California, because the quality of life has diminished as well.”\nThe California exodus by the numbers\nTalk of a California exodus gained momentum during the pandemic, and although the pace has slowed, the outflow of residents hasn’t stopped.\nWhere did they go?\nTexas topped the list. In 2023, 93,970 Californians relocated to the Lone Star State. In fact, Texas has consistently been the most popular destination for those leaving California:\n107,546 Californians moved there in 2021\n102,442 more followed in 2022\nArizona and Florida were also major draws, attracting 54,222 and 39,052 former Californians, respectively, during the most recent reporting period.\nRead more: Rich, young Americans are ditching the stormy stock market — here are the alternative assets they're banking on instead\nRising costs of living — and how to hedge against them\nThere are many theories about why so many Californians are leaving. High taxes are often cited — for example, neither Texas nor Florida imposes a state income tax. But perhaps just as important is the sky-high cost of living.\nHousing costs alone are enough to make headlines. According to data from real estate brokerage Redfin, the median home price in California currently stands at $859,700 — nearly twice the national median of $440,892.\nA recent Bankrate study found that a household in California needs an annual income of $213,447 to afford a typical home in the state.\nYet real estate remains a popular investment choice for those looking to hedge against rising living costs. When inflation goes up, property values often climb as well, reflecting the higher costs of materials, labor and land.\nAt the same time, rental income tends to rise, providing landlords with a revenue stream that adjusts with inflation.\nOver the past five years, the S&P CoreLogic Case-Shiller U.S. National Home Price NSA Index has surged more than 50%.\nThese days, you don’t need to buy an entire property outright to benefit from real estate investing. Crowdfunding platforms like Arrived have made it easier than ever for everyday investors to gain exposure to this income-generating asset class.\nBacked by world class investors like Jeff Bezos, Arrived allows you to invest in shares of rental homes with as little as $100, all without the hassle of mowing lawns, fixing leaky faucets or handling difficult tenants.\nThe process is simple: Browse a curated selection of homes that have been vetted for their appreciation and income potential. Once you find a property you like, select the number of shares you’d like to purchase, and then sit back as you start receiving positive rental income distributions from your investment.\nFor accredited investors, Homeshares gives access to the $35 trillion U.S. home equity market, which has historically been the exclusive playground of institutional investors.\nWith a minimum investment of $25,000, investors can gain direct exposure to hundreds of owner-occupied homes in top U.S. cities through their U.S. Home Equity Fund — without the headaches of buying, owning or managing property.\nWith risk-adjusted target returns ranging from 14% to 17%, this approach provides an effective, hands-off way to invest in owner-occupied residential properties across regional markets.\nAnother option is First National Realty Partners (FNRP), which allows accredited investors to diversify their portfolio through grocery-anchored commercial properties without taking on the responsibilities of being a landlord.\nWith a minimum investment of $50,000, investors can own a share of properties leased by national brands like Whole Foods, Kroger and Walmart, which provide essential goods to their communities. Thanks to Triple Net (NNN) leases, accredited investors are able to invest in these properties without worrying about tenant costs cutting into their potential returns.\nSimply answer a few questions — including how much you would like to invest — to start browsing their full list of available properties.\nWhat to read next\nHere are the 6 levels of wealth for retirement-age Americans — are you near the top or bottom of the pyramid?\nThis tiny hot Costco item has skyrocketed 74% in price in under 2 years — but now the retail giant is restricting purchases. Here’s how to buy the coveted asset in bulk\nCar insurance in America could climb to a stunning $2,502/year on average — but here’s how 2 minutes can save you more than $600 in 2025\nWant an extra $1,300,000 when you retire? Dave Ramsey says this 7-step plan ‘works every single time’ to kill debt, get rich in America — and that ‘anyone’ can do it\nMoney doesn’t have to be complicated — sign up for the free Moneywise newsletter for actionable finance tips and news you can use. Join now.\nThis article provides information only and should not be construed as advice. It is provided without warranty of any kind.\nCoreWeave’s Cooling Stock Rally Faces Even Bigger Hurdles Ahead\n(Bloomberg) -- CoreWeave Inc.’s blistering rally has lost steam as the artificial intelligence infrastructure play faces a growing tangle of bearish catalysts that threaten to further unravel its meteoric rise.\nShares of the Nvidia Corp.-backed company have tumbled 17% in less than a month after a nearly five-fold increase following its March initial public offering as investors soured on its ballooning valuation. Now it faces a wall of pressure with a series of share lockups expiring starting next month, allowing early shareholders to cash out. Meanwhile, its deal to buy Core Scientific Inc. for $9 billion drew mixed reviews, spurring at least three analysts downgrades. CoreWeave shares slipped 1% in early trading on Thursday.\n“We’re already giving CoreWeave a pass on so many things, not least of which is that it doesn’t make money and won’t for a while,” said Mark Malek, chief investment officer at Siebert Financial. “The lockup doesn’t change the story’s fundamentals, but it is another thing you’d have to give it a pass on if you’re buying now.”\nCoreWeave has become one of the most contentious stocks on Wall Street as its market value soared from less than $20 billion after its IPO to nearly $100 billion at its peak in June. The firm rents cloud-computing services to hyperscale-cloud operators like Microsoft Corp., making it a favorite of traders betting on a continuing wave of AI spending.\nBut with the company not expected to turn a profit until the end of 2026, it has become a target of short sellers and value-minded investors who are betting it’s poised to fall back to earth. Even after its recent retreat, the stock trades at nearly 9 times sales estimated over the next 12 months, compared with roughly 5 times for the Nasdaq 100.\nCoreWeave did not respond to a Bloomberg News request for comment.\nPart of what has helped fuel CoreWeave’s rally is a relatively low number of shares available to trade, the result of the lockups and a small group of large shareholders, including Magnetar Financial and Coatue Management. Less than 13% of CoreWeave’s outstanding shares, about 47 million shares, are currently available to be traded. That will come to an end starting in August when an estimated 290 million shares will be freed up for trading.\nWhile many believe that the wave of shares hitting the market will exacerbate the current selloff in CoreWeave, some on Wall Street think it’s well positioned to weather the volatility as its second-quarter earnings approach. CoreWeave is expected to report a net loss of $236 million in the second quarter on revenue of $1.08 billion.\n“We think it will do significantly better than where CoreWeave is guiding,” said Mark Klein, chief executive officer at SuRo Capital. “You can’t just throw out traditional valuation metrics, but you have to appreciate how premium brands command premium valuations.”\nStill, much of Wall Street remains unconvinced. Only three of 22 analysts covering the stock recommend buying it, according to data compiled by Bloomberg. It’s average price target is more than 30% below where it closed on Wednesday, the worst expected return in a Bloomberg index of large capitalization stocks.\nIts all-stock deal to buy Core Scientific this week only served to further sour analysts on the stock. At least three analysts, including Needham, Mizuho and Stifel cut their ratings following the announcement. Both Needham and Mizuho cited valuation, while Stifel said it was positive on the deal longer term but called out overhangs from its pending dilution and lock-up expiry.\n“We see great potential, but right now all I see are mounting losses,” Siebert’s Malek said. “I’d rather leave money on the table than flush it down the toilet. Right now all I can do is watch the rally with a smile and say wow.”",
    "reference_list": "考点 1：【exodus】 应译为 【人口外流 / 大规模迁出】\n考点 2：【The Peebles Corporation】 应译为【 皮布尔斯公司】\n考点 3：【Triple Net (NNN) leases】 应译为【 三重净租赁】\n考点 4：【lockup expiry】 应译为 【锁定期到期】\n考点 5：【sky-high cost of living 】应译为 【高得离谱的生活成本】\n考点 6：【leave money on the table 】应译为 【错失潜在收益】\n考点 7：【flush it down the toilet】 应译为 【打水漂 / 白白浪费】",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "房地产",
    "prompt_id": "89"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nWhen viewed as an elementary particle, the electron has spin and charge. When binding to the atomic nucleus, it also acquires an angular momentum quantum number corresponding to the quantized atomic orbital it occupies. Even if electrons in solids form bands and delocalize from the nuclei, in Mott insulators they retain their three fundamental quantum numbers: spin, charge and orbital1 . The hallmark of one-dimensional physics is a breaking up of the elementary electron into its separate degrees of freedom2 . The separation of the electron into independent quasi-particles that carry either spin (spinons) or charge (holons) was first observed fifteen years ago3 . Here we report observation of the separation of the orbital degree of freedom (orbiton) using resonant inelastic X-ray scattering on the one-dimensional Mott  insulator Sr2CuO3. We resolve an orbiton separating itself from spinons and propagating through the lattice as a distinct quasiparticle with a substantial dispersion in energy over momentum, of about 0.2 electronvolts, over nearly one Brillouin zone. \nIt was pointed out in the 1970s that in a solid not only the charge and spin of electrons can become ordered—leading to magnetism—but also the electrons’ orbital degree of freedom1 . This observation sparked a field that has gone on to produce a number of important results. Although a physical electron combines spin, charge and orbital, theoretically an electron can be considered a bound state of the three independent, fundamental quasi-particles: a spinon, carrying the electron’s spin; a holon (or chargon), carrying its charge; and an orbiton, carrying its orbital degree of freedom. \nA remarkable and fundamental property of one-dimensional (1D) systems is that electronic excitations break up into deconfined spinons and holons. This was predicted decades ago (ref. 2 and references therein) and confirmed in the mid 1990s by angle-resolved photoemission spectroscopy experiments3–5. The spin–charge separation is an example of particle fractionalization, a phenomenon in which the \nquantum numbers of quasi-particles are not multiples of those of the elementary particle, but fractions. This effect is one of the most unusual manifestations of collective quantum physics of interacting particles and is a profound concept that has found its way into a number of theories, for example that describing high-temperature \nsuperconductivity in copper oxides6,7. \nTo search for the further fractionalization of the electron, we consider the excitation of a copper orbital degree of freedom in the antiferromagnetic spin-chain compound Sr2CuO3. The spin–orbital separation process that we are looking for is analogous to the spin–charge separation mechanism (Fig. 1b). The latter occurs, for instance, when an electron is annihilated, removing a single spin and leaving behind a hole in the antiferromagnetic chain. This hole can start to propagate freely only after exciting one spinon (a domain wall in the  antiferromagnetic chain). Subsequently, the spinon can delocalize and separate itself completely from the holon. When instead of creating a hole, as typically is done in a photoemission experiment, an electron is excited from one copper 3d orbital to another, the phenomenon of spin–orbital separation can in principle occur (Fig. 1a). The orbiton created in this manner may also deconfine after exciting a spinon, thus splitting the electron into its orbital and spin degrees of freedom8 . \nHere we use high-resolution resonant inelastic X-ray scattering (RIXS) to search experimentally for spin–orbital separation in the quasi-1D copper oxide Sr2CuO3 (for material details, see Supplementary Information, section 1). We observe deconfinement of the spinon and orbiton during orbital excitation from the ground-state copper 3d orbital to an excited copper 3d xy or xz orbital (Fig. 1c–e). For simplicity, we will from henceforth use the so-called ‘hole’ language: although nominally there are nine electrons in the 3d orbitals of the Cu21 ion in Sr2CuO3, by using the ‘electron–hole’ transformation we can map the problem onto an effective system with one particle occupying a single 3d orbital (Supplementary Information, section 2). \nWe measure an orbiton dispersion that is almost as large as the dispersion of the two-spinon continuum at low energies. As for spin–charge separation3–5, the orbiton dispersion has periodicity p (see Fig. 1c and see discussion below), which indicates the presence of an orbiton liberated from the spinon. \nWe measured the orbital excitations of Sr2CuO3 using RIXS at the L3 edge of the copper ion. RIXS is a second-order scattering technique and can excite transitions between the copper 3d states of different symmetry (orbital excitations), owing to the involvement of two subsequent electric dipole transitions9,10 (Supplementary Information, section 3). With the unique capability of RIXS also to probe spin excitations11–13 and to vary the photon momentum transfer, the dispersion of orbital and spin excitations can be mapped out across the first Brillouin zone11–16. The experiments were carried out at the ADRESS beamline of the Swiss Light Source at the Paul Scherrer Institut17,18. \nFor fixed momentum transfer, q, along the chains, peaks in the RIXS spectrum at constant energy transfer reveal the presence of charge-neutral elementary excitations and are visible in the RIXS intensity map of Sr2CuO3 across the copper L3 edge in Fig. 2a. The spectrum for which the incident energy was precisely tuned to the resonance maximum of the absorption spectrum is shown in Fig. 2b. In both plots, the excitations of the spin, orbital and charge degrees of freedom are indicated. The momentum dependence and, in particular, the dispersion of the spin and orbital excitations (Fig. 1c and Supplementary Fig. 2a) are indicative of their collective nature. \nFor energy transfers of up to ,0.8 eV purely magnetic excitations are present, but the spectrum between ,1.5 and ,3.5 eV corresponds to excitations from the copper ground state to orbitals of symmetry (Fig. 1d, e). These peaks correspond toorbital excitations (called also d–d excitations), and not, for example, to charge transfer excitations, the intensity of which is non-zero for energies up to ,6 eV but here for the case of L-edge RIXS is at least an order of magnitude lower10. The orbital assignment of these excitations was unambiguously verified by comparing their energy with ab initio quantum chemistry cluster calculations19 (Supplementary Information, section 5, for detailed results). \nZooming into the ‘magnetic’ part of Fig. 1c, between 0 and 0.8 eV in energy transfer, reveals strongly dispersing spin excitations. At the lower boundary the dispersion has period p, and at the continuum (upper boundary) it has period 2p (Fig. 3a). These RIXS data agree very well with recent inelastic neutron scattering studies on Sr2CuO3 (ref. 20). The simultaneous presence in the spectrum of a lower edge with period p and an upper one with period 2p indicates directly that in the spin chain the magnetic excitations with spin 1 break up and fractionalize into two-spinon (and higher-order) excitations that make up a continuum20, with each spinon having spin 1/2. These spectra confirm that RIXS for magnetic excitations probes the well-known \nspin dynamical structure factor as theoretically predicted11–13, in agreement with recent studies on TiOCl (ref. 21). The excellent statistics ofthe data further allow for a direct comparison of the RIXS line shapes with the exact two- and four-spinon dynamical structure factor of the spin-1/2 Heisenberg chain. In Fig. 3b, we show the fits for three selected momentum transfer values using the exact two- and four-spinon dynamical structure factor, S(q, v) (where q and v stand for the momentum and energy of the created excitation, respectively) in the representation of ref. 22. The obtained exchange coupling is in very good agreement with the value obtained from inelastic neutron scattering data20. \nHaving unambiguously identified the fractionalized spinon excitations in the low-energy sector, we now concentrate on the orbital excitations spectrum in Fig. 4. We find that these are strongly momentum dependent and have a novel, distinct dispersion. This proves that the orbital excitations observed here are of collective nature. The xz excitation has the largest dispersion, of ,0.2 eV, and has a spectrum containing two peculiar components: a lower branch dispersing with periodicity p and, above that, an incoherent spectrum with a double-oval shape. This spectrum is strikingly similar to seemingly unrelated angle-resolved photoemission spectra of 1D copper oxides, which evidence spin–charge separation (see, for example, fig. 3 of ref. 3). This is an indication that the observed orbital dispersion is related to an analogous separation of degrees of freedom. \nTo test this conjecture, we derived a microscopic model that describes the spin–orbital interactions in Sr2CuO3 (Methods). The low-energy Kugel’–Khomskii Hamiltonian for this was obtained8,23 from the charge transfer model of Sr2CuO3 in ref. 24. The crucial part of the Hamiltonian, responsible for the xz orbital propagation, \nwhere J and JO are respectively the spin and orbital exchange constants, both of which are fixed by the charge transfer model24; EO is the xz orbital on-site energy; c z js and cjs are operators that respectively annihilate and create particles in xz orbital with spin s; Sj is the spin of the particle in x2 2 y 2 orbital; 1 2 nj counts the number of particles in xz orbital; and ‘h.c.’ denotes Hermitian conjugate. The first term in the Hamiltonian describes the propagation of orbital excitations through the lattice. The second term represents the usual Heisenberg interaction between spins, which vanishes on bonds where an orbital excitation is present (Methods\nTo quantify the spectral weights within the orbiton–spinon continuum, we have calculated for the JO–J Hamiltonian the orbital excitation Green’s function by exactly diagonalizing the Hamiltonian on 28 lattice sites (as in the spin–charge separation studies3 , finite-size effects are negligible (they are estimated at ,0.01 eV)). From this, we calculate the RIXS spectrum following ref. 13, that is, by expressing the RIXS amplitude as a product of the single-ion local RIXS effective operator and the orbital excitation Green’s function (Methods). \nWe find excellent agreement between theory and experiment (Fig. 4): both the sine-like xz orbiton dispersion and the xz spinon– orbiton continuum (the ‘double-oval’ incoherent spectrum), which are the hallmarks of spin–orbital separation, are present in the theory. The calculations also show that, in contrast to the xz orbital, the xy orbital has a small dispersion and that the excitations of both the orbital and the yz orbital are dispersionless, as is observed experimentally. This is an independent merit of the model because no fitting of dispersions to experimental data is involved. \nThe large orbiton dispersion observed in this study is the key feature that distinguishes Sr2CuO3 from other systems with orbital excitations27–29, and relies on the 1D character of Sr2CuO3. In a system of higher dimensionality, orbitons interact with magnetic excitations, which tend to slow them down and thus reduce their dispersion. In one dimension, orbitons can avoid these renormalization effects by means of spin–orbital separation",
    "ori_text": "\n\nWhen viewed as an elementary particle, the electron has spin and charge. When binding to the atomic nucleus, it also acquires an angular momentum quantum number corresponding to the quantized atomic orbital it occupies. Even if electrons in solids form bands and delocalize from the nuclei, in Mott insulators they retain their three fundamental quantum numbers: spin, charge and orbital1 . The hallmark of one-dimensional physics is a breaking up of the elementary electron into its separate degrees of freedom2 . The separation of the electron into independent quasi-particles that carry either spin (spinons) or charge (holons) was first observed fifteen years ago3 . Here we report observation of the separation of the orbital degree of freedom (orbiton) using resonant inelastic X-ray scattering on the one-dimensional Mott  insulator Sr2CuO3. We resolve an orbiton separating itself from spinons and propagating through the lattice as a distinct quasiparticle with a substantial dispersion in energy over momentum, of about 0.2 electronvolts, over nearly one Brillouin zone. \nIt was pointed out in the 1970s that in a solid not only the charge and spin of electrons can become ordered—leading to magnetism—but also the electrons’ orbital degree of freedom1 . This observation sparked a field that has gone on to produce a number of important results. Although a physical electron combines spin, charge and orbital, theoretically an electron can be considered a bound state of the three independent, fundamental quasi-particles: a spinon, carrying the electron’s spin; a holon (or chargon), carrying its charge; and an orbiton, carrying its orbital degree of freedom. \nA remarkable and fundamental property of one-dimensional (1D) systems is that electronic excitations break up into deconfined spinons and holons. This was predicted decades ago (ref. 2 and references therein) and confirmed in the mid 1990s by angle-resolved photoemission spectroscopy experiments3–5. The spin–charge separation is an example of particle fractionalization, a phenomenon in which the \nquantum numbers of quasi-particles are not multiples of those of the elementary particle, but fractions. This effect is one of the most unusual manifestations of collective quantum physics of interacting particles and is a profound concept that has found its way into a number of theories, for example that describing high-temperature \nsuperconductivity in copper oxides6,7. \nTo search for the further fractionalization of the electron, we consider the excitation of a copper orbital degree of freedom in the antiferromagnetic spin-chain compound Sr2CuO3. The spin–orbital separation process that we are looking for is analogous to the spin–charge separation mechanism (Fig. 1b). The latter occurs, for instance, when an electron is annihilated, removing a single spin and leaving behind a hole in the antiferromagnetic chain. This hole can start to propagate freely only after exciting one spinon (a domain wall in the  antiferromagnetic chain). Subsequently, the spinon can delocalize and separate itself completely from the holon. When instead of creating a hole, as typically is done in a photoemission experiment, an electron is excited from one copper 3d orbital to another, the phenomenon of spin–orbital separation can in principle occur (Fig. 1a). The orbiton created in this manner may also deconfine after exciting a spinon, thus splitting the electron into its orbital and spin degrees of freedom8 . \nHere we use high-resolution resonant inelastic X-ray scattering (RIXS) to search experimentally for spin–orbital separation in the quasi-1D copper oxide Sr2CuO3 (for material details, see Supplementary Information, section 1). We observe deconfinement of the spinon and orbiton during orbital excitation from the ground-state copper 3d orbital to an excited copper 3d xy or xz orbital (Fig. 1c–e). For simplicity, we will from henceforth use the so-called ‘hole’ language: although nominally there are nine electrons in the 3d orbitals of the Cu21 ion in Sr2CuO3, by using the ‘electron–hole’ transformation we can map the problem onto an effective system with one particle occupying a single 3d orbital (Supplementary Information, section 2). \nWe measure an orbiton dispersion that is almost as large as the dispersion of the two-spinon continuum at low energies. As for spin–charge separation3–5, the orbiton dispersion has periodicity p (see Fig. 1c and see discussion below), which indicates the presence of an orbiton liberated from the spinon. \nWe measured the orbital excitations of Sr2CuO3 using RIXS at the L3 edge of the copper ion. RIXS is a second-order scattering technique and can excite transitions between the copper 3d states of different symmetry (orbital excitations), owing to the involvement of two subsequent electric dipole transitions9,10 (Supplementary Information, section 3). With the unique capability of RIXS also to probe spin excitations11–13 and to vary the photon momentum transfer, the dispersion of orbital and spin excitations can be mapped out across the first Brillouin zone11–16. The experiments were carried out at the ADRESS beamline of the Swiss Light Source at the Paul Scherrer Institut17,18. \nFor fixed momentum transfer, q, along the chains, peaks in the RIXS spectrum at constant energy transfer reveal the presence of charge-neutral elementary excitations and are visible in the RIXS intensity map of Sr2CuO3 across the copper L3 edge in Fig. 2a. The spectrum for which the incident energy was precisely tuned to the resonance maximum of the absorption spectrum is shown in Fig. 2b. In both plots, the excitations of the spin, orbital and charge degrees of freedom are indicated. The momentum dependence and, in particular, the dispersion of the spin and orbital excitations (Fig. 1c and Supplementary Fig. 2a) are indicative of their collective nature. \nFor energy transfers of up to ,0.8 eV purely magnetic excitations are present, but the spectrum between ,1.5 and ,3.5 eV corresponds to excitations from the copper ground state to orbitals of symmetry (Fig. 1d, e). These peaks correspond toorbital excitations (called also d–d excitations), and not, for example, to charge transfer excitations, the intensity of which is non-zero for energies up to ,6 eV but here for the case of L-edge RIXS is at least an order of magnitude lower10. The orbital assignment of these excitations was unambiguously verified by comparing their energy with ab initio quantum chemistry cluster calculations19 (Supplementary Information, section 5, for detailed results). \nZooming into the ‘magnetic’ part of Fig. 1c, between 0 and 0.8 eV in energy transfer, reveals strongly dispersing spin excitations. At the lower boundary the dispersion has period p, and at the continuum (upper boundary) it has period 2p (Fig. 3a). These RIXS data agree very well with recent inelastic neutron scattering studies on Sr2CuO3 (ref. 20). The simultaneous presence in the spectrum of a lower edge with period p and an upper one with period 2p indicates directly that in the spin chain the magnetic excitations with spin 1 break up and fractionalize into two-spinon (and higher-order) excitations that make up a continuum20, with each spinon having spin 1/2. These spectra confirm that RIXS for magnetic excitations probes the well-known \nspin dynamical structure factor as theoretically predicted11–13, in agreement with recent studies on TiOCl (ref. 21). The excellent statistics ofthe data further allow for a direct comparison of the RIXS line shapes with the exact two- and four-spinon dynamical structure factor of the spin-1/2 Heisenberg chain. In Fig. 3b, we show the fits for three selected momentum transfer values using the exact two- and four-spinon dynamical structure factor, S(q, v) (where q and v stand for the momentum and energy of the created excitation, respectively) in the representation of ref. 22. The obtained exchange coupling is in very good agreement with the value obtained from inelastic neutron scattering data20. \nHaving unambiguously identified the fractionalized spinon excitations in the low-energy sector, we now concentrate on the orbital excitations spectrum in Fig. 4. We find that these are strongly momentum dependent and have a novel, distinct dispersion. This proves that the orbital excitations observed here are of collective nature. The xz excitation has the largest dispersion, of ,0.2 eV, and has a spectrum containing two peculiar components: a lower branch dispersing with periodicity p and, above that, an incoherent spectrum with a double-oval shape. This spectrum is strikingly similar to seemingly unrelated angle-resolved photoemission spectra of 1D copper oxides, which evidence spin–charge separation (see, for example, fig. 3 of ref. 3). This is an indication that the observed orbital dispersion is related to an analogous separation of degrees of freedom. \nTo test this conjecture, we derived a microscopic model that describes the spin–orbital interactions in Sr2CuO3 (Methods). The low-energy Kugel’–Khomskii Hamiltonian for this was obtained8,23 from the charge transfer model of Sr2CuO3 in ref. 24. The crucial part of the Hamiltonian, responsible for the xz orbital propagation, \nwhere J and JO are respectively the spin and orbital exchange constants, both of which are fixed by the charge transfer model24; EO is the xz orbital on-site energy; c z js and cjs are operators that respectively annihilate and create particles in xz orbital with spin s; Sj is the spin of the particle in x2 2 y 2 orbital; 1 2 nj counts the number of particles in xz orbital; and ‘h.c.’ denotes Hermitian conjugate. The first term in the Hamiltonian describes the propagation of orbital excitations through the lattice. The second term represents the usual Heisenberg interaction between spins, which vanishes on bonds where an orbital excitation is present (Methods\nTo quantify the spectral weights within the orbiton–spinon continuum, we have calculated for the JO–J Hamiltonian the orbital excitation Green’s function by exactly diagonalizing the Hamiltonian on 28 lattice sites (as in the spin–charge separation studies3 , finite-size effects are negligible (they are estimated at ,0.01 eV)). From this, we calculate the RIXS spectrum following ref. 13, that is, by expressing the RIXS amplitude as a product of the single-ion local RIXS effective operator and the orbital excitation Green’s function (Methods). \nWe find excellent agreement between theory and experiment (Fig. 4): both the sine-like xz orbiton dispersion and the xz spinon– orbiton continuum (the ‘double-oval’ incoherent spectrum), which are the hallmarks of spin–orbital separation, are present in the theory. The calculations also show that, in contrast to the xz orbital, the xy orbital has a small dispersion and that the excitations of both the orbital and the yz orbital are dispersionless, as is observed experimentally. This is an independent merit of the model because no fitting of dispersions to experimental data is involved. \nThe large orbiton dispersion observed in this study is the key feature that distinguishes Sr2CuO3 from other systems with orbital excitations27–29, and relies on the 1D character of Sr2CuO3. In a system of higher dimensionality, orbitons interact with magnetic excitations, which tend to slow them down and thus reduce their dispersion. In one dimension, orbitons can avoid these renormalization effects by means of spin–orbital separation",
    "reference_list": "考点1. \"two-spinon continuum\"推荐翻译成\"双自旋子连续谱\"。\n考点2. \"Brillouin zone\"推荐翻译成\"布里渊区\"，不可译为“布里墟区”。\n考点3：“an orbiton liberated from the spinon”中liberated推荐译为“脱离”、“分离”或“摆脱”，不可译为“解放”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "187"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n世界上每四瓶番茄酱中，就有一瓶产自新疆，这既是新疆的贡献，也是新疆的自豪。\n\n新疆番茄为什么“红”？\n\n地理条件得天独厚 被誉为番茄的“黄金产地”\n\n从异域传入中国的番茄非常喜欢充足的日照和剧烈的温差，而这些，新疆统统满足。\n\n日照丰富是新疆黄金产区的一大特色，新疆全年日照时数可达2550~3300小时，在全国各省区中位居第一。天山雪水的灌溉，成为番茄品质的加分项，因为天山雪水富含多种矿物元素，为生长在这里的番茄赋予更多矿物质和微量元素。\n新疆优越的地理条件，成就了品质绝佳的番茄，味道与营养兼具，成为越来越多人的首选。也正因此，新疆成为全球三大番茄核心产区之一，而中国也是世界第一大番茄制品出口国。\n\n育种创新 让新疆成为番茄遗传资源富集区\n\n“全世界一共研究出13个番茄种的基因组，我们现在掌握11个。”新疆农业科学院副院长、研究员、加工番茄生物育种创新团队学科带头人余庆辉说。据介绍，该研究利用第三代单分子实时测序技术、全基因组光学图谱技术和高通量染色体构象捕获测序技术对11个番茄种进行基因测序组装，组装出11个染色体水平高质量基因组，打开了番茄属遗传资源领域研究的宝库，使新疆从种植大区一跃成为世界番茄遗传资源富集区。\n\n近年来，借助多元化的育种技术，育种专家对野生番茄持续进行改良，培育出了各具特色的栽培番茄品种，使番茄的抗病性、产量、固形物含量等特性显著放大，满足了产业发展需求。“有时产量提升了，却失去了风味，很难有兼顾各方需求的完美品种。”新疆农科院加工番茄生物育种创新团队副研究员李宁说，很多人反映现在的番茄没有过去好吃了，其实就是在品种选育的过程中，为了突出产量等特性，人为导致丢失了风味特性的一种结果。\n\n自2018年研究工作启动以来，这个团队收集了8个野生番茄种、1个番茄近源野生种和2个栽培番茄代表性品种，构建了番茄属泛基因组，解析了番茄属基因组特征，重构了番茄属系统发生关系，为下一步基因的分型研究提供了平台。\n\n“三高两少”优质好吃 百搭做法融出美妙滋味\n\n由于自然条件的优势，新疆番茄具有“三高两少”的品质优势，“三高”指红色素含量高、可溶性固形物含量高、单产高；“两少”是指病虫害少、霉菌少。这就大大减少裂果、霉烂果的发生，提高整体的番茄品质。番茄霉菌视野小于25%，最低可在12%以下，远远低于我国和国外一些国家的规定标准（加拿大50%、中国40%）。于是番茄酱“两高一大”的特点就凸显出来了，“两高”是指新鲜度指标和粘度指标在世界市场上最高，“一大”是指番茄酱的理想化指标，即颗粒度大可以分装制造出最优质的沙司。\n\n新疆生产建设兵团第二师21团职工在戈壁滩晒场晾晒番茄干。今年，该团晾晒番茄干100余吨，主要销往东南亚、非洲等地。\n\n新疆番茄酱粘度好、酸甜可口、富有鲜味，其独有的酸甜口感在番茄火锅、番茄牛腩、番茄鸡翅、番茄大虾等特色菜品中起到了至关重要的作用，深受消费者的喜爱。\n\n在新疆，各类地道美食自然也少不了番茄的装点。劲道的新疆拌面包裹上一层酸爽的番茄酱，瞬间惊艳味蕾；在红透了的新疆炒米粉里，有了番茄才辣而不燥。番茄就像一个若隐若现的“百变厨神”，放在哪里，哪里就熠熠生辉。",
    "ori_text": "世界上每四瓶番茄酱中，就有一瓶产自新疆，这既是新疆的贡献，也是新疆的自豪。\n\n新疆番茄为什么“红”？\n\n地理条件得天独厚 被誉为番茄的“黄金产地”\n\n从异域传入中国的番茄非常喜欢充足的日照和剧烈的温差，而这些，新疆统统满足。\n\n日照丰富是新疆黄金产区的一大特色，新疆全年日照时数可达2550~3300小时，在全国各省区中位居第一。天山雪水的灌溉，成为番茄品质的加分项，因为天山雪水富含多种矿物元素，为生长在这里的番茄赋予更多矿物质和微量元素。\n新疆优越的地理条件，成就了品质绝佳的番茄，味道与营养兼具，成为越来越多人的首选。也正因此，新疆成为全球三大番茄核心产区之一，而中国也是世界第一大番茄制品出口国。\n\n育种创新 让新疆成为番茄遗传资源富集区\n\n“全世界一共研究出13个番茄种的基因组，我们现在掌握11个。”新疆农业科学院副院长、研究员、加工番茄生物育种创新团队学科带头人余庆辉说。据介绍，该研究利用第三代单分子实时测序技术、全基因组光学图谱技术和高通量染色体构象捕获测序技术对11个番茄种进行基因测序组装，组装出11个染色体水平高质量基因组，打开了番茄属遗传资源领域研究的宝库，使新疆从种植大区一跃成为世界番茄遗传资源富集区。\n\n近年来，借助多元化的育种技术，育种专家对野生番茄持续进行改良，培育出了各具特色的栽培番茄品种，使番茄的抗病性、产量、固形物含量等特性显著放大，满足了产业发展需求。“有时产量提升了，却失去了风味，很难有兼顾各方需求的完美品种。”新疆农科院加工番茄生物育种创新团队副研究员李宁说，很多人反映现在的番茄没有过去好吃了，其实就是在品种选育的过程中，为了突出产量等特性，人为导致丢失了风味特性的一种结果。\n\n自2018年研究工作启动以来，这个团队收集了8个野生番茄种、1个番茄近源野生种和2个栽培番茄代表性品种，构建了番茄属泛基因组，解析了番茄属基因组特征，重构了番茄属系统发生关系，为下一步基因的分型研究提供了平台。\n\n“三高两少”优质好吃 百搭做法融出美妙滋味\n\n由于自然条件的优势，新疆番茄具有“三高两少”的品质优势，“三高”指红色素含量高、可溶性固形物含量高、单产高；“两少”是指病虫害少、霉菌少。这就大大减少裂果、霉烂果的发生，提高整体的番茄品质。番茄霉菌视野小于25%，最低可在12%以下，远远低于我国和国外一些国家的规定标准（加拿大50%、中国40%）。于是番茄酱“两高一大”的特点就凸显出来了，“两高”是指新鲜度指标和粘度指标在世界市场上最高，“一大”是指番茄酱的理想化指标，即颗粒度大可以分装制造出最优质的沙司。\n\n新疆生产建设兵团第二师21团职工在戈壁滩晒场晾晒番茄干。今年，该团晾晒番茄干100余吨，主要销往东南亚、非洲等地。\n\n新疆番茄酱粘度好、酸甜可口、富有鲜味，其独有的酸甜口感在番茄火锅、番茄牛腩、番茄鸡翅、番茄大虾等特色菜品中起到了至关重要的作用，深受消费者的喜爱。\n\n在新疆，各类地道美食自然也少不了番茄的装点。劲道的新疆拌面包裹上一层酸爽的番茄酱，瞬间惊艳味蕾；在红透了的新疆炒米粉里，有了番茄才辣而不燥。番茄就像一个若隐若现的“百变厨神”，放在哪里，哪里就熠熠生辉。",
    "reference_list": "考点1：“新疆番茄为什么“红””中，红不可直译为red，结合语境推荐译为hot。\n考点2：黄金产地应该译为“a prime growing area”，此处采用比喻手法。\n考点3：泛基因组应译为“pangenome”，是基因组学术语。\n考点4：新疆生产建设兵团第二师21团职工应译为“employees from the 21st Regiment of the 2nd Division of the Xinjiang Production and Construction Corps (XPCC)“。\n考点5：百变厨神推荐译为“a versatile culinary master”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "29"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 调查过程中常出现数据缺失，在这种情形下不能直接将含缺失值的个体信息全部删除而只利用数据完全的样本数据，因为数据缺失与否往往与该数据的具体值系统地相关，比如关心的因变量是受访者的年收入，高收入群体可能不愿意将自己的收入告知他人，这种情况造成的数据缺失就不能采用直接删除法，否则会造成估计结果偏低。为此收集尽量多的协变量数据就很有意义。可以采用插补法（包括回归插补法、近邻插补法）或似然法（通过建立因变量、协变量和缺失指示变量的分布模型）[1]。在这些方法中，以往研究都假设协变量数据没有缺失，回归插补法通过有回答的样本数据建立模型，代入因变量数据缺失样本的协变量数据以估计因变量值。近邻插补法通过定义距离函数，考虑用与因变量缺失个体的协变量最相似有数据的个体因变量值插补。似然法则引入数据缺失机制，通过建模得到因变量与缺失指示变量的联合分布，进而得到参数的极大似然估计。实际调查中，协变量缺失的情况也是非常常见的，例如出于隐私考虑不愿公布年龄或婚姻状况，由于知识水平所限无法回答某些超出其知识范围的问题，也可能某些协变量收集难度大成本高，调查人员选择只收集一部分受访者的信息。协变量缺失时因变量可能没有缺失，也可能协变量和因变量同时缺失，这就大大增加了协变量关于因变量回归系数估计的难度。但目前国内外关于协变量缺失情形下尤其是缺失机制是非随机缺失时参数的估计方法研究还不多，Little（1992）[2]研究了回归分析中缺失协变量的处理方法，但其研究局限于因变量与协变量之间满足线性回归关系，且假设因变量Y与协变量向量X的联合分布。为多元正态分布，Horton和Laird（1999）[3]研究了缺失机制为MAR的属性协变量缺失问题，通过建立广义线性模型，用极大似然法进行参数估计，Michiels等（1999）[4]用选择模型和模式混合模型建立似然函数，用极大似然法估计属性协变量数据缺失时的总体参数。在软件功能日益强大的今天，数据扩充算法、EM算法、Gibbs抽样法等迭代算法应用日益广泛。SAS Proc MI可以采用多重插补法进行协变量数据缺失情形下的参数估计。R有多个软件包可以进行缺失数据统计分析，ACD包可以在因变量数据缺失时进行属性数据分析，mvnmle 包在因变量和协变量联合分布为多元正态分布时，进行协变量数据缺失情形下的参数极大似然估计，MICE包是R中目前最常用的用于缺失数据分析的软件包，可以进行多变量缺失数据的多重插补，在多个协变量都可能存在缺失值时，使用MICE包中的mice函数，通过变量之间的关系预测缺失数据，利用蒙特卡洛方法生成多个完整数据集存在imp中，再对imp进行线性回归，最后用pool函数对回归结果进行汇总。本文尝试引入以上统计计算方法，采用多重插补法、Bayes法和极大似然法，在缺失机制为MAR或NMAR情形下，估计调查数据中协变量数据缺失情形下，协变量关于因变量影响大小的回归系数。\n2.1 完全数据法\n该方法将所有含缺失值的受访者删除，仅保留完全数据样本进行统计分析，这种方法仅当缺失机制为MCAR时可以得到参数无偏估计，缺失机制为MAR或NMAR时得到的估计量有偏，若协变量数目较多，即使某受访者只有一个协变量数据缺失，仍需要将其所有数据删去，这样可能导致可用的数据量不足，造成大量的信息浪费。虽然这种方法经常采用，但并不值得推荐。本文尝试采用EM算法、Gibbs抽样法和数据扩充算法等统计计算方法，采用多重插补法、Bayes 法和极大似然法，在缺失机制为MAR或NMAR情形下，估计调查数据中协变量数据缺失情形下，反映协变量X对因变量y 影响大小的回归系数。研究可以进一步推广到协变量和因变量同时缺失的情形下定义缺失机制、建立似然模型并采用统计算法进行回归系数估计。还可以推广到对多个体多时点纵向调查，在协变量缺失的情形下，引入统计算法，进行回归系数估计。",
    "ori_text": "\n\n 调查过程中常出现数据缺失，在这种情形下不能直接将含缺失值的个体信息全部删除而只利用数据完全的样本数据，因为数据缺失与否往往与该数据的具体值系统地相关，比如关心的因变量是受访者的年收入，高收入群体可能不愿意将自己的收入告知他人，这种情况造成的数据缺失就不能采用直接删除法，否则会造成估计结果偏低。为此收集尽量多的协变量数据就很有意义。可以采用插补法（包括回归插补法、近邻插补法）或似然法（通过建立因变量、协变量和缺失指示变量的分布模型）[1]。在这些方法中，以往研究都假设协变量数据没有缺失，回归插补法通过有回答的样本数据建立模型，代入因变量数据缺失样本的协变量数据以估计因变量值。近邻插补法通过定义距离函数，考虑用与因变量缺失个体的协变量最相似有数据的个体因变量值插补。似然法则引入数据缺失机制，通过建模得到因变量与缺失指示变量的联合分布，进而得到参数的极大似然估计。实际调查中，协变量缺失的情况也是非常常见的，例如出于隐私考虑不愿公布年龄或婚姻状况，由于知识水平所限无法回答某些超出其知识范围的问题，也可能某些协变量收集难度大成本高，调查人员选择只收集一部分受访者的信息。协变量缺失时因变量可能没有缺失，也可能协变量和因变量同时缺失，这就大大增加了协变量关于因变量回归系数估计的难度。但目前国内外关于协变量缺失情形下尤其是缺失机制是非随机缺失时参数的估计方法研究还不多，Little（1992）[2]研究了回归分析中缺失协变量的处理方法，但其研究局限于因变量与协变量之间满足线性回归关系，且假设因变量Y与协变量向量X的联合分布。为多元正态分布，Horton和Laird（1999）[3]研究了缺失机制为MAR的属性协变量缺失问题，通过建立广义线性模型，用极大似然法进行参数估计，Michiels等（1999）[4]用选择模型和模式混合模型建立似然函数，用极大似然法估计属性协变量数据缺失时的总体参数。在软件功能日益强大的今天，数据扩充算法、EM算法、Gibbs抽样法等迭代算法应用日益广泛。SAS Proc MI可以采用多重插补法进行协变量数据缺失情形下的参数估计。R有多个软件包可以进行缺失数据统计分析，ACD包可以在因变量数据缺失时进行属性数据分析，mvnmle 包在因变量和协变量联合分布为多元正态分布时，进行协变量数据缺失情形下的参数极大似然估计，MICE包是R中目前最常用的用于缺失数据分析的软件包，可以进行多变量缺失数据的多重插补，在多个协变量都可能存在缺失值时，使用MICE包中的mice函数，通过变量之间的关系预测缺失数据，利用蒙特卡洛方法生成多个完整数据集存在imp中，再对imp进行线性回归，最后用pool函数对回归结果进行汇总。本文尝试引入以上统计计算方法，采用多重插补法、Bayes法和极大似然法，在缺失机制为MAR或NMAR情形下，估计调查数据中协变量数据缺失情形下，协变量关于因变量影响大小的回归系数。\n2.1 完全数据法\n该方法将所有含缺失值的受访者删除，仅保留完全数据样本进行统计分析，这种方法仅当缺失机制为MCAR时可以得到参数无偏估计，缺失机制为MAR或NMAR时得到的估计量有偏，若协变量数目较多，即使某受访者只有一个协变量数据缺失，仍需要将其所有数据删去，这样可能导致可用的数据量不足，造成大量的信息浪费。虽然这种方法经常采用，但并不值得推荐。本文尝试采用EM算法、Gibbs抽样法和数据扩充算法等统计计算方法，采用多重插补法、Bayes 法和极大似然法，在缺失机制为MAR或NMAR情形下，估计调查数据中协变量数据缺失情形下，反映协变量X对因变量y 影响大小的回归系数。研究可以进一步推广到协变量和因变量同时缺失的情形下定义缺失机制、建立似然模型并采用统计算法进行回归系数估计。还可以推广到对多个体多时点纵向调查，在协变量缺失的情形下，引入统计算法，进行回归系数估计。",
    "reference_list": "考点1：\"直接删除法\"必须译为\" Complete case analysis\"\n考点2：“大量的信息浪费”不可直译为“a lot of information waste”，推荐译为“a significant loss of information”\n考点3：“估计结果偏低”中的“偏低”不可直译为“be low”，可以译为“be biased downward”或“be artificially low”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "189"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nIn contemporary artificial intelligence research, the problem of layout (Layout) generation—the automated arrangement of visually distinct objects or functional elements within a designed frame—remains of paramount practical and theoretical significance. Layouts underpin a broad spectrum of applications ranging from magazine publishing and poster production to the design of complex user interfaces in mobile and web environments. A well-constructed layout not only directs user attention and guides reading order, but also encodes semantic relationships among visual or textual components, incorporates constraints dictated by content attributes, and adheres to general and domain-specific aesthetic principles.\nDespite rapid progress in machine learning, the manual construction of graphic layouts remains an arduous and resource-intensive process. Designers are required to orchestrate element positioning, sizing, and alignment in accordance with both objective communicative needs and subjective artistic judgments, a task that can become intractable as the complexity and variability of both content and user-specified constraints increase. This motivates the development of intelligent systems for automatic layout generation (Automatic Layout Generation), allowing efficient synthesis of designs that satisfy prescribed structural and semantic requirements.\nEarly computational methods for layout synthesis often relied on the formalization of expert rules as handcrafted energy functions or procedural grammars, encoding a priori notions of spatial harmony and alignment into optimization objectives. However, such rule-based or heuristic-driven systems lack scalability and generality, particularly when confronted with data distributions that exhibit significant heterogeneity or intricate relationships between design eleents (Design Elements). They are also limited by their dependence on manual encoding of preferences—a process difficult to generalize across diverse domains such as editorial layout, digital ads, and mobile UI screens.\nRecent advances in deep generative models have revolutionized automatic layout generation by allowing systems to learn directly from large-scale, annotated datasets . Two especially influential approaches in this context are Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) . GANs are formulated as two-player zero-sum games between a generator that synthesizes candidate samples and a discriminator that assesses the realism of those samples relative to observed data. Such adversarial training fosters the creation of highly plausible, often photorealistic outputs. In contrast, VAEs employ probabilistic encodings and Bayesian inference to model latent variable distributions over input data, enabling diversity and smooth interpolation between generated layouts.\nEach method, however, exhibits distinct limitations in the context of layout synthesis . GANs are infamous for issues such as training instability , mode collapse , and incomplete distribution coverage ; these can impede their ability to accurately recover the rich diversity of real-world layouts, especially in visually cluttered or structurally complex domains. VAEs , while often easier to train and able to capture a broader range of plausible alternatives, can suffer from trade-offs between sharpness and diversity , with generated layouts sometimes lacking the visual fidelity required for professional design.\nMore recently, research attention has shifted to a new class of generative models—the Diffusion Models (Diffusion Models)—notably represented by the Denoising Diffusion Probabilistic Model (DDPM) and related architectures. Diffusion models pose data generation as a progressive stochastic process, starting from pure Gaussian noise and iteratively denoising to synthesize high-quality structured outputs. The forward process gradually injects noise into training data according to a predefined noise schedule, while the reverse process (reverse process) employs a neural network (typically a U-Net ) to remove noise in discrete steps, reconstructing data samples that closely approximate the target distribution.\nKey advantages of diffusion models include the ability to achieve a stationary training objective (stationary training objective)—circumventing adversarial oscillation—as well as the capacity to faithfully cover the underlying data distribution . Moreover, these models afford strong sample diversity and permit straightforward conditioning on auxiliary information, making them theoretically attractive for the complex, multi-constraint setting of graphical layout generation .\nHowever, several key challenges must be addressed to adapt diffusion models to the specific structure of layout data . First, unlike grid-structured images or time-sequenced signals, a graphic layout typically comprises a variable-length, unordered set of elements, each described by both discrete (e.g., class label) and continuous (e.g., size, coordinates) attributes. Conventional convolutional neural networks (CNNs) , which excel at learning regular pixel grids but presume spatial locality, are generally ill-suited for processing such sets, especially when explicit modeling of relationships and attribute constraints is required. Second, the semantics of a layout are not solely a function of its individual components but are emergent from the interdependencies among elements, meaning that conditional generation demands sophisticated mechanisms for relational reasoning .\nAddressing these obstacles, contemporary research has advocated for the use of Transformer-based architectures (Transformer-based architectures) as the neural backbone in layout diffusion models. The self-attention mechanism intrinsic to Transformer layers is adept at modeling dependencies in unordered and variable-sized input sets, enabling efficient aggregation of global context and complex attribute interactions. Specifically, in the context of layout diffusion , a Transformer-based denoiser can predict noise vectors for each element token based on global information , facilitating accurate and flexible reverse diffusion even when layout cardinality varies significantly across samples.\nIn the conditional generation setting, such architectures further allow for the inclusion of rich attribute embeddings —capturing category labels, style codes, and textual descriptors—so that the generated layouts respect user-controlled constraints and design intents. Crucially, because the arrangement of layout elements is unordered by nature, these models typically omit positional encoding (positional encoding), diverging from mainstream practices in natural language processing or image modeling where sequence order is semantically essential.\nTo formally describe the layout modeling process, suppose that a layout instance L is a set of N elements, with each element ei represented as a tuple of continuous geometry gi  (position, width, height) and discrete or textual attributes fi (e.g., “heading”, “button”, or “price”). For consistency and stability, geometric parameters are normalized onto a fixed unit hypercube. The generative apparatus—namely, a conditional denoising diffusion probabilistic model (conditional DDPM)—defines a forward process, which stepwise corrupts g by adding Gaussian noise, and a reverse process, which sequentially denoises g back to its original configuration, all conditioned on f.\nThe conditional layout denoiser (cLayoutDenoiser) is realized as a sequence of stacked Transformer blocks . For each sample and each reverse diffusion time step t, the model receives as input (i) geometry embeddings , i.e., learned projections of noisy geometric attributes, (ii) attribute embeddings corresponding to each element, and (iii) timestep embeddings encoding the temporal context in the denoising schedule. These are concatenated along the element and feature dimensions, passed through multiple layers of multi-head self-attention, and ultimately mapped via a fully-connected output head to a noise residue prediction vector.\nThe training objective minimizes a simplified mean-squared error between the model’s predicted noise and the true noise injected in the forward process, is defined recursively by the noise schedule and ϵ∼N(0,I).\nSubstantial empirical evaluation demonstrates that Transformer-based diffusion layout models —henceforth referred to as LayoutDM —exhibit superior performance over GAN/VAE baselines on multiple public layout datasets. These include RICO (mobile UI screens), PubLayNet (scientific document layouts), Magazine (magazine spread layouts), COCO (natural scene composition layouts), and TextLogo3K (text logo bounding-box datasets). Experiments are evaluated using rigorous metrics :\nFiducial Inception Distance (FID) : measuring the statistical distance between real and generated layouts via learned feature representations;\nMax Intersection Over Union (Max IoU) : quantifying geometric similarity;\nOverlap (total overlapping area of bounding boxes); and\nAlignment loss (average visual misalignment of elements).\nIn implementation, LayoutDM typically employs eight Transformer layers (multi-head, usually eight heads per layer), learns all embedding and denoising parameters via Adam optimization at a small learning rate, and adopts batch sizes as large as hardware allows (1,024 or more). All training and inference are performed in PyTorch or PyTorch Lightning and utilize modern GPU accelerators (e.g., NVIDIA Quadro RTX 6000).\nKey ablation studies compare performance under different component configurations: e.g., the effect of omitting attribute embeddings, varying the number of Transformer layers/heads, ablation of timestep encoding, or substituting the backbone with a convolutional denoiser. Results confirm that all such features—especially self-attention across attribute-rich, unordered element sets, and conditioning on semantic attributes—are crucial for state-of-the-art layout generation.Moreover, the successes of diffusion-based layout models open broader research avenues: learning multi-modal mappings between textual descriptions and layout structures, joint co-design of content and visual style, and robust adaptation to new application domains such as game level design , responsive website layouts , or augmented reality scene annotation. This paper proposes a transformer-based diffusion model LayoutDM to address conditional layout generation. We introduce a purely transformer-based Layout Denoiser to model the diffusion reverse process. Benefitting from both DDPM and transformer, in comparison to existing methods, LayoutDM can generate high-quality generation with desired properties such as better diversity, faithful distribution coverage, and stationary training. Quantitative and qualitative results demonstrate that our model outperforms the state-of-the-art methods in terms of visual perceptual quality and diversity.Although our method shows impressive results in the conditional layout generation problem in comparison to existing methods, it still has limitations. For example, like other layout generation methods, our approach treats design elements as being on a single-layer canvas. This can not model a layout with multiple layers occluding each other. Our method also has no advantage over other generative models in generation speed because the generation of the diffusion model requires an iterative denoising process. We leave the solution to the above problems for future work.\n\n",
    "ori_text": "\n\nIn contemporary artificial intelligence research, the problem of layout (Layout) generation—the automated arrangement of visually distinct objects or functional elements within a designed frame—remains of paramount practical and theoretical significance. Layouts underpin a broad spectrum of applications ranging from magazine publishing and poster production to the design of complex user interfaces in mobile and web environments. A well-constructed layout not only directs user attention and guides reading order, but also encodes semantic relationships among visual or textual components, incorporates constraints dictated by content attributes, and adheres to general and domain-specific aesthetic principles.\nDespite rapid progress in machine learning, the manual construction of graphic layouts remains an arduous and resource-intensive process. Designers are required to orchestrate element positioning, sizing, and alignment in accordance with both objective communicative needs and subjective artistic judgments, a task that can become intractable as the complexity and variability of both content and user-specified constraints increase. This motivates the development of intelligent systems for automatic layout generation (Automatic Layout Generation), allowing efficient synthesis of designs that satisfy prescribed structural and semantic requirements.\nEarly computational methods for layout synthesis often relied on the formalization of expert rules as handcrafted energy functions or procedural grammars, encoding a priori notions of spatial harmony and alignment into optimization objectives. However, such rule-based or heuristic-driven systems lack scalability and generality, particularly when confronted with data distributions that exhibit significant heterogeneity or intricate relationships between design eleents (Design Elements). They are also limited by their dependence on manual encoding of preferences—a process difficult to generalize across diverse domains such as editorial layout, digital ads, and mobile UI screens.\nRecent advances in deep generative models have revolutionized automatic layout generation by allowing systems to learn directly from large-scale, annotated datasets . Two especially influential approaches in this context are Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) . GANs are formulated as two-player zero-sum games between a generator that synthesizes candidate samples and a discriminator that assesses the realism of those samples relative to observed data. Such adversarial training fosters the creation of highly plausible, often photorealistic outputs. In contrast, VAEs employ probabilistic encodings and Bayesian inference to model latent variable distributions over input data, enabling diversity and smooth interpolation between generated layouts.\nEach method, however, exhibits distinct limitations in the context of layout synthesis . GANs are infamous for issues such as training instability , mode collapse , and incomplete distribution coverage ; these can impede their ability to accurately recover the rich diversity of real-world layouts, especially in visually cluttered or structurally complex domains. VAEs , while often easier to train and able to capture a broader range of plausible alternatives, can suffer from trade-offs between sharpness and diversity , with generated layouts sometimes lacking the visual fidelity required for professional design.\nMore recently, research attention has shifted to a new class of generative models—the Diffusion Models (Diffusion Models)—notably represented by the Denoising Diffusion Probabilistic Model (DDPM) and related architectures. Diffusion models pose data generation as a progressive stochastic process, starting from pure Gaussian noise and iteratively denoising to synthesize high-quality structured outputs. The forward process gradually injects noise into training data according to a predefined noise schedule, while the reverse process (reverse process) employs a neural network (typically a U-Net ) to remove noise in discrete steps, reconstructing data samples that closely approximate the target distribution.\nKey advantages of diffusion models include the ability to achieve a stationary training objective (stationary training objective)—circumventing adversarial oscillation—as well as the capacity to faithfully cover the underlying data distribution . Moreover, these models afford strong sample diversity and permit straightforward conditioning on auxiliary information, making them theoretically attractive for the complex, multi-constraint setting of graphical layout generation .\nHowever, several key challenges must be addressed to adapt diffusion models to the specific structure of layout data . First, unlike grid-structured images or time-sequenced signals, a graphic layout typically comprises a variable-length, unordered set of elements, each described by both discrete (e.g., class label) and continuous (e.g., size, coordinates) attributes. Conventional convolutional neural networks (CNNs) , which excel at learning regular pixel grids but presume spatial locality, are generally ill-suited for processing such sets, especially when explicit modeling of relationships and attribute constraints is required. Second, the semantics of a layout are not solely a function of its individual components but are emergent from the interdependencies among elements, meaning that conditional generation demands sophisticated mechanisms for relational reasoning .\nAddressing these obstacles, contemporary research has advocated for the use of Transformer-based architectures (Transformer-based architectures) as the neural backbone in layout diffusion models. The self-attention mechanism intrinsic to Transformer layers is adept at modeling dependencies in unordered and variable-sized input sets, enabling efficient aggregation of global context and complex attribute interactions. Specifically, in the context of layout diffusion , a Transformer-based denoiser can predict noise vectors for each element token based on global information , facilitating accurate and flexible reverse diffusion even when layout cardinality varies significantly across samples.\nIn the conditional generation setting, such architectures further allow for the inclusion of rich attribute embeddings —capturing category labels, style codes, and textual descriptors—so that the generated layouts respect user-controlled constraints and design intents. Crucially, because the arrangement of layout elements is unordered by nature, these models typically omit positional encoding (positional encoding), diverging from mainstream practices in natural language processing or image modeling where sequence order is semantically essential.\nTo formally describe the layout modeling process, suppose that a layout instance L is a set of N elements, with each element ei represented as a tuple of continuous geometry gi  (position, width, height) and discrete or textual attributes fi (e.g., “heading”, “button”, or “price”). For consistency and stability, geometric parameters are normalized onto a fixed unit hypercube. The generative apparatus—namely, a conditional denoising diffusion probabilistic model (conditional DDPM)—defines a forward process, which stepwise corrupts g by adding Gaussian noise, and a reverse process, which sequentially denoises g back to its original configuration, all conditioned on f.\nThe conditional layout denoiser (cLayoutDenoiser) is realized as a sequence of stacked Transformer blocks . For each sample and each reverse diffusion time step t, the model receives as input (i) geometry embeddings , i.e., learned projections of noisy geometric attributes, (ii) attribute embeddings corresponding to each element, and (iii) timestep embeddings encoding the temporal context in the denoising schedule. These are concatenated along the element and feature dimensions, passed through multiple layers of multi-head self-attention, and ultimately mapped via a fully-connected output head to a noise residue prediction vector.\nThe training objective minimizes a simplified mean-squared error between the model’s predicted noise and the true noise injected in the forward process, is defined recursively by the noise schedule and ϵ∼N(0,I).\nSubstantial empirical evaluation demonstrates that Transformer-based diffusion layout models —henceforth referred to as LayoutDM —exhibit superior performance over GAN/VAE baselines on multiple public layout datasets. These include RICO (mobile UI screens), PubLayNet (scientific document layouts), Magazine (magazine spread layouts), COCO (natural scene composition layouts), and TextLogo3K (text logo bounding-box datasets). Experiments are evaluated using rigorous metrics :\nFiducial Inception Distance (FID) : measuring the statistical distance between real and generated layouts via learned feature representations;\nMax Intersection Over Union (Max IoU) : quantifying geometric similarity;\nOverlap (total overlapping area of bounding boxes); and\nAlignment loss (average visual misalignment of elements).\nIn implementation, LayoutDM typically employs eight Transformer layers (multi-head, usually eight heads per layer), learns all embedding and denoising parameters via Adam optimization at a small learning rate, and adopts batch sizes as large as hardware allows (1,024 or more). All training and inference are performed in PyTorch or PyTorch Lightning and utilize modern GPU accelerators (e.g., NVIDIA Quadro RTX 6000).\nKey ablation studies compare performance under different component configurations: e.g., the effect of omitting attribute embeddings, varying the number of Transformer layers/heads, ablation of timestep encoding, or substituting the backbone with a convolutional denoiser. Results confirm that all such features—especially self-attention across attribute-rich, unordered element sets, and conditioning on semantic attributes—are crucial for state-of-the-art layout generation.Moreover, the successes of diffusion-based layout models open broader research avenues: learning multi-modal mappings between textual descriptions and layout structures, joint co-design of content and visual style, and robust adaptation to new application domains such as game level design , responsive website layouts , or augmented reality scene annotation. This paper proposes a transformer-based diffusion model LayoutDM to address conditional layout generation. We introduce a purely transformer-based Layout Denoiser to model the diffusion reverse process. Benefitting from both DDPM and transformer, in comparison to existing methods, LayoutDM can generate high-quality generation with desired properties such as better diversity, faithful distribution coverage, and stationary training. Quantitative and qualitative results demonstrate that our model outperforms the state-of-the-art methods in terms of visual perceptual quality and diversity.Although our method shows impressive results in the conditional layout generation problem in comparison to existing methods, it still has limitations. For example, like other layout generation methods, our approach treats design elements as being on a single-layer canvas. This can not model a layout with multiple layers occluding each other. Our method also has no advantage over other generative models in generation speed because the generation of the diffusion model requires an iterative denoising process. We leave the solution to the above problems for future work.\n\n",
    "reference_list": "考点1: 描述“归一化到固定单位超立方体”时，必须用“normalized onto a fixed unit hypercube”表达，不能生造新词。\n考点2：“Fréchet Inception Distance”是一个专有名词缩写，学术论文中通常直接保留英文缩写，中文全称可以写作 Fréchet Inception 距离",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "179"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。 以下是你本次的任务：\n中华人民共和国福建省厦门市中级人民法院民事判决书\n（1997）厦民三初字第20号\n原告：厦门赣东实业有限公司\n住所：厦门市三湾路25号\n法定代表人：陈志坚，总经理\n\n原告：新加坡KALIO机械公司\n住所：新加坡科技大道837号\n法定代表人：金志河，该公司总裁\n委托代理人：刘克添，福建省方正律师事务所律师\n\n被告：三亚市安易实业有限公司\n住所：海南省三亚市赤屿路23号\n法定代表人：叶轩河，该公司总经理\n委托代理人：许可东，福建远东律师事务所律师\n\n原告厦门赣东实业有限公司（以下简称赣东公司）、新加坡KALIO机械公司（以下简称KALIO公司）与三亚市安易实业有限公司（以下简称安易公司）合同纠纷一案，本院受理后，依法组成合议庭，公开开庭进行了审理。原告赣东公司法定代表人陈志坚，KALIO公司委托代理人刘克添，被告安易公司委托代理人许可东到庭参加诉讼。本案现已审理终结。\n原告厦门赣东公司、新加坡KALIO公司诉称：\n1998年5月6日，赣东公司、KALIO公司共同作为乙方与作为甲方的安易公司签订了纺织机买卖合同。合同约定：甲方向乙方订购730部新加坡产开泰牌Z61型编织机；交货时间从1998年5月8日起至1999年1月8日止；价格按FOB（新加坡）每台20000元人民币；交货地点为厦门港；付款方式为机器运抵厦门港后付清全部货款；运输方法及费用负担：海运费用由甲方负担；违约责任，如单方违约，违约方必须向对方赔偿标准为未执行部分合同总额的10%的违约金。合同签订后，原告方按约定给被告发运了价值为900000元的全自动编织机及部分配件。安易公司陆续给付了原告机款500000元，现尚欠原告方机款400000元未付。另外，为履行合同，赣东公司为安易公司发运编织机已垫付运费5000元。\n\n二原告提出如下诉讼请求：\n1.请求法院判决被告向原告给付400000元及违约金90000元，运费5000元；\n2.请求法院判决被告二向原告赔偿其经济损失共计100000元；\n3.请求法院判决诉讼费用由被告承担。\n\n二原告向法院提交了以下证据材料：\n1.证据一为原被告签订的纺织机买卖合同。该合同由甲方安易公司加盖单位公章，法定代表人叶轩河签名，乙方赣东公司代理人陈志坚签名，KALIO公司加盖单位公章、代表人金志河签名。由此证明二原告与被告所签订的纺织机合同为有效合同，二原告与被告都应当按照合同约定履行各自义务。因此，被告方应给付拖欠的货款并承担相应的违约责任。\n2.证据二为厦门海关进口关税专用缴款书及厦门边境贸易公司代理进口证明。证明二可证明：1998年5月10日，厦门边境贸易公司作为赣东公司的代理人，从新加坡进口了57台纺织机，赣东公司于1998年8月12日向厦门边境贸易公司交纳了7700元的纺织机的代理费、办证费、商检费、口岸费等。\n3.证据三为在合同履行期间，安易公司的法定代表人叶轩河与赣东公司的委托代理人陈志坚的多次往来信件。由此证明：原告已按照上述购销合同实际履行，不存在任何违约的情形。\n4.被告对于原告提交的三项证据都没有异议。\n\n本法院认为：二原告与被告所签订的纺织机购销合同为有效合同，合同各方都应当按照合同约定履行各自义务。现被告方未履行付款义务，则被告方应给付拖欠的货款并承担违约责任。二原告要求被告给付400000元及违约金90000元，运费5000元的主张，本院予以支持；二原告要求被告赔偿100000元人民币损失的主张无事实依据，本院驳回请求。\n依照《中华人民共和国经济合同法》第六条、第29条第1款、第31条、第32条、《中华人民共和国民法通则》第一百零六条、第61条第1款之规定，判决：\n1.安易公司于本判决生效之日起十日内偿付赣东公司、KALIO公司纺织机及配件款400000元，运费5000元，并支付违约金90000元，合计495000元；\n2.案件受理费20000元，由被告负担。\n如不服本判决，可在判决书收到之日起十五日内向本院递交上诉状，并按对方当事人的人数提出副本，上诉于福建省高级人民法院。\n审判长：刘国选\n审判员：张俊中\n审判员：马俊楠\n日期：1999年3月3日\n书记员：江南\n（厦门市中级人民法院盖章）",
    "ori_text": "中华人民共和国福建省厦门市中级人民法院民事判决书（1997）厦民三初字第20号原告：厦门赣东实业有限公司住所：厦门市三湾路25号法定代表人：陈志坚，总经理\n原告：新加坡KALIO机械公司住所：新加坡科技大道837号法定代表人：金志河，该公司总裁委托代理人：刘克添，福建省方正律师事务所律师\n被告：三亚市安易实业有限公司住所：海南省三亚市赤屿路23号法定代表人：叶轩河，该公司总经理委托代理人：许可东，福建远东律师事务所律师\n原告厦门赣东实业有限公司（以下简称赣东公司）、新加坡KALIO机械公司（以下简称KALIO公司）与三亚市安易实业有限公司（以下简称安易公司）合同纠纷一案，本院受理后，依法组成合议庭，公开开庭进行了审理。原告赣东公司法定代表人陈志坚，KALIO公司委托代理人刘克添，被告安易公司委托代理人许可东到庭参加诉讼。本案现已审理终结。原告厦门赣东公司、新加坡KALIO公司诉称：1998年5月6日，赣东公司、KALIO公司共同作为乙方与作为甲方的安易公司签订了纺织机买卖合同。合同约定：甲方向乙方订购730部新加坡产开泰牌Z61型编织机；交货时间从1998年5月8日起至1999年1月8日止；价格按FOB（新加坡）每台20000元人民币；交货地点为厦门港；付款方式为机器运抵厦门港后付清全部货款；运输方法及费用负担：海运费用由甲方负担；违约责任，如单方违约，违约方必须向对方赔偿标准为未执行部分合同总额的10%的违约金。合同签订后，原告方按约定给被告发运了价值为900000元的全自动编织机及部分配件。安易公司陆续给付了原告机款500000元，现尚欠原告方机款400000元未付。另外，为履行合同，赣东公司为安易公司发运编织机已垫付运费5000元。\n二原告提出如下诉讼请求：1.请求法院判决被告向原告给付400000元及违约金90000元，运费5000元；2.请求法院判决被告二向原告赔偿其经济损失共计100000元；3.请求法院判决诉讼费用由被告承担。\n二原告向法院提交了以下证据材料：1.证据一为原被告签订的纺织机买卖合同。该合同由甲方安易公司加盖单位公章，法定代表人叶轩河签名，乙方赣东公司代理人陈志坚签名，KALIO公司加盖单位公章、代表人金志河签名。由此证明二原告与被告所签订的纺织机合同为有效合同，二原告与被告都应当按照合同约定履行各自义务。因此，被告方应给付拖欠的货款并承担相应的违约责任。2.证据二为厦门海关进口关税专用缴款书及厦门边境贸易公司代理进口证明。证明二可证明：1998年5月10日，厦门边境贸易公司作为赣东公司的代理人，从新加坡进口了57台纺织机，赣东公司于1998年8月12日向厦门边境贸易公司交纳了7700元的纺织机的代理费、办证费、商检费、口岸费等。3.证据三为在合同履行期间，安易公司的法定代表人叶轩河与赣东公司的委托代理人陈志坚的多次往来信件。由此证明：原告已按照上述购销合同实际履行，不存在任何违约的情形。4.被告对于原告提交的三项证据都没有异议。\n本法院认为：二原告与被告所签订的纺织机购销合同为有效合同，合同各方都应当按照合同约定履行各自义务。现被告方未履行付款义务，则被告方应给付拖欠的货款并承担违约责任。二原告要求被告给付400000元及违约金90000元，运费5000元的主张，本院予以支持；二原告要求被告赔偿100000元人民币损失的主张无事实依据，本院驳回请求。依照《中华人民共和国经济合同法》第六条、第29条第1款、第31条、第32条、《中华人民共和国民法通则》第一百零六条、第61条第1款之规定，判决：1.安易公司于本判决生效之日起十日内偿付赣东公司、KALIO公司纺织机及配件款400000元，运费5000元，并支付违约金90000元，合计495000元；2.案件受理费20000元，由被告负担。如不服本判决，可在判决书收到之日起十五日内向本院递交上诉状，并按对方当事人的人数提出副本，上诉于福建省高级人民法院。审判长：刘国选审判员：张俊中审判员：马俊楠日期：1999年3月3日书记员：江南（厦门市中级人民法院盖章）",
    "reference_list": "考点1：“民事判决书”推荐译为“Civil Judgment”\n考点2：“住所”推荐译为“domicile”\n考点3：“委托代理人”推荐译为“authorized counsel”\n考点4：“合议庭”推荐译为“collegial panel”\n考点5：“公开开庭”推荐译为“opened a court session publicly”\n考点6：“本案现已审理终结”推荐译为“the trial has now concluded”\n考点7：“海运费用”推荐译为“‌ocean freight fee”\n考点8：“违约金”推荐译为“liquidated damages”\n考点9：“提出如下诉讼请求”推荐译为“put forward the following claims”\n考点10：“诉讼费用”推荐译为“the court cost”\n考点11：“进口关税缴款书”推荐译为“Payment Certificate for Import Duties”\n考点12：“交纳口岸费”推荐译为“pay for port management”\n考点13：“依照……的规定，判决：”推荐译为“in accordance with the stipulation of……,it orders as follows”\n考点14：“第61条第1款”推荐译为“Article 61 Paragraph 1”\n考点15：“驳回请求”推荐译为“dismiss the claims”\n考点16：“向本院递交上诉状，上诉于福建省高级人民法院”推荐译为“bring the appeal to Fujian High People's Court via this court”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "99"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n三、基于“流量池”的叠加推荐 　　\n\n与算法的研究日益成为热点类似，流量池也是近段时间以来频繁出现的热门词汇。此前，在新媒体研究领域里，流量思维是较为集中的研究热点，甚至有学者指出，“得流量者得天下”。流量池思维则是要获取流量并通过存储、运营和发掘等手段，进行信息的再传播，以期获得更多的流量。流量思维和流量池思维最大的区别就是流量获取之后的下一步社会行为，后者更强调如何用一批老用户找到更多新的用户，而流量思维更多的是首轮传播的效果评价。通常来讲，在内容流量池表现较好的视频内容往往会进入叠加推荐的行列，从而获得更多的阅读量和点赞。叠加推荐是以内容的综合权重做评估标准，综合权重的关键指标有完播率、点赞量、评论量、转发量，且每个元素所具有的影响权重又互不相同，当达到一定量级，平台就会以大数据算法和人工运营相结合的机制进行不断的推荐。比如，当用户发布一条视频时，平台会自动将其分配到一个流量池当中，分发到一定数量级的用户的推荐界面，然后通过统计该视频的播放效果，形成一个加权分数，转发量、评论量、点赞量的权重依次递减，分数越高则获得叠加推荐的机会越大，播放效果好的视频会再次加入流量池进行更大范围的分发，而表现较差的视频则失去了被推荐的机会，沉淀至流量池底部。第二次推荐又获得比较好的反馈则进入下一轮的推荐，从而获得更大规模的推荐。流量池推荐带来了更加明显的“马太效应”，优质的视频被反复推荐，获得更大的积累优势，而在第一波流量池推送中“逊色”的视频则失去了更大规模被推荐的机会。同时，由于这类算法更加基于多重用户受众的实际行为分析，所以经常会有大量级播放次数的视频出现。与前两个算法推荐相比，流量池推荐的视频随机性更强，其推荐的法则并非主要着眼于视频内容，而更多的是通过用户的反馈进行推荐。换言之，流量池推荐更注重视频传播效果的评价而非内容生产的优劣。这也使得一些内容并不那么优质的视频利用算法推荐的漏洞或不足，能够取得很高的评价分数，从而被大量级推荐，迅速“蹿红”。\n\n四、建议与对策 　　\n\n依靠强大的算法推荐，抖音已经在目前短视频白热化的角逐中逐渐占据上风。但是，完全依靠协同过滤和精准分发的单纯算法推荐不能够充分适应目前快速发展的受众需求，平台需要进一步完善更多维度的算法推荐系统。采用更加多元和开放的算法，将会更加合理地促进优质视频内容的传播。因此，可以进一步加强对抖音用户使用行为的数据挖掘工作，引入满意度、有用性等其他考量维度，优化其产品内容评价体系分层分类，避免加剧“茧房效应”，适当调整兴趣内容与其他内容的分发比例；进一步提高平台的识别能力，对所谓的“网红”短视频内容加强甄别，提高原创视频的推广力度，加强对相似或较为雷同的视频进行过滤审核，避免“同质化”内容高频出现；积极引入或增加人工审核的机制，在审核过程中提高人工排查的参与程度，逐渐树立传播审核过程中“人”的参与意识；积极鼓励“PGC”的产品生产，对于具有优质视频生产能力的用户给予鼓励，通过身份认证、延长视频时限等方式给予支持，提升全平台的视频制作水平；始终坚持“内容为王”的运营和管理理念，依靠优质的平台内容增加用户黏度和吸引新用户，就一些具有明显“哗众取宠”和恶搞的内容，引入投诉和其他负面评价机制，进一步净化网络空间。",
    "ori_text": "三、基于“流量池”的叠加推荐 　　\n\n与算法的研究日益成为热点类似，流量池也是近段时间以来频繁出现的热门词汇。此前，在新媒体研究领域里，流量思维是较为集中的研究热点，甚至有学者指出，“得流量者得天下”。流量池思维则是要获取流量并通过存储、运营和发掘等手段，进行信息的再传播，以期获得更多的流量。流量思维和流量池思维最大的区别就是流量获取之后的下一步社会行为，后者更强调如何用一批老用户找到更多新的用户，而流量思维更多的是首轮传播的效果评价。通常来讲，在内容流量池表现较好的视频内容往往会进入叠加推荐的行列，从而获得更多的阅读量和点赞。叠加推荐是以内容的综合权重做评估标准，综合权重的关键指标有完播率、点赞量、评论量、转发量，且每个元素所具有的影响权重又互不相同，当达到一定量级，平台就会以大数据算法和人工运营相结合的机制进行不断的推荐。比如，当用户发布一条视频时，平台会自动将其分配到一个流量池当中，分发到一定数量级的用户的推荐界面，然后通过统计该视频的播放效果，形成一个加权分数，转发量、评论量、点赞量的权重依次递减，分数越高则获得叠加推荐的机会越大，播放效果好的视频会再次加入流量池进行更大范围的分发，而表现较差的视频则失去了被推荐的机会，沉淀至流量池底部。第二次推荐又获得比较好的反馈则进入下一轮的推荐，从而获得更大规模的推荐。流量池推荐带来了更加明显的“马太效应”，优质的视频被反复推荐，获得更大的积累优势，而在第一波流量池推送中“逊色”的视频则失去了更大规模被推荐的机会。同时，由于这类算法更加基于多重用户受众的实际行为分析，所以经常会有大量级播放次数的视频出现。与前两个算法推荐相比，流量池推荐的视频随机性更强，其推荐的法则并非主要着眼于视频内容，而更多的是通过用户的反馈进行推荐。换言之，流量池推荐更注重视频传播效果的评价而非内容生产的优劣。这也使得一些内容并不那么优质的视频利用算法推荐的漏洞或不足，能够取得很高的评价分数，从而被大量级推荐，迅速“蹿红”。\n\n四、建议与对策 　　\n\n依靠强大的算法推荐，抖音已经在目前短视频白热化的角逐中逐渐占据上风。但是，完全依靠协同过滤和精准分发的单纯算法推荐不能够充分适应目前快速发展的受众需求，平台需要进一步完善更多维度的算法推荐系统。采用更加多元和开放的算法，将会更加合理地促进优质视频内容的传播。因此，可以进一步加强对抖音用户使用行为的数据挖掘工作，引入满意度、有用性等其他考量维度，优化其产品内容评价体系分层分类，避免加剧“茧房效应”，适当调整兴趣内容与其他内容的分发比例；进一步提高平台的识别能力，对所谓的“网红”短视频内容加强甄别，提高原创视频的推广力度，加强对相似或较为雷同的视频进行过滤审核，避免“同质化”内容高频出现；积极引入或增加人工审核的机制，在审核过程中提高人工排查的参与程度，逐渐树立传播审核过程中“人”的参与意识；积极鼓励“PGC”的产品生产，对于具有优质视频生产能力的用户给予鼓励，通过身份认证、延长视频时限等方式给予支持，提升全平台的视频制作水平；始终坚持“内容为王”的运营和管理理念，依靠优质的平台内容增加用户黏度和吸引新用户，就一些具有明显“哗众取宠”和恶搞的内容，引入投诉和其他负面评价机制，进一步净化网络空间。",
    "reference_list": "考点1：“叠加推荐”推荐译为“Tiered Recommendations”\n考点2：“得流量者得天下”推荐译为“Win the Eyeballs, Win it All.”\n考点3：“热门词汇”推荐译为“buzzword”\n考点4：“综合权重的关键指标”推荐译为“key performance metrics”\n考点5：“播放效果”推荐译为“user engagement”\n考点6：“蹿红”推荐译为“go viral”\n考点7：“白热化的角逐”推荐译为“the fiercely competitive landscape”\n考点8：“茧房效应”推荐译为““filter bubble” effect”\n考点9：““同质化”内容”推荐译为“content homogenization”\n考点10：“恶搞”推荐译为“maliciously sensational”\n考点11：“内容为王”推荐译为“Content is king.”\n考点12：“抖音”应译为“Douyin”，译为“Tiktok”算错误",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "14"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n27日，高德地图宣布在韩国正式上线打车功能，中国游客无需更换手机卡或下载新应用，就能直接呼叫韩国本地出租车，支持中文界面叫车、跨语言沟通、实时导航和主流电子支付，加之此前就已在当地上线的地图导航服务，实现“一个APP便捷出行”。据悉，高德地图打车功能目前已覆盖首尔、釜山等韩国主要旅游城市。\n\n韩国是中国游客的重要旅游目的地之一，公开数据显示，2024年赴韩中国游客达460万人次，较2023年增长翻番。针对出境游中的语言障碍、支付门槛等痛点，高德地图基于全球领先的基础服务能力与韩国本土出行服务商合作，将国内成熟的出行服务模式延展至海外，让游客在韩国也能享受到便捷、高效的线上叫车服务。\n\n据了解，中国游客在韩旅游期间，不仅可以在高德地图上直接使用中文地址一键呼叫韩国出租车，通过APP内置通信联络司机时，AI翻译能够实时转换司乘间的中韩对话，消除语言障碍。支付环节则直连支付宝、微信等跨境电子钱包，汇率自动结算，有效解决跨境支付难题。\n\n6月12日，阿里巴巴集团旗下高德地图在日本正式上线打车功能，覆盖东京、大阪、名古屋、横滨、京都等日本热门旅游城市。这是继韩国市场之后，高德再次通过“技术创新+本地合作”的模式，持续完善海外出行服务网络，为用户提供“一个APP便捷出行”的旅行体验。据悉，高德地图用户可通过中文界面直接呼叫日本当地出租车，可以使用支付宝、微信等跨境支付。\n\n高德介绍，通过与日本出租车头部平台“GO”合作，将国内成熟的出行服务模式延伸至日本市场，成为高德国际化战略中的又一重要动作。即日起，中国内地及港澳地区用户无需更换手机卡或下载新应用，即可通过高德地图中文界面直接呼叫日本当地出租车，实现中文地址一键叫车、中日对话实时翻译，以及支付宝、微信跨境支付，有效解决了语言障碍和支付难题。结合此前就已上线的实时导航、景点查询等功能，高德进一步完善了一体化出行服务能力，以更好满足游客在异国他乡的出行需求。\n\n高德打车总裁王桂馨表示，此次在日本上线打车服务，是公司产品走向全球的重要一步。“我们始终坚持以用户需求为核心，致力于将便捷可靠的出行服务带到世界各地，通过本地化的产品创新和生态协同，为中国以及海外用户的全球出行，创造更优质的体验。”\n\n目前，高德地图在日本的打车服务已基于“GO”的覆盖网络，延伸至日本各大热门旅游城市。暑期出境游高峰将至，该功能上线后能为游客提供更便捷、丰富的数字化出行选择，让用户在日本旅游时也能享受与国内同等效率的叫车服务。",
    "ori_text": "27日，高德地图宣布在韩国正式上线打车功能，中国游客无需更换手机卡或下载新应用，就能直接呼叫韩国本地出租车，支持中文界面叫车、跨语言沟通、实时导航和主流电子支付，加之此前就已在当地上线的地图导航服务，实现“一个APP便捷出行”。据悉，高德地图打车功能目前已覆盖首尔、釜山等韩国主要旅游城市。\n\n韩国是中国游客的重要旅游目的地之一，公开数据显示，2024年赴韩中国游客达460万人次，较2023年增长翻番。针对出境游中的语言障碍、支付门槛等痛点，高德地图基于全球领先的基础服务能力与韩国本土出行服务商合作，将国内成熟的出行服务模式延展至海外，让游客在韩国也能享受到便捷、高效的线上叫车服务。\n\n据了解，中国游客在韩旅游期间，不仅可以在高德地图上直接使用中文地址一键呼叫韩国出租车，通过APP内置通信联络司机时，AI翻译能够实时转换司乘间的中韩对话，消除语言障碍。支付环节则直连支付宝、微信等跨境电子钱包，汇率自动结算，有效解决跨境支付难题。\n\n6月12日，阿里巴巴集团旗下高德地图在日本正式上线打车功能，覆盖东京、大阪、名古屋、横滨、京都等日本热门旅游城市。这是继韩国市场之后，高德再次通过“技术创新+本地合作”的模式，持续完善海外出行服务网络，为用户提供“一个APP便捷出行”的旅行体验。据悉，高德地图用户可通过中文界面直接呼叫日本当地出租车，可以使用支付宝、微信等跨境支付。\n\n高德介绍，通过与日本出租车头部平台“GO”合作，将国内成熟的出行服务模式延伸至日本市场，成为高德国际化战略中的又一重要动作。即日起，中国内地及港澳地区用户无需更换手机卡或下载新应用，即可通过高德地图中文界面直接呼叫日本当地出租车，实现中文地址一键叫车、中日对话实时翻译，以及支付宝、微信跨境支付，有效解决了语言障碍和支付难题。结合此前就已上线的实时导航、景点查询等功能，高德进一步完善了一体化出行服务能力，以更好满足游客在异国他乡的出行需求。\n\n高德打车总裁王桂馨表示，此次在日本上线打车服务，是公司产品走向全球的重要一步。“我们始终坚持以用户需求为核心，致力于将便捷可靠的出行服务带到世界各地，通过本地化的产品创新和生态协同，为中国以及海外用户的全球出行，创造更优质的体验。”\n\n目前，高德地图在日本的打车服务已基于“GO”的覆盖网络，延伸至日本各大热门旅游城市。暑期出境游高峰将至，该功能上线后能为游客提供更便捷、丰富的数字化出行选择，让用户在日本旅游时也能享受与国内同等效率的叫车服务。",
    "reference_list": "考点1：“打车功能”推荐译为“ride-hailing feature/service; ride-hailing function”\n考点2：“基础服务能力”推荐译为“fundamental service capabilities; core service infrastructure”\n考点3：“ 一键呼叫”推荐译为“one-tap hailing; one-click hailing;”\n考点4：“头部平台”推荐译为“leading platform; top platform”\n考点5：“一体化出行服务”推荐译为“ integrated mobility services”\n考点6：“暑期出境游高峰”推荐译为“the summer peak season for outbound travel; the peak of summer outbound tourism”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "6"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n**考查重点：语文素养、时代意识、家国情怀**\n\n  2025年高考语文共有5套试卷。其中，教育部教育考试院命制全国一卷和全国二卷的2道作文题，上海、天津各命制1道，北京命制2道和1篇微写作。\n\n  教育部教育考试院有关负责人表示，今年的高考作文题坚持价值引领，紧扣时代脉搏，彰显学科特色，重点考查语文素养、时代意识与家国情怀。\n\n  今年是中国人民抗日战争暨世界反法西斯战争胜利80周年。全国一卷作文题选取了三段和抗战有关的材料，将考生的视线拉回到那段浴血奋战的峥嵘岁月，引发对民族精神传承的思考。\n\n  此外，全国二卷作文题鼓励考生敢于有梦、勇于追梦；天津卷以大家熟悉的车轮、辐条等为意象，推动考生思考向心力、凝聚力对个体成长、事业发展的重要意义。\n\n  “坚持立德树人，这些试题注重引导考生树立坚定理想信念，厚植家国情怀，可以激发新时代青年勇于担当的力量。”中国教育在线总编辑陈志文说。\n\n贴近实际、贴近生活，是今年高考作文题的另一亮点。\n\n  例如，上海卷作文题围绕专业文章、通俗文章、传世文章展开，与当下的文化生活紧密相连；北京卷则从运动员中长跑时会出现的“极点”反应，以及日常生活中随处可见的比赛记分牌、车站电子时刻表等角度出发命题。\n\n  “今年的上海高考作文题与考生的日常经验比较贴合。”华东师范大学教授胡晓明分析表示，“当前，传播手段非常丰富，许多网络文章被广泛转发，不少经典作品也得到更广泛的传播。从这个角度来看，学生若对当前文化传播有一定程度了解，便可以打开思辨空间，写出言之有物的文章。”\n\n  在专家看来，这些题目的材料指向既可以是现实的，又可以是想象的，由现实展开想象，由想象观照现实，考生可以从自身生活经验谈起，切入的角度很多。\n\n**折射导向：减少机械刷题、鼓励创新表达、促进全面发展**\n\n  每年的高考作文题，都可以折射一段时间以来语文教育的发展和趋势。多位受访专家和一线教师认为，今年的作文题同样为未来一段时间的语文教育提供了新参考和新导向。\n\n  衔接教学，促进课堂提质——\n\n  在有关专家看来，以作文题为代表的2025年高考语文试题注重与教材的关联，致力于引导一线教学用好统编教材的同时学以致用。\n\n  例如，全国一卷作文题的第二则材料选自艾青的名篇《我爱这土地》，这首诗正是统编教材九年级上册的篇目之一。专家认为，这类试题要求学生在重视课堂学习的同时，做到对课内教学内容融会贯通，扭转机械刷题、以练代学的不良习惯；也要求教师在课堂上开展深度教学，提升课堂教学质量。\n\n  以人为本，鼓励创新表达——\n\n  纵观近年来的高考作文题，不少专家发现，越来越多题目不在审题立意上设置门槛，而是更加注重激发考生活跃的想象力和创造力，打开审题立意的多维空间。\n\n “从中也反映出语文教育的趋势是引导学生创新思维，大胆联想和想象。”李奇说，“这启示一线教师在教育教学过程中引导学生从苦练苦背型学习，转向探究运用型学习，从而提升学生的思维整合力、思考纵深度。”\n\n  提升素养，促进全面发展——\n\n  从古代诗歌到现代诗歌，从观察生活到深入论证，专家表示，今年的作文题对考生的综合素养提出了新要求，引导学生不断提升阅读能力、思考能力和表达能力，实现全面发展。\n\n  在柳州高级中学语文教研组长朱秋清看来，今年的高考作文题对学生综合能力要求较高。“未来的教学实践中，我们既要帮助学生打牢基础，也要引导他们更加关注现实、思考人生，充分调动他们在学习和生活中积累的经验，让学生可以在课堂教学、日常阅读、历史感悟和生活体验中实现更加全面的发展。”",
    "ori_text": "**考查重点：语文素养、时代意识、家国情怀**\n\n  2025年高考语文共有5套试卷。其中，教育部教育考试院命制全国一卷和全国二卷的2道作文题，上海、天津各命制1道，北京命制2道和1篇微写作。\n\n  教育部教育考试院有关负责人表示，今年的高考作文题坚持价值引领，紧扣时代脉搏，彰显学科特色，重点考查语文素养、时代意识与家国情怀。\n\n  今年是中国人民抗日战争暨世界反法西斯战争胜利80周年。全国一卷作文题选取了三段和抗战有关的材料，将考生的视线拉回到那段浴血奋战的峥嵘岁月，引发对民族精神传承的思考。\n\n  此外，全国二卷作文题鼓励考生敢于有梦、勇于追梦；天津卷以大家熟悉的车轮、辐条等为意象，推动考生思考向心力、凝聚力对个体成长、事业发展的重要意义。\n\n  “坚持立德树人，这些试题注重引导考生树立坚定理想信念，厚植家国情怀，可以激发新时代青年勇于担当的力量。”中国教育在线总编辑陈志文说。\n\n贴近实际、贴近生活，是今年高考作文题的另一亮点。\n\n  例如，上海卷作文题围绕专业文章、通俗文章、传世文章展开，与当下的文化生活紧密相连；北京卷则从运动员中长跑时会出现的“极点”反应，以及日常生活中随处可见的比赛记分牌、车站电子时刻表等角度出发命题。\n\n  “今年的上海高考作文题与考生的日常经验比较贴合。”华东师范大学教授胡晓明分析表示，“当前，传播手段非常丰富，许多网络文章被广泛转发，不少经典作品也得到更广泛的传播。从这个角度来看，学生若对当前文化传播有一定程度了解，便可以打开思辨空间，写出言之有物的文章。”\n\n  在专家看来，这些题目的材料指向既可以是现实的，又可以是想象的，由现实展开想象，由想象观照现实，考生可以从自身生活经验谈起，切入的角度很多。\n\n**折射导向：减少机械刷题、鼓励创新表达、促进全面发展**\n\n  每年的高考作文题，都可以折射一段时间以来语文教育的发展和趋势。多位受访专家和一线教师认为，今年的作文题同样为未来一段时间的语文教育提供了新参考和新导向。\n\n  衔接教学，促进课堂提质——\n\n  在有关专家看来，以作文题为代表的2025年高考语文试题注重与教材的关联，致力于引导一线教学用好统编教材的同时学以致用。\n\n  例如，全国一卷作文题的第二则材料选自艾青的名篇《我爱这土地》，这首诗正是统编教材九年级上册的篇目之一。专家认为，这类试题要求学生在重视课堂学习的同时，做到对课内教学内容融会贯通，扭转机械刷题、以练代学的不良习惯；也要求教师在课堂上开展深度教学，提升课堂教学质量。\n\n  以人为本，鼓励创新表达——\n\n  纵观近年来的高考作文题，不少专家发现，越来越多题目不在审题立意上设置门槛，而是更加注重激发考生活跃的想象力和创造力，打开审题立意的多维空间。\n\n “从中也反映出语文教育的趋势是引导学生创新思维，大胆联想和想象。”李奇说，“这启示一线教师在教育教学过程中引导学生从苦练苦背型学习，转向探究运用型学习，从而提升学生的思维整合力、思考纵深度。”\n\n  提升素养，促进全面发展——\n\n  从古代诗歌到现代诗歌，从观察生活到深入论证，专家表示，今年的作文题对考生的综合素养提出了新要求，引导学生不断提升阅读能力、思考能力和表达能力，实现全面发展。\n\n  在柳州高级中学语文教研组长朱秋清看来，今年的高考作文题对学生综合能力要求较高。“未来的教学实践中，我们既要帮助学生打牢基础，也要引导他们更加关注现实、思考人生，充分调动他们在学习和生活中积累的经验，让学生可以在课堂教学、日常阅读、历史感悟和生活体验中实现更加全面的发展。”",
    "reference_list": "考点1：“高考”推荐译为 National College Entrance Examination\n考点2：“时代意识”推荐译为 awareness of the times / sense of the times，不可译为timing awareness。\n考点3：“家国情怀”推荐译为 patriotic sentiment / devotion to the nation and family，不可误译为nationalism或emotional attachment to country。\n考点4：“命制”推荐译为 developed/set/designed (by the Examination Authority)\n考点5：“价值引领”推荐译为 value guidance / value-oriented approach，注意体现政策导向性质\n考点6：“紧扣时代脉搏”推荐译为 keep in step with the pulse of the times，为文化性表达，避免直译如close to the beat of the times。\n考点7：“彰显学科特色”推荐译为 highlight the discipline-specific features\n考点8：“峥嵘岁月”推荐译为 tumultuous years / the trying days of war\n考点9：“民族精神传承”推荐译为 inheritance of national spirit / passing down the national ethos\n考点10：“立德树人”推荐译为 fostering virtue through education，为教育核心术语\n考点11：“负责人” 不可译为 “responsible person/officer”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "28"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nSuch a requalification of the anthropological agenda was what Tania Stolze Lima and I wanted to contribute to when we proposed the concept of Amerindian perspectivism as the reconfiguration of a complex of ideas and practices whose power of intellectual disturbance has never been sufficiently appreciated (even if they found the word relevant) by Americanists, despite its vast diffusion in the New World To this we added the synoptic concept of multinaturalism, which presented Amerindian thought as an unsuspected partner, a dark precursor if you will, of certain contemporary philosophical programs, like those developing around theories of possible worlds, others that refuse to operate within the vicious dichotomies of modernity, or still others that, having registered the end of the hegemony of the kind of critique that demands an epistemological response to every ontological question, are slowly defining new lines of flight for thought under the rallying cries of transcendental empiricism and speculative realism.\nThe two concepts emerged following an analysis of the cosmological presuppositions of \"the metaphysics of predation\" evoked in the last chapter. We found that this metaphysics, as can be deduced from Lévi-Strauss' summary of it, reaches its highest expression in the strong speculative yield of those indigenous categories denoting matrimonial alliance, phenomena that I translated with yet another concept: virtual affinity.!\" Virtual affinity is the schematism characteristic of what Deleuze would have called the \"Other-structure\"' of Amerindian worlds and is indelibly marked by cannibalism, which is an omnipresent motif in their inhabitants' relational imagination. Interspecific perspectivism, ontological multinaturalism and cannibal alterity thus form the three aspects of an indigenous alter-anthropology that is the symmetrical and reverse transformation of Occidental anthropolo-gy—as symmetrical in Latour's sense as it is reverse in the sense of Wagner' \"reverse anthropology.\" By drawing this triangle, we can enter into the orbit of one of the philosophies of \"the exotic peoples\" that Lévi-Strauss opposed to ours and attempt, in other words, to realize something of the imposing program outlined in the fourth chapter, \"Geophilosophy,\" of What Is Philosophy?.. even if it will be at the price—but one we should always be ready to payof a certain methodological imprecision and intentional ambiguity.\nOur work's perfectly contingent point of departure was the sudden perception of a resonance between the results of our research on Amazonian cosmopolitics-on its notion of a perspectivist multiplicity intrinsic to the real-and a well-known parable on the subject of the conquest of the Americans recounted by Lévi-Strauss in Race and History:\nIn the Greater Antilles, some years after the discovery of America, while the Spaniards sent out investigating commissions to ascertain whether or not the natives had a soul, the latter were engaged in the drowning of white prisoners in order to verify, through prolonged watching, whether or not their corpses were subject to putrification.\n(L.-S. 1978[1952): 329) In this conflict between the two anthropologies, the author perceived a baroque allegory of the fact that one of the typical manifestations of human nature is the negation of its own generality.\nA kind of congenital avarice preventing the extension of the predicates of humanity to the species as a whole appears to be one of its predicates. In sum, ethnocentrism could be said to be like good sense, of which perhaps it is just the apperceptive moment: the best distributed thing in the world. The format of the lesson is familiar, but that does not lessen its sting. Overestimating one's own humanity to the detriment of the contemptible other's reveals one's deep resemblance with it. Since the other of the Same (of the European) shows itself to be the same as the Other's other (of the indigenous), the Same ends up unwittingly showing itself to be the same as the Other.\nThe anecdote fascinated Lévi-Strauss enough for him to repeat it in Iristes Tropiques. But there he added a supplementary, ironic twist, this time noting a difference (rather than this re-semblance) between the parties. While the Europeans relied on the social sciences in their investigations of the humanity of the other, the Indians placed their faith in the natural sciences; and where the former proclaimed the Indians to be animals, the latter were content to suspect the others might be gods. \"Both attitudes show equal ignorance,\" Lévi-Strauss concluded, \"but the Indian's behavior certainly had greater dignity\" (1992: 76). If this is really how things transpired,' it forces us to conclude that, despite being just as ignorant on the subject of the other, the other of the Other was not exactly the same as the other of the Same. We could even say that it was its exact opposite, if not for the fact that the relation between these two others of humanity-animality and divinity—is conceived in indigenous worlds in completely different terms than those we have inherited from Christianity.\nThe rhetorical contrast Lévi-Strauss draws succeeds because it appeals to our cosmological hierarchies rather than those of the Taino. \nIn any case, consideration of this disequilibrium was what led us to the hypothesis that Amerindian ontological regimes diverge from those widespread in the West precisely with regard to the inverse semiotic functions they respectively attribute to soul and body. The marked dimension for the Spanish was the soul, whereas the Indian emphasized the body. The Europeans never doubted that the Indians had bodies--animals have them too-and the Indians in turn never doubted that the Europeans had souls, since animals and the ghosts of the dead do as well. Thus the Europeans' ethnocentrism consisted in doubting that the body of the other contained a soul formally similar to the one inhabiting their own bodies, while the ethnocentrism of the Indians, on the contrary, entailed doubting that the others' souls or spirits could possess a body materially similar to theirs. \n• In the semiotic terms of Roy Wagner, a Melanesianist who will quickly reveal himself to be a crucial intercessor in the theory of Amerindian perspectivism, the body belongs to the innate or spontaneous dimension of European ontology (\"nature\"), which is the counter-invented result of an operation of conventionalist symbolization, while the soul would be the constructed dimension, the fruit of a \"differentiating\" symbol-ization that \"specifies and renders concrete the conventional world by tracing radical distinctions and concretizing the singular individuals of this world\" (Wagner 1981: 42). In indigenous worlds, on the contrary, the soul \"is experienced as ... a manifestation of the conventional order implicit in everything\"\nand \"sums up the ways in which its possessor\nis similar to others, over and above the ways in which he differs from them\" (Wagner 1981: 94); the body, on the contrary, belongs to the sphere of what comes from the responsibility of agents and is one of the fundamental figures of something that has to be constructed against a universal and innate ground of an \"immanent humanity\" (Wagner\n1981: 86-9), In short, European praxis consists in \"making souls\" (and differentiating cultures) on the basis of a given corporeal-material ground nature while indigenous praxis consists in \"making bodies\" (and differentiating species) on the basis of a socio-spiritual continuum, itself also given ... but in myth, as we will see.\nWagner's conceptually dense and quite original theoretical system resists didactic summary; thus we request that the reader directly engage its most elegant and realized presentation in The Invention of Culture. Grosso modo, the Wagnerian semiotic can be said to be a theory of human and nonhuman practice conceived as exhaustively consisting in the recipro-cal, recursive operation of two modes of symbolization: (1) a collectiv-izing, conventional (or literal) symbolism where signs are organized in standardized contexts (semantic domains, formal languages, etc.) to the extent that they are opposed to a heterogeneous plane of \"referents\". that is, they are seen as symbolizing something other than themselves; and (2) a differentiating, inventive (or figurative) mode in which the world of phenomena represented by conventional symbolization is understood to be constituted by \"symbols representing themselves,\" that is, events that simultaneously manifest as symbols and referents, thereby dissolving the conventional contrast. It should be observed, first of all, that the world of referents or the \"real\" is defined here as a semiotic effect: what is other to a sign is another sign having the singular capacity of \"representing itself.\" The mode of existence of actual entities qua events or occasions is a tautegory. It should be stressed that the contrast between the two modes is itself the result of a conventionalist operation (and perception): the distinction between invention and convention is itself conventional, but at the same time every convention is produced through a counter-invention. The contrast is thus intrinsically recursive, especially if we understand that human cultures are fundamentally in conflict over the mode of symbolization they (conventionally) privilege as an element appropriated for action or invention, in reserving to the other the function of the \"given.\" Cultures, human macrosystems of conventions, are distinguished by what they define as belonging to the sphere of the responsibilities of agents-the mode of the constructed-and by what belongs (because it is counter-constructed as belonging) to the world of the given or non-constructed.\nThe core of any and every set of cultural conventions is a simple distinction as to what kind of contexts- the nonconventionalized ones or those of convention itself- are to be deliberately articulated in the course of human action, and what kind of contexts are to be counter-invented as \"motivation\" under the conventional mask of \"the given\" or \"the innate.\" Of course I...] there are only two possibilities: a people who deliberately differentiate as the form of their action will invariably counter-invent a motivating collectivity as \"innate,\" and a people who deliberately collectivize will counter-invent a motivating differentiation in this way. (Wagner 1981: 51)",
    "ori_text": "\n\nSuch a requalification of the anthropological agenda was what Tania Stolze Lima and I wanted to contribute to when we proposed the concept of Amerindian perspectivism as the reconfiguration of a complex of ideas and practices whose power of intellectual disturbance has never been sufficiently appreciated (even if they found the word relevant) by Americanists, despite its vast diffusion in the New World To this we added the synoptic concept of multinaturalism, which presented Amerindian thought as an unsuspected partner, a dark precursor if you will, of certain contemporary philosophical programs, like those developing around theories of possible worlds, others that refuse to operate within the vicious dichotomies of modernity, or still others that, having registered the end of the hegemony of the kind of critique that demands an epistemological response to every ontological question, are slowly defining new lines of flight for thought under the rallying cries of transcendental empiricism and speculative realism.\nThe two concepts emerged following an analysis of the cosmological presuppositions of \"the metaphysics of predation\" evoked in the last chapter. We found that this metaphysics, as can be deduced from Lévi-Strauss' summary of it, reaches its highest expression in the strong speculative yield of those indigenous categories denoting matrimonial alliance, phenomena that I translated with yet another concept: virtual affinity.!\" Virtual affinity is the schematism characteristic of what Deleuze would have called the \"Other-structure\"' of Amerindian worlds and is indelibly marked by cannibalism, which is an omnipresent motif in their inhabitants' relational imagination. Interspecific perspectivism, ontological multinaturalism and cannibal alterity thus form the three aspects of an indigenous alter-anthropology that is the symmetrical and reverse transformation of Occidental anthropolo-gy—as symmetrical in Latour's sense as it is reverse in the sense of Wagner' \"reverse anthropology.\" By drawing this triangle, we can enter into the orbit of one of the philosophies of \"the exotic peoples\" that Lévi-Strauss opposed to ours and attempt, in other words, to realize something of the imposing program outlined in the fourth chapter, \"Geophilosophy,\" of What Is Philosophy?.. even if it will be at the price—but one we should always be ready to payof a certain methodological imprecision and intentional ambiguity.\nOur work's perfectly contingent point of departure was the sudden perception of a resonance between the results of our research on Amazonian cosmopolitics-on its notion of a perspectivist multiplicity intrinsic to the real-and a well-known parable on the subject of the conquest of the Americans recounted by Lévi-Strauss in Race and History:\nIn the Greater Antilles, some years after the discovery of America, while the Spaniards sent out investigating commissions to ascertain whether or not the natives had a soul, the latter were engaged in the drowning of white prisoners in order to verify, through prolonged watching, whether or not their corpses were subject to putrification.\n(L.-S. 1978[1952): 329) In this conflict between the two anthropologies, the author perceived a baroque allegory of the fact that one of the typical manifestations of human nature is the negation of its own generality.\nA kind of congenital avarice preventing the extension of the predicates of humanity to the species as a whole appears to be one of its predicates. In sum, ethnocentrism could be said to be like good sense, of which perhaps it is just the apperceptive moment: the best distributed thing in the world. The format of the lesson is familiar, but that does not lessen its sting. Overestimating one's own humanity to the detriment of the contemptible other's reveals one's deep resemblance with it. Since the other of the Same (of the European) shows itself to be the same as the Other's other (of the indigenous), the Same ends up unwittingly showing itself to be the same as the Other.\nThe anecdote fascinated Lévi-Strauss enough for him to repeat it in Iristes Tropiques. But there he added a supplementary, ironic twist, this time noting a difference (rather than this re-semblance) between the parties. While the Europeans relied on the social sciences in their investigations of the humanity of the other, the Indians placed their faith in the natural sciences; and where the former proclaimed the Indians to be animals, the latter were content to suspect the others might be gods. \"Both attitudes show equal ignorance,\" Lévi-Strauss concluded, \"but the Indian's behavior certainly had greater dignity\" (1992: 76). If this is really how things transpired,' it forces us to conclude that, despite being just as ignorant on the subject of the other, the other of the Other was not exactly the same as the other of the Same. We could even say that it was its exact opposite, if not for the fact that the relation between these two others of humanity-animality and divinity—is conceived in indigenous worlds in completely different terms than those we have inherited from Christianity.\nThe rhetorical contrast Lévi-Strauss draws succeeds because it appeals to our cosmological hierarchies rather than those of the Taino. \nIn any case, consideration of this disequilibrium was what led us to the hypothesis that Amerindian ontological regimes diverge from those widespread in the West precisely with regard to the inverse semiotic functions they respectively attribute to soul and body. The marked dimension for the Spanish was the soul, whereas the Indian emphasized the body. The Europeans never doubted that the Indians had bodies--animals have them too-and the Indians in turn never doubted that the Europeans had souls, since animals and the ghosts of the dead do as well. Thus the Europeans' ethnocentrism consisted in doubting that the body of the other contained a soul formally similar to the one inhabiting their own bodies, while the ethnocentrism of the Indians, on the contrary, entailed doubting that the others' souls or spirits could possess a body materially similar to theirs. \n• In the semiotic terms of Roy Wagner, a Melanesianist who will quickly reveal himself to be a crucial intercessor in the theory of Amerindian perspectivism, the body belongs to the innate or spontaneous dimension of European ontology (\"nature\"), which is the counter-invented result of an operation of conventionalist symbolization, while the soul would be the constructed dimension, the fruit of a \"differentiating\" symbol-ization that \"specifies and renders concrete the conventional world by tracing radical distinctions and concretizing the singular individuals of this world\" (Wagner 1981: 42). In indigenous worlds, on the contrary, the soul \"is experienced as ... a manifestation of the conventional order implicit in everything\"\nand \"sums up the ways in which its possessor\nis similar to others, over and above the ways in which he differs from them\" (Wagner 1981: 94); the body, on the contrary, belongs to the sphere of what comes from the responsibility of agents and is one of the fundamental figures of something that has to be constructed against a universal and innate ground of an \"immanent humanity\" (Wagner\n1981: 86-9), In short, European praxis consists in \"making souls\" (and differentiating cultures) on the basis of a given corporeal-material ground nature while indigenous praxis consists in \"making bodies\" (and differentiating species) on the basis of a socio-spiritual continuum, itself also given ... but in myth, as we will see.\nWagner's conceptually dense and quite original theoretical system resists didactic summary; thus we request that the reader directly engage its most elegant and realized presentation in The Invention of Culture. Grosso modo, the Wagnerian semiotic can be said to be a theory of human and nonhuman practice conceived as exhaustively consisting in the recipro-cal, recursive operation of two modes of symbolization: (1) a collectiv-izing, conventional (or literal) symbolism where signs are organized in standardized contexts (semantic domains, formal languages, etc.) to the extent that they are opposed to a heterogeneous plane of \"referents\". that is, they are seen as symbolizing something other than themselves; and (2) a differentiating, inventive (or figurative) mode in which the world of phenomena represented by conventional symbolization is understood to be constituted by \"symbols representing themselves,\" that is, events that simultaneously manifest as symbols and referents, thereby dissolving the conventional contrast. It should be observed, first of all, that the world of referents or the \"real\" is defined here as a semiotic effect: what is other to a sign is another sign having the singular capacity of \"representing itself.\" The mode of existence of actual entities qua events or occasions is a tautegory. It should be stressed that the contrast between the two modes is itself the result of a conventionalist operation (and perception): the distinction between invention and convention is itself conventional, but at the same time every convention is produced through a counter-invention. The contrast is thus intrinsically recursive, especially if we understand that human cultures are fundamentally in conflict over the mode of symbolization they (conventionally) privilege as an element appropriated for action or invention, in reserving to the other the function of the \"given.\" Cultures, human macrosystems of conventions, are distinguished by what they define as belonging to the sphere of the responsibilities of agents-the mode of the constructed-and by what belongs (because it is counter-constructed as belonging) to the world of the given or non-constructed.\nThe core of any and every set of cultural conventions is a simple distinction as to what kind of contexts- the nonconventionalized ones or those of convention itself- are to be deliberately articulated in the course of human action, and what kind of contexts are to be counter-invented as \"motivation\" under the conventional mask of \"the given\" or \"the innate.\" Of course I...] there are only two possibilities: a people who deliberately differentiate as the form of their action will invariably counter-invent a motivating collectivity as \"innate,\" and a people who deliberately collectivize will counter-invent a motivating differentiation in this way. (Wagner 1981: 51)",
    "reference_list": "考点1. ”virtual affinity“必须译为”虚拟姻亲“或者”虚拟姻亲关系“，一种即可，禁止前后不一致\n考点2.”transcendental empiricism“必须译为”先验经验论/主义”或“超验主义/经验论”，一种即可，禁止前后不一致\n考点3.”Geophilosophy“必须译为”地理哲学“/“地理-哲学”/“地学哲学”，一种即可，禁止前后不一致\n考点4. “baroque allegory”推荐译为“巴洛克（式）寓言”\n考点5. “cannibal alterity”推荐译为“食人的他性”/“食人式他性”，一种即可，禁止前后不一致\n考点6. multinaturalism 推荐译为 “多元自然论” 或 “多自然主义”，一种即可，禁止前后不一致\n考点7. matrimonial alliance 推荐译为 “婚姻联盟” 或 “姻亲关系”，一种即可，禁止前后不一致",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "106"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n葛兰西在论述意大利现代民族国家形成与发展中的政治领导权时，论及一个社会集团的霸权地位，体现在“统治”和“智识与道德”意义上的文化领导权：一个社会集团取得政权的首要条件就是之前已经在行使文化领导权，在其掌握政权之时，也必须延续以往的文化领导权。葛兰西明确地将“统治”和“意识形态霸权”（即文化领导权）作了区分，并强调了意识形态霸权对于取得政权和维系政权的重要意义，而意识形态还通过权力关系渗透到大众日常生活的现实意识，包括语言、常识与大众宗教，而这些意识形态要素和实践，都被整合到一个民俗体系中。至于统治阶级的意识形态霸权如何通过权力关系作用于大众的日常意识，葛兰西并没有系统地展开论述。英国马克思主义文化理论家威廉斯在葛兰西的基础上进一步论证了意识形态的作用机制，在这一机制中发挥决定性作用的不仅是观念和信仰的意识形态体系本身，还包括文化领导权所主导的社会生活的整体实践过程。而主导性的意识形态则可能遮蔽了“那一时期或社会中现实人们的那些相对复杂的、混合的、不完整的或未得到清晰表述的思想意识”。威廉斯的论述实际上肯定了葛兰西的意识形态霸权影响大众意识的观点，在此基础上又揭示了前者遮蔽后者的可能性，同时还在一定程度上避免了意识形态霸权所具有的意识形态决定论取向。至于大众意识的主体性，在意识形态霸权理论中则似乎付之阙如。\n美国的中国学家姜士彬在研究明清时期的信息沟通方式时指出，葛兰西“意识形态霸权”所指涉的现代西方社会存在私人组织和国家权力机关的二元化，所以意识形态是通过社会中的报章、教会和学校来传播和灌输的。而明清时期的所有国家机关和民间组织都被士绅这同一个精英阶层控制，以至于统治阶级“霸权”达到了惊人的强度和范围，甚至此时的中国已经成为一个“学者政权”，他将其视为一个建立在特定意识形态基础上的文化整合的过程。由于姜士彬过度强调文化整合，所以没有在意识形态霸权如何遮蔽大众意识这一层面进一步拓展威廉斯的理论观点。\n葛希芝、魏乐博在此基础上还借用了斯科特“弱者的日常抵抗”概念，论证了明清民众意识的日常抵抗形式和自主性，从而提出“民间意识形态”概念。斯科特继对东南亚农民反叛的研究之后发现了农民反抗的“日常”形式，例如磨洋工、装傻、逃避、假奉承、盗窃、散布谣言、放火、搞破坏等等，他称之为“弱者的武器”。他在关注反抗实践的同时，也关注村庄内的意识形态斗争，其核心的问题意识是讨论反抗和阶级斗争重要主题的意识形态支配问题。由于斯科特关注的是农民的日常反抗形式及其背后的意识形态问题，农民的这种大众意识形态主要是以日常反抗为基调的。而葛希芝、魏乐博及其合作者们所提出的民间意识形态概念除了包含斯科特所说的大众意识形态之外，还因明清时期士绅群体在民间社会的支配性影响力而将正统伦理观以小传统的形式纳人了民间意识形态。“民间意识形态”作为一个动态的社会进程，既呈现了姜士彬所说的文化整合机制，也凸显了民间抵抗的一面。这种民间抵抗大量地表现为一种日常反抗的形式，有时也会发展为一定规模的反叛，秘密教派可能会成为民众反叛的组织形式。当然，民众的日常抵抗和反叛也存在着意识形态与权力网络的内在一致性及特定的转化机制。韩书瑞的研究表明，白莲教不仅在教义方面与儒家伦理相契合，而且在经卷中常常提到老子和观音：在教派活动中，还可以提供与僧道、灵媒等宗教职业人员同样的服务。也正是这种正统化的民间宗教实践使得秘密教派具有实施广泛政治动员的意识形态基础。\n本文的研究问题不在于探寻“民间意识形态”本身的思想史意义，而是追究“民间意识形态”的社会建构是如何呈现为历史本体论层面的“象征支配”的。格尔兹曾论证过，意识形态之于社会政治现实的意义就在于其高度象征性能将社会情势在其构架内进行解释并赋予其意义，还能使接受它的人产生自觉的认同感。格尔兹将意识形态视为一种文化体系，意识形态对社会行为的解释使其既具有高度的象征性，又是社会一体化的文化粘合剂。格尔兹作为阐释人类学大师，尤其强调意识形态象征的意义系统，而缺乏对意识形态作为文化体系实践机制的探讨。\n布迪厄在实践理论中提出了“象征资本”的概念，以解释前资本主义经济的象征支配逻辑，其论证的核心就是经济资本如何转化为象征资本，但是这一转化过程奠定于物质基础之上，也由此产生了含情脉脉的道德面纱掩盖下的身份依附关系。其象征形式多表现为感激、效忠、尊敬、道义责任或良心债之类的道德规范和价值观，“是利用一个效忠群体所进行的物质和象征性投资，是一种象征支配”。这种发生在前资本主义经济中的象征支配的建立、维持或恢复必须运用乔装打扮、改头换面的“委婉化策略，这一策略的运用机制即“社会炼金术”的基本操作。“社会炼金术”呈现了既定秩序的合法化效应，亦即文化的再生产抑或物质再生产都行使着意识形态职能，使得依附和支配关系借助“委婉化”策略而处于隐蔽状态。在象征支配的运作逻辑中，经济基础与上层建筑的区分就显得过于简单和粗糙了。所以，不存在一个整齐划一的实体性意识形态，即使是葛兰西意义上的意识形态霸权，也是通过特定的媒介将权力关系渗透到民众日常意识和价值观中的，更不用说“民间意识形态”了。象征支配的运作逻辑中呈现出特定的分散性和整体性，一如“分散性宗教”在民众信仰中呈现为结构性与制度性的存在。\n斯科特在评论葛兰西“意识形态霸权”的局限性时指出，应避免经济决定论的极端形式的弊病，赋予广义上的意识形态领域一定程度上的自主性，但同时也应避免走向意识形态决定论的另一极端。他沿着布迪厄象征支配的“委婉化”通过细致的田野工作探讨了马来西亚塞达卡村庄意识形态斗争的日常形式，主要表现即经济支配的“委婉化”，作为其后果之一的财产关系“委婉化”，总是有关象征的操纵、斗争与冲突的焦点。物质性面相的经济支配本身就是象征支配的过程，而象征支配的实践逻辑则蕴涵了意识形态的价值操控和权力关系的运作。\n斯科特还就此提出了“双重象征操控”的概念，以进一步论证经济支配委婉化的运作逻辑也就是一种委婉化象征的互惠性的操纵。他以塞达卡的哈姆扎与其雇主哈吉·卡迪尔的关系作为案例分析了这一“双重象征操控”的机制，哈姆扎利用雇主将为其提供工作机会表述为“帮助”或“援助”，刻意以礼貌的语言“恳求”卡迪尔的“帮助”由此将自己的行动置于最有利的位置，以实现自己找工作或寻求贷款的目标，进而有意无意地使自己的行动策略为公共合法性的构建做出了贡献。“双重象征操控”强调了富人剥削的委婉化表述和“弱者”行动策略的“互惠”机制，富人或精英的支配需要“双重象征操控”的互惠机制才能得以实现。当然，这一“双重象征操控”的实现不是互惠原则所能概括的，斯科特关于支配与抵抗艺术的进一步研究表明，有权者极为关心如何使象征符合其支配形式，而从属者通常都具有充足的理由去帮助支配者维持其象征，或至少不会公开与之抵触，这就表现为支配、抵抗艺术中公开剧本和潜隐剧本之间复杂的权力关系。",
    "ori_text": "\n\n葛兰西在论述意大利现代民族国家形成与发展中的政治领导权时，论及一个社会集团的霸权地位，体现在“统治”和“智识与道德”意义上的文化领导权：一个社会集团取得政权的首要条件就是之前已经在行使文化领导权，在其掌握政权之时，也必须延续以往的文化领导权。葛兰西明确地将“统治”和“意识形态霸权”（即文化领导权）作了区分，并强调了意识形态霸权对于取得政权和维系政权的重要意义，而意识形态还通过权力关系渗透到大众日常生活的现实意识，包括语言、常识与大众宗教，而这些意识形态要素和实践，都被整合到一个民俗体系中。至于统治阶级的意识形态霸权如何通过权力关系作用于大众的日常意识，葛兰西并没有系统地展开论述。英国马克思主义文化理论家威廉斯在葛兰西的基础上进一步论证了意识形态的作用机制，在这一机制中发挥决定性作用的不仅是观念和信仰的意识形态体系本身，还包括文化领导权所主导的社会生活的整体实践过程。而主导性的意识形态则可能遮蔽了“那一时期或社会中现实人们的那些相对复杂的、混合的、不完整的或未得到清晰表述的思想意识”。威廉斯的论述实际上肯定了葛兰西的意识形态霸权影响大众意识的观点，在此基础上又揭示了前者遮蔽后者的可能性，同时还在一定程度上避免了意识形态霸权所具有的意识形态决定论取向。至于大众意识的主体性，在意识形态霸权理论中则似乎付之阙如。\n美国的中国学家姜士彬在研究明清时期的信息沟通方式时指出，葛兰西“意识形态霸权”所指涉的现代西方社会存在私人组织和国家权力机关的二元化，所以意识形态是通过社会中的报章、教会和学校来传播和灌输的。而明清时期的所有国家机关和民间组织都被士绅这同一个精英阶层控制，以至于统治阶级“霸权”达到了惊人的强度和范围，甚至此时的中国已经成为一个“学者政权”，他将其视为一个建立在特定意识形态基础上的文化整合的过程。由于姜士彬过度强调文化整合，所以没有在意识形态霸权如何遮蔽大众意识这一层面进一步拓展威廉斯的理论观点。\n葛希芝、魏乐博在此基础上还借用了斯科特“弱者的日常抵抗”概念，论证了明清民众意识的日常抵抗形式和自主性，从而提出“民间意识形态”概念。斯科特继对东南亚农民反叛的研究之后发现了农民反抗的“日常”形式，例如磨洋工、装傻、逃避、假奉承、盗窃、散布谣言、放火、搞破坏等等，他称之为“弱者的武器”。他在关注反抗实践的同时，也关注村庄内的意识形态斗争，其核心的问题意识是讨论反抗和阶级斗争重要主题的意识形态支配问题。由于斯科特关注的是农民的日常反抗形式及其背后的意识形态问题，农民的这种大众意识形态主要是以日常反抗为基调的。而葛希芝、魏乐博及其合作者们所提出的民间意识形态概念除了包含斯科特所说的大众意识形态之外，还因明清时期士绅群体在民间社会的支配性影响力而将正统伦理观以小传统的形式纳人了民间意识形态。“民间意识形态”作为一个动态的社会进程，既呈现了姜士彬所说的文化整合机制，也凸显了民间抵抗的一面。这种民间抵抗大量地表现为一种日常反抗的形式，有时也会发展为一定规模的反叛，秘密教派可能会成为民众反叛的组织形式。当然，民众的日常抵抗和反叛也存在着意识形态与权力网络的内在一致性及特定的转化机制。韩书瑞的研究表明，白莲教不仅在教义方面与儒家伦理相契合，而且在经卷中常常提到老子和观音：在教派活动中，还可以提供与僧道、灵媒等宗教职业人员同样的服务。也正是这种正统化的民间宗教实践使得秘密教派具有实施广泛政治动员的意识形态基础。\n本文的研究问题不在于探寻“民间意识形态”本身的思想史意义，而是追究“民间意识形态”的社会建构是如何呈现为历史本体论层面的“象征支配”的。格尔兹曾论证过，意识形态之于社会政治现实的意义就在于其高度象征性能将社会情势在其构架内进行解释并赋予其意义，还能使接受它的人产生自觉的认同感。格尔兹将意识形态视为一种文化体系，意识形态对社会行为的解释使其既具有高度的象征性，又是社会一体化的文化粘合剂。格尔兹作为阐释人类学大师，尤其强调意识形态象征的意义系统，而缺乏对意识形态作为文化体系实践机制的探讨。\n布迪厄在实践理论中提出了“象征资本”的概念，以解释前资本主义经济的象征支配逻辑，其论证的核心就是经济资本如何转化为象征资本，但是这一转化过程奠定于物质基础之上，也由此产生了含情脉脉的道德面纱掩盖下的身份依附关系。其象征形式多表现为感激、效忠、尊敬、道义责任或良心债之类的道德规范和价值观，“是利用一个效忠群体所进行的物质和象征性投资，是一种象征支配”。这种发生在前资本主义经济中的象征支配的建立、维持或恢复必须运用乔装打扮、改头换面的“委婉化策略，这一策略的运用机制即“社会炼金术”的基本操作。“社会炼金术”呈现了既定秩序的合法化效应，亦即文化的再生产抑或物质再生产都行使着意识形态职能，使得依附和支配关系借助“委婉化”策略而处于隐蔽状态。在象征支配的运作逻辑中，经济基础与上层建筑的区分就显得过于简单和粗糙了。所以，不存在一个整齐划一的实体性意识形态，即使是葛兰西意义上的意识形态霸权，也是通过特定的媒介将权力关系渗透到民众日常意识和价值观中的，更不用说“民间意识形态”了。象征支配的运作逻辑中呈现出特定的分散性和整体性，一如“分散性宗教”在民众信仰中呈现为结构性与制度性的存在。\n斯科特在评论葛兰西“意识形态霸权”的局限性时指出，应避免经济决定论的极端形式的弊病，赋予广义上的意识形态领域一定程度上的自主性，但同时也应避免走向意识形态决定论的另一极端。他沿着布迪厄象征支配的“委婉化”通过细致的田野工作探讨了马来西亚塞达卡村庄意识形态斗争的日常形式，主要表现即经济支配的“委婉化”，作为其后果之一的财产关系“委婉化”，总是有关象征的操纵、斗争与冲突的焦点。物质性面相的经济支配本身就是象征支配的过程，而象征支配的实践逻辑则蕴涵了意识形态的价值操控和权力关系的运作。\n斯科特还就此提出了“双重象征操控”的概念，以进一步论证经济支配委婉化的运作逻辑也就是一种委婉化象征的互惠性的操纵。他以塞达卡的哈姆扎与其雇主哈吉·卡迪尔的关系作为案例分析了这一“双重象征操控”的机制，哈姆扎利用雇主将为其提供工作机会表述为“帮助”或“援助”，刻意以礼貌的语言“恳求”卡迪尔的“帮助”由此将自己的行动置于最有利的位置，以实现自己找工作或寻求贷款的目标，进而有意无意地使自己的行动策略为公共合法性的构建做出了贡献。“双重象征操控”强调了富人剥削的委婉化表述和“弱者”行动策略的“互惠”机制，富人或精英的支配需要“双重象征操控”的互惠机制才能得以实现。当然，这一“双重象征操控”的实现不是互惠原则所能概括的，斯科特关于支配与抵抗艺术的进一步研究表明，有权者极为关心如何使象征符合其支配形式，而从属者通常都具有充足的理由去帮助支配者维持其象征，或至少不会公开与之抵触，这就表现为支配、抵抗艺术中公开剧本和潜隐剧本之间复杂的权力关系。",
    "reference_list": "考点1. “民间意识形态”推荐译为“Popular Ideology”\n考点2. “弱者的日常抵抗”推荐译为“Everyday Forms of Peasant Resistance”\n考点3. “问题意识”推荐译为“Problematic; Core Problematic”\n考点4. “磨洋工”推荐译为“Foot-dragging; Slacking off”\n考点5. “含情脉脉”推荐译为“Tender; Sentimental”\n考点6. “付之阙如”推荐译为“(is) conspicuously absent; (appears to be) a lacuna”\n考点7. “姜士彬” 必须译为“David Johnson”\n考点8. “葛希芝” 必须译为“Hill Gates”\n考点9. “统治”推荐译为“rule”\n考点10. “霸权”推荐译为“hegemonic position”\n考点11. “正统化的民间宗教实践”推荐译为“orthodox-style popular religious practice”\n考点12. “隐蔽”推荐译为““to conceal; to hide””\n考点13. “民俗”推荐译为“folkloric system; a system of folk customs”\n考点14. “整体性”推荐译为“wholeness; totality”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "122"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n1.1 Rationale of the study  \nWe live in a world of advertising. As potential consumers, we are endlessly bombarded with all kinds of product or service information from various media including newspapers, magazines, television, radio, posters and Internet, etc. Advertising provides a valuable service to society and its members, because it defines for consumers the meaning and the role of products, services, and institutions. It indicates the difference that exists between brands of products and alternative services, as well as the distinguishing characteristics of companies and institutions. Advertising also tells the consumer what a specific product, brand or service should do when it is used and thus helps him or her to understand and evaluate experience with the products and services that he or she uses. On the other hand, by making people aware of products, service and ideas, advertising promotes sales and profits. Finally, advertising is one of the major forces that are helping improve the standard of living around the world. Combined with all these communicational, marketing and social functions. Advertising becomes indispensable in the modern world.  \n  \nNaturally, advertisements in English have become an important means of communicating ideas, demonstrating a variety of linguistic features of its own. The present study attempts to examine these features at the lexical, syntactic and discourse levels, in the hope of bringing them to light and, thereby, offering help to advertisement writers and language learners.  \n  \n1.2 Definition of advertising  \nAccording to the Definition Committee of American Marketing Association(方薇, 1997:2), advertising is defined as follows:  \n  \nAdvertising is the nonpersonal communication of information usually paid for and usually persuasive in nature about products, services or ideas by identified sponsors through the various media.  \n  \n1.3 Focus of the present study  \nUsually, advertising communicates information in three types: audio, visual, and language. It is a more common case that an advertisement is a mixture of the three. In radio advertisements, music is always accompanied by language; on TV and motion pictures, music and language illustration are mixed with each other. In magazines and newspapers, advertisements are a combination of pictures and language of written information. Although music and pictures can provide some hints, or create a kind of atmosphere, the information about the product is limited. Even worse, it may lead to misunderstanding. Thus, we may say that language in a way provides more exact, detailed and dependable information whereas music and pictures only act as a supplementary means in advertising. Advertising language, playing a role of communication and persuasion, has developed its own features.  \n  \nThis paper will focus on the language features of English advertisements at lexical, syntactic and discourse levels. It is hoped, by a contrastive study of advertisements on three types of products (daily consumer goods, technical equipment and service), similarities and differences of the three types of advertisements will be summarized and possible reasons will be given in the light of the meaning, and function of language.  \n  \n1.4 Sources of data  \nAll the advertisements studied in this paper are taken from English magazines. They are chosen from Time, People and Newsweek (issues from 1999-2000), because these three magazines have a huge circulation, covering all kinds of audience. Almost all kinds of advertisements can be found in these magazines. In order to get valuable information for the study, a corpus of 60 advertisements was built, which consists of 20 daily consumer goods ads, 20 technical equipment ads, and 20 service ads. Conclusions will be drawn through quantitative and qualitative studies of the data.  \n  \n2 Lexical Features  \n2.1 Classification of advertising and its audience  \nGenerally speaking, advertisements can be divided into two types: public relation ads and commercial ads. The former tries to advocate reputation for a social group, whose purpose is to leave a favorable impression upon the potential audience. The latter leads to the act of purchasing the products or using the recommended service. Commercial ads are much more presented through mass media for the reason that manufacturers and companies are willing to spend a large sum of money to make a certain product known or to boost the image of a certain brand. In some cases, competitors, like Coca-cola and Perpsi, even spare no expense to launch advertising campaigns to win over the market share. Commercial advertising can also be divided according to the target audience into two groups: consumer advertising and business advertising. Most of the ads in the mass media are consumer advertisements. They are typically directed at consumers. By contrast, business advertising tends to be concentrated in specialized business publications, professional journals, trade shows targeting at a certain group of people involved in some business. Since consumer advertising is most accessible to common people, the present study on will focus on consumer advertising. The classification of advertising is clearly shown in the following graph:  \n  \nThe bold parts show the scope of advertisements we study. Daily consumer goods are necessities of daily life, such as food, detergent, hygiene, etc. Technical equipment is technical toys and electric equipment such as camera, vehicle, hi-fi, etc. Service covers bank, insurance, fund, etc.  \n  \nActually, advertising works effectively some of the time and doesn’t work other times. The single crucial reason that advertising does not work is that in specific instances the information it conveys never reaches the consumer at all, or is judged by the consumer to be either redundant, meaningless, or irrelevant. For example, a motorbike advertisement will probably be invisible to housewives on the lookout for new cutlery. Social status and individual interest decide that consumer goods ads are mainly targeting at women while technical equipment ads are largely aiming at men. The amount of shared knowledge between the advertiser and the audience together with the thinking habit of the audience directly influences the advertising language. Since products and audience change in every advertisement in order to achieve high advertising effectiveness, language used differs in different types of advertisements. Thus, in this paper we discuss not only the similarities of language shared by all types of advertisements but also differences of language used in different kinds of advertisements.  \n  \n2.2 Similarities at the lexical level  \nIn order to make the information accessible to audience effectively, the choice of words in advertising is very cautious and skillful. The aim of the advertiser is quite specific. He wishes to capture the attention of the members of a mass audience and by means of impressive words to persuade them to buy a product or behave in a particular way, such as going to Hawaii for all their holiday needs. Both linguistic and psychological aspects are taken into consideration in the choice of words. Sharing the same purpose of advertising－to familiarize or remind consumers of the benefits of particular products in the hope of increasing sales, the techniques used at the lexical level by advertisers do not vary markedly. The following points are some prominent similarities.",
    "ori_text": "1.1 Rationale of the study  \nWe live in a world of advertising. As potential consumers, we are endlessly bombarded with all kinds of product or service information from various media including newspapers, magazines, television, radio, posters and Internet, etc. Advertising provides a valuable service to society and its members, because it defines for consumers the meaning and the role of products, services, and institutions. It indicates the difference that exists between brands of products and alternative services, as well as the distinguishing characteristics of companies and institutions. Advertising also tells the consumer what a specific product, brand or service should do when it is used and thus helps him or her to understand and evaluate experience with the products and services that he or she uses. On the other hand, by making people aware of products, service and ideas, advertising promotes sales and profits. Finally, advertising is one of the major forces that are helping improve the standard of living around the world. Combined with all these communicational, marketing and social functions. Advertising becomes indispensable in the modern world.  \n  \nNaturally, advertisements in English have become an important means of communicating ideas, demonstrating a variety of linguistic features of its own. The present study attempts to examine these features at the lexical, syntactic and discourse levels, in the hope of bringing them to light and, thereby, offering help to advertisement writers and language learners.  \n  \n1.2 Definition of advertising  \nAccording to the Definition Committee of American Marketing Association(方薇, 1997:2), advertising is defined as follows:  \n  \nAdvertising is the nonpersonal communication of information usually paid for and usually persuasive in nature about products, services or ideas by identified sponsors through the various media.  \n  \n1.3 Focus of the present study  \nUsually, advertising communicates information in three types: audio, visual, and language. It is a more common case that an advertisement is a mixture of the three. In radio advertisements, music is always accompanied by language; on TV and motion pictures, music and language illustration are mixed with each other. In magazines and newspapers, advertisements are a combination of pictures and language of written information. Although music and pictures can provide some hints, or create a kind of atmosphere, the information about the product is limited. Even worse, it may lead to misunderstanding. Thus, we may say that language in a way provides more exact, detailed and dependable information whereas music and pictures only act as a supplementary means in advertising. Advertising language, playing a role of communication and persuasion, has developed its own features.  \n  \nThis paper will focus on the language features of English advertisements at lexical, syntactic and discourse levels. It is hoped, by a contrastive study of advertisements on three types of products (daily consumer goods, technical equipment and service), similarities and differences of the three types of advertisements will be summarized and possible reasons will be given in the light of the meaning, and function of language.  \n  \n1.4 Sources of data  \nAll the advertisements studied in this paper are taken from English magazines. They are chosen from Time, People and Newsweek (issues from 1999-2000), because these three magazines have a huge circulation, covering all kinds of audience. Almost all kinds of advertisements can be found in these magazines. In order to get valuable information for the study, a corpus of 60 advertisements was built, which consists of 20 daily consumer goods ads, 20 technical equipment ads, and 20 service ads. Conclusions will be drawn through quantitative and qualitative studies of the data.  \n  \n2 Lexical Features  \n2.1 Classification of advertising and its audience  \nGenerally speaking, advertisements can be divided into two types: public relation ads and commercial ads. The former tries to advocate reputation for a social group, whose purpose is to leave a favorable impression upon the potential audience. The latter leads to the act of purchasing the products or using the recommended service. Commercial ads are much more presented through mass media for the reason that manufacturers and companies are willing to spend a large sum of money to make a certain product known or to boost the image of a certain brand. In some cases, competitors, like Coca-cola and Perpsi, even spare no expense to launch advertising campaigns to win over the market share. Commercial advertising can also be divided according to the target audience into two groups: consumer advertising and business advertising. Most of the ads in the mass media are consumer advertisements. They are typically directed at consumers. By contrast, business advertising tends to be concentrated in specialized business publications, professional journals, trade shows targeting at a certain group of people involved in some business. Since consumer advertising is most accessible to common people, the present study on will focus on consumer advertising. The classification of advertising is clearly shown in the following graph:  \n  \nThe bold parts show the scope of advertisements we study. Daily consumer goods are necessities of daily life, such as food, detergent, hygiene, etc. Technical equipment is technical toys and electric equipment such as camera, vehicle, hi-fi, etc. Service covers bank, insurance, fund, etc.  \n  \nActually, advertising works effectively some of the time and doesn’t work other times. The single crucial reason that advertising does not work is that in specific instances the information it conveys never reaches the consumer at all, or is judged by the consumer to be either redundant, meaningless, or irrelevant. For example, a motorbike advertisement will probably be invisible to housewives on the lookout for new cutlery. Social status and individual interest decide that consumer goods ads are mainly targeting at women while technical equipment ads are largely aiming at men. The amount of shared knowledge between the advertiser and the audience together with the thinking habit of the audience directly influences the advertising language. Since products and audience change in every advertisement in order to achieve high advertising effectiveness, language used differs in different types of advertisements. Thus, in this paper we discuss not only the similarities of language shared by all types of advertisements but also differences of language used in different kinds of advertisements.  \n  \n2.2 Similarities at the lexical level  \nIn order to make the information accessible to audience effectively, the choice of words in advertising is very cautious and skillful. The aim of the advertiser is quite specific. He wishes to capture the attention of the members of a mass audience and by means of impressive words to persuade them to buy a product or behave in a particular way, such as going to Hawaii for all their holiday needs. Both linguistic and psychological aspects are taken into consideration in the choice of words. Sharing the same purpose of advertising－to familiarize or remind consumers of the benefits of particular products in the hope of increasing sales, the techniques used at the lexical level by advertisers do not vary markedly. The following points are some prominent similarities.",
    "reference_list": "考点1：“bringing them to light”推荐译为“揭示这些特点”\n考点2：“identified sponsors”中的“sponsor”应译为“广告主”，因此完整译文应该是“署名广告主”\n考点3：“on the lookout for”推荐译为“留意寻找”\n考点4：“circulation”应译为“发行量”\n考点5：“public relation ads”是广告分类的一个标准术语，应译为“公关广告”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "47"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n\tTaking advantage of online data collection and game-based assessment, we characterized comprehensive developmental trajectories of spatial cognition and its malleability in the present study. We found an a synchrony between the development of spatial cognitive performance and that of its malleability, as the learning rate peaked about 10 years earlier than performance on mental rotation. On the other hand, malleability also depended on the maturation of spatial ability, as children under the age of 10 showed particularly low malleability, which likely resulted from their underdeveloped ability of mirror image discrimination. In short, by combining both coarse but massive online data and fine tuned experimental data, our study illustrates the interaction of spatial cognition and its malleability during development, which also sheds light on translational implications for STEM related educational practice. The developmental trajectory of mental rotation performance observed here is consistent with previous reports on development in adulthood of spatial abilities based on laboratory studies (Wilson et al., 1975). Also, the widespread malleability of mental rotation across the life span is in line with the reported malleability of spatial abilities in various developmental stages (Bavelier et al., 2012; Feng et al., 2007; Uttal, Miller, et al.,2013). The convergence with the findings of traditional laboratory studies (Germine et al., 2012; Hartshorne &Germine, 2015) endorses the reliability and validity of the online game based assessment approach in the present study. Importantly, our study extended previous studies in two aspects. First, our results filled the gap between the known developmental trends of spatial abilities in childhood (Frick et al., 2013; Hawes et al.,2015;  Marmor,  1975) and adulthood (Wilson et al., 1975)by providing information on the transition between childhood and adulthood and by depicting a continuous development trajectory across the life span with the same task. \nSecond, the present study comprehensively examined the malleability of spatial ability from childhood to adulthood, identifying late adolescence (16–20years old) as a critical period when individuals are most sensitive to training on mental rotation in particular and possibly spatial cognition in general. A particularly intriguing finding of the present study is the a synchrony between the development of performance and its malleability. The asynchronous developmental paces of malleability and performance have been documented in other cognitive domains, such as language acquisition (Snow & Hoefnagel Höhle, 1978),implying a general principle for the development of cognitive functions. For instance, the training effect from daily practice in spatial cognition may accumulate through development and thus lays the foundation for performance change. Supporting this idea, our results showed that in adolescent and adult age groups, individuals with higher performance also showed higher malleability. On the other hand, both the exploratory online test and the confirmatory experiment suggest that mirror image discrimination might be a gate keeping ability that constrained the malleability of young children. This result is consistent with previous findings that children at the age of 7 to 8 or even older cannot reliably perform above chance in mental rotation tasks involving mirror image discrimination (Aaron & Malatesha, 1974;Hawes et al., 2015). The particular difficulty of mirror image discrimination, which persists across the life span(Bornstein et al., 1978; Gibson et al., 1962; Gregory &McCloskey, 2010), suggests that it may involve unique cognitive mechanisms not implicated in the discrimination of rotated stimuli. Indeed, a previous study shows that children at the age of 6 show a steady decrease in error rate in discriminating 3D objects of different orientations, but the rate of mirror image confusion stays high at least until 7 years old (Hawes et al., 2015). \nVarious cognitive mechanisms may contribute to the particular difficulty of mirror image discrimination of children. For instance, Paschke et al. (2012) suggest that mirrored images fit less to the top-down expectation; Hamm et al. (2004) propose that mirror image discrimination requires an additional “flip” of the stimuli out oft he picture plane, which requires more complex transformation of mental representation; McCloskey et al.(2006) suggest that mirror image discrimination requires additionally representing polarity correspondence between the object and the extrinsic axes, which likely poses challenges to young children (see also Gregory& McCloskey, 2010). Our study revealed that the ages between 8 and 9 were critical for developing the ability of mirror image discrimination. Therefore, future studies can test these three hypotheses with children at this age by examining whether mirror image discrimination co­exists with the contributing cognitive functions proposed by these hypotheses. Indeed, the present study suggests that mirror image discrimination might hinder mental rotation performance and its malleability in a wider range of the life span. Visual inspection of Figure4c indicates that the high performers across age groups passed the mirror image trials without much difficulty and performance improves continually, resulting in a more linear shaped learning curve compared with the low performers. In contrast, the low performers needed a substantial amount of training to succeed in mirror image trials; therefore, the learning curve was flattened as an asymptotic line at the point of the mirror image trials. The finding that high malleability of spatial cognition occurred in late adolescence is of potentially great translational implication because of the transferability of mental rotation training effects into other spatial skills(Meneghetti et al., 2016; Terlecki & Newcombe, 2005;Uttal, Meadow, et al., 2013) as well as into STEM related performance (Stransky et al., 2010). That is, training on spatial abilities may be most effective for adolescents and young adults, whereas elementary school children may not benefit as much from it. However, the training should be merit based because there were significant individual differences in malleability as revealed in this study. Finally, the training may not be fully effective until the gatekeeping ability is mastered. In addition, the present study replicated gender difference in mental rotation in the literature with a large sample. Although the male advantage in mental rotation has been well established in the literature, the source of this advantage has been a subject of debate, with arguments emphasizing either biological or experience/cultural factors (Miller & Halpern, 2014). The late emergence of gender difference observed in our study (i.e.,its presence in adolescence and early adulthood but not in childhood) implies the influence of experience related and/or environmental factors, consistent with findings of cross national research (e.g., Levine et al.,2005) and studies on gender stereotype threat (e.g.,Schmader, 2010). For instance, males might be encouraged more to participate in spatial related tasks since childhood than females, and sufficient practice leads to performance advantage in adolescence, which might encourage further participation in spatial related tasks and a persistent male advantage in the following developmental stages. However, it is also possible that the gradual unfolding of male advantage could be the result of late on set hormonal influence or sex dependent brain polymorphism, such as those taking place during and after puberty, though evidence of such influence is mixed in the literature (e.g., Herlitz et al., 2013). \nFurther, the experience related and/or environmental factors may interact with biological factors (Eagly & Wood,2013), as gender dependent educational experience and cultural expectation might facilitate the expression of phenotypes prescribed by biological factors. In sum, by combining both a coarse online test and a finetuned experiment, we depicted comprehensive developmental trajectories of spatial cognition and its malleability, which invites research on the development of other cognitive domains. However, our results should be interpreted with caution given several limitations with online studies. First, the participants were self-selected, and the sample composition was certainly biased by that of the user population of the host app. Also, the present study did not verify the accuracy of age reports made by the participants because we were unable to devise an effective safeguard/check for largescale online game-based data collection without making participants uncomfortable about their privacy. Therefore, some age reports might be inaccurate. However, this was unlikely to have distorted the pattern of the reported developmental trajectory because, given the large sample size of the present study, the noise caused by potential inaccurate age reports would have affected our estimation of all the age groups unselectively. Admittedly, the potential presence of inaccurate age reports may have led to an underestimation of developmental difference between age groups, and follow up small scale laboratory-based experiments are necessary to verify findings from the online experiment. Second, in the game-based assessment, participants reported their age information by selecting one of the age bins with the resolution of 5 years old (except theunder10 age group). \nThough this is a common practice in online game applications, it admittedly prevented us from depicting the developmental trajectory with finer resolution. This is particularly regrettable for the under10 age group and the 11–15 age group, in which rapid cognitive development in spatial cognition takes place. To some extent, the pen and paper test provided the missing piece by allowing us to analyze mental rotation ability between the ages of 6 and 13 to depict the change in mirror image discrimination ability during this period. More dedicated investigations are desirable to depict the developmental trajectory at this age range with finer resolution. Third, the online game-based assessment allowed us no control over the time span between participations or between participation activities. This might have led to additional noise in estimating the malleability of each age group. However, the variation in time span was unlikely to affect the relation between behavioral performance and its malleability of each age group differently. Fourth, online studies provide only cross sectional data. Therefore, follow-up longitudinal studies on the critical developmental periods identified by online studies are also necessary to rule out confounding factors such as the cohort effect. Fifth, in the present study, the malleability of spatial cognition was measured by the learning rate among multiple plays on mental rotation; therefore, malleability at the behavioral level may not fully capture plasticity in the neural substrates of mental rotation that may additionally reflect contributions from many factors other than training, such as lesion and sociocultural context. Future neuroimaging studies on the development of neural plasticity will likely provide an interesting comparison with the malleability solely from behavioral training. Finally, the findings of an asynchrony between performance and malleability and that of the coincidence between mirror image discrimination failure and low malleability of spatial cognition did not present causal links, and future work is needed to examine the causality among these factors.\n",
    "ori_text": "\n\n\tTaking advantage of online data collection and game-based assessment, we characterized comprehensive developmental trajectories of spatial cognition and its malleability in the present study. We found an a synchrony between the development of spatial cognitive performance and that of its malleability, as the learning rate peaked about 10 years earlier than performance on mental rotation. On the other hand, malleability also depended on the maturation of spatial ability, as children under the age of 10 showed particularly low malleability, which likely resulted from their underdeveloped ability of mirror image discrimination. In short, by combining both coarse but massive online data and fine tuned experimental data, our study illustrates the interaction of spatial cognition and its malleability during development, which also sheds light on translational implications for STEM related educational practice. The developmental trajectory of mental rotation performance observed here is consistent with previous reports on development in adulthood of spatial abilities based on laboratory studies (Wilson et al., 1975). Also, the widespread malleability of mental rotation across the life span is in line with the reported malleability of spatial abilities in various developmental stages (Bavelier et al., 2012; Feng et al., 2007; Uttal, Miller, et al.,2013). The convergence with the findings of traditional laboratory studies (Germine et al., 2012; Hartshorne &Germine, 2015) endorses the reliability and validity of the online game based assessment approach in the present study. Importantly, our study extended previous studies in two aspects. First, our results filled the gap between the known developmental trends of spatial abilities in childhood (Frick et al., 2013; Hawes et al.,2015;  Marmor,  1975) and adulthood (Wilson et al., 1975)by providing information on the transition between childhood and adulthood and by depicting a continuous development trajectory across the life span with the same task. \nSecond, the present study comprehensively examined the malleability of spatial ability from childhood to adulthood, identifying late adolescence (16–20years old) as a critical period when individuals are most sensitive to training on mental rotation in particular and possibly spatial cognition in general. A particularly intriguing finding of the present study is the a synchrony between the development of performance and its malleability. The asynchronous developmental paces of malleability and performance have been documented in other cognitive domains, such as language acquisition (Snow & Hoefnagel Höhle, 1978),implying a general principle for the development of cognitive functions. For instance, the training effect from daily practice in spatial cognition may accumulate through development and thus lays the foundation for performance change. Supporting this idea, our results showed that in adolescent and adult age groups, individuals with higher performance also showed higher malleability. On the other hand, both the exploratory online test and the confirmatory experiment suggest that mirror image discrimination might be a gate keeping ability that constrained the malleability of young children. This result is consistent with previous findings that children at the age of 7 to 8 or even older cannot reliably perform above chance in mental rotation tasks involving mirror image discrimination (Aaron & Malatesha, 1974;Hawes et al., 2015). The particular difficulty of mirror image discrimination, which persists across the life span(Bornstein et al., 1978; Gibson et al., 1962; Gregory &McCloskey, 2010), suggests that it may involve unique cognitive mechanisms not implicated in the discrimination of rotated stimuli. Indeed, a previous study shows that children at the age of 6 show a steady decrease in error rate in discriminating 3D objects of different orientations, but the rate of mirror image confusion stays high at least until 7 years old (Hawes et al., 2015). \nVarious cognitive mechanisms may contribute to the particular difficulty of mirror image discrimination of children. For instance, Paschke et al. (2012) suggest that mirrored images fit less to the top-down expectation; Hamm et al. (2004) propose that mirror image discrimination requires an additional “flip” of the stimuli out oft he picture plane, which requires more complex transformation of mental representation; McCloskey et al.(2006) suggest that mirror image discrimination requires additionally representing polarity correspondence between the object and the extrinsic axes, which likely poses challenges to young children (see also Gregory& McCloskey, 2010). Our study revealed that the ages between 8 and 9 were critical for developing the ability of mirror image discrimination. Therefore, future studies can test these three hypotheses with children at this age by examining whether mirror image discrimination co­exists with the contributing cognitive functions proposed by these hypotheses. Indeed, the present study suggests that mirror image discrimination might hinder mental rotation performance and its malleability in a wider range of the life span. Visual inspection of Figure4c indicates that the high performers across age groups passed the mirror image trials without much difficulty and performance improves continually, resulting in a more linear shaped learning curve compared with the low performers. In contrast, the low performers needed a substantial amount of training to succeed in mirror image trials; therefore, the learning curve was flattened as an asymptotic line at the point of the mirror image trials. The finding that high malleability of spatial cognition occurred in late adolescence is of potentially great translational implication because of the transferability of mental rotation training effects into other spatial skills(Meneghetti et al., 2016; Terlecki & Newcombe, 2005;Uttal, Meadow, et al., 2013) as well as into STEM related performance (Stransky et al., 2010). That is, training on spatial abilities may be most effective for adolescents and young adults, whereas elementary school children may not benefit as much from it. However, the training should be merit based because there were significant individual differences in malleability as revealed in this study. Finally, the training may not be fully effective until the gatekeeping ability is mastered. In addition, the present study replicated gender difference in mental rotation in the literature with a large sample. Although the male advantage in mental rotation has been well established in the literature, the source of this advantage has been a subject of debate, with arguments emphasizing either biological or experience/cultural factors (Miller & Halpern, 2014). The late emergence of gender difference observed in our study (i.e.,its presence in adolescence and early adulthood but not in childhood) implies the influence of experience related and/or environmental factors, consistent with findings of cross national research (e.g., Levine et al.,2005) and studies on gender stereotype threat (e.g.,Schmader, 2010). For instance, males might be encouraged more to participate in spatial related tasks since childhood than females, and sufficient practice leads to performance advantage in adolescence, which might encourage further participation in spatial related tasks and a persistent male advantage in the following developmental stages. However, it is also possible that the gradual unfolding of male advantage could be the result of late on set hormonal influence or sex dependent brain polymorphism, such as those taking place during and after puberty, though evidence of such influence is mixed in the literature (e.g., Herlitz et al., 2013). \nFurther, the experience related and/or environmental factors may interact with biological factors (Eagly & Wood,2013), as gender dependent educational experience and cultural expectation might facilitate the expression of phenotypes prescribed by biological factors. In sum, by combining both a coarse online test and a finetuned experiment, we depicted comprehensive developmental trajectories of spatial cognition and its malleability, which invites research on the development of other cognitive domains. However, our results should be interpreted with caution given several limitations with online studies. First, the participants were self-selected, and the sample composition was certainly biased by that of the user population of the host app. Also, the present study did not verify the accuracy of age reports made by the participants because we were unable to devise an effective safeguard/check for largescale online game-based data collection without making participants uncomfortable about their privacy. Therefore, some age reports might be inaccurate. However, this was unlikely to have distorted the pattern of the reported developmental trajectory because, given the large sample size of the present study, the noise caused by potential inaccurate age reports would have affected our estimation of all the age groups unselectively. Admittedly, the potential presence of inaccurate age reports may have led to an underestimation of developmental difference between age groups, and follow up small scale laboratory-based experiments are necessary to verify findings from the online experiment. Second, in the game-based assessment, participants reported their age information by selecting one of the age bins with the resolution of 5 years old (except theunder10 age group). \nThough this is a common practice in online game applications, it admittedly prevented us from depicting the developmental trajectory with finer resolution. This is particularly regrettable for the under10 age group and the 11–15 age group, in which rapid cognitive development in spatial cognition takes place. To some extent, the pen and paper test provided the missing piece by allowing us to analyze mental rotation ability between the ages of 6 and 13 to depict the change in mirror image discrimination ability during this period. More dedicated investigations are desirable to depict the developmental trajectory at this age range with finer resolution. Third, the online game-based assessment allowed us no control over the time span between participations or between participation activities. This might have led to additional noise in estimating the malleability of each age group. However, the variation in time span was unlikely to affect the relation between behavioral performance and its malleability of each age group differently. Fourth, online studies provide only cross sectional data. Therefore, follow-up longitudinal studies on the critical developmental periods identified by online studies are also necessary to rule out confounding factors such as the cohort effect. Fifth, in the present study, the malleability of spatial cognition was measured by the learning rate among multiple plays on mental rotation; therefore, malleability at the behavioral level may not fully capture plasticity in the neural substrates of mental rotation that may additionally reflect contributions from many factors other than training, such as lesion and sociocultural context. Future neuroimaging studies on the development of neural plasticity will likely provide an interesting comparison with the malleability solely from behavioral training. Finally, the findings of an asynchrony between performance and malleability and that of the coincidence between mirror image discrimination failure and low malleability of spatial cognition did not present causal links, and future work is needed to examine the causality among these factors.\n",
    "reference_list": "考点1： “ mirror image trials ” 推荐译为 “ 镜像实验”在本文语境中,可以发现trials实际上指代的是实验.\n考点2： “ game-based assessment ” 推荐译为 “ 基于游戏的测评 ”\n考点3： “ noise” 推荐译为 “ 随机误差 ”需确保“随机性”限定词不能省略\n考点4 ： “ general principle ” 在本文语境中推荐译为 推荐译为 “ 一般规律 ”\n考点5： “ the reported ” 在本文语境中推荐译为 “ 报告 ”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "105"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n在音乐综艺《歌手2025》第四期，新生代实力女歌手单依纯甩着红发，对李荣浩创作的歌曲《李白》进行了颠覆性改编。打破原曲乡村摇滚框架，融入电子音效、游戏术语、即兴念白等元素，“诗人李白”被重构为“游戏李白”，她的改编犹如一枚重磅炸弹，成为近期全网热议焦点。单依纯念出的“我本是辅助，今晚来打野”“如何呢？又能怎？”等新增歌词在B站刷屏，而此前林志炫同样在《歌手2025》中精心设计的戏曲版《悟空》，却只留下“鹦鹉侠”的调侃标签，没有激起水花。\n\n同出一部音综，都是“魔改”歌曲，为何命运截然不同？流行音乐研究专业博士、杭州师范大学副教授赵朴在接受记者采访时，给出了犀利解析：成功的“魔改”必须同时具备有梗、有趣、有料三重基因。“‘魔改’需要让歌曲变得有一点儿面目全非，又不会完全认不出原作，如果力度不够大，就成平平无奇的翻唱。而真正出圈的改编，还必须同时满足互联网传播的网感、音乐设计的巧思、精神内核的重构。”\n\n有梗：点燃破圈传播的网感引擎\n在互联网传播时代，一首歌曲是否有梗，往往成为作品能否破圈的爆破点。单依纯版《李白》将游戏术语“打野”“辅助”植入歌词，节目播出后48小时内催生16个热搜话题。那反复吟唱的“如何呢？又能怎？”恰如当代青年面对焦虑的戏谑解药，不仅让办公室白领、校园学子自发玩梗，甚至吸引了从不看音综的“路人”侧目。“《李白》的新增歌词十分具有网感，通过纯享版、切片版给大众提供了社交谈资。”赵朴指出，相较之下，林志炫的《悟空》虽在唱腔、妆造上倾注心血，却因缺乏具象记忆点，最终沦为曲高和寡的艺术实验。\n\n也有曾经破圈的“魔改”歌曲深谙此道。比如麻园诗人在《乐队的夏天3》根据王心凌同名歌曲改编的《彩虹的微笑》，以笑中带泪、苦乐参半的真挚表达，触动了很多听者。当主唱苦果用撕裂般的哭腔唱甜歌、台上的小男孩翻起跟头，这童年与现实的残酷对撞，瞬间引发很多观众包括当时台下歌手大张伟的泪点。“我们面对生活的痛苦所做出的种种努力，无非只是想在这音乐里做一个翻跟头的孩子而已，因为那一刻叫作自由。”\n\n有趣：提供新鲜奇妙的听觉体验\n一首“魔改”歌曲如何让听众在赏乐过程中，感受到趣味性？这需要整体编曲与演唱设计的巧思。比如《李白》中后段插入的失真金属和弦，如同游戏特效般刺破耳膜；而单依纯刻意保留的破音、真假声转换时的瑕疵，恰似“酒中仙”李白“醉后失态”的声音化呈现。这种介于控制和失控之间的破绽，反而让技术缺陷转化为艺术表达的情感载体，使很多听众在“难评”的猎奇感中反复品味。\n\n互联网知名乐评人耳帝直言：“在《歌手2025》大量无趣的选歌与保守改编的局面下，单依纯的尝试很值得鼓励，因为这样节目才会好看。在敢玩的同时，她依然未失去唱功的展示，最后还有一个高质量的强声E5。”但趣味也需要分寸感。比如有网友指出《李白》的缺陷：“歌曲当中用了大量游戏术语，作为非游戏玩家，听得一头雾水。”相较而言，二手玫瑰在改编《偶遇》时，通过巴乌、木鱼等冷门乐器构建异质音场，营造了静谧的宛如佛乐的氛围，既保留了音乐的新鲜感，又不设理解门槛，因此得到了更多专业乐评人的认可。\n\n有料：构建具有深度的精神内核\n什么样的“魔改”能够超越暂时的网红效应，成为值得细品的文化现象？必然得有对“料”的坚守----将原本的歌曲挖掘出更深的内涵，或者构建出新的意义。\n比如B站上的音乐博主唐宋摇滚，穿着绯色大袖襕袍、头戴展脚幞头，抱一把木吉他，操着烟嗓唱歌，新近翻唱伍佰的《last dance（最后一舞）》播放量已接近450万。在旋律朗朗上口的基础上，唐宋摇滚的新写歌词被粉丝誉为“百万填词”。战场上的金戈铁马、建功立业的豪情壮志、儿女情仇的优柔慨叹，都寓于激情饱满的唱段之间。“没点文化，还真听不懂他玩的梗。”网友感叹，跟着歌声摇摆，得以一窥大宋风云。",
    "ori_text": "在音乐综艺《歌手2025》第四期，新生代实力女歌手单依纯甩着红发，对李荣浩创作的歌曲《李白》进行了颠覆性改编。打破原曲乡村摇滚框架，融入电子音效、游戏术语、即兴念白等元素，“诗人李白”被重构为“游戏李白”，她的改编犹如一枚重磅炸弹，成为近期全网热议焦点。单依纯念出的“我本是辅助，今晚来打野”“如何呢？又能怎？”等新增歌词在B站刷屏，而此前林志炫同样在《歌手2025》中精心设计的戏曲版《悟空》，却只留下“鹦鹉侠”的调侃标签，没有激起水花。\n\n同出一部音综，都是“魔改”歌曲，为何命运截然不同？流行音乐研究专业博士、杭州师范大学副教授赵朴在接受记者采访时，给出了犀利解析：成功的“魔改”必须同时具备有梗、有趣、有料三重基因。“‘魔改’需要让歌曲变得有一点儿面目全非，又不会完全认不出原作，如果力度不够大，就成平平无奇的翻唱。而真正出圈的改编，还必须同时满足互联网传播的网感、音乐设计的巧思、精神内核的重构。”\n\n有梗：点燃破圈传播的网感引擎\n在互联网传播时代，一首歌曲是否有梗，往往成为作品能否破圈的爆破点。单依纯版《李白》将游戏术语“打野”“辅助”植入歌词，节目播出后48小时内催生16个热搜话题。那反复吟唱的“如何呢？又能怎？”恰如当代青年面对焦虑的戏谑解药，不仅让办公室白领、校园学子自发玩梗，甚至吸引了从不看音综的“路人”侧目。“《李白》的新增歌词十分具有网感，通过纯享版、切片版给大众提供了社交谈资。”赵朴指出，相较之下，林志炫的《悟空》虽在唱腔、妆造上倾注心血，却因缺乏具象记忆点，最终沦为曲高和寡的艺术实验。\n\n也有曾经破圈的“魔改”歌曲深谙此道。比如麻园诗人在《乐队的夏天3》根据王心凌同名歌曲改编的《彩虹的微笑》，以笑中带泪、苦乐参半的真挚表达，触动了很多听者。当主唱苦果用撕裂般的哭腔唱甜歌、台上的小男孩翻起跟头，这童年与现实的残酷对撞，瞬间引发很多观众包括当时台下歌手大张伟的泪点。“我们面对生活的痛苦所做出的种种努力，无非只是想在这音乐里做一个翻跟头的孩子而已，因为那一刻叫作自由。”\n\n有趣：提供新鲜奇妙的听觉体验\n一首“魔改”歌曲如何让听众在赏乐过程中，感受到趣味性？这需要整体编曲与演唱设计的巧思。比如《李白》中后段插入的失真金属和弦，如同游戏特效般刺破耳膜；而单依纯刻意保留的破音、真假声转换时的瑕疵，恰似“酒中仙”李白“醉后失态”的声音化呈现。这种介于控制和失控之间的破绽，反而让技术缺陷转化为艺术表达的情感载体，使很多听众在“难评”的猎奇感中反复品味。\n\n互联网知名乐评人耳帝直言：“在《歌手2025》大量无趣的选歌与保守改编的局面下，单依纯的尝试很值得鼓励，因为这样节目才会好看。在敢玩的同时，她依然未失去唱功的展示，最后还有一个高质量的强声E5。”但趣味也需要分寸感。比如有网友指出《李白》的缺陷：“歌曲当中用了大量游戏术语，作为非游戏玩家，听得一头雾水。”相较而言，二手玫瑰在改编《偶遇》时，通过巴乌、木鱼等冷门乐器构建异质音场，营造了静谧的宛如佛乐的氛围，既保留了音乐的新鲜感，又不设理解门槛，因此得到了更多专业乐评人的认可。\n\n有料：构建具有深度的精神内核\n什么样的“魔改”能够超越暂时的网红效应，成为值得细品的文化现象？必然得有对“料”的坚守----将原本的歌曲挖掘出更深的内涵，或者构建出新的意义。\n比如B站上的音乐博主唐宋摇滚，穿着绯色大袖襕袍、头戴展脚幞头，抱一把木吉他，操着烟嗓唱歌，新近翻唱伍佰的《last dance（最后一舞）》播放量已接近450万。在旋律朗朗上口的基础上，唐宋摇滚的新写歌词被粉丝誉为“百万填词”。战场上的金戈铁马、建功立业的豪情壮志、儿女情仇的优柔慨叹，都寓于激情饱满的唱段之间。“没点文化，还真听不懂他玩的梗。”网友感叹，跟着歌声摇摆，得以一窥大宋风云。",
    "reference_list": "考点1：“鹦鹉侠”应译为“Parrot Man”。\n考点2：“激起水花”应译为“ barely made a ripple”。 \n考点3：“魔改”应译为“drastic modification”。\n考点4：“有料”应译为“rich-contented”。\n考点5：“出圈”应译为“go viral”。\n考点6：“网感”应译为“internet sensibility”。\n考点7：“戏谑解药”应译为“a playful antidote”。\n考点8：“曲高和寡”应译为“too highbrow to be popular”。\n考点9：“麻园诗人”应译为“Mayuan Poet”。\n考点10：“乐队的夏天3”应译为“The Big Band 3”。\n考点11：“难评”应译为“hard to describe”。\n考点12：“展脚幞头”应译为“zhanjiao futou”。\n考点13：“襕袍”应译为“lanpao”。\n考点14：“大宋风云”应译为“the epic sagas of the great Song Dynasty”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "60"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThe paper begins with a discussion of feasting in small-scale societies and suggests that recognizing the manner of articulation of three particular variables-the scale of participation and financing, the frequency and structure of occurrence, and the food resources used-is an effective starting point for gauging how politically charged feasts may have been, the actual social role feasting may have played, and the variation in feasting practices across space and through time. I then present the evidence for feasting in the Southwest from A.D. 850 to present, focusing particular attention on these three variables. I conclude the paper with a case study that highlights feasting as a political resource that is linked with, but subordinate to, other resources of power, especially the control of rituals and of the knowledge necessary to perform them.\nThere are two sides to all communal behaviors: one that integrates and one that differentiates. Communal feasts are no exception. By their very nature, feasts bring people together to experience one of life's biological necessities in a communal, social manner. The communal exchange and sharing of food may be considered one of the most fundamental human transactions that, through social interaction and exchange, promotes social integration. This integrative aspect of feasting can have significant social and economic consequences. As Rappaport and Ford have noted, feasting can be an important mechanism for redistributing food among community members, and thus can be instrumental in promoting economic and social interdependence among community members. At the same time, to varying degrees, feasting can be an active context in which social hierarchy is established. Indeed, the hosting of feasts may be a particularly effective means through which to demonstrate one's economic and political abilities, and to engender prestige and the support of followers. Numerous aspects of feasting operate as public counting and ordering devices, which in turn reduce the vagueness of a social and political situation by promoting social comparison. For example, depending upon the quantity and quality of resources mobilized for communal feasts, and the frequency with which they are mobilized, feasting can be a quantitative measure of the abilities of the host as an efficient, skillful, vital, and generous leader. Since organizing and financing communal feasts often involves the cooperation of multiple individuals (e.g., communal hunts or large-scale domestic animal slaughters often precede communal feasts), large and elaborate feasts indicate that the host has control over the labor of others and is an efficient mobilizer of cooperative effort and, thus, a potential leader. Moreover, the degree to which the host successfully coordinates intercommunity participation at feasts is a particularly strong incentive for community allegiance and support, especially in situations involving supra-community alliances, exchange and marriage relations, conflict, and competition notes, \"when food distributions are financed from outside，such as in many Highland New Guinea Big-man societies, abundance of food also is an indicator of a broad network of supportive social ties.\" Finally, if rare, exotic, or highly valued resources are presented and consumed in a feast, both the host's success as a procurer of these resources and, potentially, the host's control of sacred knowledge (i.e., the knowledge of how to acquire the exotic or rare resources) may be demonstrated by hosting a particularly successful feast.These display/performance aspects of communal feasting that promote social comparison operate in tandem with feasting's more fundamental capacity as a vehicle for engendering political support by creating debt-obligations through the unequal imparting of gifts and food). The creation of debt obligation is, in many anthropologists' eyes, a fundamental aspect of feasting that makes it a potent political vehicle .\nHowever, indebtedness may not be an effective political resource unless there are social or technological mechanisms in place that allow for the monopolization of the resources necessary to finance a feast so that a number of potential followers incur debt without the means for repayment by either paying off the debt or financing their own feast. It is only under these conditions that feasts may be used effectively to amplify and maintain social differences over the long term (e.g., a generation), regardless of the productivity of the environment. In addition, financing a feast may place the host in considerable debt to the host's supporters, a situation that may actually lessen the status of the host as an independent leader. \nCommunal feasting also may be part of healing ceremonies, which are not usually structured by ritual cycles but which must occur on a fairly regular basis to prevent or cure illness. The Blessingway ceremony of the Navajo, for example, involves the feeding of the audience, which can sometimes number in the thousandsThese points are addressed below.There is tremendous variation in what has been termed feasting in middle-range societies. Most discussions of this variation have been couched in terms of ideal \"types\".The approach taken here, while not denying the utility of types as analytical constructs, focuses more on three particular dimensions of feasting that can combine in a number of ways to produce a variety of social and economic effects: 1) the scale of participation and financing; 2) the frequency and structure of occurrence; and 3) the food resources used.\nCommunal feasts can range in scale from those in which a single household sponsors a feast for bilateral relatives or other households to those hosted by entire villages and offered to members of multiple communities. The scale of most communal feasts ranks somewhere between these two extremes. Among the Mae Enga and Chimbu of Highland New Guinea, feasts may be hosted by tribes (made up of clans), clans, subclans, or lineages. Many feasts in Puebloan communities are sponsored by multiple households within a community, with much of the community invited (or obligated) to participate . To a large extent, the means through which a feast is financed, and ultimately the purpose of the feast, determines its scale. Here it is useful to distinguish between household-level finance and supra-household finance . Assuming there are inherent limits on home production as a means of expanding the resource base of a feast, the establishment of social relations outside the lineage or household through sodality membership, marriage, exchange, or indebtedness all become paramount to hosting and financing largescale feasts. Postcontact Mae Enga big men of highland New Guinea, for example, may draw upon upwards of 2,000 followers for a single feast . The greater the scale of the feast, the greater the potential for prestige enhancement on the part of sponsors. Moreover, using feasting as a recurrent social practice to enhance prestige usually requires financing on a larger scale than that of the single household or lineage (Young 1985). Scale also may relate to whether feasts are primarily \"intra-communal\" or \"inter-communal\" affairs (although this distinction is often hard to make ethnographically.) Hayden (1995), for instance, delineates within-group feasts, which he terms \"solidarity feasts,\" and between-group feasts, which are either \"reciprocal\" or \"competitive\" feasts. Reciprocal feasts function primarily to create alliances and promote cooperation among groups, while competitive feasts are hosted primarily to enhance the prestige, and political and economic support, of an aggrandizer and his/her followers or to negotiate and reaffirm extra-community political ties and agreement.Many within-group feasts have the principal effect of facilitating social integration or redistributing food among households within the village . Feasts of this type are usually financed by multiple households (often anonymously) and tend to be relatively non-competitive in nature. Compared to situations in which sponsors compete to enhance their prestige by contributing more to a feast than other sponsors, the inherent anonymity of, and lack of direct competition for, prestige in many intra-community integrative feasts tends to limit the quanitity of resources mobilized. In contrast, when feasts involve more than one community, cooperative effort on the part of village coresidents often facilitates the financing of larger and more elaborate feasts than is possible in intra-village contexts. It is in the context of inter-community (or large-scale) feasts that the prestige of aggrandizers becomes greatly enhanced relative to their followers.Much of the variation in occurrence of feasts is related to the degree to which feasting is regulated by the structure of ritual. Feasting often is associated with calendrical rituals that occur at prescribed times of the year. The kyanakwe feasting ceremony of the Zuni, for example, is held four times a year. Many feasts are held only once every several years. The Kaiko ritual of the Tsembaga of New Guinea may take place only once every 7 to 15 years . The scale of these feasts is smaller than that of unregulated or ad hoc feasts. Kaiko ritual feasts involve the participation of hundreds of people from several communities. Yet, over a year-long period of ritual feasting, only a hundred or so pigs may be killed by members of a single community. In contrast, the highly competitive, \"less regulated\" (in terms of scheduling) feasting of the Mae Enga of Highland New Guinea may involve the killing of up to 240 pigs per feast, and there may be several feasts per year, depending upon the productivity (and production) of feasting resources, as well as the number of aspiring leaders competing for prestige . Thus, ad hoc feasts are often geared more toward the enhancement of prestige than are feasts that are highly structured by a ritual cycle. Moreover, the feasibility of ad hoc feasts as aggrandizing vehicles may be restricted by the potential of the subsistence economy to generate a surplus . Societies with seasonally structured subsistence abundances may be restricted to feasting in the contexts of seasonally structured ritual feasts. This is especially the case in the context of the unpredictable yields of hunting and gathering and dry-farm agriculture.\nThe scheduling of feasts associated with rite-ofpassage rituals, such as weddings and initiation rituals, and with life-crisis events, such as mourning rituals, may not be \"regulated\" to the same degree as feasts connected with a ritual cycle. Mourning rituals, for instance, can take place months or years after a death, allowing a family to collect the necessary food and goods. Mortuary feasts are indeed prime aggrandizing events in various parts of North America and Melanesia . Initiation rites also may be postponed until there are enough initiates (i.e., the wherewithal to hold appropriately elaborate ceremonies) . On the other hand, male initiation rites in many large-scale New Guinean societies were highly regulated in the sense of occurring at regular intervals. These ceremonies are conducted by part-time ritual specialists (hatathli) but are hosted by the patient and the patient's family. Thus, this feasting is not competitive, but an obligation of the patient and his entourage. In contrast to feasts hosted by self-selected aggrandizers, the fact that the host is \"chosen\" more or less randomly (i.e., whoever gets sick) creates a situation in which feasting operates to distribute rather than consolidate responsibility, and perhaps prestige, and serves as an element in a larger ritual structure that operates to maintain community and tribal integration。In contrast, in New Guinea, feasts associated with healing ceremonies can be an avenue for prestige-enhancement on the part of big men. The relatives of the \"victim\" may organize and finance the feast, and particularly competitive individuals can search out opportunities (i.e., sick relatives) to exploit by feasting.",
    "ori_text": "\n\nThe paper begins with a discussion of feasting in small-scale societies and suggests that recognizing the manner of articulation of three particular variables-the scale of participation and financing, the frequency and structure of occurrence, and the food resources used-is an effective starting point for gauging how politically charged feasts may have been, the actual social role feasting may have played, and the variation in feasting practices across space and through time. I then present the evidence for feasting in the Southwest from A.D. 850 to present, focusing particular attention on these three variables. I conclude the paper with a case study that highlights feasting as a political resource that is linked with, but subordinate to, other resources of power, especially the control of rituals and of the knowledge necessary to perform them.\nThere are two sides to all communal behaviors: one that integrates and one that differentiates. Communal feasts are no exception. By their very nature, feasts bring people together to experience one of life's biological necessities in a communal, social manner. The communal exchange and sharing of food may be considered one of the most fundamental human transactions that, through social interaction and exchange, promotes social integration. This integrative aspect of feasting can have significant social and economic consequences. As Rappaport and Ford have noted, feasting can be an important mechanism for redistributing food among community members, and thus can be instrumental in promoting economic and social interdependence among community members. At the same time, to varying degrees, feasting can be an active context in which social hierarchy is established. Indeed, the hosting of feasts may be a particularly effective means through which to demonstrate one's economic and political abilities, and to engender prestige and the support of followers. Numerous aspects of feasting operate as public counting and ordering devices, which in turn reduce the vagueness of a social and political situation by promoting social comparison. For example, depending upon the quantity and quality of resources mobilized for communal feasts, and the frequency with which they are mobilized, feasting can be a quantitative measure of the abilities of the host as an efficient, skillful, vital, and generous leader. Since organizing and financing communal feasts often involves the cooperation of multiple individuals (e.g., communal hunts or large-scale domestic animal slaughters often precede communal feasts), large and elaborate feasts indicate that the host has control over the labor of others and is an efficient mobilizer of cooperative effort and, thus, a potential leader. Moreover, the degree to which the host successfully coordinates intercommunity participation at feasts is a particularly strong incentive for community allegiance and support, especially in situations involving supra-community alliances, exchange and marriage relations, conflict, and competition notes, \"when food distributions are financed from outside，such as in many Highland New Guinea Big-man societies, abundance of food also is an indicator of a broad network of supportive social ties.\" Finally, if rare, exotic, or highly valued resources are presented and consumed in a feast, both the host's success as a procurer of these resources and, potentially, the host's control of sacred knowledge (i.e., the knowledge of how to acquire the exotic or rare resources) may be demonstrated by hosting a particularly successful feast.These display/performance aspects of communal feasting that promote social comparison operate in tandem with feasting's more fundamental capacity as a vehicle for engendering political support by creating debt-obligations through the unequal imparting of gifts and food). The creation of debt obligation is, in many anthropologists' eyes, a fundamental aspect of feasting that makes it a potent political vehicle .\nHowever, indebtedness may not be an effective political resource unless there are social or technological mechanisms in place that allow for the monopolization of the resources necessary to finance a feast so that a number of potential followers incur debt without the means for repayment by either paying off the debt or financing their own feast. It is only under these conditions that feasts may be used effectively to amplify and maintain social differences over the long term (e.g., a generation), regardless of the productivity of the environment. In addition, financing a feast may place the host in considerable debt to the host's supporters, a situation that may actually lessen the status of the host as an independent leader. \nCommunal feasting also may be part of healing ceremonies, which are not usually structured by ritual cycles but which must occur on a fairly regular basis to prevent or cure illness. The Blessingway ceremony of the Navajo, for example, involves the feeding of the audience, which can sometimes number in the thousandsThese points are addressed below.There is tremendous variation in what has been termed feasting in middle-range societies. Most discussions of this variation have been couched in terms of ideal \"types\".The approach taken here, while not denying the utility of types as analytical constructs, focuses more on three particular dimensions of feasting that can combine in a number of ways to produce a variety of social and economic effects: 1) the scale of participation and financing; 2) the frequency and structure of occurrence; and 3) the food resources used.\nCommunal feasts can range in scale from those in which a single household sponsors a feast for bilateral relatives or other households to those hosted by entire villages and offered to members of multiple communities. The scale of most communal feasts ranks somewhere between these two extremes. Among the Mae Enga and Chimbu of Highland New Guinea, feasts may be hosted by tribes (made up of clans), clans, subclans, or lineages. Many feasts in Puebloan communities are sponsored by multiple households within a community, with much of the community invited (or obligated) to participate . To a large extent, the means through which a feast is financed, and ultimately the purpose of the feast, determines its scale. Here it is useful to distinguish between household-level finance and supra-household finance . Assuming there are inherent limits on home production as a means of expanding the resource base of a feast, the establishment of social relations outside the lineage or household through sodality membership, marriage, exchange, or indebtedness all become paramount to hosting and financing largescale feasts. Postcontact Mae Enga big men of highland New Guinea, for example, may draw upon upwards of 2,000 followers for a single feast . The greater the scale of the feast, the greater the potential for prestige enhancement on the part of sponsors. Moreover, using feasting as a recurrent social practice to enhance prestige usually requires financing on a larger scale than that of the single household or lineage (Young 1985). Scale also may relate to whether feasts are primarily \"intra-communal\" or \"inter-communal\" affairs (although this distinction is often hard to make ethnographically.) Hayden (1995), for instance, delineates within-group feasts, which he terms \"solidarity feasts,\" and between-group feasts, which are either \"reciprocal\" or \"competitive\" feasts. Reciprocal feasts function primarily to create alliances and promote cooperation among groups, while competitive feasts are hosted primarily to enhance the prestige, and political and economic support, of an aggrandizer and his/her followers or to negotiate and reaffirm extra-community political ties and agreement.Many within-group feasts have the principal effect of facilitating social integration or redistributing food among households within the village . Feasts of this type are usually financed by multiple households (often anonymously) and tend to be relatively non-competitive in nature. Compared to situations in which sponsors compete to enhance their prestige by contributing more to a feast than other sponsors, the inherent anonymity of, and lack of direct competition for, prestige in many intra-community integrative feasts tends to limit the quanitity of resources mobilized. In contrast, when feasts involve more than one community, cooperative effort on the part of village coresidents often facilitates the financing of larger and more elaborate feasts than is possible in intra-village contexts. It is in the context of inter-community (or large-scale) feasts that the prestige of aggrandizers becomes greatly enhanced relative to their followers.Much of the variation in occurrence of feasts is related to the degree to which feasting is regulated by the structure of ritual. Feasting often is associated with calendrical rituals that occur at prescribed times of the year. The kyanakwe feasting ceremony of the Zuni, for example, is held four times a year. Many feasts are held only once every several years. The Kaiko ritual of the Tsembaga of New Guinea may take place only once every 7 to 15 years . The scale of these feasts is smaller than that of unregulated or ad hoc feasts. Kaiko ritual feasts involve the participation of hundreds of people from several communities. Yet, over a year-long period of ritual feasting, only a hundred or so pigs may be killed by members of a single community. In contrast, the highly competitive, \"less regulated\" (in terms of scheduling) feasting of the Mae Enga of Highland New Guinea may involve the killing of up to 240 pigs per feast, and there may be several feasts per year, depending upon the productivity (and production) of feasting resources, as well as the number of aspiring leaders competing for prestige . Thus, ad hoc feasts are often geared more toward the enhancement of prestige than are feasts that are highly structured by a ritual cycle. Moreover, the feasibility of ad hoc feasts as aggrandizing vehicles may be restricted by the potential of the subsistence economy to generate a surplus . Societies with seasonally structured subsistence abundances may be restricted to feasting in the contexts of seasonally structured ritual feasts. This is especially the case in the context of the unpredictable yields of hunting and gathering and dry-farm agriculture.\nThe scheduling of feasts associated with rite-ofpassage rituals, such as weddings and initiation rituals, and with life-crisis events, such as mourning rituals, may not be \"regulated\" to the same degree as feasts connected with a ritual cycle. Mourning rituals, for instance, can take place months or years after a death, allowing a family to collect the necessary food and goods. Mortuary feasts are indeed prime aggrandizing events in various parts of North America and Melanesia . Initiation rites also may be postponed until there are enough initiates (i.e., the wherewithal to hold appropriately elaborate ceremonies) . On the other hand, male initiation rites in many large-scale New Guinean societies were highly regulated in the sense of occurring at regular intervals. These ceremonies are conducted by part-time ritual specialists (hatathli) but are hosted by the patient and the patient's family. Thus, this feasting is not competitive, but an obligation of the patient and his entourage. In contrast to feasts hosted by self-selected aggrandizers, the fact that the host is \"chosen\" more or less randomly (i.e., whoever gets sick) creates a situation in which feasting operates to distribute rather than consolidate responsibility, and perhaps prestige, and serves as an element in a larger ritual structure that operates to maintain community and tribal integration。In contrast, in New Guinea, feasts associated with healing ceremonies can be an avenue for prestige-enhancement on the part of big men. The relatives of the \"victim\" may organize and finance the feast, and particularly competitive individuals can search out opportunities (i.e., sick relatives) to exploit by feasting.",
    "reference_list": "考点1:\"social comparison“推荐翻译为”社会攀比“\n考点2:\"Big-man societies“必须翻译为”头人社会“，人类学专业术语，固定译法\n考点3:\"aggrandizer“推荐翻译为”夸富者“，该词在文中偏贬义，对于该词的翻译需要体现出“是通过财富、权利提升地位，提高自身声望和影响力”的意思；且不可译为“扩张者”（表意不明确）\n考点4:\" initiation rituals“推荐翻译为”成人礼“\n考点5：\"victim\"推荐翻译为“患者”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "151"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n We spend a lot of time searching for things. If we know what we are looking for in advance, a memory representation of the target will be created to guide search. But if the identity of the search target is revealed simultaneously with the presentation of the search array, is a similar memory representation formed? In the present study, 96 observers determined whether a central target was present in a peripheral search array. The results revealed that as long as the central target remained available for inspection (even if only in iconic memory), observers reinspected it after each distractor was checked, apparently forgoing consolidation of the target into working memory. The present findings challenged the assumption that evaluating items in a search array must involve comparison with a template in working memory.\n\nPalmer (1995) proposed that visual search involves four processing stages: preselection, selection, postselection, and decision. Whereas many efforts have been made to examine the mechanisms of the first three stages (e.g., Lavie, Hirst, De Fockert, & Viding, 2004; Treisman & Gelade, 1980; Wolfe, 1994), little is known about the decision stage. The decision stage involves comparisons between the attentional template (a mental representation of the target) and items in the search array (to determine whether the item is a target). Standard theories of attention assume that the template comparison occurs in working memory (Bundesen, 1990; Duncan & Humphreys, 1989; Treisman & Gelade, 1980). Consistent with this assumption, evidence demonstrates that the attentional template may be stored in working memory during the initial configuration of attentional control settings (Carlisle, Arita, Pardo, & Woodman, 2011; Woodman & Arita, 2011).\n\nHowever, consolidating information into working memory is time consuming (Jolicœur & Dell’Acqua, 1998; Vogel, Woodman, & Luck, 2006) and may sometimes be inefficient. It has been suggested that the locations of visited distractors may not be remembered during visual search (Horowitz & Wolfe, 1998) and that the attributes of a just-attended object may not always be retained in working memory (Chen & Wyble, 2015). Moreover, the speed of search is faster than the speed of memory consolidation; for example, searching for a color among a group of distinctive colors can be as fast as 10 ms per item (Olds, Cowan, & Jolicoeur, 1999), but consolidating color information into working memory takes about 50 ms per item (Vogel et al., 2006). These findings suggest that properties of the search array need not be consolidated into working memory. Then what about the target itself?\n\nIn the present study, we investigated whether target identity is stored in working memory when the identity of the target is both revealed simultaneously with the search array and remains available for inspection during search. Objects are identified and recognized more rapidly than information is consolidated into working memory (Jolicœur & Dell’Acqua, 1998; Potter, 1976; Thorpe, Fize, & Marlot, 1996). If the target identity is available for inspection only while the search array is present, observers may proceed immediately to search without stopping to consolidate the target in working memory. One way to avoid the need for consolidation is to revisit the target during search.\n\nTo test the above hypothesis, we first compared search efficiency in a target-in-memory condition (in which the target identity has to be stored in working memory) with search efficiency in a target-on-screen condition (in which the target identity is shown simultaneously with the search array and remains available during the search). Wolfe, Horowitz, Kenner, Hyle, and Vasan (2004) showed that when the target identity is revealed (as briefly as 50 ms) before the presentation of the search array, an attentional template is formed to guide search and reduce the search time. To control this top-down guidance in the target-in-memory condition, we included a target-first condition in which the target identity is presented 50 ms before the search array and remains on screen until response.\n\nThe results from Experiment 1 are consistent with the target-reidentification hypothesis. The search slope in the target-in-memory condition was 30.2 ms per item, indicating that the time for identifying a letter was 30.2 ms. The slope doubled in the target-on-screen condition (62.5 ms per item) and the target-first condition (65.5 ms per item), which suggests that, in these two conditions, each letter required a processing time sufficient for identifying two letters. A plausible explanation is that, after checking each distractor, observers reinspected the target. To provide convergent evidence for this possibility, we manipulated the form of the central target in Experiment 2: The central target was either upright or mirror reversed and tilted. Letters in the search array were all upright. We anticipated that it might take observers longer to identify the mirror-reversed and tilted letters than the upright letters. This extra target-encoding time should affect the intercept of the search-time function only if the central target is identified once, but it may increase the search slope if the central target is reinspected after each distractor is examined.\n\nIn Experiment 3, there were two types of displays: simple and complex (Fig. 1). In the simple display, the target letter was mirror reversed and tilted, while letters in the search array were upright; in the complex display, the central letter was upright, but letters in the search array were mirror reversed and tilted. In the target-on-screen condition, which display would observers search more quickly? Existing theories predict a faster search in the simple display, but the reidentification hypothesis makes an astonishing prediction, that is, search speeds for the simple and complex displays should be similar. Experiment 3 tested this prediction.\n\nPrevious work using eye tracking has suggested that in naturalistic tasks, observers may preferentially refixate parts of the work space rather than committing them to working memory (Ballard, Hayhoe, & Pelz, 1995; Hayhoe, Shrivastava, Mruczek, & Pelz, 2003). Although the search slopes reported here are unlikely to involve eye movements, in Experiment 4, we used a variant of the paradigm in which the target was mostly available in iconic memory and search could be completed with exposure times of less than 200 ms (thus minimizing the risk of eye movements). For this purpose, we switched to numeric digits and used a target preexposure of 30 ms, which was immediately followed either by the search array (immediate condition) or by an annular mask and then (1,000 ms later) by the search array (delayed condition). We reasoned that in the delayed condition, observers would need to consolidate the search target into working memory, but that in the immediate condition, iconic memory might be enough to support reidentification while not causing gaze movements.\n\nThe findings of Experiments 1 and 4 showed that when target identity is revealed simultaneously with the search array and remains available for inspection (even in iconic memory), the search slope is twice that as when the target identity is stored in working memory before the search begins. In the no-working-memory (unconsolidated-target) search conditions, observers seemed to jump right into the search, depending on reidentification of the target rather than on first establishing a representation of the search target in working memory. This could explain the drop in search-rate efficiency. In a supplementary study (Experiment S2 in the Supplemental Material), the target-in-memory condition of Experiment 1 was modified so that the previewed target would always reappear at the center of the search array. Search slopes in this hybrid condition remained low, which implies that the observers, rather than being lazy, still preferred a faster search rate, as long as sufficient time was allowed to prepare the target representation (in working memory) to guide attention.\n\nThe findings of Experiments 2 and 3 were consistent with the reidentification hypothesis—that is, when target identity is revealed simultaneously with the presentation of the search array and remains available for inspection, observers will reidentify the target after examining each distractor rather than taking the time to first consolidate the target identity into working memory. The present findings cannot be attributed to factors related to eye movements because the reidentification process can occur even in iconic memory and within a duration insufficient for initiating saccadic eye movements. If the reidentification hypothesis is correct, that implies that comparison between the target template and items in the search array does not necessarily occur in working memory and that visual search has an unconsolidatedtarget (working-memory-free) search mode.\n\nHorowitz and Wolfe (1998) showed that search efficiency does not change when the locations of the items in the search array randomly shift every 111 ms compared with when the items’ locations are fixed. They interpreted their findings as showing that the locations of visited items are not remembered (i.e., sampling with replacement; see also Gibson, Li, Skow, Brown, & Cooke, 2000; Gilchrist & Harvey, 2000; Horowitz & Wolfe, 2001, 2003). In fact, the doubled search slope in the nonconsolidated conditions of the present study is reminiscent of findings of this memory-free search. However, such searches have been reported in cases in which target consolidation has clearly occurred and the searched locations are not being consolidated. Some authors have indeed demonstrated conditions in which search occurs without replacement (Kristjánsson, 2000; Lleras, Rensink, & Enns, 2005; Peterson, Kramer, Wang, Irwin, & McCarley, 2001; Takeda, 2004). In the present case, it could be argued that ongoing attempts at consolidating the target interfered with searchlocation consolidation. However, the results of Experiment 3 seem to contradict this account. If searches in the target-on-screen condition did not include target reidentification, it is difficult to understand how search speed in the simple display was not faster than that in the complex display.\n\nAlthough target reidentification results in a steeper search slope, this strategy eliminates the time normally used for consolidating the target identity, which might involve several hundred milliseconds. Therefore, the overall efficiency of the unconsolidated-target search is likely better than that of the consolidated-target search when there is minimal preview time. Moreover, the benefit of this reidentification strategy is actually consistent with the finding that observers miss changes between two simultaneous arrays, just as they do in a flicker paradigm, but that their performance improves significantly in the simultaneous condition (e.g., ScottBrown, Baker, & Orbach, 2000).\n\nIn natural tasks (e.g., making a sandwich), observers may frequently go back to check the model (Ballard et al., 1995; Hayhoe et al., 2003), similar to the target reidentification suggested by the present findings. Although eye movements are clearly involved in those natural tasks, the phenomenon observed in the present study is likely attributable to covert attention, because the findings of Experiment 4 show that the reidentification of the target could occur in iconic memory. It also implies that the comparison between the target template and items in the search array may occur either in iconic memory (Sperling, 1960) or in fragile short-term memory (Sligte, Scholte, & Lamme, 2008, 2009).",
    "ori_text": "\n\n We spend a lot of time searching for things. If we know what we are looking for in advance, a memory representation of the target will be created to guide search. But if the identity of the search target is revealed simultaneously with the presentation of the search array, is a similar memory representation formed? In the present study, 96 observers determined whether a central target was present in a peripheral search array. The results revealed that as long as the central target remained available for inspection (even if only in iconic memory), observers reinspected it after each distractor was checked, apparently forgoing consolidation of the target into working memory. The present findings challenged the assumption that evaluating items in a search array must involve comparison with a template in working memory.\n\nPalmer (1995) proposed that visual search involves four processing stages: preselection, selection, postselection, and decision. Whereas many efforts have been made to examine the mechanisms of the first three stages (e.g., Lavie, Hirst, De Fockert, & Viding, 2004; Treisman & Gelade, 1980; Wolfe, 1994), little is known about the decision stage. The decision stage involves comparisons between the attentional template (a mental representation of the target) and items in the search array (to determine whether the item is a target). Standard theories of attention assume that the template comparison occurs in working memory (Bundesen, 1990; Duncan & Humphreys, 1989; Treisman & Gelade, 1980). Consistent with this assumption, evidence demonstrates that the attentional template may be stored in working memory during the initial configuration of attentional control settings (Carlisle, Arita, Pardo, & Woodman, 2011; Woodman & Arita, 2011).\n\nHowever, consolidating information into working memory is time consuming (Jolicœur & Dell’Acqua, 1998; Vogel, Woodman, & Luck, 2006) and may sometimes be inefficient. It has been suggested that the locations of visited distractors may not be remembered during visual search (Horowitz & Wolfe, 1998) and that the attributes of a just-attended object may not always be retained in working memory (Chen & Wyble, 2015). Moreover, the speed of search is faster than the speed of memory consolidation; for example, searching for a color among a group of distinctive colors can be as fast as 10 ms per item (Olds, Cowan, & Jolicoeur, 1999), but consolidating color information into working memory takes about 50 ms per item (Vogel et al., 2006). These findings suggest that properties of the search array need not be consolidated into working memory. Then what about the target itself?\n\nIn the present study, we investigated whether target identity is stored in working memory when the identity of the target is both revealed simultaneously with the search array and remains available for inspection during search. Objects are identified and recognized more rapidly than information is consolidated into working memory (Jolicœur & Dell’Acqua, 1998; Potter, 1976; Thorpe, Fize, & Marlot, 1996). If the target identity is available for inspection only while the search array is present, observers may proceed immediately to search without stopping to consolidate the target in working memory. One way to avoid the need for consolidation is to revisit the target during search.\n\nTo test the above hypothesis, we first compared search efficiency in a target-in-memory condition (in which the target identity has to be stored in working memory) with search efficiency in a target-on-screen condition (in which the target identity is shown simultaneously with the search array and remains available during the search). Wolfe, Horowitz, Kenner, Hyle, and Vasan (2004) showed that when the target identity is revealed (as briefly as 50 ms) before the presentation of the search array, an attentional template is formed to guide search and reduce the search time. To control this top-down guidance in the target-in-memory condition, we included a target-first condition in which the target identity is presented 50 ms before the search array and remains on screen until response.\n\nThe results from Experiment 1 are consistent with the target-reidentification hypothesis. The search slope in the target-in-memory condition was 30.2 ms per item, indicating that the time for identifying a letter was 30.2 ms. The slope doubled in the target-on-screen condition (62.5 ms per item) and the target-first condition (65.5 ms per item), which suggests that, in these two conditions, each letter required a processing time sufficient for identifying two letters. A plausible explanation is that, after checking each distractor, observers reinspected the target. To provide convergent evidence for this possibility, we manipulated the form of the central target in Experiment 2: The central target was either upright or mirror reversed and tilted. Letters in the search array were all upright. We anticipated that it might take observers longer to identify the mirror-reversed and tilted letters than the upright letters. This extra target-encoding time should affect the intercept of the search-time function only if the central target is identified once, but it may increase the search slope if the central target is reinspected after each distractor is examined.\n\nIn Experiment 3, there were two types of displays: simple and complex (Fig. 1). In the simple display, the target letter was mirror reversed and tilted, while letters in the search array were upright; in the complex display, the central letter was upright, but letters in the search array were mirror reversed and tilted. In the target-on-screen condition, which display would observers search more quickly? Existing theories predict a faster search in the simple display, but the reidentification hypothesis makes an astonishing prediction, that is, search speeds for the simple and complex displays should be similar. Experiment 3 tested this prediction.\n\nPrevious work using eye tracking has suggested that in naturalistic tasks, observers may preferentially refixate parts of the work space rather than committing them to working memory (Ballard, Hayhoe, & Pelz, 1995; Hayhoe, Shrivastava, Mruczek, & Pelz, 2003). Although the search slopes reported here are unlikely to involve eye movements, in Experiment 4, we used a variant of the paradigm in which the target was mostly available in iconic memory and search could be completed with exposure times of less than 200 ms (thus minimizing the risk of eye movements). For this purpose, we switched to numeric digits and used a target preexposure of 30 ms, which was immediately followed either by the search array (immediate condition) or by an annular mask and then (1,000 ms later) by the search array (delayed condition). We reasoned that in the delayed condition, observers would need to consolidate the search target into working memory, but that in the immediate condition, iconic memory might be enough to support reidentification while not causing gaze movements.\n\nThe findings of Experiments 1 and 4 showed that when target identity is revealed simultaneously with the search array and remains available for inspection (even in iconic memory), the search slope is twice that as when the target identity is stored in working memory before the search begins. In the no-working-memory (unconsolidated-target) search conditions, observers seemed to jump right into the search, depending on reidentification of the target rather than on first establishing a representation of the search target in working memory. This could explain the drop in search-rate efficiency. In a supplementary study (Experiment S2 in the Supplemental Material), the target-in-memory condition of Experiment 1 was modified so that the previewed target would always reappear at the center of the search array. Search slopes in this hybrid condition remained low, which implies that the observers, rather than being lazy, still preferred a faster search rate, as long as sufficient time was allowed to prepare the target representation (in working memory) to guide attention.\n\nThe findings of Experiments 2 and 3 were consistent with the reidentification hypothesis—that is, when target identity is revealed simultaneously with the presentation of the search array and remains available for inspection, observers will reidentify the target after examining each distractor rather than taking the time to first consolidate the target identity into working memory. The present findings cannot be attributed to factors related to eye movements because the reidentification process can occur even in iconic memory and within a duration insufficient for initiating saccadic eye movements. If the reidentification hypothesis is correct, that implies that comparison between the target template and items in the search array does not necessarily occur in working memory and that visual search has an unconsolidatedtarget (working-memory-free) search mode.\n\nHorowitz and Wolfe (1998) showed that search efficiency does not change when the locations of the items in the search array randomly shift every 111 ms compared with when the items’ locations are fixed. They interpreted their findings as showing that the locations of visited items are not remembered (i.e., sampling with replacement; see also Gibson, Li, Skow, Brown, & Cooke, 2000; Gilchrist & Harvey, 2000; Horowitz & Wolfe, 2001, 2003). In fact, the doubled search slope in the nonconsolidated conditions of the present study is reminiscent of findings of this memory-free search. However, such searches have been reported in cases in which target consolidation has clearly occurred and the searched locations are not being consolidated. Some authors have indeed demonstrated conditions in which search occurs without replacement (Kristjánsson, 2000; Lleras, Rensink, & Enns, 2005; Peterson, Kramer, Wang, Irwin, & McCarley, 2001; Takeda, 2004). In the present case, it could be argued that ongoing attempts at consolidating the target interfered with searchlocation consolidation. However, the results of Experiment 3 seem to contradict this account. If searches in the target-on-screen condition did not include target reidentification, it is difficult to understand how search speed in the simple display was not faster than that in the complex display.\n\nAlthough target reidentification results in a steeper search slope, this strategy eliminates the time normally used for consolidating the target identity, which might involve several hundred milliseconds. Therefore, the overall efficiency of the unconsolidated-target search is likely better than that of the consolidated-target search when there is minimal preview time. Moreover, the benefit of this reidentification strategy is actually consistent with the finding that observers miss changes between two simultaneous arrays, just as they do in a flicker paradigm, but that their performance improves significantly in the simultaneous condition (e.g., ScottBrown, Baker, & Orbach, 2000).\n\nIn natural tasks (e.g., making a sandwich), observers may frequently go back to check the model (Ballard et al., 1995; Hayhoe et al., 2003), similar to the target reidentification suggested by the present findings. Although eye movements are clearly involved in those natural tasks, the phenomenon observed in the present study is likely attributable to covert attention, because the findings of Experiment 4 show that the reidentification of the target could occur in iconic memory. It also implies that the comparison between the target template and items in the search array may occur either in iconic memory (Sperling, 1960) or in fragile short-term memory (Sligte, Scholte, & Lamme, 2008, 2009).",
    "reference_list": "考点1：“the identity of the search target”推荐翻译为“搜索目标本身”\n考点2：“iconic memory”应翻译为“映像记忆”\n考点3：“preselection, selection, postselection, and decision”推荐翻译为“选择前阶段、选择阶段、选择后阶段和决策阶段”\n考点4：“visited distractors”应翻译为“被注意过的干扰项/被检视过的干扰项”，不能翻译为“已访问的干扰项”\n考点5：“target-in-memory condition”推荐翻译为“目标在记忆中的条件”\n考点6：“target-on-screen condition”推荐翻译为“目标在屏幕上的条件”\n考点7：“eye movements”推荐翻译为“眼动”\n考点8：“reidentification hypothesis”推荐译为“再识别假设”或“重新识别假设”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "134"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n电化学系统：能量转换与反应动力学的解析\n电化学是研究电能与化学能相互转换规律的学科，其本质是氧化还原反应中电子的定向转移过程。这类反应通过两类基础装置实现：原电池将化学能自发转化为电能，而电解池则消耗电能驱动非自发化学反应。\n一、电池系统的结构与功能分类\n在原电池中，负极（亦称阳极）发生氧化反应释放电子，正极（亦称阴极）发生还原反应接收电子，电子流经外电路形成电流。典型如锌铜电池：\n1.锌阳极发生氧化反应（Zn → Zn²⁺ + 2e⁻）\n2.铜阴极发生还原反应（Cu²⁺ + 2e⁻ → Cu）\n3.两类特殊电池拓展了应用场景：\n4.蓄电池（二次电池）：通过可逆反应实现反复充放电，其循环寿命依赖于电极表面形成的固体电解质界面膜稳定性，该膜可抑制副反应并保护电极结构；\n5.贮备电池：采用物理隔离技术使电极与电解质长期分离（如电解质固态化），激活后瞬时放电，适用于应急设备与军事领域。\n电池内部结构中，隔膜承担双重使命：阻隔正负极接触防止短路，同时允许离子穿透以维持电荷平衡。电解液作为离子传导介质，其组成直接影响离子迁移率及电池内阻。近年兴起的固态电解质技术摒弃传统液态体系，利用无机晶体或聚合物传导离子，显著提升安全性并降低欧姆内阻。\n二、电极系统与界面控制机制\n电化学研究依赖三电极体系精确测量：\n1.工作电极：承载目标反应的核心平台，例如研究二氧化碳还原的铂片电极；\n2.对电极（辅助电极）：与工作电极构成电流回路，通常选用化学惰性的铂或石墨材料；\n3.参比电极：具有稳定且已知电位的基准电极（如饱和甘汞电极），用于测定工作电极的绝对电位值。\n在电极/溶液界面处，带相反电荷的粒子定向排布形成双电层，该结构如同微观电容器，直接影响电子转移步骤的能垒。通过对电极表面进行分子设计可制备修饰电极，例如将金属纳米粒子负载于碳基体增强电催化活性，或固定生物酶实现特异性检测。\n三、反应动力学的多步骤控制\n电化学反应速度由串联步骤共同决定：\n1.液相传质步骤：反应物从溶液本体扩散至电极表面附近；\n2.前置转化：反应粒子在电极界面发生预活化（如有机分子的取向吸附或质子化）；\n3.电子转移步骤：电子穿越双电层的核心电荷传递过程；\n4.随后转化：初生产物的脱附、重排或二次化学反应。\n当外电路电流通过时，电极电位将偏离平衡状态，此现象称为极化。根据起源可分为：\n1.电化学极化：电荷传递步骤动力学迟滞导致；\n2.浓差极化：反应物消耗或产物积累引发的浓度梯度效应。 两者共同构成极化内阻，其数值可通过扫描电位绘制的极化曲线量化分析。曲线特征显示：\n3.阴极极化驱使电位向负方向偏移（典型如氧气还原反应受阻）；\n4.阳极极化推动电位向正方向移动（如金属阳极溶解迟滞）。\n过电位作为极化的直接表征，其数值与电流密度满足半对数关系（塔菲尔方程）。降低过电位需协同优化离子迁移率与电化学活性表面积，后者反映电极实际参与反应的有效界面比例。\n四、能量效率的制约因素与优化策略\n电流效率衡量有效电子利用率，例如电解水制氢体系中，阴极析氢反应的电流效率可达95%以上。提升效率需抑制竞争反应：\n1.引入离子交换膜实现离子选择性透过（如氯碱工业阻隔氢氧根反渗）；\n2.调控电解液组成削弱化学极化（由前置或随后转化步骤控制的动力学阻力）。\n欧姆极化源于电流流经导体时的固有电阻，其物理本质为欧姆内阻，包含电极体电阻、集流体接触电阻及电解质阻抗三部分。通过交流阻抗谱可分离识别欧姆损耗与极化损耗。\n五、标准体系与理论基准框架\n标准电极电位在25°C、1 mol/L浓度的理想状态下测定，以标准氢电极（铂黑电极在1 atm氢气与1 mol/L H⁺溶液中的体系）为零电位基准。例如铜电极的标准电位为+0.34 V，预示其还原倾向强于氢电极。该参数虽可预测反应方向，但实际电位受界面吸附状态及双电层结构显著影响。\n电解质导电机理基于电离与电迁移：强电解质（如氯化钠）在水溶液中完全解离成正负离子，弱电解质（如醋酸）部分解离；在外加电场驱动下，离子定向电迁移形成电流，迁移速率与电场强度及离子迁移率成正比。\n六、技术前沿与工程应用突破\n现代电化学技术正在重塑能源格局：\n1.全固态电池采用陶瓷固态电解质替代有机电解液，消除燃爆风险并提升能量密度；\n2.液流电池储能系统通过离子交换膜分隔正负极电解液，实现百兆瓦级可再生能源存储；\n3.电化学合成利用修饰电极的高选择性，将二氧化碳转化为甲酸或乙烯等高值化学品。\n4.降低极化损失仍是核心挑战。以质子交换膜燃料电池为例：\n5.增加铂催化剂的电化学活性表面积可加速迟缓的氧还原反应；\n6.优化乙醇氧化的前置转化路径（如C-C键断裂步骤）能提升燃料电池效率；\n7.调控固体电解质界面膜组分可减少锂离子电池首次充放电的容量损失。\n8.在环境治理领域，电解技术展现出独特优势：\n9.电化学高级氧化通过阳极反应产生活性氧自由基降解有机污染物；\n10.电沉积法回收废水中的铜、镍等重金属，电流效率达80%以上；\n11.电解池耦合离子交换膜实现盐差能发电，开辟蓝色能源新途径。\n七、表征技术与过程监控\n电化学动力学研究依赖先进原位表征：\n1.极化曲线定量揭示电极过程的速率控制步骤；\n2.交流阻抗谱解析电池内阻组成（区分欧姆内阻与极化内阻）；\n3.显微技术观测固体电解质界面膜的形貌演化；\n4.光谱分析追踪吸附中间体的生成与转化。\n在线监控参数包括：\n1.电流效率实时反映反应选择性；\n2.过电位监控系统能耗状态；\n3.电化学活性表面积评估催化剂老化程度。\n结论\n电化学系统的核心在于协调电子转移步骤的热力学驱动力与动力学限制。从原电池自主供能到电解池强制反应，从蓄电池的循环再生再到贮备电池的长效待机，技术创新始终围绕克服欧姆极化与浓差极化、提升电流效率展开。标准电极电位奠定了理论预测基础，参比电极提供了实验测量基准，而修饰电极与固态电解质等新材料则持续突破性能边界。未来，通过多尺度调控液相传质步骤、前置转化路径及界面双电层结构，电化学技术将在清洁能源存储、污染物深度治理及高端化学品合成领域开启新纪元。\n",
    "ori_text": "\n\n电化学系统：能量转换与反应动力学的解析\n电化学是研究电能与化学能相互转换规律的学科，其本质是氧化还原反应中电子的定向转移过程。这类反应通过两类基础装置实现：原电池将化学能自发转化为电能，而电解池则消耗电能驱动非自发化学反应。\n一、电池系统的结构与功能分类\n在原电池中，负极（亦称阳极）发生氧化反应释放电子，正极（亦称阴极）发生还原反应接收电子，电子流经外电路形成电流。典型如锌铜电池：\n1.锌阳极发生氧化反应（Zn → Zn²⁺ + 2e⁻）\n2.铜阴极发生还原反应（Cu²⁺ + 2e⁻ → Cu）\n3.两类特殊电池拓展了应用场景：\n4.蓄电池（二次电池）：通过可逆反应实现反复充放电，其循环寿命依赖于电极表面形成的固体电解质界面膜稳定性，该膜可抑制副反应并保护电极结构；\n5.贮备电池：采用物理隔离技术使电极与电解质长期分离（如电解质固态化），激活后瞬时放电，适用于应急设备与军事领域。\n电池内部结构中，隔膜承担双重使命：阻隔正负极接触防止短路，同时允许离子穿透以维持电荷平衡。电解液作为离子传导介质，其组成直接影响离子迁移率及电池内阻。近年兴起的固态电解质技术摒弃传统液态体系，利用无机晶体或聚合物传导离子，显著提升安全性并降低欧姆内阻。\n二、电极系统与界面控制机制\n电化学研究依赖三电极体系精确测量：\n1.工作电极：承载目标反应的核心平台，例如研究二氧化碳还原的铂片电极；\n2.对电极（辅助电极）：与工作电极构成电流回路，通常选用化学惰性的铂或石墨材料；\n3.参比电极：具有稳定且已知电位的基准电极（如饱和甘汞电极），用于测定工作电极的绝对电位值。\n在电极/溶液界面处，带相反电荷的粒子定向排布形成双电层，该结构如同微观电容器，直接影响电子转移步骤的能垒。通过对电极表面进行分子设计可制备修饰电极，例如将金属纳米粒子负载于碳基体增强电催化活性，或固定生物酶实现特异性检测。\n三、反应动力学的多步骤控制\n电化学反应速度由串联步骤共同决定：\n1.液相传质步骤：反应物从溶液本体扩散至电极表面附近；\n2.前置转化：反应粒子在电极界面发生预活化（如有机分子的取向吸附或质子化）；\n3.电子转移步骤：电子穿越双电层的核心电荷传递过程；\n4.随后转化：初生产物的脱附、重排或二次化学反应。\n当外电路电流通过时，电极电位将偏离平衡状态，此现象称为极化。根据起源可分为：\n1.电化学极化：电荷传递步骤动力学迟滞导致；\n2.浓差极化：反应物消耗或产物积累引发的浓度梯度效应。 两者共同构成极化内阻，其数值可通过扫描电位绘制的极化曲线量化分析。曲线特征显示：\n3.阴极极化驱使电位向负方向偏移（典型如氧气还原反应受阻）；\n4.阳极极化推动电位向正方向移动（如金属阳极溶解迟滞）。\n过电位作为极化的直接表征，其数值与电流密度满足半对数关系（塔菲尔方程）。降低过电位需协同优化离子迁移率与电化学活性表面积，后者反映电极实际参与反应的有效界面比例。\n四、能量效率的制约因素与优化策略\n电流效率衡量有效电子利用率，例如电解水制氢体系中，阴极析氢反应的电流效率可达95%以上。提升效率需抑制竞争反应：\n1.引入离子交换膜实现离子选择性透过（如氯碱工业阻隔氢氧根反渗）；\n2.调控电解液组成削弱化学极化（由前置或随后转化步骤控制的动力学阻力）。\n欧姆极化源于电流流经导体时的固有电阻，其物理本质为欧姆内阻，包含电极体电阻、集流体接触电阻及电解质阻抗三部分。通过交流阻抗谱可分离识别欧姆损耗与极化损耗。\n五、标准体系与理论基准框架\n标准电极电位在25°C、1 mol/L浓度的理想状态下测定，以标准氢电极（铂黑电极在1 atm氢气与1 mol/L H⁺溶液中的体系）为零电位基准。例如铜电极的标准电位为+0.34 V，预示其还原倾向强于氢电极。该参数虽可预测反应方向，但实际电位受界面吸附状态及双电层结构显著影响。\n电解质导电机理基于电离与电迁移：强电解质（如氯化钠）在水溶液中完全解离成正负离子，弱电解质（如醋酸）部分解离；在外加电场驱动下，离子定向电迁移形成电流，迁移速率与电场强度及离子迁移率成正比。\n六、技术前沿与工程应用突破\n现代电化学技术正在重塑能源格局：\n1.全固态电池采用陶瓷固态电解质替代有机电解液，消除燃爆风险并提升能量密度；\n2.液流电池储能系统通过离子交换膜分隔正负极电解液，实现百兆瓦级可再生能源存储；\n3.电化学合成利用修饰电极的高选择性，将二氧化碳转化为甲酸或乙烯等高值化学品。\n4.降低极化损失仍是核心挑战。以质子交换膜燃料电池为例：\n5.增加铂催化剂的电化学活性表面积可加速迟缓的氧还原反应；\n6.优化乙醇氧化的前置转化路径（如C-C键断裂步骤）能提升燃料电池效率；\n7.调控固体电解质界面膜组分可减少锂离子电池首次充放电的容量损失。\n8.在环境治理领域，电解技术展现出独特优势：\n9.电化学高级氧化通过阳极反应产生活性氧自由基降解有机污染物；\n10.电沉积法回收废水中的铜、镍等重金属，电流效率达80%以上；\n11.电解池耦合离子交换膜实现盐差能发电，开辟蓝色能源新途径。\n七、表征技术与过程监控\n电化学动力学研究依赖先进原位表征：\n1.极化曲线定量揭示电极过程的速率控制步骤；\n2.交流阻抗谱解析电池内阻组成（区分欧姆内阻与极化内阻）；\n3.显微技术观测固体电解质界面膜的形貌演化；\n4.光谱分析追踪吸附中间体的生成与转化。\n在线监控参数包括：\n1.电流效率实时反映反应选择性；\n2.过电位监控系统能耗状态；\n3.电化学活性表面积评估催化剂老化程度。\n结论\n电化学系统的核心在于协调电子转移步骤的热力学驱动力与动力学限制。从原电池自主供能到电解池强制反应，从蓄电池的循环再生再到贮备电池的长效待机，技术创新始终围绕克服欧姆极化与浓差极化、提升电流效率展开。标准电极电位奠定了理论预测基础，参比电极提供了实验测量基准，而修饰电极与固态电解质等新材料则持续突破性能边界。未来，通过多尺度调控液相传质步骤、前置转化路径及界面双电层结构，电化学技术将在清洁能源存储、污染物深度治理及高端化学品合成领域开启新纪元。\n",
    "reference_list": "考点1：“蓄电池（二次电池）“必须译为：”：“Accumulator“\n考点2：“固体电解质界面膜“必须译为：”Solid Electrolyte Interphase“\n考点3：“工作电极“推荐译为：”Working Electrode“\n考点4：“对电极（辅助电极）“推荐译为：”Counter Electrode“\n考点5：“双电层“推荐译为：”Double Layer“\n考点6：“液相传质步骤“推荐译为：”Liquid Transfer Procedure“\n考点7：“前置转化“推荐译为：”Preceding Reaction“\n考点8：“浓差极化“推荐译为：”Concentration Polarization“\n考点9：离子迁移率 推荐译为”Ion Migration Rate“\n考点10：“固态电解质”必须译为 “solid-state electrolyte”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "121"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n一、基于用户信息的基本协同过滤 　　\n\n基于用户信息的基本协同过滤是抖音整个算法体系中最基础和最简单的算法，也是在视频推广过程中普遍应用的算法。抖音通过获取用户注册时的基本信息，如性别、年龄、地址和基本兴趣点，对用户的画像有了大致的描绘。其后，在信息分发过程中，抖音通过考虑用户之间的相似程度进行相似内容的推荐。当用户开始接触平台，且所提供的信息越详细或越准确，其对用户需求的判断越接近用户的真实需要。我们可以构建如下推荐模式模型。 　　\n\n假如A、B、C、D的基本信息较为相似，则前期在A、B、C共同感兴趣的内容或产生点赞、评论、转发等使用行为的内容会较为优先推荐给D。比如，抖音的主界面分为同城和推荐两个模块，推荐模块一个重要的原则就是视频内容和用户兴趣的匹配程度。匹配程度越高的信息越能够被推荐。通常，在平台用户的初期使用阶段，此种获取方式最为主要，这种相对简单的算法推荐原则对于用户具体兴趣的判断是相对模糊的，更多的是相似特征人群的兴趣集合判断。可以说，不断扩大的用户数量和使用行为为这类基础算法提供了数据源，通过海量数据的收集与分析，这类算法的精准程度会不断提升。与快手等其他视频应用不同，抖音用户较为集中在城市，用户的学历和年龄差距相对较小，媒介素养也较为相似，而这也是这类基础算法较为适用的重要原因。 　　\n\n二、基于“去中心化”的精准推送 　　\n\n社交媒体最重要的原则就是“去中心化”，“把关人”的作用逐渐弱化，每个用户都是传播场域中的节点，每个节点都可以独立地生产内容，拥有一定的话语权，内容并非集中于少数的关键用户。在这种“去中心化”的精准推送中，内容和社交关系成为被抓取作为信息精准分发的主要依据。我们可以通过用户个人的视角构建如下信息获得模型。 　　\n\n这一类的精准算法可以分为两大类：一类是以内容兴趣点为筛选维度的推荐，这个维度下，现实社交环境中的联系较弱，甚至没有联系；另一类是以社交强联系为筛选维度的推荐，在通讯录中的好友、同学都会成为推荐所抓取的对象。重合部分往往会获得较多的推荐。 　　\n\n内容维度可以理解为以相同的职业、爱好、话题组成的相近兴趣的集合。平台基于用户使用行为的习惯，诸如点赞、评论、转发等行为，通过数据驱动的方式挖掘用户的兴趣点，从而在下一轮的视频推荐中合理选择，进一步取悦用户，增加黏度。 　　\n\n社交关系维度可以理解为以现实的社交关系为连接的集合。这类关系基于社交关系的联系程度从而变得更强。每个人的社交圈都随着移动互联技术的进步而不断扩大，但是，用户本身和现实社交中好友或同学的关注点相似性不高。正是基于这种算法推荐，用户在抖音的使用过程中通常会看到通讯录好友发布的内容，因为平台通过算法也优先推荐强关系的好友发布的内容。这反映出短视频平台重要的社交属性，通过自己拍摄视频在强关系中的展示，能够满足使用者的需要，增强认同感和满足被别人了解的社交需求。",
    "ori_text": "一、基于用户信息的基本协同过滤 　　\n\n基于用户信息的基本协同过滤是抖音整个算法体系中最基础和最简单的算法，也是在视频推广过程中普遍应用的算法。抖音通过获取用户注册时的基本信息，如性别、年龄、地址和基本兴趣点，对用户的画像有了大致的描绘。其后，在信息分发过程中，抖音通过考虑用户之间的相似程度进行相似内容的推荐。当用户开始接触平台，且所提供的信息越详细或越准确，其对用户需求的判断越接近用户的真实需要。我们可以构建如下推荐模式模型。 　　\n\n假如A、B、C、D的基本信息较为相似，则前期在A、B、C共同感兴趣的内容或产生点赞、评论、转发等使用行为的内容会较为优先推荐给D。比如，抖音的主界面分为同城和推荐两个模块，推荐模块一个重要的原则就是视频内容和用户兴趣的匹配程度。匹配程度越高的信息越能够被推荐。通常，在平台用户的初期使用阶段，此种获取方式最为主要，这种相对简单的算法推荐原则对于用户具体兴趣的判断是相对模糊的，更多的是相似特征人群的兴趣集合判断。可以说，不断扩大的用户数量和使用行为为这类基础算法提供了数据源，通过海量数据的收集与分析，这类算法的精准程度会不断提升。与快手等其他视频应用不同，抖音用户较为集中在城市，用户的学历和年龄差距相对较小，媒介素养也较为相似，而这也是这类基础算法较为适用的重要原因。 　　\n\n二、基于“去中心化”的精准推送 　　\n\n社交媒体最重要的原则就是“去中心化”，“把关人”的作用逐渐弱化，每个用户都是传播场域中的节点，每个节点都可以独立地生产内容，拥有一定的话语权，内容并非集中于少数的关键用户。在这种“去中心化”的精准推送中，内容和社交关系成为被抓取作为信息精准分发的主要依据。我们可以通过用户个人的视角构建如下信息获得模型。 　　\n\n这一类的精准算法可以分为两大类：一类是以内容兴趣点为筛选维度的推荐，这个维度下，现实社交环境中的联系较弱，甚至没有联系；另一类是以社交强联系为筛选维度的推荐，在通讯录中的好友、同学都会成为推荐所抓取的对象。重合部分往往会获得较多的推荐。 　　\n\n内容维度可以理解为以相同的职业、爱好、话题组成的相近兴趣的集合。平台基于用户使用行为的习惯，诸如点赞、评论、转发等行为，通过数据驱动的方式挖掘用户的兴趣点，从而在下一轮的视频推荐中合理选择，进一步取悦用户，增加黏度。 　　\n\n社交关系维度可以理解为以现实的社交关系为连接的集合。这类关系基于社交关系的联系程度从而变得更强。每个人的社交圈都随着移动互联技术的进步而不断扩大，但是，用户本身和现实社交中好友或同学的关注点相似性不高。正是基于这种算法推荐，用户在抖音的使用过程中通常会看到通讯录好友发布的内容，因为平台通过算法也优先推荐强关系的好友发布的内容。这反映出短视频平台重要的社交属性，通过自己拍摄视频在强关系中的展示，能够满足使用者的需要，增强认同感和满足被别人了解的社交需求。",
    "reference_list": "考点1：“基于用户信息的基本协同过滤”推荐译为“User-based Collaborative Filtering”\n考点2：“视频推广”推荐译为“Video Promotion”\n考点3：“基本兴趣点”推荐译为“user interest tags”\n考点4：“媒介素养”推荐译为“Media Literacy”\n考点5：“精准算法”推荐译为“accurate algorithm”\n考点6：“增加黏度”推荐译为“increasing user stickiness”\n考点7：“强关系”推荐译为“within their close circles”或“strong ties”\n考点8：“认同感”推荐译为“personal validation”\n考点9：“用户的画像”推荐译为“user personas”\n考点10：“抓取”推荐译为“extracted”\n考点11：“取悦用户”推荐译为“to better cater to the user”\n考点12：“同城和推荐两个模块”中的“同城”需译为“Same City”\n考点13：“同城和推荐两个模块”中的“推荐”需译为“For You”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "13"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n自从那个下午我无意中进了这园子，就再没长久地离开过它。我一下子就理解了它的意图。正如我在一篇小说中所说的：“在人口密聚的城市里，有这样一个宁静的去处，像是上帝的苦心安排。”\n\n两条腿残废后的最初几年，我找不到工作，找不到去路，忽然间几乎什么都找不到了，我就摇了轮椅总是到它那儿去，仅为着那儿是可以逃避一个世界的另一个世界。我在那篇小说中写道：“没处可去我便一天到晚耗在这园子里。跟上班下班一样，别人去上班我就摇了轮椅到这儿来。园子无人看管，上下班时间有些抄近路的人们从园中穿过，园子里活跃一阵，过后便沉寂下来。”“园墙在金晃晃的空气中斜切下一溜荫凉，我把轮椅开进去，把椅背放倒，坐着或是躺着，看书或者想事，撅一杈树枝左右拍打，驱赶那些和我一样不明白为什么要来这世上的小昆虫。”“蜂儿如一朵小雾稳稳地停在半空；蚂蚁摇头晃脑捋着触须，猛然间想透了什么，转身疾行而去；瓢虫爬得不耐烦了，累了祈祷一回便支开翅膀，忽悠一下升空了；树干上留着一只蝉蜕，寂寞如一间空屋；露水在草叶上滚动、聚集，压弯了草叶轰然坠地摔开万道金光。”“满园子都是草木竞相生长弄出的响动，窸窸窣窣窸窸窣窣片刻不息。”这都是真实的记录，园子荒芜但并不衰败。\n\n除去几座殿堂我无法进去，除去那座祭坛我不能上去而只能从各个角度张望它，地坛的每一棵树下我都去过，差不多它的每一米草地上都有过我的车轮印。无论是什么季节，什么天气，什么时间，我都在这园子里呆过。有时候呆一会儿就回家，有时候就呆到满地上都亮起月光。记不清都是在它的哪些角落里了。我一连几小时专心致志地想关于死的事，也以同样的耐心和方式想过我为什么要出生。这样想了好几年，最后事情终于弄明白了：一个人，出生了，这就不再是一个可以辩论的问题，而只是上帝交给他的一个事实；上帝在交给我们这件事实的时候，已经顺便保证了它的结果，所以死是一件不必急于求成的事，死是一个必然会降临的节日。这样想过之后我安心多了，眼前的一切不再那么可怕。比如你起早熬夜准备考试的时候，忽然想起有一个长长的假期在前面等待你，你会不会觉得轻松一点？并且庆幸并且感激这样的安排？\n\n剩下的就是怎样活的问题了，这却不是在某一个瞬间就能完全想透的、不是一次性能够解决的事，怕是活多久就要想它多久了，就像是伴你终生的魔鬼或恋人。所以，十五年了，我还是总得到那古园里去，去它的老树下或荒草边或颓墙旁，去默坐，去呆想，去推开耳边的嘈杂理一理纷乱的思绪，去窥看自己的心魂。十五年中，这古园的形体被不能理解它的人肆意雕琢，幸好有些东西是任谁也不能改变它的。譬如祭坛石门中的落日，寂静的光辉平铺的一刻，地上的每一个坎坷都被映照得灿烂；譬如在园中最为落寞的时间，一群雨燕便出来高歌，把天地都叫喊得苍凉；譬如冬天雪地上孩子的脚印，总让人猜想他们是谁，曾在哪儿做过些什么，然后又都到哪儿去了；譬如那些苍黑的古柏，你忧郁的时候它们镇静地站在那儿，你欣喜的时候它们依然镇静地站在那儿，它们没日没夜地站在那儿从你没有出生一直站到这个世界上又没了你的时候；譬如暴雨骤临园中，激起一阵阵灼烈而清纯的草木和泥土的气味，让人想起无数个夏天的事件；譬如秋风忽至，再有一场早霜，落叶或飘摇歌舞或坦然安卧，满园中播散着熨帖而微苦的味道。味道是最说不清楚的。味道不能写只能闻，要你身临其境去闻才能明了。味道甚至是难于记忆的，只有你又闻到它你才能记起它的全部情感和意蕴。所以我常常要到那园子里去。",
    "ori_text": "自从那个下午我无意中进了这园子，就再没长久地离开过它。我一下子就理解了它的意图。正如我在一篇小说中所说的：“在人口密聚的城市里，有这样一个宁静的去处，像是上帝的苦心安排。”\n\n两条腿残废后的最初几年，我找不到工作，找不到去路，忽然间几乎什么都找不到了，我就摇了轮椅总是到它那儿去，仅为着那儿是可以逃避一个世界的另一个世界。我在那篇小说中写道：“没处可去我便一天到晚耗在这园子里。跟上班下班一样，别人去上班我就摇了轮椅到这儿来。园子无人看管，上下班时间有些抄近路的人们从园中穿过，园子里活跃一阵，过后便沉寂下来。”“园墙在金晃晃的空气中斜切下一溜荫凉，我把轮椅开进去，把椅背放倒，坐着或是躺着，看书或者想事，撅一杈树枝左右拍打，驱赶那些和我一样不明白为什么要来这世上的小昆虫。”“蜂儿如一朵小雾稳稳地停在半空；蚂蚁摇头晃脑捋着触须，猛然间想透了什么，转身疾行而去；瓢虫爬得不耐烦了，累了祈祷一回便支开翅膀，忽悠一下升空了；树干上留着一只蝉蜕，寂寞如一间空屋；露水在草叶上滚动、聚集，压弯了草叶轰然坠地摔开万道金光。”“满园子都是草木竞相生长弄出的响动，窸窸窣窣窸窸窣窣片刻不息。”这都是真实的记录，园子荒芜但并不衰败。\n\n除去几座殿堂我无法进去，除去那座祭坛我不能上去而只能从各个角度张望它，地坛的每一棵树下我都去过，差不多它的每一米草地上都有过我的车轮印。无论是什么季节，什么天气，什么时间，我都在这园子里呆过。有时候呆一会儿就回家，有时候就呆到满地上都亮起月光。记不清都是在它的哪些角落里了。我一连几小时专心致志地想关于死的事，也以同样的耐心和方式想过我为什么要出生。这样想了好几年，最后事情终于弄明白了：一个人，出生了，这就不再是一个可以辩论的问题，而只是上帝交给他的一个事实；上帝在交给我们这件事实的时候，已经顺便保证了它的结果，所以死是一件不必急于求成的事，死是一个必然会降临的节日。这样想过之后我安心多了，眼前的一切不再那么可怕。比如你起早熬夜准备考试的时候，忽然想起有一个长长的假期在前面等待你，你会不会觉得轻松一点？并且庆幸并且感激这样的安排？\n\n剩下的就是怎样活的问题了，这却不是在某一个瞬间就能完全想透的、不是一次性能够解决的事，怕是活多久就要想它多久了，就像是伴你终生的魔鬼或恋人。所以，十五年了，我还是总得到那古园里去，去它的老树下或荒草边或颓墙旁，去默坐，去呆想，去推开耳边的嘈杂理一理纷乱的思绪，去窥看自己的心魂。十五年中，这古园的形体被不能理解它的人肆意雕琢，幸好有些东西是任谁也不能改变它的。譬如祭坛石门中的落日，寂静的光辉平铺的一刻，地上的每一个坎坷都被映照得灿烂；譬如在园中最为落寞的时间，一群雨燕便出来高歌，把天地都叫喊得苍凉；譬如冬天雪地上孩子的脚印，总让人猜想他们是谁，曾在哪儿做过些什么，然后又都到哪儿去了；譬如那些苍黑的古柏，你忧郁的时候它们镇静地站在那儿，你欣喜的时候它们依然镇静地站在那儿，它们没日没夜地站在那儿从你没有出生一直站到这个世界上又没了你的时候；譬如暴雨骤临园中，激起一阵阵灼烈而清纯的草木和泥土的气味，让人想起无数个夏天的事件；譬如秋风忽至，再有一场早霜，落叶或飘摇歌舞或坦然安卧，满园中播散着熨帖而微苦的味道。味道是最说不清楚的。味道不能写只能闻，要你身临其境去闻才能明了。味道甚至是难于记忆的，只有你又闻到它你才能记起它的全部情感和意蕴。所以我常常要到那园子里去。",
    "reference_list": "考点1：“园子”应译为“Ditan Park或park”，此处的园子指北京地坛公园，不可译为garden。\n考点2：“殿堂”可译为“hall”。\n考点3：“那座祭坛我不能上去”表达“上去”不可用climb，此文作者行动不便、坐轮椅，因此不可翻译为climb。\n考点4：“石门”推荐译为“stone arch”，用gate不合适。\n考点5：“镇静地”推荐译为“sedately”，不可用calmly，calmly着重描述在压力情境下保持克制、稳定的行为方式，和此处古树的状态不符。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "散文",
    "prompt_id": "1"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n摘   要：\n批判性思维是促使学生深度理解物理概念并提升其解决复杂问题能力的关键因素。然而，传统教学多聚焦于批判性思维相关的分析推理技能，较少关注批判性思维的认知基础。通过分析三个典型的物理学习案例，揭示批判性思维在物理学习中的表现特征。在此基础上，基于双加工理论和抑制控制理论，提出物理学习中批判性思维的认知基础在于学生能否识别并抑制直觉优势反应，转而调动系统２进行理性思考。接着，从认知行为与神经机制两个方面梳理抑制控制与批判性思维的实证证据。最后，从抑制控制训练融入物理课堂、提供支持性的物理课堂环境、抑制控制的自我监控与实践等方面提出对物理教学的启示。\n批判性思维是21世纪人才应该具备的关键能力，尤其在科学教育领域，其对于学生形成理性判断、批判评估与创新表达的能力尤为重要。习近平总书记在中国科协第十次全国代表大会上的讲话中特别指出：“要更加重视人才自主培养，更加重视科学精神、创新能力、批判性思维的培养培育。”国内外科学课程亦高度强调批判性思维的重要性，如《普通高中物理课程标准（2017年版2020年修订）》指出：“……需要培养学生能够基于事实证据和科学推理对不同观点和结论提出质疑和批判，进行检验和修正，进而提出创新性见解的能力与品质”。\n然而，我国青少年的批判性思维能力发展仍面临相当大的挑战。Loyalka等人对中、美、印、俄四国STEM专业大学生的追踪调查发现，中国大学生在入学时批判性思维能力与他国相当，但在四年后出现显著下降。因此，仅依赖逻辑训练或知识灌输可能不足以支撑学生批判性思维的持续发展。\n近年来，来自认知心理学和神经科学的研究为理解批判性思维提供了新视角。研究指出，批判性思维不仅依赖推理技能，还受到个体能否抑制系统１产生的直觉性优势反应、成功调动系统２进行逻辑加工的制约。例如，在物理学习中，学习者可能会因套用直觉或经验法则而作出错误判断。这些快速反应往往具有高度自动化特征，难以被意识到，因而需要抑制控制的参与才能启动反思性或批判性的思维加工。\n本文基于双加工理论与抑制控制理论，指出物理学习中批判性思维的认知基础在于学习者能否识别并抑制直觉优势反应，转而调动系统２进行理性思考，这种抑制系统１和调动系统２的能力与执行功能中的抑制控制密切相关。本文在回顾批判性思维内涵的基础上，通过三个典型的物理学习案例揭示批判性思维在物理学习中的表现，进一步从理论和实证层面梳理了抑制控制与批判性思维之间的关联。在此基础上，本文还从抑制控制的视角对物理教学中培养学生的批判性思维提出了建议。\n ",
    "ori_text": "摘   要：\n批判性思维是促使学生深度理解物理概念并提升其解决复杂问题能力的关键因素。然而，传统教学多聚焦于批判性思维相关的分析推理技能，较少关注批判性思维的认知基础。通过分析三个典型的物理学习案例，揭示批判性思维在物理学习中的表现特征。在此基础上，基于双加工理论和抑制控制理论，提出物理学习中批判性思维的认知基础在于学生能否识别并抑制直觉优势反应，转而调动系统２进行理性思考。接着，从认知行为与神经机制两个方面梳理抑制控制与批判性思维的实证证据。最后，从抑制控制训练融入物理课堂、提供支持性的物理课堂环境、抑制控制的自我监控与实践等方面提出对物理教学的启示。\n批判性思维是21世纪人才应该具备的关键能力，尤其在科学教育领域，其对于学生形成理性判断、批判评估与创新表达的能力尤为重要。习近平总书记在中国科协第十次全国代表大会上的讲话中特别指出：“要更加重视人才自主培养，更加重视科学精神、创新能力、批判性思维的培养培育。”国内外科学课程亦高度强调批判性思维的重要性，如《普通高中物理课程标准（2017年版2020年修订）》指出：“……需要培养学生能够基于事实证据和科学推理对不同观点和结论提出质疑和批判，进行检验和修正，进而提出创新性见解的能力与品质”。\n然而，我国青少年的批判性思维能力发展仍面临相当大的挑战。Loyalka等人对中、美、印、俄四国STEM专业大学生的追踪调查发现，中国大学生在入学时批判性思维能力与他国相当，但在四年后出现显著下降。因此，仅依赖逻辑训练或知识灌输可能不足以支撑学生批判性思维的持续发展。\n近年来，来自认知心理学和神经科学的研究为理解批判性思维提供了新视角。研究指出，批判性思维不仅依赖推理技能，还受到个体能否抑制系统１产生的直觉性优势反应、成功调动系统２进行逻辑加工的制约。例如，在物理学习中，学习者可能会因套用直觉或经验法则而作出错误判断。这些快速反应往往具有高度自动化特征，难以被意识到，因而需要抑制控制的参与才能启动反思性或批判性的思维加工。\n本文基于双加工理论与抑制控制理论，指出物理学习中批判性思维的认知基础在于学习者能否识别并抑制直觉优势反应，转而调动系统２进行理性思考，这种抑制系统１和调动系统２的能力与执行功能中的抑制控制密切相关。本文在回顾批判性思维内涵的基础上，通过三个典型的物理学习案例揭示批判性思维在物理学习中的表现，进一步从理论和实证层面梳理了抑制控制与批判性思维之间的关联。在此基础上，本文还从抑制控制的视角对物理教学中培养学生的批判性思维提出了建议。\n ",
    "reference_list": "考点 1：《普通高中物理课程标准（2017 年版 2020 年修订）》 应译为\"Physics Curriculum Standards for Senior High Schools (2017 Edition, 2020 Revision)\"\n考点 2：STEM 专业大学生 应译为 \"STEM major college students\"\n考点 3：追踪调查 应译为\" longitudinal study /tracking survey”\n考点4：高度自动化特征 应译为\" highly automated characteristics\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "97"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n近年来,在系列助农政策的支持下,我国特色林果的机械化生产技术得到迅速发展。然而,采收作为特色林果生产过程中劳动强度最大的环节,其机械化技术水平偏低已成为制约我国特色林果产业发展的主要问题。为全面了解我国特色林果机械化采收技术的发展现状和存在问题,系统梳理2018—2023年国内外在林果机械化采收领域的相关技术与装备研究,并进行深入分析。目前我国针对林果机械化采收技术的研究大部分停留在理论层面,落地用于实际生产的设备较少,且现有的机械采收设备大多需要人工辅助进行作业,功能相对单一且自动化程度较低。在此基础上提出我国特色林果采收设备应向自动化、智能化以及功能多样化等方向发展的思路,为进一步推动我国特色林果产业的机械化生产奠定基础。\n近年来,桑葚、红枣、核桃等特色林果的种植面积生产过程中机械化程度逐渐增加,全过程自动化生产方式成为特色林果生产的发展趋势,其中机械化采收直接关系到特色林果产品的产出质量,是特色林果产业转变发展方式、节本增效、增强国际市场竞争力的重要途径之一[1],大力发展林果业机械化采收对促进我国特色林果产业发展具有重要意义。\n林果机械化采收技术在国外已较为成熟,广泛应用于柑橘、樱桃、杏和红枣等林果的采收环节。然而,这些采收设备因其较强的针对性,难以适应我国果园的地形和多样化种植模式。相比之下,我国林果机械化采收技术起步较晚,技术层面尚有诸多不足。因此,研发适合我国林果园机械化作业的采收设备,对于推动我国特色林果产业迈向全程全面机械化生产具有重要意义。\n本文基于现有的特色林果机械化采收技术,深入剖析我国林果机械化采收设备在行走、采摘和收获等作业环节中存在的问题,并针对这些问题提出切实可行的解决方案,以满足我国林果收获的实际需求,为我国特色林果机械化生产技术的持续发展提供参考。\n1振动式采收\n振动采收是我国果园使用最广泛的机械化采收方式之一,其工作原理为:通过振动器直接接触果树,使果树以一定的频率和振幅振动,带动果实产生惯性力,当惯性力大于果实的脱落阻力时,果实掉落,达到采摘果实的目的。振动采摘的工作原理决定了该方式的适用对象为果实较坚硬、对采摘质量要求不高的干果类、坚果类和部分鲜果类林果。\n在研发振动采收设备之前,国内外学者通过构建果树模型并进行了深入的分析,研究了果树在受到振动时各部分的响应情况及不同振动位置对果实的损伤情况[2]。基于不同振动位置的采收效果,将林果振动式采收机分为树冠振动式、树枝振摇式(枝条)和树干振动式3种类型。\n1.1树冠振动式采收\n树冠振动式采收装置通常依靠指拍杆或拨棒插入果树冠层,使用动力装置驱动指拍杆以一定轨迹运动,以带动冠层枝条进行振动,从而达到落果的效果。在国外,树冠振动采收技术发展较为成熟,不仅实现了对一般林果在田间环境下的机械化采收,对于易受损伤的葡萄等浆果脱粒作业亦具备实现可能性。Caprara[3]和Pellenc[4]等通过动力装置驱动指拍杆击打葡萄藤实现葡萄采收,Ioan[5]利用偏心圆盘摇杆机构驱动尼龙弹性杆振摇葡萄藤实现酿酒葡萄采收。在我国,树冠振动技术的作业对象仍以对外观破损要求较低的红枣、核桃等林果为主。为了适应我国新疆红枣的矮化密植种植模式,付威等[6]设计了一种树冠振动式采收机———4ZZ-4自走式红枣收获机,梅松等[7]研究了通过拍打红枣树冠层枝条来实现红枣果实脱落。此外,树冠振动采收方式在核桃、油茶果、柑橘等果树的采收作业中应用广泛,王真真等[8]通过研究驱动拨杆转动来拍打核桃冠层,有效地降低了采收过程中装置对树枝的机械损伤;吴问天[9]、伍德林[10]和杜小强[11]等针对油茶果树的生长特点和果实脱落时的受力情况设计了适合油茶采收的树冠式振动采收装置;蒲应俊[12]根据柑橘树冠形态和果实分布特点设计了一种上、下两段式树冠振动装置,当上、下振动系统的振动频率分别为4.7Hz、4.1Hz时,其采收率和树冠损伤率分别为82.5%、3.9%。已有的树冠振动式采收机具有较高的采收效率和采净率,适合大面积种植的小型林果采收,且选择合适的振动力度和频率进行作业,对果树冠层枝条的损伤较小。树冠振动采收装置对红枣、枸杞等小型林果的采收效果较好[13]。",
    "ori_text": "近年来,在系列助农政策的支持下,我国特色林果的机械化生产技术得到迅速发展。然而,采收作为特色林果生产过程中劳动强度最大的环节,其机械化技术水平偏低已成为制约我国特色林果产业发展的主要问题。为全面了解我国特色林果机械化采收技术的发展现状和存在问题,系统梳理2018—2023年国内外在林果机械化采收领域的相关技术与装备研究,并进行深入分析。目前我国针对林果机械化采收技术的研究大部分停留在理论层面,落地用于实际生产的设备较少,且现有的机械采收设备大多需要人工辅助进行作业,功能相对单一且自动化程度较低。在此基础上提出我国特色林果采收设备应向自动化、智能化以及功能多样化等方向发展的思路,为进一步推动我国特色林果产业的机械化生产奠定基础。\n近年来,桑葚、红枣、核桃等特色林果的种植面积生产过程中机械化程度逐渐增加,全过程自动化生产方式成为特色林果生产的发展趋势,其中机械化采收直接关系到特色林果产品的产出质量,是特色林果产业转变发展方式、节本增效、增强国际市场竞争力的重要途径之一[1],大力发展林果业机械化采收对促进我国特色林果产业发展具有重要意义。\n林果机械化采收技术在国外已较为成熟,广泛应用于柑橘、樱桃、杏和红枣等林果的采收环节。然而,这些采收设备因其较强的针对性,难以适应我国果园的地形和多样化种植模式。相比之下,我国林果机械化采收技术起步较晚,技术层面尚有诸多不足。因此,研发适合我国林果园机械化作业的采收设备,对于推动我国特色林果产业迈向全程全面机械化生产具有重要意义。\n本文基于现有的特色林果机械化采收技术,深入剖析我国林果机械化采收设备在行走、采摘和收获等作业环节中存在的问题,并针对这些问题提出切实可行的解决方案,以满足我国林果收获的实际需求,为我国特色林果机械化生产技术的持续发展提供参考。\n1振动式采收\n振动采收是我国果园使用最广泛的机械化采收方式之一,其工作原理为:通过振动器直接接触果树,使果树以一定的频率和振幅振动,带动果实产生惯性力,当惯性力大于果实的脱落阻力时,果实掉落,达到采摘果实的目的。振动采摘的工作原理决定了该方式的适用对象为果实较坚硬、对采摘质量要求不高的干果类、坚果类和部分鲜果类林果。\n在研发振动采收设备之前,国内外学者通过构建果树模型并进行了深入的分析,研究了果树在受到振动时各部分的响应情况及不同振动位置对果实的损伤情况[2]。基于不同振动位置的采收效果,将林果振动式采收机分为树冠振动式、树枝振摇式(枝条)和树干振动式3种类型。\n1.1树冠振动式采收\n树冠振动式采收装置通常依靠指拍杆或拨棒插入果树冠层,使用动力装置驱动指拍杆以一定轨迹运动,以带动冠层枝条进行振动,从而达到落果的效果。在国外,树冠振动采收技术发展较为成熟,不仅实现了对一般林果在田间环境下的机械化采收,对于易受损伤的葡萄等浆果脱粒作业亦具备实现可能性。Caprara[3]和Pellenc[4]等通过动力装置驱动指拍杆击打葡萄藤实现葡萄采收,Ioan[5]利用偏心圆盘摇杆机构驱动尼龙弹性杆振摇葡萄藤实现酿酒葡萄采收。在我国,树冠振动技术的作业对象仍以对外观破损要求较低的红枣、核桃等林果为主。为了适应我国新疆红枣的矮化密植种植模式,付威等[6]设计了一种树冠振动式采收机———4ZZ-4自走式红枣收获机,梅松等[7]研究了通过拍打红枣树冠层枝条来实现红枣果实脱落。此外,树冠振动采收方式在核桃、油茶果、柑橘等果树的采收作业中应用广泛,王真真等[8]通过研究驱动拨杆转动来拍打核桃冠层,有效地降低了采收过程中装置对树枝的机械损伤;吴问天[9]、伍德林[10]和杜小强[11]等针对油茶果树的生长特点和果实脱落时的受力情况设计了适合油茶采收的树冠式振动采收装置;蒲应俊[12]根据柑橘树冠形态和果实分布特点设计了一种上、下两段式树冠振动装置,当上、下振动系统的振动频率分别为4.7Hz、4.1Hz时,其采收率和树冠损伤率分别为82.5%、3.9%。已有的树冠振动式采收机具有较高的采收效率和采净率,适合大面积种植的小型林果采收,且选择合适的振动力度和频率进行作业,对果树冠层枝条的损伤较小。树冠振动采收装置对红枣、枸杞等小型林果的采收效果较好[13]。",
    "reference_list": "考点 1：“国际市场竞争力” 推荐译为 “competitiveness in the international market”\n考点 2：“干果类” 推荐译为 “dry fruits”\n考点 3：“树冠振动式” 推荐译为 “canopy shaker type”\n考点 4：“树枝振摇式” 推荐译为 “branch shaker type”\n考点 5：“树干振动式” 推荐译为 “trunk shaker type”\n考点 6：“指拍杆” 必须译为 “finger-beating rod”\n考点7：“浆果脱粒作业”推荐译为“berry destemming operations”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "173"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n二、物流行业未来发展趋势\n2.1 物流运行保持良好增长\n展望2025年，随着更加积极的财政政策和适度宽松的货币政策贯彻落实，政策“组合拳”将加快落地，社会物流需求有望得到提振。我国物流市场将保持温和增长态势，助力经济持续回升向好。这一趋势不仅得益于政策环境的优化，还受益于物流行业自身的结构调整和转型升级。\n2.2 提质增效降本走向深入\n物流降成本的出发点是服务实体经济，重点是通过提质增效降低供应链全链条的物流成本。受增长压力和降本要求影响，越来越多的工商企业、物流企业将逐步从流程优化、资源整合向更加深入的组织协同转变。在企业内部、企业之间、产业之间打破市场边界，加强与上下游、区域间联动融合，有望打开降本增效新空间，挖掘企业“第三利润源”，助力增强产业竞争力。\n2.3 供应链升级加快提速\n我国传统的运输、仓储业态已基本完成向现代物流服务的转型升级，下一阶段将加快向现代供应链转型升级。供应链是物流的高级形态，致力于通过生产组织方式的变革来创造新价值。随着产业高端化趋势显现，工商企业与物流企业将深化供应链融合创新，提供专业化、一体化、集成化的供应链解决方案，满足客户多样化需求，共同实现供应链价值创造。\n三、物流行业未来发展趋势前景\n3.1 韧性安全水平持续提升\n我国出口货物结构发生根本性转变，从劳动密集型产品转向装备制造等中高端产品。同时，制造业“出海”将更加深入，逐步向“本地化生产、全球化流通”转变。这将推动现代物流加快从“跟随”战略转向“本地化”战略，加大国际物流市场布局和资源投入，通过与国际合作伙伴加强合作，共同构筑韧性安全的全球供应链服务体系，更好服务高水平对外开放。\n3.2 数智化转型提档升级\n数字经济与现代物流的融合发展走在各行业前列，我国物流领域基本具备了数字化能力。下一步，通过数字技术和物流组织的有机连接，实现更高水平的效能提升。将先进的数字技术与现代供应链的组织方式深度融合，大力发展平台经济，形成创新驱动的生产组织方式和运行模式，有望推动现代物流从信息化向智能化的跃迁，构建形成随需应变的数字供应链，开拓产业发展新赛道。\n3.3 结构调整力度有所加大\n随着国家大力提振消费，超大规模市场优势显现，消费物流的市场贡献将进一步增长。外部市场环境倒逼制造业加快向高端化升级，工业物流市场中的装备制造物流需求仍将保持韧性，支柱地位将进一步得到巩固。随着铁路货运深化市场改革，“铁路进码头”“白货上铁路”将成为趋势，运输结构持续得到优化。",
    "ori_text": "二、物流行业未来发展趋势\n2.1 物流运行保持良好增长\n展望2025年，随着更加积极的财政政策和适度宽松的货币政策贯彻落实，政策“组合拳”将加快落地，社会物流需求有望得到提振。我国物流市场将保持温和增长态势，助力经济持续回升向好。这一趋势不仅得益于政策环境的优化，还受益于物流行业自身的结构调整和转型升级。\n2.2 提质增效降本走向深入\n物流降成本的出发点是服务实体经济，重点是通过提质增效降低供应链全链条的物流成本。受增长压力和降本要求影响，越来越多的工商企业、物流企业将逐步从流程优化、资源整合向更加深入的组织协同转变。在企业内部、企业之间、产业之间打破市场边界，加强与上下游、区域间联动融合，有望打开降本增效新空间，挖掘企业“第三利润源”，助力增强产业竞争力。\n2.3 供应链升级加快提速\n我国传统的运输、仓储业态已基本完成向现代物流服务的转型升级，下一阶段将加快向现代供应链转型升级。供应链是物流的高级形态，致力于通过生产组织方式的变革来创造新价值。随着产业高端化趋势显现，工商企业与物流企业将深化供应链融合创新，提供专业化、一体化、集成化的供应链解决方案，满足客户多样化需求，共同实现供应链价值创造。\n三、物流行业未来发展趋势前景\n3.1 韧性安全水平持续提升\n我国出口货物结构发生根本性转变，从劳动密集型产品转向装备制造等中高端产品。同时，制造业“出海”将更加深入，逐步向“本地化生产、全球化流通”转变。这将推动现代物流加快从“跟随”战略转向“本地化”战略，加大国际物流市场布局和资源投入，通过与国际合作伙伴加强合作，共同构筑韧性安全的全球供应链服务体系，更好服务高水平对外开放。\n3.2 数智化转型提档升级\n数字经济与现代物流的融合发展走在各行业前列，我国物流领域基本具备了数字化能力。下一步，通过数字技术和物流组织的有机连接，实现更高水平的效能提升。将先进的数字技术与现代供应链的组织方式深度融合，大力发展平台经济，形成创新驱动的生产组织方式和运行模式，有望推动现代物流从信息化向智能化的跃迁，构建形成随需应变的数字供应链，开拓产业发展新赛道。\n3.3 结构调整力度有所加大\n随着国家大力提振消费，超大规模市场优势显现，消费物流的市场贡献将进一步增长。外部市场环境倒逼制造业加快向高端化升级，工业物流市场中的装备制造物流需求仍将保持韧性，支柱地位将进一步得到巩固。随着铁路货运深化市场改革，“铁路进码头”“白货上铁路”将成为趋势，运输结构持续得到优化。",
    "reference_list": "考点1：“政策‘组合拳’”推荐译为“policy package”。\n考点2：”高端化“不可简单译为“upgrading”\n考点3：“业态”推荐译为“business format”。\n考点4：“第三利润源“应该译为“the third profit source”是，一个特定的经济学概念。\n考点5：”白货“应该译为“general cargo”，是铁路货运离你关于的专业术语，指包装规整、价值较高的工业制成品和消费品。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "37"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n移动、引拍、击球——测试场地上，一个四足机器人灵活地挥动机械臂，将飞来的羽毛球打回给它的人类对手。近日，瑞士苏黎世联邦理工学院研究团队在国际期刊《科学·机器人学》上发布了其研发的新型足式机器人系统（见图，瑞士苏黎世联邦理工学院供图）。这个特殊的“运动员”能够仅凭机载感知设备预测羽毛球飞行轨迹、调整自身位置并精确完成击打动作。“我们的成果展示了足式机器人如何执行复杂、动态、由感知驱动的任务，可以为整合机器人高速感知和全身协调能力提供新的思路。”该研究的第一作者、苏黎世联邦理工学院机器人系统实验室的马云涛博士在接受本报记者采访时表示。\n羽毛球是世界上速度最快的球类运动之一，球速最高可达每小时400公里以上。运动员需要在极短的时间内捕捉羽毛球飞行轨迹，然后在一定范围内快速完成位移和击球动作。这项运动对预判、跑位和挥拍技术要求比较高，因而成为测试机器人动态感知与运动协调能力的理想项目。马云涛解释说，选择羽毛球作为实验对象，通过设置固定和移动等不同难度的击打目标，研究团队可以渐进式地检验和提升机器人性能。\n要成为合格的“羽毛球选手”，机器人首先要做到“看得清”。现有商用机载相机的运动稳定性、可变焦距和信息处理能力等方面远逊于人眼，为实现有效的视觉追踪，研究团队开发了感知噪声模型，用以量化机器人抖动、旋转等运动状态对目标追踪的影响，使机器人能够主动适应动态模糊、目标遮挡等干扰。即便目标因高速运动或遮挡短暂消失，机器人仍可基于历史运动轨迹持续预测其位置。当羽毛球高速飞离视野中心时，机器人也会主动调整身体俯仰角度，将目标保持在相机视野内以优化追踪效果。\n让机器人“动得准”是另一大挑战。传统运动机器人往往将移动与操作任务分离——底盘负责跑位，而机械臂负责操作。这种“各司其职”的设计使机器人难以应对复杂的动态环境。“我们通过一个基于强化学习的统一控制框架，将主动感知、移动和操作功能整合为一体。”该研究的共同作者、苏黎世联邦理工学院机械与加工工程系教授马科·胡特表示，这项技术可同步协调机器人周身18个关节的运动，通过判断来球的时间和距离，自主调整步态和击球方式。实验显示，在测试条件下，机器人可以在单个回合内与人类对手进行10次连续对打，且对于落在球场中心区域的球达到近100%的拦截成功率。\n目前，机器人从发现对手击球到发出挥拍动作平均需要约0.35秒，其感知和反应能力仍有提升空间。研究团队计划通过集成更多传感器、融合多种传感模式并优化视觉算法等，进一步升级机器人性能。未来，这一成果有望走出球场，应用于更多需要快速响应和全身协调的复杂场景。“机器人学会了如何平衡感知稳定性与运动灵活性，这种视觉与运动之间的紧密耦合不仅对体育运动至关重要，对于灾难响应、人机协作等动态应用场景同样关键。这是迈向更具感知力与响应能力的移动机器人的重要一步。”马科·胡特表示。\n“相较于轮式和履带式机器人，足式机器人具有更强的通用性，能够适应更广泛的应用场景，加之与人工智能技术的融合，将具备强大的感知和操作功能。”中国社会科学院中国式现代化研究院研究员李晓华表示，“随着人工智能与机器人本体技术的突破及深度融合，规模化生产促进生产成本显著下降，功能更强大、价格更低廉的足式机器人将在工业、休闲娱乐、居家生活、养老照护等领域获得广泛应用，发展成为对国民经济具有重要推动力和影响力的新兴产业。",
    "ori_text": "移动、引拍、击球——测试场地上，一个四足机器人灵活地挥动机械臂，将飞来的羽毛球打回给它的人类对手。近日，瑞士苏黎世联邦理工学院研究团队在国际期刊《科学·机器人学》上发布了其研发的新型足式机器人系统（见图，瑞士苏黎世联邦理工学院供图）。这个特殊的“运动员”能够仅凭机载感知设备预测羽毛球飞行轨迹、调整自身位置并精确完成击打动作。“我们的成果展示了足式机器人如何执行复杂、动态、由感知驱动的任务，可以为整合机器人高速感知和全身协调能力提供新的思路。”该研究的第一作者、苏黎世联邦理工学院机器人系统实验室的马云涛博士在接受本报记者采访时表示。\n羽毛球是世界上速度最快的球类运动之一，球速最高可达每小时400公里以上。运动员需要在极短的时间内捕捉羽毛球飞行轨迹，然后在一定范围内快速完成位移和击球动作。这项运动对预判、跑位和挥拍技术要求比较高，因而成为测试机器人动态感知与运动协调能力的理想项目。马云涛解释说，选择羽毛球作为实验对象，通过设置固定和移动等不同难度的击打目标，研究团队可以渐进式地检验和提升机器人性能。\n要成为合格的“羽毛球选手”，机器人首先要做到“看得清”。现有商用机载相机的运动稳定性、可变焦距和信息处理能力等方面远逊于人眼，为实现有效的视觉追踪，研究团队开发了感知噪声模型，用以量化机器人抖动、旋转等运动状态对目标追踪的影响，使机器人能够主动适应动态模糊、目标遮挡等干扰。即便目标因高速运动或遮挡短暂消失，机器人仍可基于历史运动轨迹持续预测其位置。当羽毛球高速飞离视野中心时，机器人也会主动调整身体俯仰角度，将目标保持在相机视野内以优化追踪效果。\n让机器人“动得准”是另一大挑战。传统运动机器人往往将移动与操作任务分离——底盘负责跑位，而机械臂负责操作。这种“各司其职”的设计使机器人难以应对复杂的动态环境。“我们通过一个基于强化学习的统一控制框架，将主动感知、移动和操作功能整合为一体。”该研究的共同作者、苏黎世联邦理工学院机械与加工工程系教授马科·胡特表示，这项技术可同步协调机器人周身18个关节的运动，通过判断来球的时间和距离，自主调整步态和击球方式。实验显示，在测试条件下，机器人可以在单个回合内与人类对手进行10次连续对打，且对于落在球场中心区域的球达到近100%的拦截成功率。\n目前，机器人从发现对手击球到发出挥拍动作平均需要约0.35秒，其感知和反应能力仍有提升空间。研究团队计划通过集成更多传感器、融合多种传感模式并优化视觉算法等，进一步升级机器人性能。未来，这一成果有望走出球场，应用于更多需要快速响应和全身协调的复杂场景。“机器人学会了如何平衡感知稳定性与运动灵活性，这种视觉与运动之间的紧密耦合不仅对体育运动至关重要，对于灾难响应、人机协作等动态应用场景同样关键。这是迈向更具感知力与响应能力的移动机器人的重要一步。”马科·胡特表示。\n“相较于轮式和履带式机器人，足式机器人具有更强的通用性，能够适应更广泛的应用场景，加之与人工智能技术的融合，将具备强大的感知和操作功能。”中国社会科学院中国式现代化研究院研究员李晓华表示，“随着人工智能与机器人本体技术的突破及深度融合，规模化生产促进生产成本显著下降，功能更强大、价格更低廉的足式机器人将在工业、休闲娱乐、居家生活、养老照护等领域获得广泛应用，发展成为对国民经济具有重要推动力和影响力的新兴产业。",
    "reference_list": "考点 1：“四足机器人”应译为 \"quadrupedal robot\"\n考点 2：“机载感知设备”应译为 \"onboard perception system\"\n考点3：“足式机器人系统” 应译为 \"legged robotic system\"\n考点4：“行轨迹 ”应译为 \"flight trajectory\"\n考点5：“运动协调能力 ”应译为 \"motor coordination ability\"\n考点6：“动态模糊”应译为 \"motion blur\"\n考点7：历史运动轨迹 应译为 \"historical motion trajectory\"\n考点8：俯仰角度 应译为 \"pitch angle\"\n考点9：新兴产业 应译为 \"emerging industry\"\n考点10：“黎世联邦理工学院”应译为“ETH Zurich”\n考点11： “《科学·机器人学》”应译为“Science Robotics”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "85"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 与《社会学基本概念》中“代表与支配”合一的行政集团相关的是韦伯所谓的“自由代表制”类型。在《支配的类型》中，“自由代表制”与占有代表特权的身份型代表和约束型代表形成明显的反差。其差别的焦点在于，“自由代表认为表达自己实在的信念才与自己被推举为代表相符。这类自由代表在韦伯看来是“支配者”而不是被代表者的代理人。对韦伯来说，自由代表和代议机构的结合(而不是代表制本身)是西方历史的独特动力。这种结合面临两个方向的基本挑战，即直接面对选民的领袖制度和政党的科层化。为后代学者熟知的现代政治家的天职观恰恰只能出现在政治经营的两个典型困境的考验--民粹政治家与政党机构化--之后。政治天职被政治经营考验，体现了韦伯对正当性支配之说的局限性的认识。\n根本而言，自由代表制积极地扩展了《社会学基本概念》当中“代表和支配合一的说法而不是与之构成矛盾。它与《政治作为天职》的核心论点是相互呼应的，都是对天职观两分的深化。两种意义上的“政治为业”相互刺激，是现代政治家的伦理出现的基本前提，这决定了韦伯眼中的现代政治家其实相当“晚出”，而且只能以“责任伦理”作为根本的规范共性。\n在“高度统一和最严格的纪律”的结合方面，政党选举打破了乡绅名士和国会议员的限制，将政党权力放在了可以持续推进组织化的人身上。要平衡专业官僚，政治的支配意志需要更强大的民意动员。党工、总统和议会选举出的首相(凯撒制领袖)能对抗科层制形成的一种压倒生命力的理念，一旦职官再度变成专业官员控制的位置，也就是出现一战前德国式的行政官员变成望族的那种情形，那么民意领袖和政党机器合一的制度就会面临最大的挑战。而从首席政治家开始，政党选举越来越成为政治家的试金石。无论在议会制下还是在直接民选制下，胜利党领袖在理论上都表明政治家在行使支配者的力量，而不只是作为行政集团的首脑。这些促使领袖获得代议制选举胜利的政治经营，尤其是体现在盎格鲁-萨克逊传统中的机构化，构成了韦伯笔下的“机器”。\n韦伯在19世纪前半期的美国和1868年之后的英国看见了借助政党机器抑制望族和议会的民选领袖。民意领袖借助机器化的政党机构战胜了望族和国会，这个过程与《政治作为天职》开始的时候君主借助行政官僚抑制贵族制有些形式上的类似。例如格莱斯通和迪斯莱利均需要一个隐在演说的幕后、以让领袖得到足够选民支持为已任的“党魁”。党魁接受一切针对其不择手段的“政治伦理”的指责包括接受以清除党魁的腐败为已任的党内候选者的指责。在韦伯看来，被上流鄙视是他们“志业性”的一部分。\n政治家的责任围绕着权力展开，认识到权力是手段，而且要从这一手段而不是一般性的道德原则中找到一种伦理的力量，这是政治家的独有使命。将权力作为手段来享受是政治家产生内在支柱的前提，这一点和上文所说的国家作为特殊的政治手段而产生规范性要求的命题有内在的呼应。不过，政治家对自己用权力来追求什么的回答只能是基于信念。和《弗莱堡演讲》不同，韦伯在这个演说中并没有告诉我们政治家信仰的“目标”应该以什么样的价值尺度来衡量。然而，韦伯对什么样的人格会为运用权力负责任却有清楚的标准。\n如果政治伦理的特殊性在于权力背后的责任感，那么韦伯只提供了责任感的人格保证：政治人格在于热情、责任心和判断力，这是韦伯关于志业政治家人格最著名的结论。只有具备政治人格，才能在正确的距离下看待权力是所有政治的手段这件事情，并将正当性的追求返回到政治家本身。\n这样，韦伯在演讲开始时对国家的定义和在文末对政治家的期待之间形成了有意思的对照：在对国家的定义当中，我们只能够讨论国家动用什么手段去实现目标，而不能讨论国家可以实现什么目标。而在这里，政治家要对作为政治手段的权力负责，却没有关于权力的目标的价值(正义)尺度可用。韦伯赋予政治一种伦理色彩的前提是人格，而非政治目标的价值。\n“机器”的譬喻在《政治作为天职》当中被韦伯给予了政党机器，而不是行政官僚。党内那些“自觉”放弃自身信念，或是在思想上尽量简陋的追随者才最典型地代表了机器。领袖出现的必然条件--或者说代价--就是机器。在《经济与社会》的写作体系当中，机器的譬喻只在《支配社会学》中大量地出现，在《社会学基本概念》和《支配的类型》这两篇以概念界说为重的文字中出现得很少，甚至没有韦伯在《政治共同体》篇中使用得多。\n领袖事实上能做到的，不取决于他自己，而是追随者行动的动机”。这些动机并不会和家产制支配之下有什么变化，都是“报复欲、权利欲、掠夺欲和俸禄欲”，而政治伦理不过是用再真诚不过的政治家理想让这些欲望在道德上正当化而已。信仰的英雄是消逝得最快的英雄，这就形成了一种悖论：如果目标的实现不取决于政治家自己的理想，而是追随者的动机，而追随政治家的人本质上是放弃或者剥脱信念的，那么所谓责任感，就首先是对无信念的政治负责任的伦理。“无情”的支配不来自于本不属于支配者的专业官员，而来自支配者自己。政治家“会意识到在这些悙谬的压力下所发生的改变，而且这改变是由他自己来负责任的”。\n天职观的两分以政治家区分信念和魔鬼般的世界为前提，浸透了强烈的新教政治的风格。责任伦理是对政治没有伦理的鲜明回应。政治的经营是政治家无法摆脱的魔鬼般的力量，政治家的责任伦理的力量是始终和魔鬼相伴的力量，一种人世禁欲主义的体现。浮士德笔下和灵魂同在的魔鬼在韦伯看来才是政治家的最好写照。",
    "ori_text": "\n\n 与《社会学基本概念》中“代表与支配”合一的行政集团相关的是韦伯所谓的“自由代表制”类型。在《支配的类型》中，“自由代表制”与占有代表特权的身份型代表和约束型代表形成明显的反差。其差别的焦点在于，“自由代表认为表达自己实在的信念才与自己被推举为代表相符。这类自由代表在韦伯看来是“支配者”而不是被代表者的代理人。对韦伯来说，自由代表和代议机构的结合(而不是代表制本身)是西方历史的独特动力。这种结合面临两个方向的基本挑战，即直接面对选民的领袖制度和政党的科层化。为后代学者熟知的现代政治家的天职观恰恰只能出现在政治经营的两个典型困境的考验--民粹政治家与政党机构化--之后。政治天职被政治经营考验，体现了韦伯对正当性支配之说的局限性的认识。\n根本而言，自由代表制积极地扩展了《社会学基本概念》当中“代表和支配合一的说法而不是与之构成矛盾。它与《政治作为天职》的核心论点是相互呼应的，都是对天职观两分的深化。两种意义上的“政治为业”相互刺激，是现代政治家的伦理出现的基本前提，这决定了韦伯眼中的现代政治家其实相当“晚出”，而且只能以“责任伦理”作为根本的规范共性。\n在“高度统一和最严格的纪律”的结合方面，政党选举打破了乡绅名士和国会议员的限制，将政党权力放在了可以持续推进组织化的人身上。要平衡专业官僚，政治的支配意志需要更强大的民意动员。党工、总统和议会选举出的首相(凯撒制领袖)能对抗科层制形成的一种压倒生命力的理念，一旦职官再度变成专业官员控制的位置，也就是出现一战前德国式的行政官员变成望族的那种情形，那么民意领袖和政党机器合一的制度就会面临最大的挑战。而从首席政治家开始，政党选举越来越成为政治家的试金石。无论在议会制下还是在直接民选制下，胜利党领袖在理论上都表明政治家在行使支配者的力量，而不只是作为行政集团的首脑。这些促使领袖获得代议制选举胜利的政治经营，尤其是体现在盎格鲁-萨克逊传统中的机构化，构成了韦伯笔下的“机器”。\n韦伯在19世纪前半期的美国和1868年之后的英国看见了借助政党机器抑制望族和议会的民选领袖。民意领袖借助机器化的政党机构战胜了望族和国会，这个过程与《政治作为天职》开始的时候君主借助行政官僚抑制贵族制有些形式上的类似。例如格莱斯通和迪斯莱利均需要一个隐在演说的幕后、以让领袖得到足够选民支持为已任的“党魁”。党魁接受一切针对其不择手段的“政治伦理”的指责包括接受以清除党魁的腐败为已任的党内候选者的指责。在韦伯看来，被上流鄙视是他们“志业性”的一部分。\n政治家的责任围绕着权力展开，认识到权力是手段，而且要从这一手段而不是一般性的道德原则中找到一种伦理的力量，这是政治家的独有使命。将权力作为手段来享受是政治家产生内在支柱的前提，这一点和上文所说的国家作为特殊的政治手段而产生规范性要求的命题有内在的呼应。不过，政治家对自己用权力来追求什么的回答只能是基于信念。和《弗莱堡演讲》不同，韦伯在这个演说中并没有告诉我们政治家信仰的“目标”应该以什么样的价值尺度来衡量。然而，韦伯对什么样的人格会为运用权力负责任却有清楚的标准。\n如果政治伦理的特殊性在于权力背后的责任感，那么韦伯只提供了责任感的人格保证：政治人格在于热情、责任心和判断力，这是韦伯关于志业政治家人格最著名的结论。只有具备政治人格，才能在正确的距离下看待权力是所有政治的手段这件事情，并将正当性的追求返回到政治家本身。\n这样，韦伯在演讲开始时对国家的定义和在文末对政治家的期待之间形成了有意思的对照：在对国家的定义当中，我们只能够讨论国家动用什么手段去实现目标，而不能讨论国家可以实现什么目标。而在这里，政治家要对作为政治手段的权力负责，却没有关于权力的目标的价值(正义)尺度可用。韦伯赋予政治一种伦理色彩的前提是人格，而非政治目标的价值。\n“机器”的譬喻在《政治作为天职》当中被韦伯给予了政党机器，而不是行政官僚。党内那些“自觉”放弃自身信念，或是在思想上尽量简陋的追随者才最典型地代表了机器。领袖出现的必然条件--或者说代价--就是机器。在《经济与社会》的写作体系当中，机器的譬喻只在《支配社会学》中大量地出现，在《社会学基本概念》和《支配的类型》这两篇以概念界说为重的文字中出现得很少，甚至没有韦伯在《政治共同体》篇中使用得多。\n领袖事实上能做到的，不取决于他自己，而是追随者行动的动机”。这些动机并不会和家产制支配之下有什么变化，都是“报复欲、权利欲、掠夺欲和俸禄欲”，而政治伦理不过是用再真诚不过的政治家理想让这些欲望在道德上正当化而已。信仰的英雄是消逝得最快的英雄，这就形成了一种悖论：如果目标的实现不取决于政治家自己的理想，而是追随者的动机，而追随政治家的人本质上是放弃或者剥脱信念的，那么所谓责任感，就首先是对无信念的政治负责任的伦理。“无情”的支配不来自于本不属于支配者的专业官员，而来自支配者自己。政治家“会意识到在这些悙谬的压力下所发生的改变，而且这改变是由他自己来负责任的”。\n天职观的两分以政治家区分信念和魔鬼般的世界为前提，浸透了强烈的新教政治的风格。责任伦理是对政治没有伦理的鲜明回应。政治的经营是政治家无法摆脱的魔鬼般的力量，政治家的责任伦理的力量是始终和魔鬼相伴的力量，一种人世禁欲主义的体现。浮士德笔下和灵魂同在的魔鬼在韦伯看来才是政治家的最好写照。",
    "reference_list": "考点1. “支配”推荐译为“Domination”\n考点2. \"支配者”推荐译为“Ruler; Dominator”\n考点3. “责任伦理”推荐译为“Ethic of Responsibility”\n考点4. “自由代表制”推荐译为“Free Representation”\n考点5. “乡绅名士”推荐译为“Notables”\n考点6. “凯撒制领袖, 民意领袖”推荐译为“Plebiscitary Leadership; Caesarist Leader”\n考点7. “机器”推荐译为“(Party) Machine”\n考点8. “自觉放弃自身信念”推荐译为“Disenchantment of the soul; ”\n考点9. “入世禁欲主义”推荐译为“Inner-worldly Asceticism”，\n考点10. “政治经营”推荐译为“the operation of politics (as an enterprise)\n考点11. ”行政集团”建议译为“administrative group; administrative corps”\n考点12. “民粹政治家”建议译为“demagogue”\n考点13. “政治人格”建议译为“political personality”\n考点14. “志业性”建议译为“vocational character”\n考点15.“天职, 志业”推荐译为“Vocation; Calling”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "123"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n具身智能研究范畴已从早期的感知 — 反应式系统，发展至当代融合非平稳动力学建模与神经符号混合推理的跨学科前沿。当前，研究者借鉴形态计算、感官运动偶合与主动推理等理论框架，试图构建具有自组织与自适应能力的物理智能体。形态计算关注利用机器人本体的物理属性以减轻控制计算负担，而感官运动偶合则强调感知输入与运动输出的共同涌现机制，为多自由度系统的柔性操控提供新思路。主动推理以自由能原理为基础，通过最小化对环境模型的不确定性，达成对动态场景的自发贝叶斯更新。\n在具身智能的仿真与实证研究中，可微分仿真平台已成为关键工具。诸如可微分光照模拟、可微分流体动力学与可微分多体动力学的联合仿真，可通过梯度反向传播实现对物理参数的端到端训练。研究团队利用可微分仿真器与脉冲神经网络相结合，探索神经形态硬件在实时高频反馈任务中的可行性；并引入共轭梯度解算器对接全向移动底盘与仿生手爪的协同运动规划，以兼顾能量效率与轨迹精度。\n从算法层面看，近年兴起的图注意力网络与拓扑流形学习方法，为刻画高维状态空间中的结构化约束提供了有效途径。通过构建基于图卷积的世界模型，研究者能够在多主体协作场景中，利用张量分解与谱聚类方法对交互关系进行稀疏编码；进一步结合基于变分贝叶斯的群体推理，实现对智能体集群行为的宏观策略优化。此外，混合整数规划与深度确定性策略梯度的混合框架，已被用于解决高维离散动作与连续控制一体化决策问题。\n在生物启发层面，仿生柔体机器人与可重构结构的结合日趋深入。研究者通过脉冲编码的软体流变元件，实现对触觉 — 形变反馈的实时重构，并利用稀疏自编码器对触觉时序信号进行特征抽取。该方案在复杂管道导航与狭窄空间抓取任务中，展现出超越刚体机器人显著的鲁棒性与柔性适应能力。与此同时，基于仿生学的非线性共振控制技术，正被用于增强软体机构在高速振动环境中的稳定性。\n具身智能中的层次化控制方法亦不断演进。自顶向下的层次化部分可由符号规划器输出高层目标节点序列，随后由基于混沌系统的低层连续控制器进行实时执行；而自底向上的子任务发现，则运用面向补偿学习的元强化学习算法，在不确定性环境中自主生成行为原型。这种双向耦合的控制范式，结合了形式化方法与统计学习的优势，能够在开放世界任务中快速收敛至次优或近似最优解。\n在多模态感知方面，跨域时空对齐技术正在广泛应用。通过谱域散度最小化与流形正则化，研究者实现了视觉 — 激光雷达 — 红外成像等异构数据的统一表征；并借助基于能量模型的对抗学习，对传感器故障或数据稀疏情况下的鲁棒性进行系统评估。更进一步，融合自监督的周期一致性损失与几何约束正则化，能够在无标签环境下，自动生成高质量的语义地图。\n工业界亦在快速跟进：面向智造车间的具身智能系统，已逐步从原型验证转向小规模部署。若干企业采用神经符号混合推理架构，结合可微分示教与在线迁移学习，实现了机器手臂在异构工件 — 不同表面材质 — 多工序装配中的自适应夹持与路线规划。与此同时，针对动态协作机器人与人类工人的交互安全，研究机构提出了基于约束优化的实时安全壳算法，以确保协作空间内的碰撞避免与轨迹协同。\n开放研究挑战方面，首当其冲的是多尺度动力学的统一表征。现有模型多针对有限自由度或刚体假设，却难以兼顾非线性耦合、柔体变形与流体 - 固体交互等多物理场耦合问题。为弥补此短板，一些前沿研究将稀疏标量场分解与基于图的多物理仿真融合，通过自适应网格细化与基于高阶有限元的本构模型，对复杂拓扑变化过程进行可微化表达。该方法在预测软体水下推进机理与仿真生物诱导流场中取得了初步成果。\n其次，具身智能安全与伦理审查尚未形成系统方法论。随著智能体具备更高自主决策能力，如何在决策流程中引入符合社会规范与法律法规的价值约束，成为亟待解决的跨学科课题。研究者正在探索基于博弈论的伦理多目标优化，将道德权衡映射为约束优化问题；并计划在仿真预演环节，引入虚拟伦理审计器，以量化智能体在不同场景下的伦理风险暴露。\n面向未来，异构计算架构与硬 — 软件协同设计是推动具身智能实用化的关键。除神经形态芯片外，多核时序处理器、高性能 FPGA 与可重构 ASIC 的融合，能够为高维感知和闭环反馈提供低延迟与确定性性能；而软硬件协同优化框架，将围绕调度算法、功耗模型与实时操作系统内核层面进行深入耦合，为现场可部署的具身智能系统奠定基础。\n总之，具身智能正处于从理论化探究向工程化应用的临界阶段。跨学科融合、仿真 — 现实闭环与安全伦理共建，将成为未来研究的三大主轴。唯有在动力学本质、认知推理与系统工程层面形成闭环迭代，方能真正迈入 “类人自主” 与 “自主可解释” 并重的物理智能新时代。",
    "ori_text": "\n\n具身智能研究范畴已从早期的感知 — 反应式系统，发展至当代融合非平稳动力学建模与神经符号混合推理的跨学科前沿。当前，研究者借鉴形态计算、感官运动偶合与主动推理等理论框架，试图构建具有自组织与自适应能力的物理智能体。形态计算关注利用机器人本体的物理属性以减轻控制计算负担，而感官运动偶合则强调感知输入与运动输出的共同涌现机制，为多自由度系统的柔性操控提供新思路。主动推理以自由能原理为基础，通过最小化对环境模型的不确定性，达成对动态场景的自发贝叶斯更新。\n在具身智能的仿真与实证研究中，可微分仿真平台已成为关键工具。诸如可微分光照模拟、可微分流体动力学与可微分多体动力学的联合仿真，可通过梯度反向传播实现对物理参数的端到端训练。研究团队利用可微分仿真器与脉冲神经网络相结合，探索神经形态硬件在实时高频反馈任务中的可行性；并引入共轭梯度解算器对接全向移动底盘与仿生手爪的协同运动规划，以兼顾能量效率与轨迹精度。\n从算法层面看，近年兴起的图注意力网络与拓扑流形学习方法，为刻画高维状态空间中的结构化约束提供了有效途径。通过构建基于图卷积的世界模型，研究者能够在多主体协作场景中，利用张量分解与谱聚类方法对交互关系进行稀疏编码；进一步结合基于变分贝叶斯的群体推理，实现对智能体集群行为的宏观策略优化。此外，混合整数规划与深度确定性策略梯度的混合框架，已被用于解决高维离散动作与连续控制一体化决策问题。\n在生物启发层面，仿生柔体机器人与可重构结构的结合日趋深入。研究者通过脉冲编码的软体流变元件，实现对触觉 — 形变反馈的实时重构，并利用稀疏自编码器对触觉时序信号进行特征抽取。该方案在复杂管道导航与狭窄空间抓取任务中，展现出超越刚体机器人显著的鲁棒性与柔性适应能力。与此同时，基于仿生学的非线性共振控制技术，正被用于增强软体机构在高速振动环境中的稳定性。\n具身智能中的层次化控制方法亦不断演进。自顶向下的层次化部分可由符号规划器输出高层目标节点序列，随后由基于混沌系统的低层连续控制器进行实时执行；而自底向上的子任务发现，则运用面向补偿学习的元强化学习算法，在不确定性环境中自主生成行为原型。这种双向耦合的控制范式，结合了形式化方法与统计学习的优势，能够在开放世界任务中快速收敛至次优或近似最优解。\n在多模态感知方面，跨域时空对齐技术正在广泛应用。通过谱域散度最小化与流形正则化，研究者实现了视觉 — 激光雷达 — 红外成像等异构数据的统一表征；并借助基于能量模型的对抗学习，对传感器故障或数据稀疏情况下的鲁棒性进行系统评估。更进一步，融合自监督的周期一致性损失与几何约束正则化，能够在无标签环境下，自动生成高质量的语义地图。\n工业界亦在快速跟进：面向智造车间的具身智能系统，已逐步从原型验证转向小规模部署。若干企业采用神经符号混合推理架构，结合可微分示教与在线迁移学习，实现了机器手臂在异构工件 — 不同表面材质 — 多工序装配中的自适应夹持与路线规划。与此同时，针对动态协作机器人与人类工人的交互安全，研究机构提出了基于约束优化的实时安全壳算法，以确保协作空间内的碰撞避免与轨迹协同。\n开放研究挑战方面，首当其冲的是多尺度动力学的统一表征。现有模型多针对有限自由度或刚体假设，却难以兼顾非线性耦合、柔体变形与流体 - 固体交互等多物理场耦合问题。为弥补此短板，一些前沿研究将稀疏标量场分解与基于图的多物理仿真融合，通过自适应网格细化与基于高阶有限元的本构模型，对复杂拓扑变化过程进行可微化表达。该方法在预测软体水下推进机理与仿真生物诱导流场中取得了初步成果。\n其次，具身智能安全与伦理审查尚未形成系统方法论。随著智能体具备更高自主决策能力，如何在决策流程中引入符合社会规范与法律法规的价值约束，成为亟待解决的跨学科课题。研究者正在探索基于博弈论的伦理多目标优化，将道德权衡映射为约束优化问题；并计划在仿真预演环节，引入虚拟伦理审计器，以量化智能体在不同场景下的伦理风险暴露。\n面向未来，异构计算架构与硬 — 软件协同设计是推动具身智能实用化的关键。除神经形态芯片外，多核时序处理器、高性能 FPGA 与可重构 ASIC 的融合，能够为高维感知和闭环反馈提供低延迟与确定性性能；而软硬件协同优化框架，将围绕调度算法、功耗模型与实时操作系统内核层面进行深入耦合，为现场可部署的具身智能系统奠定基础。\n总之，具身智能正处于从理论化探究向工程化应用的临界阶段。跨学科融合、仿真 — 现实闭环与安全伦理共建，将成为未来研究的三大主轴。唯有在动力学本质、认知推理与系统工程层面形成闭环迭代，方能真正迈入 “类人自主” 与 “自主可解释” 并重的物理智能新时代。",
    "reference_list": "考点1：“梯度反向传播”推荐译为“back propagation”\n考点2：“软体流变元件”推荐译为“ rheological components”\n考点3：“语义地图”推荐译为“semantic map”\n考点4：“感官运动耦合”推荐译为“sensory-motor coupling”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "168"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。 以下是你本次的任务：\nInsert Table 1\nAs shown in Table 1, diverse theoretical perspectives and methodological approaches have emerged in relation to the study of influencers. Follower and human influencer perspectives are common (Franke et al. 2023). Recently, the emergence of virtual influencers has provided brands\nwith new ways to communicate with consumers (Ramadan et al. 2021). This development offers a fresh perspective on the role of influencers, particularly concerning the role of virtual influencers (e.g., Lou et al. 2023; Mouritzen et al. 2023) within traditionally human-focused social media ecosystems. Virtual influencers are computer-generated, animated characters that behave like real humans, and are usually controlled by firms or agencies (Hofeditz et al. 2022). They are becoming increasingly realistic, narrowing the gap between humans and virtual agents (Sands et al. 2022).\nThey tend to gather a large number of followers (Thomas and Fowler 2020) as they offer consumers unique social interactions that bridge the real and imaginary worlds (Arsenyan and Mirowska 2021). Virtual influencers represent the direction in which brands embed artificial intelligence (AI) in their communications (Ahn et al., 2022), enabling new forms of interaction between consumers and AI-powered agents (Huh et al. 2023). Virtual influencers can offer brands a number of advantages over human influencers, such as content control, flexibility (Miao et al. 2021), and enhanced perceived ad novelty (Franke et al. 2023). Therefore, it is not surprising that brands leverage the unique relationship between virtual influencers and followers. However, our current 7 knowledge of this phenomenon is limited, because virtual influencers integrate both human and virtual features. To uncover the nature of the virtual influencer-follower relationship, there is a need to understand the identity of virtual influencer, as it defines their relationships with their followers (Mrad et al. 2022). To attest to their identity, virtual influencers rely on perceived anthropomorphism (Ahn et al. 2022). Anthropomorphism is an inductive inference process by which consumers attribute human-like characteristics, intentions, or mental states to nonhuman agents (Waytz et al. 2010). It can lower reactance towards virtual agents (Fernandes and Oliveira 2021), make interactions more effective,and influence consumer trust in promotional content (Touré-Tillery and McGill 2015). A growing number of researchers have explored the influence of anthropomorphism on consumer interactions with AI agents, particularly chatbots (e.g., Crolic et al. 2022). Anthropomorphism enhances consumers’ perceptions of chatbots’ social presence and emotional connections to firms (Araujo 2018). A highly anthropomorphic chatbot can prompt consumers’ perceptions of a human actor and satisfy their human interaction needs (Sheehan et al. 2020). However, the nature of interactions with chatbots differs from that with virtual influencers, and the findings from this literature may not apply to virtual influencers. Companies use chatbots to engage with consumers in conversational settings (Youn and Jin 2021). Their relationships with consumers are two-sided, short-lived, goal-oriented, and functional. Consumers engage in conversations with robots to perform tasks. Nonetheless, the relationship between virtual influencers and consumers is different, as it involves repeated interactions, leading to strong bonds and relational patterns (Mrad et al. 2022). Knowledge of the relationship with the audience is crucial for understanding the impact of virtual influencers on consumers. To date, researchers have addressed the relationship between human influencers and followers through parasocial relationship lenses, as discussed in the next section. A parasocial relationshipis readily applicable to human influencers (Labrecque 2014) but it is even more relevant in the case of virtual influencers, as they are non-sentient and unable to build bonds by themselves.However, consumers can develop an attachment to virtual influencers that resemble human interaction with the help of the human-like identity that virtual influencers present.\nParasocial relationship theory\nParasocial relationships are one-sided relationships that humans form with media figures or online characters such as social media influencers (Lou et al. 2023). Similarly, relationships between humans and virtual influencers fall within the parasocial relationship category. A sense of connection, relational intimacy, and emotions may develop even when the ‘subject’ is unaware of their existence. By definition, parasocial relationships are primarily one-sided because relational knowledge and interest remain unreciprocated (Escalas and Bettman 2017). Although there is a friendly atmosphere between the media persona and their audience (Horton and Wohl 1956), the media persona does not possess the same relational knowledge as the individuals in their audience. Parasocial relationships represent unreciprocated bonds driven by feelings of intimacy, kinship, and attachment. Traditionally, researchers have identified these dynamics in TV and radio contexts (Horton and Wohl 1956); however, they are also deemed relevant in various other settings, including social media, where influencers reveal life events and everyday moments that create relationship intimacy and perceived reciprocity among their followers (Lou 2021). Researchers have extended the notion of parasocial relationships to avatars, robots (Whang and Im 2021) and brands in general (Labrecque 2014). The frequency of engagement, including even low-level interactions, such as seeing others, helps in relationship development (Heide and Miner 1992). This is relevant in both real-life and online settings. Marketers draw on trust in parasocial relationships, for instance, in celebrities endorsing products (Chung and Cho 2017), which is well-received by consumers and increases their purchase intention to endorse products (Lou 2021). Nonetheless, developing a parasocial relationship also\ndepends on perceived authenticity and credibility (Whang and Im 2021), including an organic fit between the influencer and the endorsed products/services. Perceived similarities strengthen relationships: humans are naturally drawn to others who have similar traits and characteristics, even if these similarities only exist at the level of perception and even if the subject of attraction is non-human (Whang and Im 2021). However, a non-human entity is typically perceived as genuine when it is anthropomorphized and human-like (Whang and Im 2021). Perceived mutuality is stronger with human-like non-humans (Whang and Im 2021), and consumers associate higher levels of consciousness and responsibility with them, as opposed to less human-like non-humans (Aggarwal and McGill 2007). Both the study of parasocial relationships and social comparison theory are concerned with relationships, social interactions, and self-worth. Parasocial relationships influence self-evaluation and perceived self-worth. For instance, when people compare themselves unfavorably to celebrity figures, their self-esteem may decrease (Staniewski and Awruk 2022). The existing literature in this area lacks an in-depth understanding of how anthropomorphization influences parasocial relationships and social comparisons between virtual influencers and their followers. The following section delves into the relevant aspects of social comparison theory. \nSocial comparison theory\nSocial comparison processes can influence identification; thus, followers may assess their position within a group of fans. This may be a human or non-human fan group; in either case, the parasocial relationships within the follower group can contribute to an individual’s social identity (Aw and Chuah 2021). Social comparison is a widely shared human trait that involves comparing ourselves to others and is an important element of human life. This theory explains how individuals compare themselves to others and gain or lose self-esteem, depending on evaluations of their abilities, achievements, beliefs, attitudes, and appearances compared to those of their peers (Festinger 1954). Advertising scholarship shows that social comparisons to idealized celebrities can lower one’s self-esteem related to physical attractiveness and financial success (Gulas and McKeage 2000), and increase the sharing of materialistic values enacted through imitation, such as the purchase of products that celebrities possess (Chan and Prendergast 2008).\nGoethals (1986) views social comparison theory as a natural extension of researching how people evaluate themselves, approach their reference groups, and the comparative functions reference groups provide, including pressure towards conformity. Suls and Wheeler (2013) identified influencing factors in social comparison theory, such as individuals’ adaptiveness, egocentrism, tendency for projecting, approaches to belief formation, and whether individuals critically revisit or review beliefs. Social comparisons may lead to both positive (e.g., feeling motivated to improve) and negative emotions. For instance, envy towards those perceived as more attractive may lead to undervaluing them in other areas, such as professional skills (Bower 2001).Incorporating social comparison theory into our theorization opens up versatile possibilities. Comparisons are inherent in relationships with others and in one’s own relationships with oneself. Researchers have used it to study burnout (Buunk and Schaufeli 2018) and deception regarding consumption (Argo et al. 2006). This theory identifies multiple ways of making comparisons. Comparisons can range from extremely negative (upward comparisons) to highly positive valence (downward comparisons) (Goethals 1986). Examples of negativity relate to a lack of selfappreciation, depressive feelings, distress, and offending others, whereas positivity is typically about feeling more motivated and grateful as a result of social comparisons. Despite their practical relevance, little is known about social comparisons that occur between humans in relation to virtual influencers. Hence, this study addresses the following research question: How does the virtual influencer phenomenon influence followers’ online social experiences through social comparisons and parasocial relationships? This study sought to uncover how social comparisons and parasocial relationships manifest in the virtual influencer phenomenon. It aims to further understand how individuals perceive themselves in comparison to virtual influencers and how they form emotional relationships with them. Utilizing a theory of knitting approach following De Pelecijn et al. (2023), synergies have been identified between the key theoretical streams of anthropomorphization, parasocial relationships, and social comparison theory:relevance, little is known about social comparisons that occur between humans in relation to virtual influencers. Hence, this study addresses the following research question: How does the virtual influencer phenomenon influence followers’ online social experiences through social comparisons and parasocial relationships? This study sought to uncover how social comparisons and parasocial relationships manifest in the virtual influencer phenomenon. It aims to further understand how individuals perceive themselves in comparison to virtual influencers and how they form emotional relationships with them. Utilizing a theory of knitting approach following De Pelecijn et al. (2023), synergies have been identified between the key theoretical streams of anthropomorphization, parasocial relationships, and social comparison theory:",
    "ori_text": "Insert Table 1\nAs shown in Table 1, diverse theoretical perspectives and methodological approaches have emerged in relation to the study of influencers. Follower and human influencer perspectives are common (Franke et al. 2023). Recently, the emergence of virtual influencers has provided brands\nwith new ways to communicate with consumers (Ramadan et al. 2021). This development offers a fresh perspective on the role of influencers, particularly concerning the role of virtual influencers (e.g., Lou et al. 2023; Mouritzen et al. 2023) within traditionally human-focused social media ecosystems. Virtual influencers are computer-generated, animated characters that behave like real humans, and are usually controlled by firms or agencies (Hofeditz et al. 2022). They are becoming increasingly realistic, narrowing the gap between humans and virtual agents (Sands et al. 2022).\nThey tend to gather a large number of followers (Thomas and Fowler 2020) as they offer consumers unique social interactions that bridge the real and imaginary worlds (Arsenyan and Mirowska 2021). Virtual influencers represent the direction in which brands embed artificial intelligence (AI) in their communications (Ahn et al., 2022), enabling new forms of interaction between consumers and AI-powered agents (Huh et al. 2023). Virtual influencers can offer brands a number of advantages over human influencers, such as content control, flexibility (Miao et al. 2021), and enhanced perceived ad novelty (Franke et al. 2023). Therefore, it is not surprising that brands leverage the unique relationship between virtual influencers and followers. However, our current 7 knowledge of this phenomenon is limited, because virtual influencers integrate both human and virtual features. To uncover the nature of the virtual influencer-follower relationship, there is a need to understand the identity of virtual influencer, as it defines their relationships with their followers (Mrad et al. 2022). To attest to their identity, virtual influencers rely on perceived anthropomorphism (Ahn et al. 2022). Anthropomorphism is an inductive inference process by which consumers attribute human-like characteristics, intentions, or mental states to nonhuman agents (Waytz et al. 2010). It can lower reactance towards virtual agents (Fernandes and Oliveira 2021), make interactions more effective,and influence consumer trust in promotional content (Touré-Tillery and McGill 2015). A growing number of researchers have explored the influence of anthropomorphism on consumer interactions with AI agents, particularly chatbots (e.g., Crolic et al. 2022). Anthropomorphism enhances consumers’ perceptions of chatbots’ social presence and emotional connections to firms (Araujo 2018). A highly anthropomorphic chatbot can prompt consumers’ perceptions of a human actor and satisfy their human interaction needs (Sheehan et al. 2020). However, the nature of interactions with chatbots differs from that with virtual influencers, and the findings from this literature may not apply to virtual influencers. Companies use chatbots to engage with consumers in conversational settings (Youn and Jin 2021). Their relationships with consumers are two-sided, short-lived, goal-oriented, and functional. Consumers engage in conversations with robots to perform tasks. Nonetheless, the relationship between virtual influencers and consumers is different, as it involves repeated interactions, leading to strong bonds and relational patterns (Mrad et al. 2022). Knowledge of the relationship with the audience is crucial for understanding the impact of virtual influencers on consumers. To date, researchers have addressed the relationship between human influencers and followers through parasocial relationship lenses, as discussed in the next section. A parasocial relationshipis readily applicable to human influencers (Labrecque 2014) but it is even more relevant in the case of virtual influencers, as they are non-sentient and unable to build bonds by themselves.However, consumers can develop an attachment to virtual influencers that resemble human interaction with the help of the human-like identity that virtual influencers present.\nParasocial relationship theory\nParasocial relationships are one-sided relationships that humans form with media figures or online characters such as social media influencers (Lou et al. 2023). Similarly, relationships between humans and virtual influencers fall within the parasocial relationship category. A sense of connection, relational intimacy, and emotions may develop even when the ‘subject’ is unaware of their existence. By definition, parasocial relationships are primarily one-sided because relational knowledge and interest remain unreciprocated (Escalas and Bettman 2017). Although there is a friendly atmosphere between the media persona and their audience (Horton and Wohl 1956), the media persona does not possess the same relational knowledge as the individuals in their audience. Parasocial relationships represent unreciprocated bonds driven by feelings of intimacy, kinship, and attachment. Traditionally, researchers have identified these dynamics in TV and radio contexts (Horton and Wohl 1956); however, they are also deemed relevant in various other settings, including social media, where influencers reveal life events and everyday moments that create relationship intimacy and perceived reciprocity among their followers (Lou 2021). Researchers have extended the notion of parasocial relationships to avatars, robots (Whang and Im 2021) and brands in general (Labrecque 2014). The frequency of engagement, including even low-level interactions, such as seeing others, helps in relationship development (Heide and Miner 1992). This is relevant in both real-life and online settings. Marketers draw on trust in parasocial relationships, for instance, in celebrities endorsing products (Chung and Cho 2017), which is well-received by consumers and increases their purchase intention to endorse products (Lou 2021). Nonetheless, developing a parasocial relationship also\ndepends on perceived authenticity and credibility (Whang and Im 2021), including an organic fit between the influencer and the endorsed products/services. Perceived similarities strengthen relationships: humans are naturally drawn to others who have similar traits and characteristics, even if these similarities only exist at the level of perception and even if the subject of attraction is non-human (Whang and Im 2021). However, a non-human entity is typically perceived as genuine when it is anthropomorphized and human-like (Whang and Im 2021). Perceived mutuality is stronger with human-like non-humans (Whang and Im 2021), and consumers associate higher levels of consciousness and responsibility with them, as opposed to less human-like non-humans (Aggarwal and McGill 2007). Both the study of parasocial relationships and social comparison theory are concerned with relationships, social interactions, and self-worth. Parasocial relationships influence self-evaluation and perceived self-worth. For instance, when people compare themselves unfavorably to celebrity figures, their self-esteem may decrease (Staniewski and Awruk 2022). The existing literature in this area lacks an in-depth understanding of how anthropomorphization influences parasocial relationships and social comparisons between virtual influencers and their followers. The following section delves into the relevant aspects of social comparison theory. \nSocial comparison theory\nSocial comparison processes can influence identification; thus, followers may assess their position within a group of fans. This may be a human or non-human fan group; in either case, the parasocial relationships within the follower group can contribute to an individual’s social identity (Aw and Chuah 2021). Social comparison is a widely shared human trait that involves comparing ourselves to others and is an important element of human life. This theory explains how individuals compare themselves to others and gain or lose self-esteem, depending on evaluations of their abilities, achievements, beliefs, attitudes, and appearances compared to those of their peers (Festinger 1954). Advertising scholarship shows that social comparisons to idealized celebrities can lower one’s self-esteem related to physical attractiveness and financial success (Gulas and McKeage 2000), and increase the sharing of materialistic values enacted through imitation, such as the purchase of products that celebrities possess (Chan and Prendergast 2008).\nGoethals (1986) views social comparison theory as a natural extension of researching how people evaluate themselves, approach their reference groups, and the comparative functions reference groups provide, including pressure towards conformity. Suls and Wheeler (2013) identified influencing factors in social comparison theory, such as individuals’ adaptiveness, egocentrism, tendency for projecting, approaches to belief formation, and whether individuals critically revisit or review beliefs. Social comparisons may lead to both positive (e.g., feeling motivated to improve) and negative emotions. For instance, envy towards those perceived as more attractive may lead to undervaluing them in other areas, such as professional skills (Bower 2001).Incorporating social comparison theory into our theorization opens up versatile possibilities. Comparisons are inherent in relationships with others and in one’s own relationships with oneself. Researchers have used it to study burnout (Buunk and Schaufeli 2018) and deception regarding consumption (Argo et al. 2006). This theory identifies multiple ways of making comparisons. Comparisons can range from extremely negative (upward comparisons) to highly positive valence (downward comparisons) (Goethals 1986). Examples of negativity relate to a lack of selfappreciation, depressive feelings, distress, and offending others, whereas positivity is typically about feeling more motivated and grateful as a result of social comparisons. Despite their practical relevance, little is known about social comparisons that occur between humans in relation to virtual influencers. Hence, this study addresses the following research question: How does the virtual influencer phenomenon influence followers’ online social experiences through social comparisons and parasocial relationships? This study sought to uncover how social comparisons and parasocial relationships manifest in the virtual influencer phenomenon. It aims to further understand how individuals perceive themselves in comparison to virtual influencers and how they form emotional relationships with them. Utilizing a theory of knitting approach following De Pelecijn et al. (2023), synergies have been identified between the key theoretical streams of anthropomorphization, parasocial relationships, and social comparison theory:relevance, little is known about social comparisons that occur between humans in relation to virtual influencers. Hence, this study addresses the following research question: How does the virtual influencer phenomenon influence followers’ online social experiences through social comparisons and parasocial relationships? This study sought to uncover how social comparisons and parasocial relationships manifest in the virtual influencer phenomenon. It aims to further understand how individuals perceive themselves in comparison to virtual influencers and how they form emotional relationships with them. Utilizing a theory of knitting approach following De Pelecijn et al. (2023), synergies have been identified between the key theoretical streams of anthropomorphization, parasocial relationships, and social comparison theory:",
    "reference_list": "考点1：”human influencer“推荐翻译为“真人网红”，因这篇文章的人工智能语境，人类与AI形成对比。翻译为网红、人类影响者均不对。\n考点2：“virtual influencers”推荐翻译为“虚拟网红”，注意全文的人工智能营销、网红营销的语境。\n考点3：”This development offers a fresh perspective on the role of influencers,”推荐翻译为“这一发展为研究网红的角色提供了新鲜视角，“\n考点4：”ecosystems.”社交媒体生态”\n考点5：“virtual agents”应结合上下文语境和学界惯例翻译为“虚拟人”\n考点6：“direction”推荐翻译为趋势\n考点7：“enabling”推荐翻译为使XX成为可能\n考点8：“ perceived anthropomorphism\"推荐翻译为“感知拟人性（感知拟人度也可）“\n考点9：”attribute to ”推荐翻译为”将XXX赋予“。\n考点10：”settings“推荐翻译为“情境”\n考点11：”reveal“推荐翻译为“分享”\n考点12：”avatars“推荐翻译为“虚拟形象”\n考点13：”relevant“推荐翻译为“适用的”\n考点14：”human or non-human fan group“应翻译为”崇拜真人或虚拟角色的粉丝群体“\n考点15： “increase the sharing of materialistic values enacted through imitation,“ 推荐翻译为”增加通过模仿来实现的物质主义价值观的传播“\n考点16： ”practical relevance“推荐翻译为”实际相关性“\n考点17：”key theoretical streams“推荐翻译为”关键理论脉络“\n考点18：“Nonhuman agents”推荐翻译为“非人类主体”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "100"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nWhy learn English\n\nLearning English is a good way to improve your professional future and expand your horizons. More and more people around the world use English as a way to connect with people from different cultural backgrounds. The English language has become the lingua franca of international communication, trade, business, diplomacy, and many other areas. Mastering the language will open doors for you, both expected and unexpected.\n\nAccording to the EF English Proficiency Index (EPI), the world's largest ranking of countries and regions by English skills, more than 1 billion people speak English as a first or second language, and hundreds of millions as a third or fourth. English proficiency helps scientists, researchers, tourists, and business professionals exchange information. On an individual level, people who speak English get better jobs, earn more, and have access to more of the information available online.\n\n6 benefits of learning English\n\nIf you're still not convinced of the benefits of learning English, here are a few more:\n\n1. Learning English will build up your confidence. Mastering something you've struggled with for years is extremely satisfying.\n2. Learning English boosts your career by allowing you to follow the latest trends in your field, attend conferences, and evolve into positions with an international remit.\n3. Learning a new language keeps your mind healthy, stimulating your memory and increasing mental flexibility.\n4. Learning English gives you access to more of the world's knowledge, and from a wider variety of perspectives. Over half of the material online is in English, and all of the world's top scientific journals are published in that language.\n5. Learning English makes international travel easier and more fulfilling. You'll be less dependent on guides and translators, able to explore the world on your own.\n6. Learning English allows you to meet people from other places and expand your cultural understanding. The world is more interconnected than ever before.\n\nHow to learn English\n\nThe secret to learning English quickly isn’t much of a secret: increase your exposure to the language. Ideally, you should be surrounded by English 24 hours a day, 7 days a week. That’s why going abroad is such an effective way to learn a language. But if travel isn’t an option, you can still create an English immersion environment at home. Do it by reading in English, listening to English podcasts, watching TV in English, speaking to people in English at work, making English-speaking friends online, etc. At first, this sounds daunting. But you can do it if you take it one step at a time.\n\n1. First, think of something you’re already doing every day. Let’s pretend you like to jog while listening to a sports podcast.\n2. Now look for a sports podcast in English. Google is your friend.\n3. When you jog tomorrow, listen to it. Congratulations, you’ve just converted 30 minutes of your day into English!\n\nRepeat this procedure to convert chunks of your day bit by bit. If you read the newspaper, switch to an English-language paper. If you watch football, watch the match on a British TV station. If you cook, use recipes from American websites. If you make pottery, find an English-language pottery forum where you discuss your craft. Everything you’re already doing can be done in English, guaranteed.\n\nYou can also start to do new things in English too, of course. Do you have English-speaking colleagues? Send them friendly e-mails. Chat with them in the empty minutes before a meeting begins. Are there foreign tourists in your city? Find out if you can volunteer at one of the sights they visit: a museum, a park, a monument. Or maybe your airport or train station needs volunteers. You can also go hang out at one of those places informally and help people who look lost. Just be careful not to be creepy about it. Is there an expat community in your city? Look on Facebook for American, British, or Canadian cultural associations. They may have monthly or bi-monthly meetups you can attend. These tend to be informal events in a bar or restaurant and are open to everyone.\n\nHow to stay motivated while learning English\n\nOne of the most common mistakes people make when trying to learn English is underestimating how long it will take. Everyone says children are natural language learners, but they’re two years old before they even start to form sentences. Learning English is a long-term goal. Be patient with yourself. Staying motivated over months or years is a major challenge, but it’s essential if you want to master English. A huge body of research proves it.\n\nHere are a few tips to keep your motivation high: \n\n1. Do things in English that you already like doing. If you’re having fun while speaking English, you’ll be less inclined to quit. Follow your passions.\n2. Make English a habit. Build it in to your everyday life. The less you have to think about it, the more likely you are to use English every day. Automatically. \n3. Keep a learning journal. Write down what you're doing to improve your English, and keep track of milestones like your first movie in English without subtitles, your first meeting in English, or your first date with an English speaker.\n4. Award yourself prizes for accomplishing specific goals. The prizes can be big or small. A new shirt. A candy bar. A trip to London. Your brain is wired to detect which types of activities deliver rewards. If you make English one of those activities, it will automatically motivate you to learn English.\n5. Keep track of the numbers. Our free standardized English test will help you. Take it every 6 months.\n\nHow to measure your English level\n\nIt is important to measure your English level before you start studying and then regularly throughout the learning process. Otherwise, you can't tell how much progress you're making. There are many different ways of measuring progress. The best way of establishing a benchmark is to test yourself against the goal you are trying to reach. For example, if your goal is to be able to make presentations at work in English, then you need to try and make a presentation at work in English and see how it goes. Take some notes afterwards about how you felt and what you need to work on. This will be your benchmark. After 6 months of learning English and working towards this goal, make another presentation and see how much you've improved.\n\nIf you've got a more generic goal, taking a standardized English test(the TOEFL or IELTS) is a good way to get a benchmark of your current level and keep track of your progress moving forward.",
    "ori_text": "Why learn English\n\nLearning English is a good way to improve your professional future and expand your horizons. More and more people around the world use English as a way to connect with people from different cultural backgrounds. The English language has become the lingua franca of international communication, trade, business, diplomacy, and many other areas. Mastering the language will open doors for you, both expected and unexpected.\n\nAccording to the EF English Proficiency Index (EPI), the world's largest ranking of countries and regions by English skills, more than 1 billion people speak English as a first or second language, and hundreds of millions as a third or fourth. English proficiency helps scientists, researchers, tourists, and business professionals exchange information. On an individual level, people who speak English get better jobs, earn more, and have access to more of the information available online.\n\n6 benefits of learning English\n\nIf you're still not convinced of the benefits of learning English, here are a few more:\n\n1. Learning English will build up your confidence. Mastering something you've struggled with for years is extremely satisfying.\n2. Learning English boosts your career by allowing you to follow the latest trends in your field, attend conferences, and evolve into positions with an international remit.\n3. Learning a new language keeps your mind healthy, stimulating your memory and increasing mental flexibility.\n4. Learning English gives you access to more of the world's knowledge, and from a wider variety of perspectives. Over half of the material online is in English, and all of the world's top scientific journals are published in that language.\n5. Learning English makes international travel easier and more fulfilling. You'll be less dependent on guides and translators, able to explore the world on your own.\n6. Learning English allows you to meet people from other places and expand your cultural understanding. The world is more interconnected than ever before.\n\nHow to learn English\n\nThe secret to learning English quickly isn’t much of a secret: increase your exposure to the language. Ideally, you should be surrounded by English 24 hours a day, 7 days a week. That’s why going abroad is such an effective way to learn a language. But if travel isn’t an option, you can still create an English immersion environment at home. Do it by reading in English, listening to English podcasts, watching TV in English, speaking to people in English at work, making English-speaking friends online, etc. At first, this sounds daunting. But you can do it if you take it one step at a time.\n\n1. First, think of something you’re already doing every day. Let’s pretend you like to jog while listening to a sports podcast.\n2. Now look for a sports podcast in English. Google is your friend.\n3. When you jog tomorrow, listen to it. Congratulations, you’ve just converted 30 minutes of your day into English!\n\nRepeat this procedure to convert chunks of your day bit by bit. If you read the newspaper, switch to an English-language paper. If you watch football, watch the match on a British TV station. If you cook, use recipes from American websites. If you make pottery, find an English-language pottery forum where you discuss your craft. Everything you’re already doing can be done in English, guaranteed.\n\nYou can also start to do new things in English too, of course. Do you have English-speaking colleagues? Send them friendly e-mails. Chat with them in the empty minutes before a meeting begins. Are there foreign tourists in your city? Find out if you can volunteer at one of the sights they visit: a museum, a park, a monument. Or maybe your airport or train station needs volunteers. You can also go hang out at one of those places informally and help people who look lost. Just be careful not to be creepy about it. Is there an expat community in your city? Look on Facebook for American, British, or Canadian cultural associations. They may have monthly or bi-monthly meetups you can attend. These tend to be informal events in a bar or restaurant and are open to everyone.\n\nHow to stay motivated while learning English\n\nOne of the most common mistakes people make when trying to learn English is underestimating how long it will take. Everyone says children are natural language learners, but they’re two years old before they even start to form sentences. Learning English is a long-term goal. Be patient with yourself. Staying motivated over months or years is a major challenge, but it’s essential if you want to master English. A huge body of research proves it.\n\nHere are a few tips to keep your motivation high: \n\n1. Do things in English that you already like doing. If you’re having fun while speaking English, you’ll be less inclined to quit. Follow your passions.\n2. Make English a habit. Build it in to your everyday life. The less you have to think about it, the more likely you are to use English every day. Automatically. \n3. Keep a learning journal. Write down what you're doing to improve your English, and keep track of milestones like your first movie in English without subtitles, your first meeting in English, or your first date with an English speaker.\n4. Award yourself prizes for accomplishing specific goals. The prizes can be big or small. A new shirt. A candy bar. A trip to London. Your brain is wired to detect which types of activities deliver rewards. If you make English one of those activities, it will automatically motivate you to learn English.\n5. Keep track of the numbers. Our free standardized English test will help you. Take it every 6 months.\n\nHow to measure your English level\n\nIt is important to measure your English level before you start studying and then regularly throughout the learning process. Otherwise, you can't tell how much progress you're making. There are many different ways of measuring progress. The best way of establishing a benchmark is to test yourself against the goal you are trying to reach. For example, if your goal is to be able to make presentations at work in English, then you need to try and make a presentation at work in English and see how it goes. Take some notes afterwards about how you felt and what you need to work on. This will be your benchmark. After 6 months of learning English and working towards this goal, make another presentation and see how much you've improved.\n\nIf you've got a more generic goal, taking a standardized English test(the TOEFL or IELTS) is a good way to get a benchmark of your current level and keep track of your progress moving forward.",
    "reference_list": "考点1：“lingua franca”推荐译为“通用语”或“国际通用语言”。\n考点2：“remit”在“positions with an international remit”中推荐译为“职责范围”或“工作范畴”。\n考点3：“standardized English test”应保持“标准化英语测试”表达。\n考点4：“EF English Proficiency Index (EPI)”应译为“英孚英语熟练度指标 (EPI)”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "教育",
    "prompt_id": "22"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n从1968年的《太阳王子霍尔斯的大冒险》到2013年的《起风了》，不难发现，在其不同时期的动画作品中都体现着他独特的世界观、历史观、人生观和艺术观。并且，还构筑了一个令人叹为观止宫式世界，干净的画面配上时而空灵、时而轻快、时而震撼的音乐，让人不由自主的深陷其中，发现、体会、探索并深思其中暗藏的人生哲理。更值得惊叹的是，他的动画作品大多以坚强且独立的女孩或年轻女性为主角，以她们独特的视角反映不同题材的故事，把令人反思的讯息融入其中，用其独特的创作手法将环保、人生、梦想、生存等要素淋漓尽致的展现在作品中，成功的塑造了一个个活灵活现的人物，触动着我们的心灵。 　　\n\n一、宫崎骏影视动画作品的主题特色 　　\n\n（一）人文主义的深刻体现 　　\n\n人文主义是指社会价值取向倾向于对人的个性的关怀，注重强调维护人性尊严，提倡宽容，反对暴力，主张自由平等和自我价值体现的一种哲学思潮与世界观。宫崎骏的影视动画作品以关注环境、战争、人生、梦想、真情等为主题，将人与人、人与自然之间的关系作为主线展开叙述。其前期的作品主要表现人与自然之间的关系为主，后期的作品主要探讨人与人、社会之间的关系为主。《风之谷》、《龙猫》、《千与千寻》等都用人物细致入微的演绎展现她们心中极致的爱。 　　\n\n（二）女性主义的完美诠释 　　\n\n宫崎骏在其影视动画作品中善用女性的视角隐晦的去揭示那些被我们忽视的问题——人与自然的不和谐、环境的污染、战争的伤害等。很显然，这些主题恰恰是需要全人类甚至是全世界共同关注的。其影片中的女主角既有女性的柔美与温和，又有在面对困难与危险时的坚毅和刚强，很显然这些人物的塑造成为影片中美好与胜利的化身。《幽灵公主》、《哈尔的移动城堡》等作品中的女性形象用她们的行动诠释着生活的意义。 　　\n\n宫崎骏通过动画使人文主义和女性主义的主题得到最完美的诠释。在“宫崎骏世界”里，少女是纯洁美好的象征，透过一双真挚善良的双眸带领着观影者跟随导演一起感受影片中女性的成长历程，去体会生活中的真善美。影片将贴合故事情节的人文主义通过少女们感性细腻的瞳孔淋漓尽致的展现在观影者的面前。\n\n二、宫崎骏影视动画作品的风格特色\n\n（一）人物选择的象征性——用小人物塑造大形象\n\n　　宫崎骏的影视动画作品中的人物大多是平凡的年轻女性，而且也打破了主角特有的模式，大多采用的是平凡无奇的面孔充当故事的主角。并且，通过故事情节的曲折发展和主角身上独有的魅力来吸引观众的注意。正因为有了这样的人物塑造与定位，很容易使观影者深入其中，并发现主角的魅力所在，也可以在最大程度上破除了影视作品中的主角与现实中人的距离。\n\n（二）主题的多样性——用小事件展现大内涵\n\n　　宫崎骏的影视动画作品中的事件几乎是身边随处可见。然而，宫崎骏为现实蒙上了写意的面纱，用细腻的笔法隐晦的描绘细节并展现深刻的内涵。影片中栩栩如生的人物，震撼着我们的心灵，使我们不得不反思自己在现实社会中所扮演的角色，更让我们深刻的反思自己的行为是否正确。\n\n　　宫崎骏以其独特的宫式风格用小人物塑造大形象，用小事件展现大内涵，用最真实的情感述说故事，用最细腻的笔法描绘情节，起到了小中见大的作用。而恰恰是这些生活中的小事能够带给观影者心灵上的洗礼，并深受触动甚至产生共鸣。",
    "ori_text": "从1968年的《太阳王子霍尔斯的大冒险》到2013年的《起风了》，不难发现，在其不同时期的动画作品中都体现着他独特的世界观、历史观、人生观和艺术观。并且，还构筑了一个令人叹为观止宫式世界，干净的画面配上时而空灵、时而轻快、时而震撼的音乐，让人不由自主的深陷其中，发现、体会、探索并深思其中暗藏的人生哲理。更值得惊叹的是，他的动画作品大多以坚强且独立的女孩或年轻女性为主角，以她们独特的视角反映不同题材的故事，把令人反思的讯息融入其中，用其独特的创作手法将环保、人生、梦想、生存等要素淋漓尽致的展现在作品中，成功的塑造了一个个活灵活现的人物，触动着我们的心灵。 　　\n\n一、宫崎骏影视动画作品的主题特色 　　\n\n（一）人文主义的深刻体现 　　\n\n人文主义是指社会价值取向倾向于对人的个性的关怀，注重强调维护人性尊严，提倡宽容，反对暴力，主张自由平等和自我价值体现的一种哲学思潮与世界观。宫崎骏的影视动画作品以关注环境、战争、人生、梦想、真情等为主题，将人与人、人与自然之间的关系作为主线展开叙述。其前期的作品主要表现人与自然之间的关系为主，后期的作品主要探讨人与人、社会之间的关系为主。《风之谷》、《龙猫》、《千与千寻》等都用人物细致入微的演绎展现她们心中极致的爱。 　　\n\n（二）女性主义的完美诠释 　　\n\n宫崎骏在其影视动画作品中善用女性的视角隐晦的去揭示那些被我们忽视的问题——人与自然的不和谐、环境的污染、战争的伤害等。很显然，这些主题恰恰是需要全人类甚至是全世界共同关注的。其影片中的女主角既有女性的柔美与温和，又有在面对困难与危险时的坚毅和刚强，很显然这些人物的塑造成为影片中美好与胜利的化身。《幽灵公主》、《哈尔的移动城堡》等作品中的女性形象用她们的行动诠释着生活的意义。 　　\n\n宫崎骏通过动画使人文主义和女性主义的主题得到最完美的诠释。在“宫崎骏世界”里，少女是纯洁美好的象征，透过一双真挚善良的双眸带领着观影者跟随导演一起感受影片中女性的成长历程，去体会生活中的真善美。影片将贴合故事情节的人文主义通过少女们感性细腻的瞳孔淋漓尽致的展现在观影者的面前。\n\n二、宫崎骏影视动画作品的风格特色\n\n（一）人物选择的象征性——用小人物塑造大形象\n\n　　宫崎骏的影视动画作品中的人物大多是平凡的年轻女性，而且也打破了主角特有的模式，大多采用的是平凡无奇的面孔充当故事的主角。并且，通过故事情节的曲折发展和主角身上独有的魅力来吸引观众的注意。正因为有了这样的人物塑造与定位，很容易使观影者深入其中，并发现主角的魅力所在，也可以在最大程度上破除了影视作品中的主角与现实中人的距离。\n\n（二）主题的多样性——用小事件展现大内涵\n\n　　宫崎骏的影视动画作品中的事件几乎是身边随处可见。然而，宫崎骏为现实蒙上了写意的面纱，用细腻的笔法隐晦的描绘细节并展现深刻的内涵。影片中栩栩如生的人物，震撼着我们的心灵，使我们不得不反思自己在现实社会中所扮演的角色，更让我们深刻的反思自己的行为是否正确。\n\n　　宫崎骏以其独特的宫式风格用小人物塑造大形象，用小事件展现大内涵，用最真实的情感述说故事，用最细腻的笔法描绘情节，起到了小中见大的作用。而恰恰是这些生活中的小事能够带给观影者心灵上的洗礼，并深受触动甚至产生共鸣。",
    "reference_list": "考点1：“宫崎骏世界”和“宫式世界”是一个意思，应该采用统一的翻译\n考点2：“生活中的真善美”推荐译为“the kindness and the beauty in daily life”\n考点3：“故事情节的曲折发展“推荐译为“plenty of ups-and-downs”\n考点4：“细腻的笔法”推荐译为“delicately crafted stories”\n考点5：“人与人、社会之间的关系”推荐译为“the relationships between people and between individuals and society”，不可直译为“the relationships between people and society”\n考点6：“人文主义”译为“humanism”\n考点7：“女性主义”译为“feminism”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "18"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 迪士尼历经了“内容起家—渠道布局（线下乐园+线上广播）—回归内容—渠道再布局（流媒体）”的发展过程，形成了内容和渠道的深度绑定和协同。迪士尼自 1923 年成立之始专注于电影内容制作，打造了米老鼠、唐老鸭等知名 IP；1955 年开始陆续推出多个迪士尼现代主题公园，形成了面向全球的线下变现渠道；1981-2001 之间，迪士尼公布有线电视网络计划、成立电影发行商试金石影业、收购美国广播公司 ABC，完成线上渠道布局；2005 年起迪士尼收购皮克斯、漫威、卢卡斯等内容制作工作室，回归内容建设；2012 年迪士尼流媒体布局拉开大幕，开始向新的流媒体渠道延伸。2017 年迪士尼宣布将推出自有流媒体平台，并计划于 19 年将其全部电影从 Netflix下架而作为自有平台的独占内容；2018 年底，迪士尼自有流媒体平台命名为“Disney+”；19 年 4 月，迪士尼确认 Disney+于 19 年 11 月上线。加上 18 年已上线的体育流媒体平台ESPN+，迪士尼流媒体战略下的三把利剑基本打造完毕。\n\n迪士尼加速进军流媒体受市场青睐。自 3 月完成对福克斯的收购后，迪士尼股价快速上行，截至 2019 年 6 月 5 日累计涨幅超过 20%，而同期奈飞股价则震荡下行，迪士尼加速进军流媒体为什么被市场看好？它的核心竞争优势在哪？迪士尼竞争核心：时间构筑内容壁垒、多变现渠道降低内容成本率、充裕现金流支撑内容投入。\n1）迪士尼内容自制始于 1923 年，近百年的自制+收购历史绘制庞大内容版图。1）自制：迪士尼自 1923 年创立以来，塑造了米老鼠、唐老鸭等经典动画形象；1950 年代打造了《金银岛》、《加勒比海盗》等真人系列电影； 2）收购：2006 年以 74 亿美元并购皮克斯动画工作室，2009 年以 40 亿美元并购漫威（旗下有多达 5000 个漫画人物），2012 年以 40.5亿美元并购手握星球大战系列 IP 的卢卡斯影业，累计并购支出达到 156.9 亿美元，2019年 3 月以 713 亿美元收购 21 世纪福克斯。目前已形成华特迪士尼影业、漫威影业、皮克斯影业、卢卡斯影业、21 世纪福克斯等在内的完整内容体系。相比之下，自制历史较短、原创占比较低的 Netflix 内容投入大，且外购版权面临一定的可持续问题。1）从自制内容投入占比看，渠道起家的 Netflix 2012 年才开启原创内容制作，2015 年起其自制内容投入开始提速，至 1Q19 Netflix 原创内容资产占全部内容资产比例达到 31.5%。但相比之下，迪士尼长期保持较高的自制内容投入比例，其自制内容投入占内容总投入比例超过 40%（净现金流出口径），且即将上线的 Disney+平台上的内容将全部为迪士尼自有内容及相关衍生节目。2）从 Netflix 外购版权价格和持续性看：受到竞争对手排他策略、以及授权合同到期等因素影响，外购成本快速上升，从 2013 年4000 万美元一季的《铁杉树丛》到 2016 年 1.3 亿美元一季的《王冠》，头部内容的采购成本不断上涨。迪士尼 2017 年 8 月宣布从 2019 年起撤出奈飞平台上所有迪士尼电影版权，且 19 年开始不再向奈飞提供新的迪士尼和皮克斯电影，外购版权面临一定的可持续问题。\n2）多变现渠道提高内容变现效率，较高利润率为迪士尼流媒体业务构建定价优势。传媒产品一次性生产成本高，降低成本有两种方式，一是尽可能压缩成本，提高效率；二是生产更多的商品，将固定成本摊销到更多的产品中去，比如对同一产品进行多次销售，复制过程中边际成本递减。迪士尼电影产品制作完成后，线上可通过广播、电视、流媒体平台变现，线下通过影院票房、主题乐园变现，此外版权分销及 IP 授权均可带来内容的多次变现；而 Netflix 目前仅有会员收入这一变现渠道。较高的内容变现效率带来较高利润率，客观上为迪士尼流媒体业务实现较低定价作支撑。较高利润率客观上支撑了迪士尼流媒体平台会员较低的定价。通过低价获取用户，扩大用户规模和会员收入，再反哺到内容制作中，形成正向循环。\n3）迪士尼现金流充裕，且融资成本较低。迪士尼拥有足够的现金流支撑其流媒体布局（预计 2020 年为 Disney+投入 10 亿美元进行原创内容制作，年投入金额 2024 年将达到 25 亿美元），而 Netflix 则需要高额举债来投入原创。为维持用户增长，Netflix 近年在原创和外购版权内容上的投入迅速增加，2018 年 Netflix 内容成本净现金流出达 120.4 亿美元，占营收的 77.9%，2019 年 4 月计划发行 20 亿美元债券将使 Netflix 的长期债务达到约 123 亿美元，给公司造成较大现金流压力。",
    "ori_text": "\n\n 迪士尼历经了“内容起家—渠道布局（线下乐园+线上广播）—回归内容—渠道再布局（流媒体）”的发展过程，形成了内容和渠道的深度绑定和协同。迪士尼自 1923 年成立之始专注于电影内容制作，打造了米老鼠、唐老鸭等知名 IP；1955 年开始陆续推出多个迪士尼现代主题公园，形成了面向全球的线下变现渠道；1981-2001 之间，迪士尼公布有线电视网络计划、成立电影发行商试金石影业、收购美国广播公司 ABC，完成线上渠道布局；2005 年起迪士尼收购皮克斯、漫威、卢卡斯等内容制作工作室，回归内容建设；2012 年迪士尼流媒体布局拉开大幕，开始向新的流媒体渠道延伸。2017 年迪士尼宣布将推出自有流媒体平台，并计划于 19 年将其全部电影从 Netflix下架而作为自有平台的独占内容；2018 年底，迪士尼自有流媒体平台命名为“Disney+”；19 年 4 月，迪士尼确认 Disney+于 19 年 11 月上线。加上 18 年已上线的体育流媒体平台ESPN+，迪士尼流媒体战略下的三把利剑基本打造完毕。\n\n迪士尼加速进军流媒体受市场青睐。自 3 月完成对福克斯的收购后，迪士尼股价快速上行，截至 2019 年 6 月 5 日累计涨幅超过 20%，而同期奈飞股价则震荡下行，迪士尼加速进军流媒体为什么被市场看好？它的核心竞争优势在哪？迪士尼竞争核心：时间构筑内容壁垒、多变现渠道降低内容成本率、充裕现金流支撑内容投入。\n1）迪士尼内容自制始于 1923 年，近百年的自制+收购历史绘制庞大内容版图。1）自制：迪士尼自 1923 年创立以来，塑造了米老鼠、唐老鸭等经典动画形象；1950 年代打造了《金银岛》、《加勒比海盗》等真人系列电影； 2）收购：2006 年以 74 亿美元并购皮克斯动画工作室，2009 年以 40 亿美元并购漫威（旗下有多达 5000 个漫画人物），2012 年以 40.5亿美元并购手握星球大战系列 IP 的卢卡斯影业，累计并购支出达到 156.9 亿美元，2019年 3 月以 713 亿美元收购 21 世纪福克斯。目前已形成华特迪士尼影业、漫威影业、皮克斯影业、卢卡斯影业、21 世纪福克斯等在内的完整内容体系。相比之下，自制历史较短、原创占比较低的 Netflix 内容投入大，且外购版权面临一定的可持续问题。1）从自制内容投入占比看，渠道起家的 Netflix 2012 年才开启原创内容制作，2015 年起其自制内容投入开始提速，至 1Q19 Netflix 原创内容资产占全部内容资产比例达到 31.5%。但相比之下，迪士尼长期保持较高的自制内容投入比例，其自制内容投入占内容总投入比例超过 40%（净现金流出口径），且即将上线的 Disney+平台上的内容将全部为迪士尼自有内容及相关衍生节目。2）从 Netflix 外购版权价格和持续性看：受到竞争对手排他策略、以及授权合同到期等因素影响，外购成本快速上升，从 2013 年4000 万美元一季的《铁杉树丛》到 2016 年 1.3 亿美元一季的《王冠》，头部内容的采购成本不断上涨。迪士尼 2017 年 8 月宣布从 2019 年起撤出奈飞平台上所有迪士尼电影版权，且 19 年开始不再向奈飞提供新的迪士尼和皮克斯电影，外购版权面临一定的可持续问题。\n2）多变现渠道提高内容变现效率，较高利润率为迪士尼流媒体业务构建定价优势。传媒产品一次性生产成本高，降低成本有两种方式，一是尽可能压缩成本，提高效率；二是生产更多的商品，将固定成本摊销到更多的产品中去，比如对同一产品进行多次销售，复制过程中边际成本递减。迪士尼电影产品制作完成后，线上可通过广播、电视、流媒体平台变现，线下通过影院票房、主题乐园变现，此外版权分销及 IP 授权均可带来内容的多次变现；而 Netflix 目前仅有会员收入这一变现渠道。较高的内容变现效率带来较高利润率，客观上为迪士尼流媒体业务实现较低定价作支撑。较高利润率客观上支撑了迪士尼流媒体平台会员较低的定价。通过低价获取用户，扩大用户规模和会员收入，再反哺到内容制作中，形成正向循环。\n3）迪士尼现金流充裕，且融资成本较低。迪士尼拥有足够的现金流支撑其流媒体布局（预计 2020 年为 Disney+投入 10 亿美元进行原创内容制作，年投入金额 2024 年将达到 25 亿美元），而 Netflix 则需要高额举债来投入原创。为维持用户增长，Netflix 近年在原创和外购版权内容上的投入迅速增加，2018 年 Netflix 内容成本净现金流出达 120.4 亿美元，占营收的 77.9%，2019 年 4 月计划发行 20 亿美元债券将使 Netflix 的长期债务达到约 123 亿美元，给公司造成较大现金流压力。",
    "reference_list": "考点1: 三把利剑，推荐翻译为three pillars或者three strategic platforms\n考点2:  内容壁垒，推荐翻译为IP barriers\n考点3: 内容版图，推荐翻译为IP library/content empire\n考点4:  边际成本递减，必须翻译为diminishing marginal costs, 固定术语",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "155"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThermal draw of the fibre computer\nThe fibre draw process started with the construction of a macroscopic preform (Fig. 1b) comprising a sacrificial, stress-bearing polymethylmethacrylate (PMMA) cladding encasing an inner hollow thermoplastic cyclic olefin copolymer elastomer (ECOC) cylinder. During the draw process, the PMMA viscous fluid carried most of the tension and offered superior dimensional control, which the more rheologically complex viscoelastic fluid (ECOC) would not. Without this, the sudden transfer of tension from the elastomer to the electrodes as the preform collapses on devices leads to an asymmetric and non-conformal fibre profile near the devices. In addition, drawing the elastomer on its own under high stress would lead to molecular chain alignment, reducing the elasticity of the fibre once quenched. During the draw process, the wires with the pre-connected devices were fed into a single large channel of the preform while the dimensions were reduced to fibre size (Fig. 1b). To maintain the structural elasticity of the conductors through the draw, it is important that the helix diameter be substantially smaller than the fibre channel diameter to minimize the frictional resistance between the wires and the polymer. After the draw process, the PMMA layer was peeled away, leaving an ECOC fibre with eight encapsulated microelectronic devices separated by nearly 15 cm, connected by helically structured wires internal to the fibre (Extended Data Figs. 2 and 3). Because the size of some devices was larger than the steady-state diameter of the fibre away from the devices, which was about 1.35 mm, the channel of the fibre fully collapsed at the devices such that the devices were surrounded by a highly conformal layer of ECOC.\nTensile and flexural properties\nCompared with planar approaches with anisotropic bending stiffness, this solvent-free high-speed thermal draw approach enables conformal, hermetic encapsulation of devices within fibres composed of an elastomer with more than an order of magnitude lower modulus than conventional thermoplastics28,31, providing isotropic flexibility and elasticity35. A representative tensile measurement of a section of fibre between devices (Fig. 1c) showed that breakage of the larger-diameter strain-limiting wire occurred at 6.6% strain, whereas the failure of the first electrode necessary for fibre computer functionality occurred at 67.1% strain. Similarly, a section of the fibre with an embedded device withstood 37% strain before failure (Supplementary Fig. 2). We also found that the fibres maintained functionality for more than a thousand cycles of stretching, representative of high yarn strain in conventional wearable textiles36,37,38, with further improvements in fatigue life possible through application-specific tuning of the wire helix properties (Extended Data Fig. 4).\nIn addition to elastic deformations, we show that the fibre computer is capable of withstanding millimetre-scale flexural deformations, which are crucial for fabric formation and knitting in particular39,40. Bending radius measurements (Fig. 1d) showed that non-device-containing segments sustained flexural stresses down to a bending radius of 0.25 mm without failure, whereas a device-containing segment sustained flexural stresses down to a bending radius of 2.38 mm before the first break of a functional electrode due to the modulus mismatch near devices. We also found that the fibre computer withstood ten machine-washing cycles with no degradation in functionality (Extended Data Fig. 5), demonstrating environmental resilience along with mechanical reliability.\nBraided fibre cladding\nTo further improve the mechanical robustness and surface properties of the fibre computers for fabric integration, we covered the fibre computers with diagonally interlaced textile yarns using a 16-carrier braiding machine (Fig. 1b). The elasticity of the fibre was maintained during the braiding process using a tensioned core loading approach. The versatility of this method with respect to reconfiguration of the type of yarn used, number of carriers and helix pitch allowed the independent design of the mechanical and surface properties of the fibre41,42. A wide variety of yarns were used to cover the fibre computers, including polylactic acid (PLA), Kevlar, cotton and polyester (Fig. 1e,f). The tensile strength of the fibre computer varied with yarn type and denier. A fibre computer braided with 360-denier cotton yarn had a tensile strength of 49 N, whereas a fibre computer braided with 540-denier polyester yarn had a tensile strength of 146 N (Extended Data Fig. 6). Beyond improvements in tensile strength, covering the core with low-friction yarn materials, such as polyester, reduced stiction compared to bare ECOC fibres and prevented stiction to surfaces, such as knitting needles, from causing the fibre to stretch beyond its failure strain.\nFibre computer characterization\nEach fibre computer consists of eight devices connected on a single I2C bus, enabling sensing, computation, storage and communication in a single fibre (Fig. 2a). Four of these devices are sensors: a photodetector, a temperature sensor, a PPG sensor, and an accelerometer, which collect information from the environment and wearer through optical, thermal and mechanical transduction (Fig. 2b). The 32-bit MCU, capable of operating at frequencies up to 96 MHz, provides both computation and storage, with an ARM Cortex-M4 processor with a floating-point unit alongside 256 KB of onboard flash memory and 96 KB of RAM. If required, the generalizability of the interposer approach also allows storage capacity to be expanded by adding downstream memory chips. We implemented two electromagnetic methods for external communications: optically through an LED and through radio-frequency signals from a BLE unit. Intrafibre communication within the system uses the I2C addressing protocol, operating at a clock speed of 100 kHz, although the MCU can drive the bus frequencies up to a maximum of 3.4 MHz for higher throughput applications. The physical architecture uses four wires allocated for I2C (data, clock, power and ground) along with an additional wire dedicated to modulating the LED for optical communications. Through the I2C interface, devices along the length of the fibre can be individually addressed by means of unique 7-bit serial addresses, enabling processor interfacing with less than a 1-ms delay between sequential reads or writes (Extended Data Fig. 5). The MCU can also be dynamically reprogrammed over I2C to target different application requirements, even after fibre integration. The I2C protocol was selected for its use of only two signal conductors, minimizing potential mechanical failure modes; other protocols, such as serial peripheral interface (SPI) and universal asynchronous receiver-transmitter (UART), may also be adopted by either adding additional conductors to the fibre or through device-to-device communications on a single interposer. For applications with more stringent timing requirements, we found that transmission through the in-fibre electrodes over device-to-device spacings can support frequencies of up to 128 MHz (Supplementary Fig. 4), allowing for the adoption of higher-speed protocols if needed.\nPhysiological computing demonstration\nTo demonstrate the sensing, processing and communication capabilities of the fibre computer in a simple application, we show that health metrics, such as heart rate measurements, can be analysed on the basis of data collected by the embedded PPG sensor in close contact with the subject’s skin using signal filtering and feature recognition techniques applied by the in-fibre processor. As PPG sensors are susceptible to motion artefact noise, we show that the in-fibre MCU is capable of applying low-pass filtering and gradient thresholding to recognize individual pulses in real time from the PPG data stream received over I2C (Fig. 2c(ii)). The timing of the pulse peaks was used to calculate the wearer’s heart rate, and the MCU relayed these real-time estimates over I2C to the in-fibre BLE node, which was able to communicate the results to any BLE-compatible display device (Fig. 2c(iii)).\n\nPower considerations\nTo power the embedded devices in the fibre computer, we integrated a pin-type lithium-ion battery only 3.65 mm in diameter inside an ECOC fibre, using a lower-temperature fibre draw to prevent the temperature rise from causing battery degradation. To allow for ease of connection for power, reprogramming and charging, the fibre computers and fibre batteries were terminated with 2.5-mm tip–ring–ring–sleeve (TRRS) audio connectors that can be connected together (Supplementary Fig. 7). After the draw process, we found that the battery-embedded fibre retained a rated battery capacity of 15 mAh (Fig. 2d(i)) and remained rechargeable over multiple uses (Fig. 2d(ii)). To reduce the battery voltage to the required 3.3 V power and I2C logic levels, an in-fibre LDO voltage regulator and pull-up resistors for the I2C bus were incorporated into the fibre computers. Given the baseline average current consumption during code execution (Fig. 2d(iii)), the battery-embedded fibre was capable of powering the fibre computer for up to 6 h. The capability for high-efficiency 1C discharge also demonstrated the ability to accommodate spikes in the current draw, such as those that occur during communications (Supplementary Fig. 6).\nFabric networking\nUsing the fibre computer, we proceeded to create a network of fibre computers in textile fabric. We chose optical and radio-frequency communications to avoid rigid interconnects and complex wiring schemes, which do not support ad hoc networking.\nOptical communications\nOptical communications were enabled through the use of a light sensor and LED present in each fibre. On–off keying modulation of the LED was used with Manchester encoding to eliminate the need for a separate clock signal and provide noise tolerance (Fig. 3c). We demonstrate optical communications up to 10 kHz (Extended Data Fig. 7); higher-speed optical communications can also be implemented using higher-bandwidth photodetectors. For multi-fibre optical communications, an addressable message protocol was established. The network architecture used a two-bus topology (Fig. 3a), where LED and light sensor pairs in each fibre were coupled to those in other fibres by means of two waveguide buses, which acted to improve the bidirectional communication distance compared to free-space transmission. For fibre pairs with LEDs that are aligned on the same bus, or if the distance between fibres is too large for detection, the message must be transmitted to an intermediary fibre, which can then repeat the message to the receiving fibre. To access the guided modes of the square PMMA waveguides, light must pass directly through the ECOC–PMMA interface without escaping into air. This requires a sufficient interfacial contact area between the fibre and waveguide, which can be created by deforming the surface of the elastomeric fibre with compression of the waveguide onto the fibre (Supplementary Figs. 8 and 9). We indeed found that transmission from one fibre to another was aided by increasing the compression force (Fig. 3d), with the amount of compression necessary varying on the basis of the waveguide size (Supplementary Fig. 10). At constant compression, we found that the light propagating in the waveguide had an attenuation coefficient of 0.18–0.28 cm−1 (Supplementary Fig. 10), with losses caused by the bending of the waveguide and out-coupling to the yarns of the fabric (Fig. 3e). In the future, alternate strategies for waveguide coupling and confinement, including grating couplers43,44, low-index claddings and directional light emitters, could be explored for higher-efficiency transmission.\n",
    "ori_text": "\n\nThermal draw of the fibre computer\nThe fibre draw process started with the construction of a macroscopic preform (Fig. 1b) comprising a sacrificial, stress-bearing polymethylmethacrylate (PMMA) cladding encasing an inner hollow thermoplastic cyclic olefin copolymer elastomer (ECOC) cylinder. During the draw process, the PMMA viscous fluid carried most of the tension and offered superior dimensional control, which the more rheologically complex viscoelastic fluid (ECOC) would not. Without this, the sudden transfer of tension from the elastomer to the electrodes as the preform collapses on devices leads to an asymmetric and non-conformal fibre profile near the devices. In addition, drawing the elastomer on its own under high stress would lead to molecular chain alignment, reducing the elasticity of the fibre once quenched. During the draw process, the wires with the pre-connected devices were fed into a single large channel of the preform while the dimensions were reduced to fibre size (Fig. 1b). To maintain the structural elasticity of the conductors through the draw, it is important that the helix diameter be substantially smaller than the fibre channel diameter to minimize the frictional resistance between the wires and the polymer. After the draw process, the PMMA layer was peeled away, leaving an ECOC fibre with eight encapsulated microelectronic devices separated by nearly 15 cm, connected by helically structured wires internal to the fibre (Extended Data Figs. 2 and 3). Because the size of some devices was larger than the steady-state diameter of the fibre away from the devices, which was about 1.35 mm, the channel of the fibre fully collapsed at the devices such that the devices were surrounded by a highly conformal layer of ECOC.\nTensile and flexural properties\nCompared with planar approaches with anisotropic bending stiffness, this solvent-free high-speed thermal draw approach enables conformal, hermetic encapsulation of devices within fibres composed of an elastomer with more than an order of magnitude lower modulus than conventional thermoplastics28,31, providing isotropic flexibility and elasticity35. A representative tensile measurement of a section of fibre between devices (Fig. 1c) showed that breakage of the larger-diameter strain-limiting wire occurred at 6.6% strain, whereas the failure of the first electrode necessary for fibre computer functionality occurred at 67.1% strain. Similarly, a section of the fibre with an embedded device withstood 37% strain before failure (Supplementary Fig. 2). We also found that the fibres maintained functionality for more than a thousand cycles of stretching, representative of high yarn strain in conventional wearable textiles36,37,38, with further improvements in fatigue life possible through application-specific tuning of the wire helix properties (Extended Data Fig. 4).\nIn addition to elastic deformations, we show that the fibre computer is capable of withstanding millimetre-scale flexural deformations, which are crucial for fabric formation and knitting in particular39,40. Bending radius measurements (Fig. 1d) showed that non-device-containing segments sustained flexural stresses down to a bending radius of 0.25 mm without failure, whereas a device-containing segment sustained flexural stresses down to a bending radius of 2.38 mm before the first break of a functional electrode due to the modulus mismatch near devices. We also found that the fibre computer withstood ten machine-washing cycles with no degradation in functionality (Extended Data Fig. 5), demonstrating environmental resilience along with mechanical reliability.\nBraided fibre cladding\nTo further improve the mechanical robustness and surface properties of the fibre computers for fabric integration, we covered the fibre computers with diagonally interlaced textile yarns using a 16-carrier braiding machine (Fig. 1b). The elasticity of the fibre was maintained during the braiding process using a tensioned core loading approach. The versatility of this method with respect to reconfiguration of the type of yarn used, number of carriers and helix pitch allowed the independent design of the mechanical and surface properties of the fibre41,42. A wide variety of yarns were used to cover the fibre computers, including polylactic acid (PLA), Kevlar, cotton and polyester (Fig. 1e,f). The tensile strength of the fibre computer varied with yarn type and denier. A fibre computer braided with 360-denier cotton yarn had a tensile strength of 49 N, whereas a fibre computer braided with 540-denier polyester yarn had a tensile strength of 146 N (Extended Data Fig. 6). Beyond improvements in tensile strength, covering the core with low-friction yarn materials, such as polyester, reduced stiction compared to bare ECOC fibres and prevented stiction to surfaces, such as knitting needles, from causing the fibre to stretch beyond its failure strain.\nFibre computer characterization\nEach fibre computer consists of eight devices connected on a single I2C bus, enabling sensing, computation, storage and communication in a single fibre (Fig. 2a). Four of these devices are sensors: a photodetector, a temperature sensor, a PPG sensor, and an accelerometer, which collect information from the environment and wearer through optical, thermal and mechanical transduction (Fig. 2b). The 32-bit MCU, capable of operating at frequencies up to 96 MHz, provides both computation and storage, with an ARM Cortex-M4 processor with a floating-point unit alongside 256 KB of onboard flash memory and 96 KB of RAM. If required, the generalizability of the interposer approach also allows storage capacity to be expanded by adding downstream memory chips. We implemented two electromagnetic methods for external communications: optically through an LED and through radio-frequency signals from a BLE unit. Intrafibre communication within the system uses the I2C addressing protocol, operating at a clock speed of 100 kHz, although the MCU can drive the bus frequencies up to a maximum of 3.4 MHz for higher throughput applications. The physical architecture uses four wires allocated for I2C (data, clock, power and ground) along with an additional wire dedicated to modulating the LED for optical communications. Through the I2C interface, devices along the length of the fibre can be individually addressed by means of unique 7-bit serial addresses, enabling processor interfacing with less than a 1-ms delay between sequential reads or writes (Extended Data Fig. 5). The MCU can also be dynamically reprogrammed over I2C to target different application requirements, even after fibre integration. The I2C protocol was selected for its use of only two signal conductors, minimizing potential mechanical failure modes; other protocols, such as serial peripheral interface (SPI) and universal asynchronous receiver-transmitter (UART), may also be adopted by either adding additional conductors to the fibre or through device-to-device communications on a single interposer. For applications with more stringent timing requirements, we found that transmission through the in-fibre electrodes over device-to-device spacings can support frequencies of up to 128 MHz (Supplementary Fig. 4), allowing for the adoption of higher-speed protocols if needed.\nPhysiological computing demonstration\nTo demonstrate the sensing, processing and communication capabilities of the fibre computer in a simple application, we show that health metrics, such as heart rate measurements, can be analysed on the basis of data collected by the embedded PPG sensor in close contact with the subject’s skin using signal filtering and feature recognition techniques applied by the in-fibre processor. As PPG sensors are susceptible to motion artefact noise, we show that the in-fibre MCU is capable of applying low-pass filtering and gradient thresholding to recognize individual pulses in real time from the PPG data stream received over I2C (Fig. 2c(ii)). The timing of the pulse peaks was used to calculate the wearer’s heart rate, and the MCU relayed these real-time estimates over I2C to the in-fibre BLE node, which was able to communicate the results to any BLE-compatible display device (Fig. 2c(iii)).\n\nPower considerations\nTo power the embedded devices in the fibre computer, we integrated a pin-type lithium-ion battery only 3.65 mm in diameter inside an ECOC fibre, using a lower-temperature fibre draw to prevent the temperature rise from causing battery degradation. To allow for ease of connection for power, reprogramming and charging, the fibre computers and fibre batteries were terminated with 2.5-mm tip–ring–ring–sleeve (TRRS) audio connectors that can be connected together (Supplementary Fig. 7). After the draw process, we found that the battery-embedded fibre retained a rated battery capacity of 15 mAh (Fig. 2d(i)) and remained rechargeable over multiple uses (Fig. 2d(ii)). To reduce the battery voltage to the required 3.3 V power and I2C logic levels, an in-fibre LDO voltage regulator and pull-up resistors for the I2C bus were incorporated into the fibre computers. Given the baseline average current consumption during code execution (Fig. 2d(iii)), the battery-embedded fibre was capable of powering the fibre computer for up to 6 h. The capability for high-efficiency 1C discharge also demonstrated the ability to accommodate spikes in the current draw, such as those that occur during communications (Supplementary Fig. 6).\nFabric networking\nUsing the fibre computer, we proceeded to create a network of fibre computers in textile fabric. We chose optical and radio-frequency communications to avoid rigid interconnects and complex wiring schemes, which do not support ad hoc networking.\nOptical communications\nOptical communications were enabled through the use of a light sensor and LED present in each fibre. On–off keying modulation of the LED was used with Manchester encoding to eliminate the need for a separate clock signal and provide noise tolerance (Fig. 3c). We demonstrate optical communications up to 10 kHz (Extended Data Fig. 7); higher-speed optical communications can also be implemented using higher-bandwidth photodetectors. For multi-fibre optical communications, an addressable message protocol was established. The network architecture used a two-bus topology (Fig. 3a), where LED and light sensor pairs in each fibre were coupled to those in other fibres by means of two waveguide buses, which acted to improve the bidirectional communication distance compared to free-space transmission. For fibre pairs with LEDs that are aligned on the same bus, or if the distance between fibres is too large for detection, the message must be transmitted to an intermediary fibre, which can then repeat the message to the receiving fibre. To access the guided modes of the square PMMA waveguides, light must pass directly through the ECOC–PMMA interface without escaping into air. This requires a sufficient interfacial contact area between the fibre and waveguide, which can be created by deforming the surface of the elastomeric fibre with compression of the waveguide onto the fibre (Supplementary Figs. 8 and 9). We indeed found that transmission from one fibre to another was aided by increasing the compression force (Fig. 3d), with the amount of compression necessary varying on the basis of the waveguide size (Supplementary Fig. 10). At constant compression, we found that the light propagating in the waveguide had an attenuation coefficient of 0.18–0.28 cm−1 (Supplementary Fig. 10), with losses caused by the bending of the waveguide and out-coupling to the yarns of the fabric (Fig. 3e). In the future, alternate strategies for waveguide coupling and confinement, including grating couplers43,44, low-index claddings and directional light emitters, could be explored for higher-efficiency transmission.\n",
    "reference_list": "考点1：“thermal draw”应该译为热拉制”，因为这是面料行业的主流翻译\n考点2：“polyester”必须译为“聚酯纤维/涤纶”，译文取其一就可，且译文前后需保持一致\n考点3：  \"denier\"必须译为旦/旦尼尔；丹/丹尼，译文取其一就可，且要保持译文一致性\n考点4：“Power considerations”推荐译为“功率考虑”或者“功耗考虑”，因为整个段落在讲的就是电力能源的消耗，译文取其一就可，且要保持译文一致性\n考点5：“Ad hoc networking 应该译为“自组织网络”，不可遗漏Ad hoc 的翻译，表示自行组织，或者临时的。\n考点6：”message protocol“结合上下文应该译为“通信协议”，不可译为“消息协议”这种模糊用词\n考点7：”PPG sensor“应该译为“光电容积脉搏波传感器”，首次出现时，译文应该给出全称，之后再给出简称\n考点8：”I2C“的中文标准译名为 \"I2C总线\"，全称 \"Inter-Integrated Circuit\"，应该译为”集成电路间总线 或 内部集成电路总线“，译文选取一种即可，维持译文的一致性，首次出现时，译文应该给出全称，之后再给出简称\n考点9：“serial peripheral interface (SPI)“应该译为译为”串行外设接口（简称 SPI接口）”首次出现时，译文应该给出全称，之后再给出简称\n考点10：“universal asynchronous receiver-transmitter“应该译为”通用异步收发器（简称 UART）”，业内主流翻译\n考点11：“RAM” 应该译为”随机存取存储器”，首次出现时，译文应该给出全称，之后再给出简称\n考点12：“fibre computer”推荐译为“纤维计算机”或者“智能纤维计算机”，选取一种即可，保持译文一致性",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "200"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nLiability, Indemnification and Release\n1. Each party shall indemnify the other from any and all losses that may arise out of breach by such party of any of the warranties set forth in this Article, and each party shall indemnify the other party from any and all losses that may arise out of breach by such party of any of the agreed terms in this Agreement.\n2. Without limiting any right or remedy available to the non-defaulting party at law or in equity, upon the termination of this Agreement in accordance with Articles X, the defaulting party shall indemnify the other party for all damages, costs, charges and expenses suffered or incurred by it in connection with the termination due to the negligence, breach of duty or other default or wrongdoing of the defaulting party, its servants, employees,agents or contractors.\n3. The CJV shall be solely and fully responsible for the quality of the Products manufactured hereunder, for their conformity with the Technical Data and for their compliance with the laws and regulations from time to time in force in the Territory. The CJV shall indemnify Party B against any loss or damage directly or indirectly suffered by Party B as a result of the failure of the Products manufactured hereunder to comply with the Technical Data(\"Defective Products\")or to comply with such laws or regulations; provided, however, that such indemnification shall not exceed the total of ex-factory sales price, costs of delivery and transportation and other costs associated with the recall of these Defective Products.\n4. Each Party hereby indemnifies the other Party and undertakes to hold harmless and defend the other Party against any and all claims, suits, losses,damages, disbursements (including legal and management costs) arising out of any alleged or actual breach or failure to comply with the terms and conditions hereof including but not limited to any infringement of the otherParty's intellectual property or other rights occurring as a result of theoffending Party's fault, omission or activities in connection with the Project.5. Consultant hereby agrees to indemnify, hold harmless and defend Client from and against any and all claims, liabilities, losses, expenses (including reasonable attorneys' fees),or damages (collectively \"Liabilities\") asserted against Client by a third party to the extent such Liabilities result from the infringement of the Works delivered on any third party's trade secret,trademark, service mark, copyright or patent issued as of the date of this Agreement (collectively, an \"Intellectual Property Right\"); provided that Client: (i) promptly notifies Consultant of any third party claim subject to indemnification hereunder, (ii) gives Consultant the right to control and direct the preparation of a defense, the defense and any settlement of any such claim, (iii) gives full cooperation to Consultant for the defense of same and (iv) complies with Consultant's direction to cease any use of the Works which, in Consultant's sole judgment, is likely to be ruled an infringement on a third party's Intellectual Property Right..\n6. Each Party forever releases and discharges the other from all claims.debts, allegations, actions, causes of action and demands, whether known or unknown, arising from or in connection with the Claim and existing as at the date of this Settlement Agreement, including without limitation any liability for legal costs connected with or arising out of the subject matter of the Claim. Any other claims unrelated to the Claim that one Party may have against another, whether prior to or after the date hereof, shall not be affected or otherwise prejudiced by this Agreement.\nParty B irrevocably waives all rights that it may have in law or contract against Party A, its affiliates, subsidiaries and related companies howsoever arising in respect of or in connection with the Claim.\n\nTaxation\n1. All taxes, customs duties and other charges payable (i) in connection with the importation of the Equipment to China and (ii) in the execution of this Agreement to be levied by the Government of the PRC on Party A shall be paid by Party A.\n2. \"Taxation\" means:\na) any liability of the Company to any form of taxation whether created or imposed in the PRC or any other part of the world and, without prejudice to the generality of the foregoing, includes any tax computed on profits or income, any tax computed on capital assets, estate duty, profits tax,provisional profits tax, interest tax, death duty, gift duty, payroll tax withholding tax, rates, custom and excise duty, transfer tax, inheritance tax,stamp duty, capital duty, employment taxes, value added tax, and generally any tax, imposition, levy or rates or any amount payable to the revenue.customs or fiscal authorities in any part of the world; and\nb) all costs, interest, penalties, charges and expenses incidental or relating to the liability referred to in (a) above.\n3. All fees, expenses and other charges payable to Consultant hereunder do not include any sales, use, excise, value added or other applicable taxes,tariffs or duties, payment of which shall be the sole responsibility of Client(excluding any applicable taxes based on Consultant's net income or taxes arising from the employment or independent contractor relationship between Consultant and its personnel). In the event that such taxes, tariffs or duties are assessed against Consultant, Client shall reimburse Consultant for any such amounts paid by Consultant or, prior to the payment of such amounts by Consultant, provide Consultant with valid tax exemption certificates with respect thereto. If Client is required by law to make any tax deduction,withholding or payment from any amount paid or payable by Client to Consultant under this Agreement, the amount paid or payable to Consultant shall be grossed-up to the extent necessary to ensure that Consultant receives and retains, free of liability, the net amount equal to the amount that Consultant would have received and retained,had no tax deduction or withholding been made.\n4.It is understood and agreed specifically by the parties to this Agreement that Party B shall be an independent contractor, and that nothing in this Agreement or in the performance of any of its provisions is intended or shall be construed to constitute either party an agent, legal representative.subsidiary, joint venturer, partner, employer, or employee of the other for any purpose whatsoever. As an independent contractor, Party B agrees that it will be responsible for and will pay all income and other national, federal.state, provincial, and local taxes and charges assessable on it. It is understood and agreed that nothing in this Agreement authori-zes Party B to make any contract, agreement, warranty or representation on Party A's behalf, or to incur any debt or other obligation in Party A's name, and that Party A shall in no event assume liability or be deemed liable hereunder as a result of any such action of Party B.\n\n1. \"Taxes\" include all forms of taxation,estate duties, deductions,withholdings, duties, imposts,levies, fees, charges, social security contributions and rates imposed, levied, collected, withheld or assessed by any local, municipal, regional, urban, governmental, state, federal or other body in Hong Kong and elsewhere, and any interest, additional taxation,penalty, surcharge or fine in connection therewith.2. Consultant is performing the Services as an independent contractor and not as an employee of Client and none of Consultant's personnel shall be entitled to receive any compensation, benefits or other incidents0remployment from Client. Subject to Article X,Consultant shall be responsible for all taxes and other expenses arising from the employment or independent contractor relationship between Consultant and its personnel and the rendition of Services here-under by such personnel to Client.Nothing in this Agreement shall be deemed to constitute a partnership,joint venture, or fiduciary relationship between Client and Consultant, nor shall anything in this Agreement be deemed to create an agency relationship between Consultant and Client. Neither Consultant nor Client shall be or become liable or bound by any representation, act or omission whatsoever of the other.\n\nIf any portion, term or provision of this Agreement shall be held illegal void or ineffective under, or in conflict with, any applicable law, the validity of the remaining provisions shall not be affected thereby, and a substitute provision will be negotiated to preserve as near as possible the original.intent of the Agreement.",
    "ori_text": "\nLiability, Indemnification and Release\n1. Each party shall indemnify the other from any and all losses that may arise out of breach by such party of any of the warranties set forth in this Article, and each party shall indemnify the other party from any and all losses that may arise out of breach by such party of any of the agreed terms in this Agreement.\n2. Without limiting any right or remedy available to the non-defaulting party at law or in equity, upon the termination of this Agreement in accordance with Articles X, the defaulting party shall indemnify the other party for all damages, costs, charges and expenses suffered or incurred by it in connection with the termination due to the negligence, breach of duty or other default or wrongdoing of the defaulting party, its servants, employees,agents or contractors.\n3. The CJV shall be solely and fully responsible for the quality of the Products manufactured hereunder, for their conformity with the Technical Data and for their compliance with the laws and regulations from time to time in force in the Territory. The CJV shall indemnify Party B against any loss or damage directly or indirectly suffered by Party B as a result of the failure of the Products manufactured hereunder to comply with the Technical Data(\"Defective Products\")or to comply with such laws or regulations; provided, however, that such indemnification shall not exceed the total of ex-factory sales price, costs of delivery and transportation and other costs associated with the recall of these Defective Products.\n4. Each Party hereby indemnifies the other Party and undertakes to hold harmless and defend the other Party against any and all claims, suits, losses,damages, disbursements (including legal and management costs) arising out of any alleged or actual breach or failure to comply with the terms and conditions hereof including but not limited to any infringement of the otherParty's intellectual property or other rights occurring as a result of theoffending Party's fault, omission or activities in connection with the Project.5. Consultant hereby agrees to indemnify, hold harmless and defend Client from and against any and all claims, liabilities, losses, expenses (including reasonable attorneys' fees),or damages (collectively \"Liabilities\") asserted against Client by a third party to the extent such Liabilities result from the infringement of the Works delivered on any third party's trade secret,trademark, service mark, copyright or patent issued as of the date of this Agreement (collectively, an \"Intellectual Property Right\"); provided that Client: (i) promptly notifies Consultant of any third party claim subject to indemnification hereunder, (ii) gives Consultant the right to control and direct the preparation of a defense, the defense and any settlement of any such claim, (iii) gives full cooperation to Consultant for the defense of same and (iv) complies with Consultant's direction to cease any use of the Works which, in Consultant's sole judgment, is likely to be ruled an infringement on a third party's Intellectual Property Right..\n6. Each Party forever releases and discharges the other from all claims.debts, allegations, actions, causes of action and demands, whether known or unknown, arising from or in connection with the Claim and existing as at the date of this Settlement Agreement, including without limitation any liability for legal costs connected with or arising out of the subject matter of the Claim. Any other claims unrelated to the Claim that one Party may have against another, whether prior to or after the date hereof, shall not be affected or otherwise prejudiced by this Agreement.\nParty B irrevocably waives all rights that it may have in law or contract against Party A, its affiliates, subsidiaries and related companies howsoever arising in respect of or in connection with the Claim.\n\nTaxation\n1. All taxes, customs duties and other charges payable (i) in connection with the importation of the Equipment to China and (ii) in the execution of this Agreement to be levied by the Government of the PRC on Party A shall be paid by Party A.\n2. \"Taxation\" means:\na) any liability of the Company to any form of taxation whether created or imposed in the PRC or any other part of the world and, without prejudice to the generality of the foregoing, includes any tax computed on profits or income, any tax computed on capital assets, estate duty, profits tax,provisional profits tax, interest tax, death duty, gift duty, payroll tax withholding tax, rates, custom and excise duty, transfer tax, inheritance tax,stamp duty, capital duty, employment taxes, value added tax, and generally any tax, imposition, levy or rates or any amount payable to the revenue.customs or fiscal authorities in any part of the world; and\nb) all costs, interest, penalties, charges and expenses incidental or relating to the liability referred to in (a) above.\n3. All fees, expenses and other charges payable to Consultant hereunder do not include any sales, use, excise, value added or other applicable taxes,tariffs or duties, payment of which shall be the sole responsibility of Client(excluding any applicable taxes based on Consultant's net income or taxes arising from the employment or independent contractor relationship between Consultant and its personnel). In the event that such taxes, tariffs or duties are assessed against Consultant, Client shall reimburse Consultant for any such amounts paid by Consultant or, prior to the payment of such amounts by Consultant, provide Consultant with valid tax exemption certificates with respect thereto. If Client is required by law to make any tax deduction,withholding or payment from any amount paid or payable by Client to Consultant under this Agreement, the amount paid or payable to Consultant shall be grossed-up to the extent necessary to ensure that Consultant receives and retains, free of liability, the net amount equal to the amount that Consultant would have received and retained,had no tax deduction or withholding been made.\n4.It is understood and agreed specifically by the parties to this Agreement that Party B shall be an independent contractor, and that nothing in this Agreement or in the performance of any of its provisions is intended or shall be construed to constitute either party an agent, legal representative.subsidiary, joint venturer, partner, employer, or employee of the other for any purpose whatsoever. As an independent contractor, Party B agrees that it will be responsible for and will pay all income and other national, federal.state, provincial, and local taxes and charges assessable on it. It is understood and agreed that nothing in this Agreement authori-zes Party B to make any contract, agreement, warranty or representation on Party A's behalf, or to incur any debt or other obligation in Party A's name, and that Party A shall in no event assume liability or be deemed liable hereunder as a result of any such action of Party B.\n\n1. \"Taxes\" include all forms of taxation,estate duties, deductions,withholdings, duties, imposts,levies, fees, charges, social security contributions and rates imposed, levied, collected, withheld or assessed by any local, municipal, regional, urban, governmental, state, federal or other body in Hong Kong and elsewhere, and any interest, additional taxation,penalty, surcharge or fine in connection therewith.2. Consultant is performing the Services as an independent contractor and not as an employee of Client and none of Consultant's personnel shall be entitled to receive any compensation, benefits or other incidents0remployment from Client. Subject to Article X,Consultant shall be responsible for all taxes and other expenses arising from the employment or independent contractor relationship between Consultant and its personnel and the rendition of Services here-under by such personnel to Client.Nothing in this Agreement shall be deemed to constitute a partnership,joint venture, or fiduciary relationship between Client and Consultant, nor shall anything in this Agreement be deemed to create an agency relationship between Consultant and Client. Neither Consultant nor Client shall be or become liable or bound by any representation, act or omission whatsoever of the other.\n\nIf any portion, term or provision of this Agreement shall be held illegal void or ineffective under, or in conflict with, any applicable law, the validity of the remaining provisions shall not be affected thereby, and a substitute provision will be negotiated to preserve as near as possible the original.intent of the Agreement.",
    "reference_list": "考点1：“hold harmless and defend”建议译为“使……免受损害，并为其进行抗辩”，漏“defend”判错，体现组合表达\n考点2：“any loss or damage”并列时须译作“任何损失或损害”，不可合并成“损失”\n考点3：“servants”应译为“服务人员、雇员、代理人或承包商”，不宜漏译，应与“employees, agents, contractors”并列处理\n考点4：“shall not exceed…”建议直译为“不得超过……”，避免“该等赔偿不应超过”式弱化表达\n考点5：“provided, however, that…”建议译为“但前提是”或“但条件是”，避免“但该等赔偿不应超过……”模糊主语\n考点6：“as a result of the offending Party's fault, omission or activities”建议译为“因过错方/侵权方的过错、不作为或行为造成”，避免简化为“由于该方……导致……”；“offending Party”优先译为“过错方/侵权方”，不可译作“违约方”\n考点7：“promptly notifies”应译为“及时通知”；“gives... the right to control”建议译为“赋予……控制权”；“gives full cooperation”应译为“给予充分合作”；“complies with Consultant’s direction”宜译为“遵从……指示”。四项并列内容建议保留**“(i)(ii)(iii)(iv)”等编号结构，增强条款层次感和逻辑清晰度，避免散列句式弱化义务承担；\n考点8：“waives all rights… howsoever arising”推荐译为“不可撤销地放弃……一切权利，且无论以何种方式/原因产生”，保持法律术语严谨性\n考点9：“forever releases and discharges…”建议译为“永远免除和解除”，保留法律解除义务和权利的双重含义\n考点10：“any and all claims, suits, losses…”建议译为“任何及所有索赔、诉讼、损失……”，不可省略“any and all”结构强调义，“any and all …”保留为“任何及所有……”，只译“任何”视为次优\n考点11：“alleged or actual breach or failure…”译为“被指控的或实际的违反或未履行……”，需体现“alleged”之未决状态\n考点12：“grossedup”应译为“返还计还原”或“税前补偿”，体现“税后净得”概念\n考点13：“tax deduction, withholding or payment”建议按术语对应译为“税款扣除、预扣或缴纳”\n考点14：“constitute... an agent, legal representative, subsidiary, joint venturer, partner, employer, or employee”应完整译为“构成一方为另一方的代理人、法定代表人、子公司、合营方、合作伙伴、雇主或雇员”；“shall not be construed to...”宜译为“不得被解释为……”。此类身份排除性表达应使用“不构成……亦不得解释为……”双重否定结构，增强法律约束力；\n考点15：“employment taxes”推荐译为“就业税”，不应漏译为“用工相关税”\n考点16：“imposts, levies, rates...”等多类税收推荐采用“征收、课征、税率”等合适对应术语，避免合并简化为“税收”一词\n考点17：“shall not be or become liable or bound by any representation, act or omission whatsoever of the other”两层后果并列保留“不承担责任，亦不受其约束”，且不得遗漏“omission”“whatsoever”\n考点18：“a substitute provision will be negotiated to preserve…”建议译为“由双方协商达成一项尽可能接近原意的替代条款”，避免模糊为“达成新的条款”\n考点19：“reimburse... or provide... exemption certificates”应译为“（客户应）偿付（顾问已缴纳的税款），或（在顾问缴纳前向其）提供（有效的）免税证明”，结构表示二选一义务，。避免中译为“若……则……或……”等逻辑模糊句式，应准确呈现“偿付或提供证明”二选一义务关系\n考点20：“negligence, breach of duty or other default or wrongdoing”须全译为“过失、违反义务或其他违约或不当行为”\n考点21：“in Consultant’s sole judgment”必须体现“单方/独自判断”的权利\n考点22：“patent issued as of the date of this Agreement”译为“截至本协议签署之日已授权的专利”，不可译“已公告”\n考点23：“Party A, its affiliates, subsidiaries and related companies”三类主体分别列出，不可统称“关联公司”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "104"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nAnother set of unresolved problems of interpretation concerns the traditional society – its social structure, the administrative institutions and ideology of its government and its economic growth. One widely held assumption is that this traditional society had created such an effective and balanced structure of ideas and practices that an innovative response to Western contact was difficult. In this view China’s ‘maturity’ was evidenced in her stability, her capacity to maintain a steady state almost like the homeostasis of physiology. To put it another way, the accumulation of vested interests was so great as to inhibit change. The result was a tremendous inertia or persistence in established ways, a tendency to change only within tradition. This notion of China’s inertial momentum and non-responsiveness is supported also by the concept of the autonomy of culture – that Chinese ways were different, mutually reinforcing, and therefore resistant to outside stimuli.\n\nBroad conceptions of this sort may of course merely substitute for thought. No doubt they display the degree of our present ignorance. Yet if history is to give understanding to non-historians, it must use general ideas. The essential prerequisite for generalizing is a factual picture of the Chinese state and society, including its general conditions and institutional practices, about 1800. At this time China’s population was over 300 million, almost double that of Europe including Russia, and it is safe to say that her home market and domestic trade were also far greater than those of Europe.\n\nThe inertial momentum of China's social order was evident in the early nineteenth century at every level – among the common people in the peasant villages and market towns, among the dominant big families of the local elite or ‘gentry’, in the layers of imperial administration rising from the local magistracies all the way up to the court at Peking, and in the monarchy at the top of the human scene. This Chinese world (t'ien-hsia, ‘all under heaven’) was considered to be, and to a large extent was, remarkably unified, homogeneous and long-lasting.\n\nThe unity of the empire had been the first great achievement of Chinese civilization and it remained a major concern, for unity meant peace. And yet the mere size and diversity of the empire often made for disunity. The eighteen provinces were divided by nature into a number of discrete and clearly marked regions, each comparatively self-sufficient. The central Taiyuan plain and Fen river valley of Shansi province, for example, were bounded on two sides by mountains and on two sides by the Yellow River. The great irrigated basin of Szechwan was ringed by mountains and communicated with the rest of China mainly through the Yangtze gorges. Yunnan province in the south-west was a plateau not in easy touch with the rest of the country. The great rice baskets of the Canton delta, the Yangtze delta, and Hunan and Hupei provinces each provided a base for local power. South Manchuria, as foreigners have called it in the twentieth century, or in Chinese terms of 1800 Liao-tung, was another power base where the Ch’ing dynasty of the Manchus had built up its strength before taking over south China with the Wall in 1644.\n\nMoreover, China stretched so far from north to south that the climatic difference created contrasting ways of life in the two regions. In the south and south-east, the heavy monsoon rainfall in summer facilitated double-cropping of rice. In contrast, the sparseness and unpredictability of rainfall on the north-western Great Wall frontier left people there constantly in danger of famine. The dry farmers in the north could live in houses of tamped earth walls or simple sun-baked brick with thatched roofs, while the wet farmers of the south had to use kiln-baked brick and tile roofs. They also wore straw sandals or clogs instead of cloth shoes, and broad plaited hats against rain and sun rather than the fur-covered caps of the north with ear flaps against winter cold. Much transport in the south was on waterways or, alternatively, on stone-paved paths not adequate for wheeled vehicles. Carrying poles, barrows and donkeys were universal, but the typical north China transport was by two-wheeled cart along dusty roads, frequently sunk several feet down into the loess soil scoured out by the wind. Most striking was the scenic contrast between the broad north China plain, dotted by walled villages that could defend themselves against cavalry raiders, and the typical hill country of south China where cavalry were useless and farmsteads might be more widely scattered in smaller units amid a lush cover of trees and vegetation. Since irrigated rice culture was far more productive than dry cereal farming, south China had a higher per capita food supply and more landlordism and tenancy among farmers.\n\nThe gradual spread of Chinese civilization, with its characteristic features of intensive agriculture, tightly-organized family life, and bureaucratic administration, had given an underlying homogeneity to the whole country north and south, east and west. Perhaps this homogeneity was greater in the minds of the ruling elite than a sociologist would have found it to be in fact. Nevertheless, it was generally assumed. Like political unity, cultural homogeneity was one of China’s great social myths, demonstrating the universality of the Confucian way of life. Consequently, regional differences and the forms of localism have not yet been much studied, for it had always been and still is the fashion to discuss the vast land of China as a unit.\n\n\nThe sense of unity and homogeneity had been fostered by the extraordinary continuity of the Chinese way of life, which came down undisrupted from neolithic times before the dawn of history. Hoe agriculture by family groups in settled villages had emerged by the fifth millennium BC in the Wei valley near the great bend of the Yellow River (as at the site of Pan-p’o outside Sian). Despite occasional invasions of warrior-rulers, Chinese village life had evolved steadily from that time with a continuity seemingly unbroken by sudden changes, either social or technological. The maintenance of peace and order among the village communities had been the special concern of China’s equally ancient ruling class. Under successive dynasties it had gradually created complex institutions of bureaucratic government. Until after 1800 the agrarian-bureaucratic empire of China thus preserved a social order more ancient than, and very different from, the commercial-military society of Europe.\n\nThe individual’s prowess and aggressiveness, including his use of violence, had not been fostered in China’s agrarian communities as much as in the seafaring, warfare, exploration and overseas emigration of the Europeans.\n\nBy 1800 we may assume that the ordinary peasants, who formed at least four-fifths of the population, were cultured individuals in the sense that they were well-schooled in the bonds of kinship, the duties of status, and the forms of politeness and social deportment, but generally illiterate or only semi-literate. Consequently their lives were less devoted to Confucian rationalism than to the lore, superstitions and Taoist-Buddhist religious observances of the folk culture. As farmers, most of them lived close to nature. They were accustomed to nature’s beauties but also suffered from epidemic diseases, for example, the prevalence of eye and skin ailments and intestinal parasites. As commoners, they were well aware of the ruling elite and its prerogatives, but they saw little of it directly and were chiefly absorbed in their own village-and-market-centre community.\n\nThe usual village, perhaps one hundred households, was below the market level and not self-sufficient. Its real community centred on the market town, which was, of course, within walking distance not more than two or three miles away, so that a family member might go there and return on a periodic market day. The schedule of markets in one town, say on the third, sixth and eighth days of the ten-day cycle, would be integrated with the schedules of the adjacent towns, which might have their markets on the second, fourth, seventh and ninth days, or the third, fifth, eighth and tenth days of the cycle. In this way itinerant pedlars and merchants who operated out of a still larger market centre, could make the rounds of the market towns in its region. The lowest level or standard market town was usually surrounded by a dozen or eighteen villages, totalling perhaps fifteen hundred households or seven thousand people. From one of these village households an able-bodied male through the years might visit the market town a thousand times, and thus in its tea houses, its local temple or its occasional fairs and holiday celebrations have an opportunity to meet a large proportion of his market community.\n\nThe basis of this community was not only economic – to exchange surplus farm or handicraft products so as to secure paper, iron implements, ceramic-ware or other imports – but also social. Since many villages were dominated by one kinship group, the rule of exogamous marriage led families to seek brides in other villages, usually through market town matchmakers. A secret society lodge, if present, would normally be centred in the market town, and there also the peasant would meet any local members of the ruling class or representatives of officialdom.\n\nIn this peasant society, the individual depended upon his own kinship group for his livelihood and for the security provided in modern societies through insurance, as well as for education, recreation and major social contact. From infancy he was trained to observe the proper familial relationships, especially filial piety. The three bonds (san-kang) of the classical teaching were authoritarian, enjoining obedience to parents, subordination of wives to husbands, and loyalty of subject to ruler. But the hierarchy of status within the nuclear family was only part of the kinship network that extended out into the common descent group or lineage with which most families were connected.",
    "ori_text": "\n\nAnother set of unresolved problems of interpretation concerns the traditional society – its social structure, the administrative institutions and ideology of its government and its economic growth. One widely held assumption is that this traditional society had created such an effective and balanced structure of ideas and practices that an innovative response to Western contact was difficult. In this view China’s ‘maturity’ was evidenced in her stability, her capacity to maintain a steady state almost like the homeostasis of physiology. To put it another way, the accumulation of vested interests was so great as to inhibit change. The result was a tremendous inertia or persistence in established ways, a tendency to change only within tradition. This notion of China’s inertial momentum and non-responsiveness is supported also by the concept of the autonomy of culture – that Chinese ways were different, mutually reinforcing, and therefore resistant to outside stimuli.\n\nBroad conceptions of this sort may of course merely substitute for thought. No doubt they display the degree of our present ignorance. Yet if history is to give understanding to non-historians, it must use general ideas. The essential prerequisite for generalizing is a factual picture of the Chinese state and society, including its general conditions and institutional practices, about 1800. At this time China’s population was over 300 million, almost double that of Europe including Russia, and it is safe to say that her home market and domestic trade were also far greater than those of Europe.\n\nThe inertial momentum of China's social order was evident in the early nineteenth century at every level – among the common people in the peasant villages and market towns, among the dominant big families of the local elite or ‘gentry’, in the layers of imperial administration rising from the local magistracies all the way up to the court at Peking, and in the monarchy at the top of the human scene. This Chinese world (t'ien-hsia, ‘all under heaven’) was considered to be, and to a large extent was, remarkably unified, homogeneous and long-lasting.\n\nThe unity of the empire had been the first great achievement of Chinese civilization and it remained a major concern, for unity meant peace. And yet the mere size and diversity of the empire often made for disunity. The eighteen provinces were divided by nature into a number of discrete and clearly marked regions, each comparatively self-sufficient. The central Taiyuan plain and Fen river valley of Shansi province, for example, were bounded on two sides by mountains and on two sides by the Yellow River. The great irrigated basin of Szechwan was ringed by mountains and communicated with the rest of China mainly through the Yangtze gorges. Yunnan province in the south-west was a plateau not in easy touch with the rest of the country. The great rice baskets of the Canton delta, the Yangtze delta, and Hunan and Hupei provinces each provided a base for local power. South Manchuria, as foreigners have called it in the twentieth century, or in Chinese terms of 1800 Liao-tung, was another power base where the Ch’ing dynasty of the Manchus had built up its strength before taking over south China with the Wall in 1644.\n\nMoreover, China stretched so far from north to south that the climatic difference created contrasting ways of life in the two regions. In the south and south-east, the heavy monsoon rainfall in summer facilitated double-cropping of rice. In contrast, the sparseness and unpredictability of rainfall on the north-western Great Wall frontier left people there constantly in danger of famine. The dry farmers in the north could live in houses of tamped earth walls or simple sun-baked brick with thatched roofs, while the wet farmers of the south had to use kiln-baked brick and tile roofs. They also wore straw sandals or clogs instead of cloth shoes, and broad plaited hats against rain and sun rather than the fur-covered caps of the north with ear flaps against winter cold. Much transport in the south was on waterways or, alternatively, on stone-paved paths not adequate for wheeled vehicles. Carrying poles, barrows and donkeys were universal, but the typical north China transport was by two-wheeled cart along dusty roads, frequently sunk several feet down into the loess soil scoured out by the wind. Most striking was the scenic contrast between the broad north China plain, dotted by walled villages that could defend themselves against cavalry raiders, and the typical hill country of south China where cavalry were useless and farmsteads might be more widely scattered in smaller units amid a lush cover of trees and vegetation. Since irrigated rice culture was far more productive than dry cereal farming, south China had a higher per capita food supply and more landlordism and tenancy among farmers.\n\nThe gradual spread of Chinese civilization, with its characteristic features of intensive agriculture, tightly-organized family life, and bureaucratic administration, had given an underlying homogeneity to the whole country north and south, east and west. Perhaps this homogeneity was greater in the minds of the ruling elite than a sociologist would have found it to be in fact. Nevertheless, it was generally assumed. Like political unity, cultural homogeneity was one of China’s great social myths, demonstrating the universality of the Confucian way of life. Consequently, regional differences and the forms of localism have not yet been much studied, for it had always been and still is the fashion to discuss the vast land of China as a unit.\n\n\nThe sense of unity and homogeneity had been fostered by the extraordinary continuity of the Chinese way of life, which came down undisrupted from neolithic times before the dawn of history. Hoe agriculture by family groups in settled villages had emerged by the fifth millennium BC in the Wei valley near the great bend of the Yellow River (as at the site of Pan-p’o outside Sian). Despite occasional invasions of warrior-rulers, Chinese village life had evolved steadily from that time with a continuity seemingly unbroken by sudden changes, either social or technological. The maintenance of peace and order among the village communities had been the special concern of China’s equally ancient ruling class. Under successive dynasties it had gradually created complex institutions of bureaucratic government. Until after 1800 the agrarian-bureaucratic empire of China thus preserved a social order more ancient than, and very different from, the commercial-military society of Europe.\n\nThe individual’s prowess and aggressiveness, including his use of violence, had not been fostered in China’s agrarian communities as much as in the seafaring, warfare, exploration and overseas emigration of the Europeans.\n\nBy 1800 we may assume that the ordinary peasants, who formed at least four-fifths of the population, were cultured individuals in the sense that they were well-schooled in the bonds of kinship, the duties of status, and the forms of politeness and social deportment, but generally illiterate or only semi-literate. Consequently their lives were less devoted to Confucian rationalism than to the lore, superstitions and Taoist-Buddhist religious observances of the folk culture. As farmers, most of them lived close to nature. They were accustomed to nature’s beauties but also suffered from epidemic diseases, for example, the prevalence of eye and skin ailments and intestinal parasites. As commoners, they were well aware of the ruling elite and its prerogatives, but they saw little of it directly and were chiefly absorbed in their own village-and-market-centre community.\n\nThe usual village, perhaps one hundred households, was below the market level and not self-sufficient. Its real community centred on the market town, which was, of course, within walking distance not more than two or three miles away, so that a family member might go there and return on a periodic market day. The schedule of markets in one town, say on the third, sixth and eighth days of the ten-day cycle, would be integrated with the schedules of the adjacent towns, which might have their markets on the second, fourth, seventh and ninth days, or the third, fifth, eighth and tenth days of the cycle. In this way itinerant pedlars and merchants who operated out of a still larger market centre, could make the rounds of the market towns in its region. The lowest level or standard market town was usually surrounded by a dozen or eighteen villages, totalling perhaps fifteen hundred households or seven thousand people. From one of these village households an able-bodied male through the years might visit the market town a thousand times, and thus in its tea houses, its local temple or its occasional fairs and holiday celebrations have an opportunity to meet a large proportion of his market community.\n\nThe basis of this community was not only economic – to exchange surplus farm or handicraft products so as to secure paper, iron implements, ceramic-ware or other imports – but also social. Since many villages were dominated by one kinship group, the rule of exogamous marriage led families to seek brides in other villages, usually through market town matchmakers. A secret society lodge, if present, would normally be centred in the market town, and there also the peasant would meet any local members of the ruling class or representatives of officialdom.\n\nIn this peasant society, the individual depended upon his own kinship group for his livelihood and for the security provided in modern societies through insurance, as well as for education, recreation and major social contact. From infancy he was trained to observe the proper familial relationships, especially filial piety. The three bonds (san-kang) of the classical teaching were authoritarian, enjoining obedience to parents, subordination of wives to husbands, and loyalty of subject to ruler. But the hierarchy of status within the nuclear family was only part of the kinship network that extended out into the common descent group or lineage with which most families were connected.",
    "reference_list": "考点1：assumption 应译为 认定，主张，看法。不应译为“假设”\n考点2：inertia or persistence 应译为“惯性，或称为持久性”\n考点3：resistant应译为抗拒或对……有抵抗力，不应译为“抵制”或“抵御”\n考点4：substitute for thought推荐译为“替代深入思考”\n考点5：market town应译为“市镇”\n考点6：the eighteen provinces were divided by nature…… 应译为十八省因自然地理条件被分割为\n考点7: and Hunan and Hubei provinces 应译为湖广，因为两地在此处连在一起表述\n考点8：power base 应译为政权或势力的根据地\n考点9：taking over south of the Wall 应译为占领了长城以南的地区\n考点10：intensive agriculture在历史学里应翻译为精耕农业，而不是集约化农业\n考点11: Confucian way of life应译为“儒家之道”“儒家的典型特征”等，不应直译为“生活方式”\n考点12：hoe agriculture应意译为耕种农业\n考点13：village-and-market-centre community应译为以村和市镇为中心的社区\n考点14：insurance 应译为生活保障，指现代社会提供的生活保障，并非保险",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "170"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n跨境并购中的反垄断审查与国家安全审查协同机制\n\n 一、审查标准的冲突与协调\n跨境并购的双重审查体系（反垄断审查与国家安全审查）常因标准差异引发合规困境。反垄断审查聚焦 “市场集中度”（HHI 指数）与 “竞争损害可能性”，而国家安全审查侧重 “关键领域控制权” 与 “供应链安全”，二者的核心冲突体现在三方面：\n1. 审查范围的重叠与空白\n根据《国务院反垄断委员会关于平台经济领域反垄断指南》，“数据集中” 可纳入反垄断审查；而《网络安全审查办法》将 “数据跨境” 列为国家安全审查重点。某跨国互联网企业收购中国社交平台时，因 “合并后市场份额达 35%” 触发反垄断审查，同时因 “掌握 1 亿用户生物信息” 被要求进行网络安全审查，导致同一交易面临两次审查，流程耗时延长 4 个月。反之，某些涉及 “非敏感技术但高市场份额” 的并购（如农用机械制造企业收购），因未落入国家安全审查范围，仅通过反垄断审查即完成交易，引发 “安全审查覆盖不全” 的争议。\n2. 审查标准的实质性差异\n反垄断审查中的 “相关市场界定”（如 “即时通讯服务市场”“云计算服务市场”）与国家安全审查中的 “关键领域划分”（如 “关键信息基础设施”“核心数据”）缺乏统一标准。例如，某半导体企业收购案中，反垄断机构界定相关市场为 “28 纳米以下芯片制造”，认定 “合并后市场集中度未达垄断阈值”；而国家安全审查机构将其归为 “核心元器件领域”，以 “可能影响供应链安全” 为由否决交易，标准冲突导致企业合规成本倍增。\n3. 审查期限的衔接问题\n《反垄断法》规定经营者集中审查期限为 30 日（初步审查）+90 日（进一步审查），特殊情况可延长 60 日；而《国家安全审查办法》未明确审查期限，实践中平均耗时 6-12 个月。某能源企业跨境并购案中，反垄断审查已通过，但国家安全审查持续 14 个月，导致交易因超过 “签约后 18 个月生效” 的条款而失效，企业损失定金 2 亿元。\n\n二、审查豁免与例外情形的适用争议\n两类审查均设有豁免条款，但适用条件的模糊性引发实践分歧：\n1. “小额交易豁免” 的认定分歧\n反垄断审查对 “交易额低于 4 亿元且各方市场份额低于 15%” 的交易可豁免审查，但国家安全审查无类似规定。某外资企业收购中国区域性连锁超市（交易额 3.8 亿元，市场份额 12%），虽符合反垄断豁免条件，却因 “涉及生鲜供应链数据” 被纳入国家安全审查，企业质疑 “小额交易不应触发安全审查”，但现行法规未明确排除。\n2. “危机并购例外” 的适用空白\n当目标企业面临破产时，反垄断审查可适用 “濒临破产企业抗辩”（如《横向合并指南》规定的 “若无并购则企业将退出市场”），但国家安全审查未设立类似例外。2023 年某国产芯片设计企业因资金链断裂拟被外资收购，反垄断审查以 “有助于维持市场竞争” 批准，而国家安全审查以 “技术外流风险” 否决，最终企业破产清算，引发 “安全审查是否应兼顾市场效率” 的讨论。\n3. “国有资本并购” 的审查差异\n国有企业跨境并购时，反垄断审查适用与民营企业相同的标准（如某央企收购海外能源公司因 “全球市场份额超 50%” 被附加剥离资产条件），但国家安全审查对 “国有资本控股” 的交易往往放宽标准，某国企收购境外港口企业时，因 “涉及关键基础设施” 本应从严审查，却以 “国有资本保障安全” 为由快速通过，被质疑 “审查标准双重化”。\n\n 三、数字化背景下的新型审查挑战\n数据资产与新兴技术的跨境流动，使两类审查面临协同难题：\n1. 数据并购的双重审查困境\n企业通过 “资产收购” 获取数据时，若数据量未达 “经营者集中” 阈值（如收购仅含 10 万用户数据的小公司），可规避反垄断审查，但可能因 “数据敏感程度”（如健康数据）触发国家安全审查。某跨境医疗 APP 收购案中，收购标的用户量仅 8 万（未达反垄断申报标准），却因 “包含 HIV 感染者数据” 被要求进行网络安全审查，企业因未提前预判而导致交易搁置。\n2. “扼杀式并购” 的识别盲区\n大型科技企业收购初创公司以消灭潜在竞争对手（即 “扼杀式并购”），可能不违反反垄断法（因初创公司市场份额低），但可能涉及 “核心技术流失”。某海外巨头收购中国 AI 算法初创公司（市场份额 0.3%），反垄断审查未予禁止，而国家安全审查以 “算法可用于军事仿真” 为由否决，凸显 “非竞争因素主导审查” 的新趋势。\n3. 审查信息共享的障碍\n反垄断审查机构需获取 “市场份额数据”“竞争影响分析”，国家安全审查机构需掌握 “技术敏感程度”“供应链依赖度”，但两类信息分属不同部门管理，且涉及商业秘密与国家秘密的界限。某汽车行业并购案中，反垄断机构要求共享国家安全审查中的 “技术评估报告” 被拒，导致无法全面评估 “合并对新能源汽车技术竞争的影响”。\n\n 四、协同审查机制的完善路径\n实践中已探索三类协同模式，但仍需优化：\n1. “一案双报” 的流程整合\n上海试点 “反垄断与国家安全审查联办窗口”，企业提交一套材料即可同时启动两类审查，审查期限按 “就长不就短” 原则（如国家安全审查耗时较长则以其为准）。某集成电路企业通过该窗口完成审查，总耗时较分开申报缩短 50%，但 “材料复用率” 仅 60%（因部分信息需分别适配两类审查要求）。\n2. 审查标准的衔接清单\n商务部发布《跨境并购敏感领域清单》，明确 “同时触发两类审查的领域”（如人工智能、生物医药）及 “优先适用安全审查的情形”（如涉及军事配套产业）。某生物制药企业并购案依据清单直接进入联合审查，避免了 “重复论证”，但清单未涵盖 “数据跨境 + 市场垄断” 的复合情形。\n3. 争议解决的会商机制\n设立跨部门会商小组，对标准冲突案件进行联合评审。2024 年某无人机企业并购案中，反垄断机构认为 “市场集中度未超标”，安全审查机构担忧 “飞控技术外流”，经会商后附加 “技术授权仅限民用领域” 的条件，促成交易通过，为类似案件提供了参考。\n",
    "ori_text": "\n\n跨境并购中的反垄断审查与国家安全审查协同机制\n\n 一、审查标准的冲突与协调\n跨境并购的双重审查体系（反垄断审查与国家安全审查）常因标准差异引发合规困境。反垄断审查聚焦 “市场集中度”（HHI 指数）与 “竞争损害可能性”，而国家安全审查侧重 “关键领域控制权” 与 “供应链安全”，二者的核心冲突体现在三方面：\n1. 审查范围的重叠与空白\n根据《国务院反垄断委员会关于平台经济领域反垄断指南》，“数据集中” 可纳入反垄断审查；而《网络安全审查办法》将 “数据跨境” 列为国家安全审查重点。某跨国互联网企业收购中国社交平台时，因 “合并后市场份额达 35%” 触发反垄断审查，同时因 “掌握 1 亿用户生物信息” 被要求进行网络安全审查，导致同一交易面临两次审查，流程耗时延长 4 个月。反之，某些涉及 “非敏感技术但高市场份额” 的并购（如农用机械制造企业收购），因未落入国家安全审查范围，仅通过反垄断审查即完成交易，引发 “安全审查覆盖不全” 的争议。\n2. 审查标准的实质性差异\n反垄断审查中的 “相关市场界定”（如 “即时通讯服务市场”“云计算服务市场”）与国家安全审查中的 “关键领域划分”（如 “关键信息基础设施”“核心数据”）缺乏统一标准。例如，某半导体企业收购案中，反垄断机构界定相关市场为 “28 纳米以下芯片制造”，认定 “合并后市场集中度未达垄断阈值”；而国家安全审查机构将其归为 “核心元器件领域”，以 “可能影响供应链安全” 为由否决交易，标准冲突导致企业合规成本倍增。\n3. 审查期限的衔接问题\n《反垄断法》规定经营者集中审查期限为 30 日（初步审查）+90 日（进一步审查），特殊情况可延长 60 日；而《国家安全审查办法》未明确审查期限，实践中平均耗时 6-12 个月。某能源企业跨境并购案中，反垄断审查已通过，但国家安全审查持续 14 个月，导致交易因超过 “签约后 18 个月生效” 的条款而失效，企业损失定金 2 亿元。\n\n二、审查豁免与例外情形的适用争议\n两类审查均设有豁免条款，但适用条件的模糊性引发实践分歧：\n1. “小额交易豁免” 的认定分歧\n反垄断审查对 “交易额低于 4 亿元且各方市场份额低于 15%” 的交易可豁免审查，但国家安全审查无类似规定。某外资企业收购中国区域性连锁超市（交易额 3.8 亿元，市场份额 12%），虽符合反垄断豁免条件，却因 “涉及生鲜供应链数据” 被纳入国家安全审查，企业质疑 “小额交易不应触发安全审查”，但现行法规未明确排除。\n2. “危机并购例外” 的适用空白\n当目标企业面临破产时，反垄断审查可适用 “濒临破产企业抗辩”（如《横向合并指南》规定的 “若无并购则企业将退出市场”），但国家安全审查未设立类似例外。2023 年某国产芯片设计企业因资金链断裂拟被外资收购，反垄断审查以 “有助于维持市场竞争” 批准，而国家安全审查以 “技术外流风险” 否决，最终企业破产清算，引发 “安全审查是否应兼顾市场效率” 的讨论。\n3. “国有资本并购” 的审查差异\n国有企业跨境并购时，反垄断审查适用与民营企业相同的标准（如某央企收购海外能源公司因 “全球市场份额超 50%” 被附加剥离资产条件），但国家安全审查对 “国有资本控股” 的交易往往放宽标准，某国企收购境外港口企业时，因 “涉及关键基础设施” 本应从严审查，却以 “国有资本保障安全” 为由快速通过，被质疑 “审查标准双重化”。\n\n 三、数字化背景下的新型审查挑战\n数据资产与新兴技术的跨境流动，使两类审查面临协同难题：\n1. 数据并购的双重审查困境\n企业通过 “资产收购” 获取数据时，若数据量未达 “经营者集中” 阈值（如收购仅含 10 万用户数据的小公司），可规避反垄断审查，但可能因 “数据敏感程度”（如健康数据）触发国家安全审查。某跨境医疗 APP 收购案中，收购标的用户量仅 8 万（未达反垄断申报标准），却因 “包含 HIV 感染者数据” 被要求进行网络安全审查，企业因未提前预判而导致交易搁置。\n2. “扼杀式并购” 的识别盲区\n大型科技企业收购初创公司以消灭潜在竞争对手（即 “扼杀式并购”），可能不违反反垄断法（因初创公司市场份额低），但可能涉及 “核心技术流失”。某海外巨头收购中国 AI 算法初创公司（市场份额 0.3%），反垄断审查未予禁止，而国家安全审查以 “算法可用于军事仿真” 为由否决，凸显 “非竞争因素主导审查” 的新趋势。\n3. 审查信息共享的障碍\n反垄断审查机构需获取 “市场份额数据”“竞争影响分析”，国家安全审查机构需掌握 “技术敏感程度”“供应链依赖度”，但两类信息分属不同部门管理，且涉及商业秘密与国家秘密的界限。某汽车行业并购案中，反垄断机构要求共享国家安全审查中的 “技术评估报告” 被拒，导致无法全面评估 “合并对新能源汽车技术竞争的影响”。\n\n 四、协同审查机制的完善路径\n实践中已探索三类协同模式，但仍需优化：\n1. “一案双报” 的流程整合\n上海试点 “反垄断与国家安全审查联办窗口”，企业提交一套材料即可同时启动两类审查，审查期限按 “就长不就短” 原则（如国家安全审查耗时较长则以其为准）。某集成电路企业通过该窗口完成审查，总耗时较分开申报缩短 50%，但 “材料复用率” 仅 60%（因部分信息需分别适配两类审查要求）。\n2. 审查标准的衔接清单\n商务部发布《跨境并购敏感领域清单》，明确 “同时触发两类审查的领域”（如人工智能、生物医药）及 “优先适用安全审查的情形”（如涉及军事配套产业）。某生物制药企业并购案依据清单直接进入联合审查，避免了 “重复论证”，但清单未涵盖 “数据跨境 + 市场垄断” 的复合情形。\n3. 争议解决的会商机制\n设立跨部门会商小组，对标准冲突案件进行联合评审。2024 年某无人机企业并购案中，反垄断机构认为 “市场集中度未超标”，安全审查机构担忧 “飞控技术外流”，经会商后附加 “技术授权仅限民用领域” 的条件，促成交易通过，为类似案件提供了参考。\n",
    "reference_list": "考点 1:“《国务院反垄断委员会关于平台经济领域反垄断指南》” 必须译为 “Anti-monopoly Guidelines of the Anti-monopoly Commission of the State Council for the Field of Platform Economy”，固定译法\n考点 2: “《网络安全审查办法” 必须译为 “The Measures for Cybersecurity Review”，固定译法\n考点 3:“相关市场界定” 推荐译为 “relevant market definition”\n考点 4:“《反垄断法》” 必须译为 “The Anti-Monopoly Law ”，固定译法\n考点 5:“经营者集中” 推荐译为 “concentration of undertakings”，不能译为 “enterprise merger”，因为此处表示的不是“兼并”的意思\n考点 6:“HHI ”必须译为“Herfindahl-Hirschman Index (HHI)”，固定译法，且首次出现应该用全称，之后再用简称\n考点 7:“数据集中” 必须译为“data aggregation”。不能译为 “data concentration”，固定译法\n考点 8:“技术外流风险” 推荐译为 “risk of technology outflow”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "164"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n      这几天心里颇不宁静。今晚在院子里坐着乘凉，忽然想起日日走过的荷塘，在这满月的光里，总该另有一番样子吧。月亮渐渐地升高了，墙外马路上孩子们的欢笑，已经听不见了;妻在屋里拍着闰儿，迷迷糊糊地哼着眠歌。我悄悄地披了大衫，带上门出去。\n　　沿着荷塘，是一条曲折的小煤屑路。这是一条幽僻的路;白天也少人走，夜晚更加寂寞。荷塘四面，长着许多树，蓊蓊郁郁的。路的一旁，是些杨柳，和一些不知道名字的树。没有月光的晚上，这路上阴森森的，有些怕人。今晚却很好，虽然月光也还是淡淡的。\n　　路上只我一个人，背着手踱着。这一片天地好像是我的;我也像超出了平常的自己，到了另一世界里。我爱热闹，也爱冷静;爱群居，也爱独处。像今晚上，一个人在这苍茫的月下，什么都可以想，什么都可以不想，便觉是个自由的人。白天里一定要做的事，一定要说的话，现在都可不理。这是独处的妙处，我且受用这无边的荷香月色好了。\n　　曲曲折折的荷塘上面，弥望的是田田的叶子。叶子出水很高，像亭亭的舞女的裙。层层的叶子中间，零星地点缀着些白花，有袅娜地开着的，有羞涩地打着朵儿的;正如一粒粒的明珠，又如碧天里的星星，又如刚出浴的美人。微风过处，送来缕缕清香，仿佛远处高楼上渺茫的歌声似的。这时候叶子与花也有一丝的颤动，像闪电般，霎时传过荷塘的那边去了。叶子本是肩并肩密密地挨着，这便宛然有了一道凝碧的波痕。叶子底下是脉脉的流水，遮住了，不能见一些颜色;而叶子却更见风致了。\n　　月光如流水一般，静静地泻在这一片叶子和花上。薄薄的青雾浮起在荷塘里。叶子和花仿佛在牛乳中洗过一样;又像笼着轻纱的梦。虽然是满月，天上却有一层淡淡的云，所以不能朗照;但我以为这恰是到了好处——酣眠固不可少，小睡也别有风味的。月光是隔了树照过来的，高处丛生的灌木，落下参差的斑驳的黑影，峭楞楞如鬼一般;弯弯的杨柳的稀疏的倩影，却又像是画在荷叶上。塘中的月色并不均匀;但光与影有着和谐的旋律，如梵婀玲上奏着的名曲。\n　　荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住;只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾;但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打采的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声;但热闹是它们的，我什么也没有。\n　　忽然想起采莲的事情来了。采莲是江南的旧俗，似乎很早就有，而六朝时为盛;从诗歌里可以约略知道。采莲的是少年的女子，她们是荡着小船，唱着艳歌去的。采莲人不用说很多，还有看采莲的人。那是一个热闹的季节，也是一个风流的季节。梁元帝《采莲赋》里说得好：\n　　于是妖童媛女，荡舟心许;鷁首徐回，兼传羽杯;欋将移而藻挂，船欲动而萍开。尔其纤腰束素，迁延顾步;夏始春余，叶嫩花初，恐沾裳而浅笑，畏倾船而敛裾。\n　　可见当时嬉游的光景了。这真是有趣的事，可惜我们现在早已无福消受了。\n　　于是又记起《西洲曲》里的句子：\n　　采莲南塘秋，莲花过人头;低头弄莲子，莲子清如水。今晚若有采莲人，这儿的莲花也算得“过人头”了;只不见一些流水的影子，是不行的。这令我到底惦着江南了。——这样想着，猛一抬头，不觉已是自己的门前;轻轻地推门进去，什么声息也没有，妻已睡熟好久了。",
    "ori_text": "      这几天心里颇不宁静。今晚在院子里坐着乘凉，忽然想起日日走过的荷塘，在这满月的光里，总该另有一番样子吧。月亮渐渐地升高了，墙外马路上孩子们的欢笑，已经听不见了;妻在屋里拍着闰儿，迷迷糊糊地哼着眠歌。我悄悄地披了大衫，带上门出去。\n　　沿着荷塘，是一条曲折的小煤屑路。这是一条幽僻的路;白天也少人走，夜晚更加寂寞。荷塘四面，长着许多树，蓊蓊郁郁的。路的一旁，是些杨柳，和一些不知道名字的树。没有月光的晚上，这路上阴森森的，有些怕人。今晚却很好，虽然月光也还是淡淡的。\n　　路上只我一个人，背着手踱着。这一片天地好像是我的;我也像超出了平常的自己，到了另一世界里。我爱热闹，也爱冷静;爱群居，也爱独处。像今晚上，一个人在这苍茫的月下，什么都可以想，什么都可以不想，便觉是个自由的人。白天里一定要做的事，一定要说的话，现在都可不理。这是独处的妙处，我且受用这无边的荷香月色好了。\n　　曲曲折折的荷塘上面，弥望的是田田的叶子。叶子出水很高，像亭亭的舞女的裙。层层的叶子中间，零星地点缀着些白花，有袅娜地开着的，有羞涩地打着朵儿的;正如一粒粒的明珠，又如碧天里的星星，又如刚出浴的美人。微风过处，送来缕缕清香，仿佛远处高楼上渺茫的歌声似的。这时候叶子与花也有一丝的颤动，像闪电般，霎时传过荷塘的那边去了。叶子本是肩并肩密密地挨着，这便宛然有了一道凝碧的波痕。叶子底下是脉脉的流水，遮住了，不能见一些颜色;而叶子却更见风致了。\n　　月光如流水一般，静静地泻在这一片叶子和花上。薄薄的青雾浮起在荷塘里。叶子和花仿佛在牛乳中洗过一样;又像笼着轻纱的梦。虽然是满月，天上却有一层淡淡的云，所以不能朗照;但我以为这恰是到了好处——酣眠固不可少，小睡也别有风味的。月光是隔了树照过来的，高处丛生的灌木，落下参差的斑驳的黑影，峭楞楞如鬼一般;弯弯的杨柳的稀疏的倩影，却又像是画在荷叶上。塘中的月色并不均匀;但光与影有着和谐的旋律，如梵婀玲上奏着的名曲。\n　　荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住;只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾;但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打采的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声;但热闹是它们的，我什么也没有。\n　　忽然想起采莲的事情来了。采莲是江南的旧俗，似乎很早就有，而六朝时为盛;从诗歌里可以约略知道。采莲的是少年的女子，她们是荡着小船，唱着艳歌去的。采莲人不用说很多，还有看采莲的人。那是一个热闹的季节，也是一个风流的季节。梁元帝《采莲赋》里说得好：\n　　于是妖童媛女，荡舟心许;鷁首徐回，兼传羽杯;欋将移而藻挂，船欲动而萍开。尔其纤腰束素，迁延顾步;夏始春余，叶嫩花初，恐沾裳而浅笑，畏倾船而敛裾。\n　　可见当时嬉游的光景了。这真是有趣的事，可惜我们现在早已无福消受了。\n　　于是又记起《西洲曲》里的句子：\n　　采莲南塘秋，莲花过人头;低头弄莲子，莲子清如水。今晚若有采莲人，这儿的莲花也算得“过人头”了;只不见一些流水的影子，是不行的。这令我到底惦着江南了。——这样想着，猛一抬头，不觉已是自己的门前;轻轻地推门进去，什么声息也没有，妻已睡熟好久了。",
    "reference_list": "考点1：“颇不宁静”应该译为“ rather restless”，表示内心烦乱。\n考点2：“乘凉”应译为“enjoying the cool”，是中国特有的夏日习惯。\n考点3：“大衫”应译为“long robe”，中国特有服饰。 \n考点4：“踱着”应译为“strolling”，表示慢速、悠闲、带有沉思意味的散步。\n考点5：“苍茫”应译为“vast and mistry ”，形容的是一种广阔、空旷、辽远而又有些模糊不清的景象。\n考点6：“受用”应译为“indulge in”表示沉浸在这片风景之中。\n考点7：“田田的叶子”应译为“an expanse of leaves”，表示一大片的荷叶。\n考点8：“风致”应译为“attractive”表示吸引人的。\n考点9：“梵炯铃”应译为“violin”，当时那个年代外来的音译词。\n考点10：“风流的”应译为“romantic”，形容男女之间的浪漫爱情关系。\n考点11：“梁元帝的”应译为“Emperor Yuan of the Liang Dynasty”。\n考点12：“妖童媛女的”应译为“charming boys and lovely maidens”，指的是有魅力的男子和可爱的女子。\n考点13：“惦着”应译为“miss”，表示想念。\n考点14：“江南”应译为“south of the Yangtze River”，指明具体的地理位置。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "散文",
    "prompt_id": "51"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n关税缓和背景下，会议认为“主要经济指标表现良好”，强调“保持政策连续性稳定性”。日内瓦会谈后，美国对中国加征关税缓和，支撑了出口，在此带动下，二季度经济运行虽然较一季度小幅放缓，但整体平稳。会议认为“我国经济运行稳中有进”，“主要经济指标表现良好”，对于风险挑战的定调也由4月政治局会议中的“外部冲击影响加大”变为“依然面临不少风险挑战”。因此，政策方面延续了4月政治局会议中提出的“稳就业、稳企业、稳市场、稳预期”，更多强调“保持政策连续性稳定性”和“持续发力”，但也提出“增强灵活性预见性”和“适时加力”，我们认为后者更多是针对经济运行超预期走弱情形下的政策储备。\n\n三季度或聚焦发挥已有政策效力，不排除四季度财政加码的可能性。会议指出，“宏观政策要持续发力、适时加力，要落实落细更加积极的财政政策，充分释放政策效应”，“适时加力”这一表述，或更多是针对经济运行超预期走弱情形下的政策储备。展望三季度，财政政策或聚焦发挥已出台的财政政策工具效力，如加强对政府投资项目的督导，以配合政府债券的加快发行和使用。展望全年，财政收入存在低于预算目标的可能，若四季度经济超预期走弱，或出台增量财政政策，如提前下达明年部分政府债额度或者通过特定机构利润上缴等方式，以补足年内财政收支缺口。\n\n存量债务的风险化解工作持续推进。会议指出要“积极稳妥化解地方政府债务风险，严禁新增隐性债务”，相较4月政治局会议，新增“有力有序有效推进地方融资平台出清”的表述。去年以来，地方政府陆续制定了区域内城投退平台的时间表，伴随着隐性债务的偿还加快，退平台的城投名单也将继续扩围。据财政部统计[2]，2024年的2万亿元置换债券已于今年上半年全部使用完毕，今年的2万亿元置换债券截至6月末已发行1.8万亿元，已使用1.44万亿元。不过城投退平台后需遵循市场化的融资方式，这意味着城投扩表的难度增加，对地方基建的托举相对有限。\n\n降低融资成本未必需要调降政策利率，改革性措施与结构性货币政策工具或为重点。本次政治局会议继续强调“货币政策要保持流动性充裕，促进社会综合融资成本下行”，从最近几个月的货币政策态度来看，降低综合融资成本未必意味着需要继续调降政策利率，《金融时报》在此前的文章《社会融资成本下降成效显著》中提出“目前我国贷款利息成本已经很低，未来降低综合融资成本关键是要降低抵押担保费、中介服务费等非利息成本”[3]。此外，本次政治局会议继续强调“用好各项结构性货币政策工具”，央行对经济运行薄弱环节以及可能遭受冲击的风险环节提供针对性的支持，有可能成为接下来货币政策的重要抓手。\n\n培育服务消费，保障改善民生。会议提出“深入实施提振消费专项行动”，要求“在扩大商品消费的同时，培育服务消费新的增长点”。当前的以旧换新政策侧重于扩大商品消费，而培育发展服务消费在2023年以来的政治局会议中被多次提及。参考以往政策表述，主要指向了体育休闲、文化旅游等文娱休闲领域，以及养老、育幼、家政等基本民生领域。会议还提出“在保障改善民生中扩大消费需求”，民生或成为促消费政策的重要抓手。例如近期出台的育儿补贴制度、推行免费学前教育、向中度以上失能老年人发放养老服务消费补贴等，重点关注“一老一小”，在保民生、促消费的同时，也有助于应对人口结构变化、提高增长潜力。\n\n加力支持科技创新。本次会议指出，要“坚持以科技创新引领新质生产力发展，加快培育具有国际竞争力的新兴支柱产业，推动科技创新和产业创新深度融合发展”，总体延续了此前对新质生产力的表述。我们认为，对科技创新、新质生产力的支持是未来的中长期主线。政治局会议也指出，要用好结构性货币政策工具，“加力支持科技创新”。2025年4月，政治局会议提出要“创新推出债券市场的‘科技板’”。根据人民银行数据，截至2025年5月，已经有将近100家左右的机构在发行科技创新债券，金额超过了2500亿元[4]。除了债券支持工具外，对科技创新的信贷支持也在加大。截至2025年3月末，科技型中小企业贷款余额已超过3.3万亿元，同比增长24%，连续三年增速超过20%[5]。\n\n纵深推进全国统一大市场建设，推动市场竞争秩序持续优化，是理解“反内卷”政策的关键。此前《反不正当竞争法》完成修订，为治理企业的无序竞争提供了法律依据。近日两部委推出《价格法修正草案（征求意见稿）》[6]，明确提出规范市场价格秩序，并加强成本监审。“反内卷”继续沿着市场化、法治化的治理思路推进，光伏、水泥、煤炭和化工等重点行业的产能调控政策后续落地实施，政策效果值得持续观察。在制度层面上，“内卷”的成因既有市场失灵，也表现为部分地方政府行政干预[7]，规范地方招商引资行为，也是完善市场竞争秩序的重要一环。",
    "ori_text": "\n\n关税缓和背景下，会议认为“主要经济指标表现良好”，强调“保持政策连续性稳定性”。日内瓦会谈后，美国对中国加征关税缓和，支撑了出口，在此带动下，二季度经济运行虽然较一季度小幅放缓，但整体平稳。会议认为“我国经济运行稳中有进”，“主要经济指标表现良好”，对于风险挑战的定调也由4月政治局会议中的“外部冲击影响加大”变为“依然面临不少风险挑战”。因此，政策方面延续了4月政治局会议中提出的“稳就业、稳企业、稳市场、稳预期”，更多强调“保持政策连续性稳定性”和“持续发力”，但也提出“增强灵活性预见性”和“适时加力”，我们认为后者更多是针对经济运行超预期走弱情形下的政策储备。\n\n三季度或聚焦发挥已有政策效力，不排除四季度财政加码的可能性。会议指出，“宏观政策要持续发力、适时加力，要落实落细更加积极的财政政策，充分释放政策效应”，“适时加力”这一表述，或更多是针对经济运行超预期走弱情形下的政策储备。展望三季度，财政政策或聚焦发挥已出台的财政政策工具效力，如加强对政府投资项目的督导，以配合政府债券的加快发行和使用。展望全年，财政收入存在低于预算目标的可能，若四季度经济超预期走弱，或出台增量财政政策，如提前下达明年部分政府债额度或者通过特定机构利润上缴等方式，以补足年内财政收支缺口。\n\n存量债务的风险化解工作持续推进。会议指出要“积极稳妥化解地方政府债务风险，严禁新增隐性债务”，相较4月政治局会议，新增“有力有序有效推进地方融资平台出清”的表述。去年以来，地方政府陆续制定了区域内城投退平台的时间表，伴随着隐性债务的偿还加快，退平台的城投名单也将继续扩围。据财政部统计[2]，2024年的2万亿元置换债券已于今年上半年全部使用完毕，今年的2万亿元置换债券截至6月末已发行1.8万亿元，已使用1.44万亿元。不过城投退平台后需遵循市场化的融资方式，这意味着城投扩表的难度增加，对地方基建的托举相对有限。\n\n降低融资成本未必需要调降政策利率，改革性措施与结构性货币政策工具或为重点。本次政治局会议继续强调“货币政策要保持流动性充裕，促进社会综合融资成本下行”，从最近几个月的货币政策态度来看，降低综合融资成本未必意味着需要继续调降政策利率，《金融时报》在此前的文章《社会融资成本下降成效显著》中提出“目前我国贷款利息成本已经很低，未来降低综合融资成本关键是要降低抵押担保费、中介服务费等非利息成本”[3]。此外，本次政治局会议继续强调“用好各项结构性货币政策工具”，央行对经济运行薄弱环节以及可能遭受冲击的风险环节提供针对性的支持，有可能成为接下来货币政策的重要抓手。\n\n培育服务消费，保障改善民生。会议提出“深入实施提振消费专项行动”，要求“在扩大商品消费的同时，培育服务消费新的增长点”。当前的以旧换新政策侧重于扩大商品消费，而培育发展服务消费在2023年以来的政治局会议中被多次提及。参考以往政策表述，主要指向了体育休闲、文化旅游等文娱休闲领域，以及养老、育幼、家政等基本民生领域。会议还提出“在保障改善民生中扩大消费需求”，民生或成为促消费政策的重要抓手。例如近期出台的育儿补贴制度、推行免费学前教育、向中度以上失能老年人发放养老服务消费补贴等，重点关注“一老一小”，在保民生、促消费的同时，也有助于应对人口结构变化、提高增长潜力。\n\n加力支持科技创新。本次会议指出，要“坚持以科技创新引领新质生产力发展，加快培育具有国际竞争力的新兴支柱产业，推动科技创新和产业创新深度融合发展”，总体延续了此前对新质生产力的表述。我们认为，对科技创新、新质生产力的支持是未来的中长期主线。政治局会议也指出，要用好结构性货币政策工具，“加力支持科技创新”。2025年4月，政治局会议提出要“创新推出债券市场的‘科技板’”。根据人民银行数据，截至2025年5月，已经有将近100家左右的机构在发行科技创新债券，金额超过了2500亿元[4]。除了债券支持工具外，对科技创新的信贷支持也在加大。截至2025年3月末，科技型中小企业贷款余额已超过3.3万亿元，同比增长24%，连续三年增速超过20%[5]。\n\n纵深推进全国统一大市场建设，推动市场竞争秩序持续优化，是理解“反内卷”政策的关键。此前《反不正当竞争法》完成修订，为治理企业的无序竞争提供了法律依据。近日两部委推出《价格法修正草案（征求意见稿）》[6]，明确提出规范市场价格秩序，并加强成本监审。“反内卷”继续沿着市场化、法治化的治理思路推进，光伏、水泥、煤炭和化工等重点行业的产能调控政策后续落地实施，政策效果值得持续观察。在制度层面上，“内卷”的成因既有市场失灵，也表现为部分地方政府行政干预[7]，规范地方招商引资行为，也是完善市场竞争秩序的重要一环。",
    "reference_list": "考点1：“关税缓和”推荐译为“easing tariffs”\n考点2：“稳中有进”推荐译为“steady progress\"，\"maintaining stability while making progress”\n考点3：“定调”推荐译为“Set the tone”\n考点4：“预见性”推荐译为“forward-looking”\n考点5：“适时加力”推荐译为“well-timed measures”\n考点6：“财政加码”推荐译为“increase fiscal stimulus”\n考点7：“存量债务”推荐译为“outstanding debt”\n考点8：“地方融资平台出清”推荐译为“clearing of local government financing vehicles”\n考点9：“置换债券”推荐译为“Bond Swap”\n考点10：“社会综合融资成本下行”推荐译为“a decline in overall social financing costs”\n考点11：“提振消费专项行动”推荐译为“special action plan to boost consumption”\n考点12：“科技板”必须译为“Sci-Tech Board ”\n考点13：“全国统一大市场建设”必须译为“construction of a unified national market”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "138"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n一、 互动式电影概述\n（一）互动式电影的概念\n科学技术带动了传播媒介的转换以及影视与游戏形态的变革，互动式电影（Interactive  Movie）是科学技术的不断发展发展产生的一种新型电影形式。互动式电影是传统电影结合不断发展的数字游戏与数字媒体技术所产生的概念，它是相交于传统电影和电子游戏之间的新型领域，相较于电子游戏，互动式电影更加倾向于影像质感与整体叙事；相较于传统电影，游戏大师Chris Crawford认为：“电影并没有交互性。电影以精心构思好的方式进行叙事，而互动叙事则是随着情节的不断发展逐步建立起来的。”[  ChrisCrawford. 游戏大师Chris Crawford谈互动叙事[M]. 人民邮电出版社, 2015.]\n互动式电影让观众拥有更多自由选择的权利，对于观众来说，互动式电影突破了以往的界限，观众不仅仅是观众，观众也成为了叙事的参与者与创造者。与往常观众被动接受内容的传统电影不同，互动式电影在不同的叙事情节点设置不同的个性化选项，观众可以根据自己的意愿从提供的交互选项中选择一个延续剧情的发展，观众的差异化选择会进入不同的故事情节，最后形成多元的结局。\n值得注意的是，观众选择的互动选项不一定是关键情节的关键选择，也有许多日常的交互，比如由2018年由奈飞（Netflix）出品的互动式电影·《黑镜：潘达斯奈基》中主角父亲早上问主角吃什么早餐，主角决定听什么音乐，这些细节都可以由观众个性选择，不同的选择会影响后续的剧情走向与结局。充满创造性和个性化的电影叙事，这是互动式电影带给观众一种崭新的介入性强的观影体验。现代电子游戏注重游戏操作和游戏机制，电子游戏玩家获得成就感的方式是通过自身的游戏操作技术突破一道道游戏关卡最终实现胜利，而互动式电影更注重的是通过交互机制增强故事的表现力，它没有获得胜利的条件也没有方向和路线，无论观众如何选择都不会导致失败，最终的结局都是由观众根据自身的意愿选择产生，都是拥有闭环叙事的结局。\n\n黑镜：潘达斯奈基\n（二）互动式电影的发展现状\n一部63分钟的捷克短片叫做《一个男人与他的房子》于1967年出现在蒙特利尔世博会上，惊动了当时整个电影界，这是世界上第一部互动式电影，当时电影的播放渠道主要集中在影院放映，配备按钮和互动设备的高额成本和技术限制让影院望而却步，很快互动式电影便陷入沉寂之中。\n随着科学技术的发展，电子计算机，电子移动设备的大量使用以及互联网的不断发展，人类进入了数字媒介时代，随着3D图形技术的逐渐成熟，电子游戏电影化形成的交互式电影游戏崭露头角，在2010年，游戏制作人大卫·凯奇的作品《暴雨》  打破了互动式电影游戏的沉寂。\n超凡双生\n二、互动式电影跨媒介叙事方式的探究\n（一）超叙事互动：网状及分支叙事模式\n传统的电影叙事是导演对电影情节整体安排下的一次线性叙事，因为这种叙事单线输出于观众的。我们不难发现其实传统电影中的所有线索往往都涵盖在一个固定的框架中，犹如交错的道路，导演只设置一条路线所通往的地点，可能线索伴随着时间或是空间进行线性推动。“超叙事互动”\n 这种多选择，多路线的网状及分支叙事模式是互动式电影最大特点之一，观众的每一次选择都在原有的故事情节上建立了新平行时空，互动者在现实世界中思考和抉择，互动者的每一个选择都会影响虚拟世界的剧情走向，从而推进故事的发展。如互动式电影《夜班》。\n\n\n（二）开放式叙事：被弱化的间离效应\n传统电影中观众观看电影的元素包括：剧情，画面，演员表演，特效动画，都是由电影导演与编剧们创造的一个“囚笼”，观众们从电影开始到结束始终困在这个盒子里，无论电影如何演绎都无法突破这个“囚笼”，这是传统电影的“封闭叙事”属性。而互动式电影通过融合电子游戏的交互模式让观众拥有了打破“囚笼”的能力，观众拥有了书写文本的能力，打破了创作者们打造的囚笼，“开放叙事”由此产生。\n上文提及的《一个男人与他的房子》需要观众选择红绿按钮来决定不同的电影剧情走向。观众们在观影时不同的选择给与了观众们新奇感，但完成所有的选择后影片的结局却又让观众们食而无味，观众以为自己选择的不同按钮能够给电影带来不同的结局走向，但是他们的选择毫无意义，无论如何选择那个按钮走那条剧情线，影片的结局最终也只有一个，直到最后观众们还是被导演玩弄于股掌之中。通过这个例子我们不难发现其实最早的互动式电影中还是无法脱离传统电影的线性叙事思路，即所有线索往往都涵盖在一个固定的框架中，犹如交错的道路。\n导演预先设置一个所有道路所通往的终点，观众则通过自身思考，选择不同的道路。观众设想的每一条道路都可以使整个观影过程完整。但是观众面对的剧情选择往往情感上仍有缺失，因为导演可以设定路线但不能对每一位观众面对的结局进行优化，线性电影的结局往往是封闭的，唯一的，一部分原因归结于当时电影的时长和容量限制了这种需求的达成。如今随着互联网与新媒体技术的发展，互动式电影真正让观众参与了叙事，实现了影游在叙事上的融合。观众真正加入叙事，并可以按照自身的意志对叙事进行创作，此时不同方向的开展路线拥有了不同的结局，传统的封闭式结构由此发生了改变。如互动式电影《深海》共有2条主要故事线，15条支线，将近60个交互点，高达25个结局；《黑镜：潘达斯奈基》主副线约5个小时，30多个交互点相互排列组合最终会产生5个各不相同的方向的15个结局；《夜班》整部电影更拥有高达180个可以选择的交互按钮，7个不同的结局。面对以往观众对传统电影唯一结局的情感缺失，互动式电影给予了观众重新再来的契机，错误可以被改正，惋惜的瞬间可以被重现。\n现阶段互动式电影的开放式叙事更多的是对叙事文本的不确定性进行填充，可进行的交互选择往往还是在一定的范围之内，但已经产生了观众对叙事文本的能动性参与，弱化了间离效果。间离化效果是由戏剧家布莱希特提出的戏剧表演艺术的代表性观点，在电影艺术中普遍得到应用,它主要表现为利用旁白、标语、歌唱等形式提醒观众当前的故事为虚构而不是真实，并通过客观视角或第三人称视角对叙事进行修改和更正。[ 贝・布莱希特. 布莱希特论戏剧[M]. 中国戏剧出版社, 1990.]由于互动式电影更注重沉浸感和主体的情感体验，在互动式电影中制作者往往就会弱化间离效果，通过设置交互界面增强观众的沉浸感体验。为了达到间离效果的目的，互动式电影往往采用分章节分段落的方式让观众逐渐了解电影的世界观和虚构的故事框架，最终完成对故事叙事的认知，形成开放式叙事。\n",
    "ori_text": "一、 互动式电影概述\n（一）互动式电影的概念\n科学技术带动了传播媒介的转换以及影视与游戏形态的变革，互动式电影（Interactive  Movie）是科学技术的不断发展发展产生的一种新型电影形式。互动式电影是传统电影结合不断发展的数字游戏与数字媒体技术所产生的概念，它是相交于传统电影和电子游戏之间的新型领域，相较于电子游戏，互动式电影更加倾向于影像质感与整体叙事；相较于传统电影，游戏大师Chris Crawford认为：“电影并没有交互性。电影以精心构思好的方式进行叙事，而互动叙事则是随着情节的不断发展逐步建立起来的。”[  ChrisCrawford. 游戏大师Chris Crawford谈互动叙事[M]. 人民邮电出版社, 2015.]\n互动式电影让观众拥有更多自由选择的权利，对于观众来说，互动式电影突破了以往的界限，观众不仅仅是观众，观众也成为了叙事的参与者与创造者。与往常观众被动接受内容的传统电影不同，互动式电影在不同的叙事情节点设置不同的个性化选项，观众可以根据自己的意愿从提供的交互选项中选择一个延续剧情的发展，观众的差异化选择会进入不同的故事情节，最后形成多元的结局。\n值得注意的是，观众选择的互动选项不一定是关键情节的关键选择，也有许多日常的交互，比如由2018年由奈飞（Netflix）出品的互动式电影·《黑镜：潘达斯奈基》中主角父亲早上问主角吃什么早餐，主角决定听什么音乐，这些细节都可以由观众个性选择，不同的选择会影响后续的剧情走向与结局。充满创造性和个性化的电影叙事，这是互动式电影带给观众一种崭新的介入性强的观影体验。现代电子游戏注重游戏操作和游戏机制，电子游戏玩家获得成就感的方式是通过自身的游戏操作技术突破一道道游戏关卡最终实现胜利，而互动式电影更注重的是通过交互机制增强故事的表现力，它没有获得胜利的条件也没有方向和路线，无论观众如何选择都不会导致失败，最终的结局都是由观众根据自身的意愿选择产生，都是拥有闭环叙事的结局。\n\n黑镜：潘达斯奈基\n（二）互动式电影的发展现状\n一部63分钟的捷克短片叫做《一个男人与他的房子》于1967年出现在蒙特利尔世博会上，惊动了当时整个电影界，这是世界上第一部互动式电影，当时电影的播放渠道主要集中在影院放映，配备按钮和互动设备的高额成本和技术限制让影院望而却步，很快互动式电影便陷入沉寂之中。\n随着科学技术的发展，电子计算机，电子移动设备的大量使用以及互联网的不断发展，人类进入了数字媒介时代，随着3D图形技术的逐渐成熟，电子游戏电影化形成的交互式电影游戏崭露头角，在2010年，游戏制作人大卫·凯奇的作品《暴雨》  打破了互动式电影游戏的沉寂。\n超凡双生\n二、互动式电影跨媒介叙事方式的探究\n（一）超叙事互动：网状及分支叙事模式\n传统的电影叙事是导演对电影情节整体安排下的一次线性叙事，因为这种叙事单线输出于观众的。我们不难发现其实传统电影中的所有线索往往都涵盖在一个固定的框架中，犹如交错的道路，导演只设置一条路线所通往的地点，可能线索伴随着时间或是空间进行线性推动。“超叙事互动”\n 这种多选择，多路线的网状及分支叙事模式是互动式电影最大特点之一，观众的每一次选择都在原有的故事情节上建立了新平行时空，互动者在现实世界中思考和抉择，互动者的每一个选择都会影响虚拟世界的剧情走向，从而推进故事的发展。如互动式电影《夜班》。\n\n\n（二）开放式叙事：被弱化的间离效应\n传统电影中观众观看电影的元素包括：剧情，画面，演员表演，特效动画，都是由电影导演与编剧们创造的一个“囚笼”，观众们从电影开始到结束始终困在这个盒子里，无论电影如何演绎都无法突破这个“囚笼”，这是传统电影的“封闭叙事”属性。而互动式电影通过融合电子游戏的交互模式让观众拥有了打破“囚笼”的能力，观众拥有了书写文本的能力，打破了创作者们打造的囚笼，“开放叙事”由此产生。\n上文提及的《一个男人与他的房子》需要观众选择红绿按钮来决定不同的电影剧情走向。观众们在观影时不同的选择给与了观众们新奇感，但完成所有的选择后影片的结局却又让观众们食而无味，观众以为自己选择的不同按钮能够给电影带来不同的结局走向，但是他们的选择毫无意义，无论如何选择那个按钮走那条剧情线，影片的结局最终也只有一个，直到最后观众们还是被导演玩弄于股掌之中。通过这个例子我们不难发现其实最早的互动式电影中还是无法脱离传统电影的线性叙事思路，即所有线索往往都涵盖在一个固定的框架中，犹如交错的道路。\n导演预先设置一个所有道路所通往的终点，观众则通过自身思考，选择不同的道路。观众设想的每一条道路都可以使整个观影过程完整。但是观众面对的剧情选择往往情感上仍有缺失，因为导演可以设定路线但不能对每一位观众面对的结局进行优化，线性电影的结局往往是封闭的，唯一的，一部分原因归结于当时电影的时长和容量限制了这种需求的达成。如今随着互联网与新媒体技术的发展，互动式电影真正让观众参与了叙事，实现了影游在叙事上的融合。观众真正加入叙事，并可以按照自身的意志对叙事进行创作，此时不同方向的开展路线拥有了不同的结局，传统的封闭式结构由此发生了改变。如互动式电影《深海》共有2条主要故事线，15条支线，将近60个交互点，高达25个结局；《黑镜：潘达斯奈基》主副线约5个小时，30多个交互点相互排列组合最终会产生5个各不相同的方向的15个结局；《夜班》整部电影更拥有高达180个可以选择的交互按钮，7个不同的结局。面对以往观众对传统电影唯一结局的情感缺失，互动式电影给予了观众重新再来的契机，错误可以被改正，惋惜的瞬间可以被重现。\n现阶段互动式电影的开放式叙事更多的是对叙事文本的不确定性进行填充，可进行的交互选择往往还是在一定的范围之内，但已经产生了观众对叙事文本的能动性参与，弱化了间离效果。间离化效果是由戏剧家布莱希特提出的戏剧表演艺术的代表性观点，在电影艺术中普遍得到应用,它主要表现为利用旁白、标语、歌唱等形式提醒观众当前的故事为虚构而不是真实，并通过客观视角或第三人称视角对叙事进行修改和更正。[ 贝・布莱希特. 布莱希特论戏剧[M]. 中国戏剧出版社, 1990.]由于互动式电影更注重沉浸感和主体的情感体验，在互动式电影中制作者往往就会弱化间离效果，通过设置交互界面增强观众的沉浸感体验。为了达到间离效果的目的，互动式电影往往采用分章节分段落的方式让观众逐渐了解电影的世界观和虚构的故事框架，最终完成对故事叙事的认知，形成开放式叙事。\n",
    "reference_list": "1. “成就感”不可译为“achieve satisfaction”，推荐译为sense of achievement\n2. “结局走向”不可译为“ending directions”，推荐译为“endings”或“outcomes”\n3. “介入性”推荐译为“highly participatory”或“highly interactive”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "193"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n Representations, Warranties and Undertakings\nParty A hereby represents and warrants to Party B as follows:a) Party A is a company duly organized, validly existing and in good standing as a legal person under the laws of the PRC.b) Party A has full legal right, power and authority to execute and deliver this Contract and all of the contracts and documents referred to in this Contract to which Party A is a party and to observe and perform its obligations hereunder and thereunder.\nc)Party A has taken all appropriate and necessary corporate actions to authorize the execution and delivery of this Contract and all of the contracts and documents referred to in this Contract to which Party A is a party and to authorize the performance and observance of the terms and conditions hereof and thereof.\nd) Party A has obtained all consents, approvals and authorizations necessaryfor the valid execution and delivery of this Contract and all of the contractsand documents referred to in this Contract to which Party B is a party,provided, however, that this Contract is subject to the approval of the Examination and Approval Authority before the same may become effective.\nThe Vendor represents, warrants and undertakes to and with the Purchaserthat each ofthe statements set out in Schedule A is now and shall at all timesbetween the date hereof and Completion (both dates inclusive) be true andaccurate. The Vendor acknowledges that the Purchaser has entered into thisAgreement in reliance upon the Warranties and has been induced by them toenter into this Agreement.\nParty A represents and warrants that there are no conditions at, on, underor related to, the real property constituting all or any portion of the Landwhich presently or potentially pose a hazard to human health or theenvironment, whether or not in compliance with law, and there has been nomanufacture, use, treatment, storage, transportation, or disposal of any\nhazardous or toxic substance, pollutant, or contaminant on the Land nor anyrelease of any hazardous or toxic substance, pollutant, or contaminant intoor upon or over the Land.\nParty A further represents and warrants that the Land is free and clear of anyand all claims, charges, easement, encumbrances, lease, covenants, securityinterest, liens, option, pledge, rights of others, or restrictions, whetherimposed by agreement, understanding, law, equity or otherwise.\nParty A warrants, agrees and undertakes to Party B that neither Party A(whether directly or indirectly) nor any Connected Person (whether individually or jointly) shall, during the term of this Agreement, and for two(2)years after the expiry or termination of this Agreement:a)undertake any business which is in direct competition with the business ofParty B without the written consent issued by the legal representative ofParty B;\nb) solicit or entice away any customer, employee, director or supplier ofParty B for whatever reason; and\nc)produce any products which is identical or similar in composition or appearance to any of the Products without the prior consent of Party B.For the purposes of this Article 4:\n\"Connected Person\" means any or all of the following persons: (i) the parent company or shareholders holding 50% or more of the equity of Party A; (ii)any corporation or business that is affiliated with Party A; or (iii) any officer employee, independent contractor, partner, joint venturer or agent of Party A or of any business affiliated with Party A; or (iv) any firm or corporation in which Party A or its parent company or affiliate company has an interest whether such interest is legally enforceable or not.5.The express warranties in this Agreement shall be in lieu of all other warranties, express or implied, including the implied warranties of interoperability, and fitness for a particular purpose.merchant ability, non-infringement, \nResponsibilities and Obligations\nParty A shall exercise, and ensure that all its servants, employees, agents or contractors exercise, all due diligence and care in the performance of the Services and each of the responsibilities so described. Specifically, andwithout limiting the generality of the foregoing, Party A shall bear allresponsibility for any losses or damages suffered by Party B as a result ofany mistakes, errors or omissions caused by Party A in connection with theprocessing and packing of the Products.\nThe Company appreciates that whilst the Sponsor will use its reasonableendeavors to discharge its duties as sponsor to the Company and provide theCompany with advice and assistance as described above, it remains theprimary responsibility of the directors of the Company to ensure that theCompany will comply in full with and discharge its responsibili-ties underthe Growth Enterprise Market (\"GEM\")Listing Rules and other relevantlaws and regulations applicable to the Company. Save as describedhereunder, the Sponsor does not have any duty to monitor or otherwise toensure that the Company is in continuous compliance with the GEM ListingRules and other relevant laws and regulations applicable to the Company.\n3.It is understood and agreed that each of the parties hereto is anindependent contractor and that neither party is, nor shall be considered tobe, an agent, distributor, fiduciary or representative of the other. Neitherparty shall act or represent itself, directly or by implication, as an agent ofthe other or in any manner assume or create any obligation on behalf of, orin the name of, the other.\nResponsibilities of Party A:\nIn addition to its other obligations under this Contract, Party A shall, from time to time throughout the period of the Joint Venture term, be responsible.\nat no cost to the JVC (excepted as provided in Section X or as mayotherwise be agreed by the JVC in writing), for the following:\na) to use best efforts to apply and take all actions necessary or appropriateon behalf of the JVC to obtain the necessary approvals, permits, certificatesand licenses for the establishment and operation ofthe JVC, and use the bestefforts to do, fulfill and perform any and all acts, conditions and thingsrequired to ensure the continuing validity and effectiveness of suchapprovals, permits, certificates and licenses;b)to assist the JVC in applying for, obtaining and maintaining tax(including without limitation income tax, tariffs, customs duties, excisetaxes, business tax, and value-added tax)reductions and exemptions andother investment incentives that may be available to the JVC;\nc)to assist the JVC in applying for, obtaining and maintaining specialbusiness opportunities, relationships or qualifications relating to or madeavailable by any gov-ernment departments or agencies, including withoutlimitation tax-advantaged import quotas, subsidies for purchase of local rawmaterials, and special toll processing or government supply contracts;d) to assist the JVC in obtaining water and power supplies, transportationand communications services and facilities, and use best efforts to obtain foithe JVC utility rates and quotas and other rights under the most favorableterms and conditions available to the JVC, and to liaise with the relevantauthorities effectively to achieve all ofthe above;\ne)to assist the directors and employees of the JVC and any employees ofParty B and the JVC's foreign contractors and consultants traveling to Chinain connection with the JVC's activities to obtain all necessary entry visaswork permits and residence permits;\nf)(f) to assist the JVC in preparing and presenting customs declarationshandling clearing procedures for machinery and equipment purchased orleased outside China by the JVC, applying for all available exemptions fromcustoms duty, value added tax, sales tax or other charges, and arranging fortransportation of the same within China;.\ng)to assist the JVC in obtaining loans and other credit facilities fromChinese banks or other financial institutions at the most favorable rates andterms available; and\nh) to handle other matters entrusted to it by the JVC.\nSeverability and Waiver\nIf any one or more of the provisions contained in this Agreement or anydocument executed in connection herewith shall .; be invalid, illegal, orunenforceable in any respect under any applicable law,(i) the validity.legality and enforce-j ability of the remaining provisions contained hereinor c therein shall not in any way be affected or impaired and shall remainin full force and effect; and (ii) the invalid, illegal or unenforceableprovision shall be replaced by a valid, legal and enforceable provision thatcomes closest to expressing the true intent of such invalid, illegal orunenforceable provision.\nIf any of the provisions ofthis Agreement is held invalid or unenforceableand unless the invalidity or unenforceability thereof does substantialviolation to the underlying intent \\- and sense of the remainder of thisAgreement, such invalidity or unenforceability shall not affect in any waythe validity and enforceability of any other provisions of this Agreementexcept those which the invalidated or unenforceable provisions comprise anintegral part of or are otherwise clearly inseparable from. That invalidity or unenforceability shall not affect any valid and enforceable application of the remaining provisions, and each such provision shall be deemed to beeffective, operative, made, or entered into in the manner and to the full extent permitted by law.\nAny provision of this Deed prohibited by or which is unlawful orunenforceable under any applicable law actually applied by any court ofcompetent jurisdiction shall, to the extent required by such law, be severecfrom this Deed and rendered ineffective so far as is possible withoutmodifying the remaining provisions of this Deed. Where, however, theprovisions of any such applicable law may be waived, they are herebywaived by the parties hereto to the full extent permitted by such law to theend that this Deed shall be valid, binding and enforceable in accordancewith its terms.\nUnless otherwise provided for herein, failure or delay on the part of anyparty to exercise any right, power or privilege under this Agreement shallnot operate as a waiver thereof, nor shall any single or partial exercise ofany right, power or privilege preclude further exercise thereof or exercise ofany other right, power or privilege. A waiver by one of the parties at anytime of a breach of any term or provision of this Agreement committed bythe other party shall not be construed as a waiver by such party of anysubsequent breach to be committed by the other party, nor shall it beconstrued as a waiver by such party of its rights under such provision or anyof its other rights under this Agreement.\nThe failure of either party at any time or times to require performance ofany provision hereof shall in no manner affect its right at a later time toenforce the same. No waiver by either party of any condition or any breach of any of the terms, covenants or conditions contained in this Agreement shall be effective unless in writing, and no waiver in any one or more instances shall be construed as a further or continuing waiver of any other condition or any breach of any other terms, covenants or conditions.6. The Parties recognize and agree that their respective covenants andundertakings contained in this Agreement are of a special and unique natureand that a breach will result in irreparable injury for which there is noadequate remedy at law, and therefore the parties expressly agree that ifeither party shall at any time breach or in any way violate this Agreement.then Party A or Party B, as the case may be, shall be entitled to equitablerelief by way of injunction (in addition to, and not in substitution for, anyand all other relief to which such party may be entitled either at law or inequity) to restrain such breach and to compel compliance with theobligations undertaken. Each of the parties do hereby waive any proof that such breach will cause irreparable injury to such party or that there is no adequate remedy at law.\n\n\n",
    "ori_text": "\n\n Representations, Warranties and Undertakings\nParty A hereby represents and warrants to Party B as follows:a) Party A is a company duly organized, validly existing and in good standing as a legal person under the laws of the PRC.b) Party A has full legal right, power and authority to execute and deliver this Contract and all of the contracts and documents referred to in this Contract to which Party A is a party and to observe and perform its obligations hereunder and thereunder.\nc)Party A has taken all appropriate and necessary corporate actions to authorize the execution and delivery of this Contract and all of the contracts and documents referred to in this Contract to which Party A is a party and to authorize the performance and observance of the terms and conditions hereof and thereof.\nd) Party A has obtained all consents, approvals and authorizations necessaryfor the valid execution and delivery of this Contract and all of the contractsand documents referred to in this Contract to which Party B is a party,provided, however, that this Contract is subject to the approval of the Examination and Approval Authority before the same may become effective.\nThe Vendor represents, warrants and undertakes to and with the Purchaserthat each ofthe statements set out in Schedule A is now and shall at all timesbetween the date hereof and Completion (both dates inclusive) be true andaccurate. The Vendor acknowledges that the Purchaser has entered into thisAgreement in reliance upon the Warranties and has been induced by them toenter into this Agreement.\nParty A represents and warrants that there are no conditions at, on, underor related to, the real property constituting all or any portion of the Landwhich presently or potentially pose a hazard to human health or theenvironment, whether or not in compliance with law, and there has been nomanufacture, use, treatment, storage, transportation, or disposal of any\nhazardous or toxic substance, pollutant, or contaminant on the Land nor anyrelease of any hazardous or toxic substance, pollutant, or contaminant intoor upon or over the Land.\nParty A further represents and warrants that the Land is free and clear of anyand all claims, charges, easement, encumbrances, lease, covenants, securityinterest, liens, option, pledge, rights of others, or restrictions, whetherimposed by agreement, understanding, law, equity or otherwise.\nParty A warrants, agrees and undertakes to Party B that neither Party A(whether directly or indirectly) nor any Connected Person (whether individually or jointly) shall, during the term of this Agreement, and for two(2)years after the expiry or termination of this Agreement:a)undertake any business which is in direct competition with the business ofParty B without the written consent issued by the legal representative ofParty B;\nb) solicit or entice away any customer, employee, director or supplier ofParty B for whatever reason; and\nc)produce any products which is identical or similar in composition or appearance to any of the Products without the prior consent of Party B.For the purposes of this Article 4:\n\"Connected Person\" means any or all of the following persons: (i) the parent company or shareholders holding 50% or more of the equity of Party A; (ii)any corporation or business that is affiliated with Party A; or (iii) any officer employee, independent contractor, partner, joint venturer or agent of Party A or of any business affiliated with Party A; or (iv) any firm or corporation in which Party A or its parent company or affiliate company has an interest whether such interest is legally enforceable or not.5.The express warranties in this Agreement shall be in lieu of all other warranties, express or implied, including the implied warranties of interoperability, and fitness for a particular purpose.merchant ability, non-infringement, \nResponsibilities and Obligations\nParty A shall exercise, and ensure that all its servants, employees, agents or contractors exercise, all due diligence and care in the performance of the Services and each of the responsibilities so described. Specifically, andwithout limiting the generality of the foregoing, Party A shall bear allresponsibility for any losses or damages suffered by Party B as a result ofany mistakes, errors or omissions caused by Party A in connection with theprocessing and packing of the Products.\nThe Company appreciates that whilst the Sponsor will use its reasonableendeavors to discharge its duties as sponsor to the Company and provide theCompany with advice and assistance as described above, it remains theprimary responsibility of the directors of the Company to ensure that theCompany will comply in full with and discharge its responsibili-ties underthe Growth Enterprise Market (\"GEM\")Listing Rules and other relevantlaws and regulations applicable to the Company. Save as describedhereunder, the Sponsor does not have any duty to monitor or otherwise toensure that the Company is in continuous compliance with the GEM ListingRules and other relevant laws and regulations applicable to the Company.\n3.It is understood and agreed that each of the parties hereto is anindependent contractor and that neither party is, nor shall be considered tobe, an agent, distributor, fiduciary or representative of the other. Neitherparty shall act or represent itself, directly or by implication, as an agent ofthe other or in any manner assume or create any obligation on behalf of, orin the name of, the other.\nResponsibilities of Party A:\nIn addition to its other obligations under this Contract, Party A shall, from time to time throughout the period of the Joint Venture term, be responsible.\nat no cost to the JVC (excepted as provided in Section X or as mayotherwise be agreed by the JVC in writing), for the following:\na) to use best efforts to apply and take all actions necessary or appropriateon behalf of the JVC to obtain the necessary approvals, permits, certificatesand licenses for the establishment and operation ofthe JVC, and use the bestefforts to do, fulfill and perform any and all acts, conditions and thingsrequired to ensure the continuing validity and effectiveness of suchapprovals, permits, certificates and licenses;b)to assist the JVC in applying for, obtaining and maintaining tax(including without limitation income tax, tariffs, customs duties, excisetaxes, business tax, and value-added tax)reductions and exemptions andother investment incentives that may be available to the JVC;\nc)to assist the JVC in applying for, obtaining and maintaining specialbusiness opportunities, relationships or qualifications relating to or madeavailable by any gov-ernment departments or agencies, including withoutlimitation tax-advantaged import quotas, subsidies for purchase of local rawmaterials, and special toll processing or government supply contracts;d) to assist the JVC in obtaining water and power supplies, transportationand communications services and facilities, and use best efforts to obtain foithe JVC utility rates and quotas and other rights under the most favorableterms and conditions available to the JVC, and to liaise with the relevantauthorities effectively to achieve all ofthe above;\ne)to assist the directors and employees of the JVC and any employees ofParty B and the JVC's foreign contractors and consultants traveling to Chinain connection with the JVC's activities to obtain all necessary entry visaswork permits and residence permits;\nf)(f) to assist the JVC in preparing and presenting customs declarationshandling clearing procedures for machinery and equipment purchased orleased outside China by the JVC, applying for all available exemptions fromcustoms duty, value added tax, sales tax or other charges, and arranging fortransportation of the same within China;.\ng)to assist the JVC in obtaining loans and other credit facilities fromChinese banks or other financial institutions at the most favorable rates andterms available; and\nh) to handle other matters entrusted to it by the JVC.\nSeverability and Waiver\nIf any one or more of the provisions contained in this Agreement or anydocument executed in connection herewith shall .; be invalid, illegal, orunenforceable in any respect under any applicable law,(i) the validity.legality and enforce-j ability of the remaining provisions contained hereinor c therein shall not in any way be affected or impaired and shall remainin full force and effect; and (ii) the invalid, illegal or unenforceableprovision shall be replaced by a valid, legal and enforceable provision thatcomes closest to expressing the true intent of such invalid, illegal orunenforceable provision.\nIf any of the provisions ofthis Agreement is held invalid or unenforceableand unless the invalidity or unenforceability thereof does substantialviolation to the underlying intent \\- and sense of the remainder of thisAgreement, such invalidity or unenforceability shall not affect in any waythe validity and enforceability of any other provisions of this Agreementexcept those which the invalidated or unenforceable provisions comprise anintegral part of or are otherwise clearly inseparable from. That invalidity or unenforceability shall not affect any valid and enforceable application of the remaining provisions, and each such provision shall be deemed to beeffective, operative, made, or entered into in the manner and to the full extent permitted by law.\nAny provision of this Deed prohibited by or which is unlawful orunenforceable under any applicable law actually applied by any court ofcompetent jurisdiction shall, to the extent required by such law, be severecfrom this Deed and rendered ineffective so far as is possible withoutmodifying the remaining provisions of this Deed. Where, however, theprovisions of any such applicable law may be waived, they are herebywaived by the parties hereto to the full extent permitted by such law to theend that this Deed shall be valid, binding and enforceable in accordancewith its terms.\nUnless otherwise provided for herein, failure or delay on the part of anyparty to exercise any right, power or privilege under this Agreement shallnot operate as a waiver thereof, nor shall any single or partial exercise ofany right, power or privilege preclude further exercise thereof or exercise ofany other right, power or privilege. A waiver by one of the parties at anytime of a breach of any term or provision of this Agreement committed bythe other party shall not be construed as a waiver by such party of anysubsequent breach to be committed by the other party, nor shall it beconstrued as a waiver by such party of its rights under such provision or anyof its other rights under this Agreement.\nThe failure of either party at any time or times to require performance ofany provision hereof shall in no manner affect its right at a later time toenforce the same. No waiver by either party of any condition or any breach of any of the terms, covenants or conditions contained in this Agreement shall be effective unless in writing, and no waiver in any one or more instances shall be construed as a further or continuing waiver of any other condition or any breach of any other terms, covenants or conditions.6. The Parties recognize and agree that their respective covenants andundertakings contained in this Agreement are of a special and unique natureand that a breach will result in irreparable injury for which there is noadequate remedy at law, and therefore the parties expressly agree that ifeither party shall at any time breach or in any way violate this Agreement.then Party A or Party B, as the case may be, shall be entitled to equitablerelief by way of injunction (in addition to, and not in substitution for, anyand all other relief to which such party may be entitled either at law or inequity) to restrain such breach and to compel compliance with theobligations undertaken. Each of the parties do hereby waive any proof that such breach will cause irreparable injury to such party or that there is no adequate remedy at law.\n\n\n",
    "reference_list": "考点1：“duly organized, validly existing and in good standing”应整体视为法律惯用表达，推荐译为“依法设立、有效存续且资格完备”。\n考点2：“observe and perform”常见于合同义务条款中，推荐译为“遵守并履行”，前者偏规范性、后者偏操作性。\n考点3：“solicit or entice away”意群应理解为“招揽或诱使……离开”，勿拆译为“请求”或“诱惑”。\n考点4：“hazardous or toxic substance, pollutant, or contaminant”为环境法术语，“contaminant\"应译为“致污物”。\n考点5：“equitable relief by way of injunction”中“injunction”应译为“禁令”。\n考点6:   “servant”在此语境中推荐译为“服务人员”，不可译为“仆人”\n考点7:   “understanding”在此语境中应译为“谅解”，属于法律文件中的固定翻译，不可译为“理解”\n考点8:   “charges”作为法律术语时，常指财产上的担保设定，这里应译为“担保”，不可译为“费用”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "166"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nIn recent years, with the rapid development of technologies such as artificial intelligence (AI), the Internet of Things (IoT), and 5G communication, a new wave of information technology revolution has emerged. AI technology, serving as the \"central brain\" that powers smart manufacturing, smart cities, and the metaverse, plays a pivotal role in the digital era. It is widely acknowledged that algorithms, data, and computational power (chips) are the three core elements driving AI development, with chips forming the foundation for the practical implementation of AI.\nAs research on large models such as ChatGPT and GPT-4 continues to progress, model structures are becoming increasingly complex, and the demand for data and computational resources is growing exponentially. Simultaneously, the gradual diminishing of Moore’s Law has slowed the evolution of chip manufacturing processes. The disparity between algorithm development and hardware advancement poses a significant challenge: how to efficiently process massive datasets using complex algorithms has become a pressing issue in the AI domain.\nThe root cause of this challenge lies in the limitations of chips, which are currently constrained by the \"von Neumann architecture bottleneck.\" In von Neumann architecture, data storage and processing are separated, and data is transferred between memory and processors through buses. Frequent data transfers incur substantial time and energy costs, leading to what is termed the \"memory wall\" and the \"power wall.\" Moreover, as device sizes approach physical limits, the traditional approach of improving chip performance solely through process advancements faces increasing obstacles, resulting in the so-called \"process wall.\"\nTo address these challenges, academia and industry worldwide have conducted extensive research from multiple dimensions, including architecture, process, and integration, to explore new-generation chip technologies for the post-Moore era. For instance, dataflow architecture chips enable streaming computation, achieving significantly higher throughput than von Neumann architecture for large-scale AI data processing; reconfigurable chips provide high flexibility and energy-efficient computation through software-defined hardware circuit structures; wafer-scale chips expand chip area using advanced process technologies to enhance computational power; and 3D chips stack multiple chips vertically using 3D integration packaging technology to achieve high bandwidth and computational power. Among these, in-memory computing chips stand out by integrating storage and computation through collaborative innovation across devices, architectures, circuits, and processes, fundamentally overcoming the von Neumann architecture bottleneck.\nIn-memory computing chips have architectural features that significantly reduce data transfer overhead, addressing the \"memory wall\" and \"power wall.\" Additionally, their highly parallel computing capabilities enable performance comparable to that of advanced processes, even with relatively mature process nodes, thereby alleviating the pressure of process miniaturization. Furthermore, in-memory computing technology seamlessly integrates with other advanced technologies, such as reconfigurable chips, wafer-scale chips, and 3D integration, making it one of the most promising directions in post-Moore era chip technology.\nThe concept of in-memory computing can be traced back to the 1970s when Kautz from the Stanford Research Institute first proposed the idea. The core principle is to perform computation directly within memory, reducing the overhead of data transfer between memory and processors. Subsequent research has focused on chip circuit structures, computational architectures, and system applications. However, due to the complexity of circuit design and the difficulty of implementation, most of the early research effectively realized \"near-memory computing.\" The main distinction between near-memory and in-memory computing is that the former still requires data to be read out of memory for computation, with the results then stored back into memory. Current industry-standard solutions for near-memory computing include techniques such as 3D packaging and high-bandwidth memory (HBM) to shorten the distance between memory and processors and increase data bandwidth. These technologies are relatively mature and have been scaled into mass production.\nLeading semiconductor companies such as AMD, Intel, Samsung, and SK Hynix have introduced near-memory computing chips based on HBM and 2.5D/3D packaging technologies. For example, Samsung’s latest HBM3 Icebolt technology employs a near-memory computing architecture, utilizing 12 layers of 10nm-class dynamic random-access memory (DRAM) to achieve processing speeds of up to 6.4 Gbps and bandwidths of up to 819 GB/s.\nHowever, near-memory computing still adheres to the von Neumann architecture, which fundamentally separates storage and computation. While it reduces data transfer overhead to some extent, it cannot entirely eliminate the von Neumann bottleneck. In recent years, in-memory computing architectures that integrate storage and computation into a unified framework have become a hotspot in academia and industry.\nIn-memory computing chips can be broadly categorized into analog and digital paradigms:\n1.\tAnalog in-memory computing: Signals within or near the storage array are processed as analog signals. Operations such as matrix multiplications leverage the intrinsic physical behavior of the storage array, often relying on digital-to-analog and analog-to-digital converters for signal conversion. Analog computation typically utilizes Ohm’s law and Kirchhoff’s law to achieve high energy efficiency but may suffer from lower precision and reliability.\n2.\tDigital in-memory computing: Signals within or near the storage array are processed as digital signals, typically using techniques like adder trees and shifters. Digital in-memory computing achieves arbitrary precision but has relatively lower energy efficiency and higher cost per unit area.\nResearch on in-memory computing chips spans various storage media. Chips based on traditional media like SRAM and NOR Flash are relatively mature and have entered small-scale production. Meanwhile, chips leveraging emerging non-volatile storage media, such as magnetic random-access memory (MRAM), resistive random-access memory (RRAM), phase-change random-access memory (PCRAM), and ferroelectric field-effect transistors (FeFET), are transitioning from foundational research to industrialization. Research institutions and companies from the United States, China, and South Korea have made significant advances in this field, with notable contributions from IBM, Stanford University, Princeton University, SK Hynix, Samsung, Tsinghua University, Peking University, and the Chinese Academy of Sciences Institute of Microelectronics.\nDespite these advancements, effective chip design relies heavily on EDA (Electronic Design Automation) tools, which remain in the early stages for in-memory computing. Current academic efforts have produced simple single-point tools for simulation modeling and automated synthesis, but no comprehensive EDA tool platform akin to those for digital circuit design has been established, making it challenging to support large-scale automated design of in-memory computing chips.\nCurrent research on in-memory computing chips is primarily focused on single-point technologies, with many technical challenges remaining in areas such as devices, circuits, architectures, EDA tools, and system applications. The future development of in-memory computing chips is expected to focus on the following four trends:\n1.\tShifting Toward the Perception End for Ultra-Low Power Consumption: Targeting edge markets like wearable devices and IoT, ultra-low power and low-cost solutions will be developed. Current perception chips rely on analog-to-digital converters to process data, which is slow and energy-intensive. By integrating in-memory computing chips with perception modules and developing efficient mixed-signal processing methods, it will be possible to achieve a fully integrated perception-storage-computation solution, drastically reducing overhead and achieving ultra-low power consumption.\n2.\tShifting Toward the Edge/Cloud for Extreme Computational Power: For applications like edge/cloud servers, data centers, and autonomous driving, in-memory computing chips can offer massive parallel computing capabilities. Current edge/cloud processors, typically based on GPUs, face significant data communication overheads, limiting their actual computational efficiency. In-memory computing chips, optimized for large-scale matrix operations such as those in Transformer-based models, can greatly reduce bandwidth requirements and enhance computational power.\n3.\tCo-Design of Heterogeneous Architectures and Integration: Combining different computational architectures and hardware units can maximize their strengths while compensating for their weaknesses. For example, integrating analog and digital in-memory computing architectures can strike a balance between precision, energy efficiency, area, and cost. Advanced packaging technologies like 2.5D/3D integration and chiplets can be leveraged to integrate CPUs, GPUs, and in-memory computing chips fabricated at different process nodes, fully realizing the advantages of heterogeneous architectures.\n4.\tDevelopment of EDA and Application Toolchains: As in-memory computing chips move from proof-of-concept to large-scale production, the development of automated EDA tools and application toolchains becomes critical. These tools can simplify chip design, reduce development costs, and accelerate deployment. A robust ecosystem of open-source and standardized platforms will drive mass production and widespread adoption of in-memory computing chips.\nTo date, in-memory computing chip technology has garnered significant attention from academia and industry, achieving a series of breakthroughs. However, before large-scale industrialization can be realized, several critical scientific issues need to be addressed in areas such as low-power mixed-signal circuits, high-density in-memory computing media, automated EDA tools, and methods/standards/processes for heterogeneous integration.\nAt the terminal end, the core challenge lies in the ultra-low-power processing of multi-modal information. Existing solutions for perception-storage-computing chips primarily focus on single-modality signal processing (e.g., auditory, visual, or tactile), while intelligent systems often require comprehensive analysis of multi-modal data to perceive and interpret their environment. Designing a multi-modal perception-storage-computing architecture and its associated low-power mixed-signal circuits is a critical scientific problem in achieving \"ultra-low power\" integration. This research spans multiple disciplines, including devices, processes, chips, algorithms, and applications, necessitating cross-layer collaborative optimization. Key questions include improving existing devices or fabricating new ones, optimizing processing technology for reliability and precision, designing efficient multi-modal mixed-signal circuits, creating algorithms tailored to hardware, and establishing user-friendly application ecosystems.\nAt the edge/cloud level, the primary challenges are computational power, precision, and bandwidth. Leveraging the massive parallel computing capabilities of in-memory computing chips becomes particularly critical for large-scale model applications, which impose stringent demands on scale, precision, and computational power. For instance, large-scale models require single arrays exceeding 10k × 10k, total memory capacities reaching gigabit levels, and single-chip computational performance (8-bit fixed-point numbers) of at least 100 TOPS (tera operations per second). Furthermore, increasing integration scales bring challenges like error propagation, non-uniformity, and reliability issues. Overcoming these requires breakthroughs in fundamental principles, device technologies, and theoretical models for defect and error propagation.",
    "ori_text": "\n\nIn recent years, with the rapid development of technologies such as artificial intelligence (AI), the Internet of Things (IoT), and 5G communication, a new wave of information technology revolution has emerged. AI technology, serving as the \"central brain\" that powers smart manufacturing, smart cities, and the metaverse, plays a pivotal role in the digital era. It is widely acknowledged that algorithms, data, and computational power (chips) are the three core elements driving AI development, with chips forming the foundation for the practical implementation of AI.\nAs research on large models such as ChatGPT and GPT-4 continues to progress, model structures are becoming increasingly complex, and the demand for data and computational resources is growing exponentially. Simultaneously, the gradual diminishing of Moore’s Law has slowed the evolution of chip manufacturing processes. The disparity between algorithm development and hardware advancement poses a significant challenge: how to efficiently process massive datasets using complex algorithms has become a pressing issue in the AI domain.\nThe root cause of this challenge lies in the limitations of chips, which are currently constrained by the \"von Neumann architecture bottleneck.\" In von Neumann architecture, data storage and processing are separated, and data is transferred between memory and processors through buses. Frequent data transfers incur substantial time and energy costs, leading to what is termed the \"memory wall\" and the \"power wall.\" Moreover, as device sizes approach physical limits, the traditional approach of improving chip performance solely through process advancements faces increasing obstacles, resulting in the so-called \"process wall.\"\nTo address these challenges, academia and industry worldwide have conducted extensive research from multiple dimensions, including architecture, process, and integration, to explore new-generation chip technologies for the post-Moore era. For instance, dataflow architecture chips enable streaming computation, achieving significantly higher throughput than von Neumann architecture for large-scale AI data processing; reconfigurable chips provide high flexibility and energy-efficient computation through software-defined hardware circuit structures; wafer-scale chips expand chip area using advanced process technologies to enhance computational power; and 3D chips stack multiple chips vertically using 3D integration packaging technology to achieve high bandwidth and computational power. Among these, in-memory computing chips stand out by integrating storage and computation through collaborative innovation across devices, architectures, circuits, and processes, fundamentally overcoming the von Neumann architecture bottleneck.\nIn-memory computing chips have architectural features that significantly reduce data transfer overhead, addressing the \"memory wall\" and \"power wall.\" Additionally, their highly parallel computing capabilities enable performance comparable to that of advanced processes, even with relatively mature process nodes, thereby alleviating the pressure of process miniaturization. Furthermore, in-memory computing technology seamlessly integrates with other advanced technologies, such as reconfigurable chips, wafer-scale chips, and 3D integration, making it one of the most promising directions in post-Moore era chip technology.\nThe concept of in-memory computing can be traced back to the 1970s when Kautz from the Stanford Research Institute first proposed the idea. The core principle is to perform computation directly within memory, reducing the overhead of data transfer between memory and processors. Subsequent research has focused on chip circuit structures, computational architectures, and system applications. However, due to the complexity of circuit design and the difficulty of implementation, most of the early research effectively realized \"near-memory computing.\" The main distinction between near-memory and in-memory computing is that the former still requires data to be read out of memory for computation, with the results then stored back into memory. Current industry-standard solutions for near-memory computing include techniques such as 3D packaging and high-bandwidth memory (HBM) to shorten the distance between memory and processors and increase data bandwidth. These technologies are relatively mature and have been scaled into mass production.\nLeading semiconductor companies such as AMD, Intel, Samsung, and SK Hynix have introduced near-memory computing chips based on HBM and 2.5D/3D packaging technologies. For example, Samsung’s latest HBM3 Icebolt technology employs a near-memory computing architecture, utilizing 12 layers of 10nm-class dynamic random-access memory (DRAM) to achieve processing speeds of up to 6.4 Gbps and bandwidths of up to 819 GB/s.\nHowever, near-memory computing still adheres to the von Neumann architecture, which fundamentally separates storage and computation. While it reduces data transfer overhead to some extent, it cannot entirely eliminate the von Neumann bottleneck. In recent years, in-memory computing architectures that integrate storage and computation into a unified framework have become a hotspot in academia and industry.\nIn-memory computing chips can be broadly categorized into analog and digital paradigms:\n1.\tAnalog in-memory computing: Signals within or near the storage array are processed as analog signals. Operations such as matrix multiplications leverage the intrinsic physical behavior of the storage array, often relying on digital-to-analog and analog-to-digital converters for signal conversion. Analog computation typically utilizes Ohm’s law and Kirchhoff’s law to achieve high energy efficiency but may suffer from lower precision and reliability.\n2.\tDigital in-memory computing: Signals within or near the storage array are processed as digital signals, typically using techniques like adder trees and shifters. Digital in-memory computing achieves arbitrary precision but has relatively lower energy efficiency and higher cost per unit area.\nResearch on in-memory computing chips spans various storage media. Chips based on traditional media like SRAM and NOR Flash are relatively mature and have entered small-scale production. Meanwhile, chips leveraging emerging non-volatile storage media, such as magnetic random-access memory (MRAM), resistive random-access memory (RRAM), phase-change random-access memory (PCRAM), and ferroelectric field-effect transistors (FeFET), are transitioning from foundational research to industrialization. Research institutions and companies from the United States, China, and South Korea have made significant advances in this field, with notable contributions from IBM, Stanford University, Princeton University, SK Hynix, Samsung, Tsinghua University, Peking University, and the Chinese Academy of Sciences Institute of Microelectronics.\nDespite these advancements, effective chip design relies heavily on EDA (Electronic Design Automation) tools, which remain in the early stages for in-memory computing. Current academic efforts have produced simple single-point tools for simulation modeling and automated synthesis, but no comprehensive EDA tool platform akin to those for digital circuit design has been established, making it challenging to support large-scale automated design of in-memory computing chips.\nCurrent research on in-memory computing chips is primarily focused on single-point technologies, with many technical challenges remaining in areas such as devices, circuits, architectures, EDA tools, and system applications. The future development of in-memory computing chips is expected to focus on the following four trends:\n1.\tShifting Toward the Perception End for Ultra-Low Power Consumption: Targeting edge markets like wearable devices and IoT, ultra-low power and low-cost solutions will be developed. Current perception chips rely on analog-to-digital converters to process data, which is slow and energy-intensive. By integrating in-memory computing chips with perception modules and developing efficient mixed-signal processing methods, it will be possible to achieve a fully integrated perception-storage-computation solution, drastically reducing overhead and achieving ultra-low power consumption.\n2.\tShifting Toward the Edge/Cloud for Extreme Computational Power: For applications like edge/cloud servers, data centers, and autonomous driving, in-memory computing chips can offer massive parallel computing capabilities. Current edge/cloud processors, typically based on GPUs, face significant data communication overheads, limiting their actual computational efficiency. In-memory computing chips, optimized for large-scale matrix operations such as those in Transformer-based models, can greatly reduce bandwidth requirements and enhance computational power.\n3.\tCo-Design of Heterogeneous Architectures and Integration: Combining different computational architectures and hardware units can maximize their strengths while compensating for their weaknesses. For example, integrating analog and digital in-memory computing architectures can strike a balance between precision, energy efficiency, area, and cost. Advanced packaging technologies like 2.5D/3D integration and chiplets can be leveraged to integrate CPUs, GPUs, and in-memory computing chips fabricated at different process nodes, fully realizing the advantages of heterogeneous architectures.\n4.\tDevelopment of EDA and Application Toolchains: As in-memory computing chips move from proof-of-concept to large-scale production, the development of automated EDA tools and application toolchains becomes critical. These tools can simplify chip design, reduce development costs, and accelerate deployment. A robust ecosystem of open-source and standardized platforms will drive mass production and widespread adoption of in-memory computing chips.\nTo date, in-memory computing chip technology has garnered significant attention from academia and industry, achieving a series of breakthroughs. However, before large-scale industrialization can be realized, several critical scientific issues need to be addressed in areas such as low-power mixed-signal circuits, high-density in-memory computing media, automated EDA tools, and methods/standards/processes for heterogeneous integration.\nAt the terminal end, the core challenge lies in the ultra-low-power processing of multi-modal information. Existing solutions for perception-storage-computing chips primarily focus on single-modality signal processing (e.g., auditory, visual, or tactile), while intelligent systems often require comprehensive analysis of multi-modal data to perceive and interpret their environment. Designing a multi-modal perception-storage-computing architecture and its associated low-power mixed-signal circuits is a critical scientific problem in achieving \"ultra-low power\" integration. This research spans multiple disciplines, including devices, processes, chips, algorithms, and applications, necessitating cross-layer collaborative optimization. Key questions include improving existing devices or fabricating new ones, optimizing processing technology for reliability and precision, designing efficient multi-modal mixed-signal circuits, creating algorithms tailored to hardware, and establishing user-friendly application ecosystems.\nAt the edge/cloud level, the primary challenges are computational power, precision, and bandwidth. Leveraging the massive parallel computing capabilities of in-memory computing chips becomes particularly critical for large-scale model applications, which impose stringent demands on scale, precision, and computational power. For instance, large-scale models require single arrays exceeding 10k × 10k, total memory capacities reaching gigabit levels, and single-chip computational performance (8-bit fixed-point numbers) of at least 100 TOPS (tera operations per second). Furthermore, increasing integration scales bring challenges like error propagation, non-uniformity, and reliability issues. Overcoming these requires breakthroughs in fundamental principles, device technologies, and theoretical models for defect and error propagation.",
    "reference_list": "考点1：“memory wall” 必须译为 “存储墙”。\n考点2：“process wall” 必须译为 “制程墙”。\n考点3：“High‑Bandwidth Memory (HBM)” 必须译为 “高带宽内存（HBM）”。\n考点4：“analog in‑memory computing” 必须译为 “模拟存内计算”。\n考点5：“digital in‑memory computing” 必须译为 “数字存内计算”。\n考点6：“SRAM / NOR Flash” 必须译为 “静态随机存取存储器 / NOR型闪存”。\n考点7：“MRAM / RRAM / PCRAM / FeFET” 必须译为 “磁阻存储器 / 阻变存储器 / 相变存储器 / 铁电场效应晶体管”。\n考点8：“chiplets / 2.5D/3D integration” 必须译为 “芯粒 / 2.5D/3D集成”。\n考点9：“dynamic random‑access memory (DRAM)” 必须译为 “动态随机存取存储器（DRAM）”。\n考点10：“TOPS (8-bit fixed-point)”推荐译为“万亿次每秒（8位定点，TOPS）”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "150"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nCave 17 at the Dunhuang cave complex is a cache of religious texts and social records sealed at the beginning of the eleventh century and discovered in 1900. Legal documents from this cave show that ordained Buddhist monks and nuns in Dunhuang actively engaged in legal practices as plaintiffs, defendants, witnesses, mediators, and representatives in the trial of various disputes. Where did these monks and nuns get their legal education? And what roles did they play in circulating legal knowledge in Dunhuang? Addressing these questions is crucial for my larger project on the interaction between religion and law in China as they can help paint a fuller picture of how Buddhism and the state interacted in the legal arena in pre-modern China. Elsewhere, I have discussed how the jurisdictional boundary between the state and the Buddhist monastic community shifted in central China and analyzed cases in which individual monks and nuns litigated in the lay courts in Dunhuang. This article aims to understand the legal landscape on the frontier in Dunhuang, with a particular focus on ordained Buddhists’ access to legal texts and the roles they played in producing and preserving them. My primary sources are colophons on the Chinese manuscripts of Buddhist monastic law texts (Vinaya) discovered in the Dunhuang cave 17.\n\nMy examination of the said colophons will reveal that ordained Buddhist monks and nuns played various roles in the circulation of legal knowledge in Dunhuang. They were patrons, scribes, and owners of various Buddhist monastic law texts circulated in Dunhuang. In cave 17, we can find Buddhist monastic law texts of all the major surviving traditions. The majority of them are law texts transmitted from the Dharmaguptaka tradition, but those of the Mahāsāṃghika, Sarvāstivāda, Mahīśāsaka, and Mūlasarvāstivāda traditions have also appeared in the same cave. These monastic law texts cover Buddhist liturgical and disciplinary guidelines ranging from the five precepts for the lay Buddhist householder, to the eight temporary fasting precepts, the 10 precepts for ordained novices, the six additional precepts for probationary Buddhist nuns, and the full set of disciplinary rules for fully ordained Buddhist monks and nuns.\n\nThis examination, however, is not comprehensive. Ideally, we need to combine this examination with a study on the Buddhist monastic law texts written in Tibetan and other languages found in cave 17. Since Shayne Clarke and his team at McMaster University are currently working on a project surveying the Tibetan Vinaya texts from the Dunhuang manuscript collection, I did not discuss the Tibetan materials in the present article. It is also important to note that while my discussion below focuses on Buddhist monastic law texts, those were not the only type of legal texts circulated in Dunhuang. In this cave, we also find fragments of the primary legal texts promulgated by the Tang court. These include code, statutes, regulations, and ordinances. Several judicial judgments  from the Tang, one of which I will discuss below, were also found in Dunhuang. Moreover, we have also found damaged copies of the section on The Penal Code  from The Book of the Han.\n\nBefore discussing how ordained Buddhists engaged in the copying, collecting, and preserving of Buddhist monastic law texts in Dunhuang, it is necessary to provide an overview of the workflow of text copying in Dunhuang. Scribes in Dunhuang copied Buddhist legal texts over several centuries. The earliest Buddhist monastic law text found in cave 17 is the Sarvāstivāda Prātimokṣa for Ordained Buddhist Monks . The scribe, a Buddhist monk Deyou, stated in the colophon that he copied this text in the southern part of Dunhuang during the summer rainy season retreat in 406, one year after he received his full ordination in 405. Copying of Buddhist monastic law texts continued in Dunhuang without interruption toward the end of the tenth century. Even after Dunhuang fell under Tibetan control, Buddhist text copying continued from 786 to 848.\n\nThe Tibetan scholar Zhang Yanqing’s extensive study on the copying of Tibetan Buddhist texts in Dunhuang helps unveil important aspects of the workflow of text copying in this area. At the beginning of the Tibetan occupation of Dunhuang, text-copying focused on Chinese Buddhist texts. With support from the Tibetan king Khri gtsug lde brtsan, massive copying of Tibetan Buddhist texts began in 822 and continued in Shazhou until 838. Teams stationed at a particular scriptorium (gur) with multiple scribes and proofreaders copied large texts. Before starting the copying, they would secure a mother copy (dpe’) and proofread it multiple times. Each scribe would receive a mother copy of their targeted text and paper, and an administrator would record the distribution of paper and mother copies. A loan record on Pelliot chinois 3010v illustrates this practice. This manuscript states that on the seventeenth day in the fifth month in a mouse year , Sanjie monastery, one of the local monasteries in Dunhuang, borrowed six bundles of the Chinese translation of the Dharmaguptaka Vinaya  and their brocade bundle covers for copying . When a scribe completed a copy, a proofreader would check the replica against the original. It was normal to proofread the copied Tibetan Buddhist texts at least three or four times, or 10 times in rare cases.\n\nIn contrast to proofreading the Buddhist text commissioned by the Tibetan king anywhere between three times and 10 times, proofreaders normally proofread the Chinese copies of Buddhist monastic law texts found in Dunhuang once, twice, or none. For instance, Jingtu monastery owned a copy of the Commentary on the Dharmaguptaka Prātimokṣa. Its colophon informs us that an unspecified proofreader proofread it once at the Mogao cave on the first day in the third month in a horse year.\n\nCopies of the Buddhist monastic law texts found in cave 17 were produced in various locations. Some of them were locally copied in Dunhuang. On the nineteenth day in the eleventh month in a dog year, an unspecified scribe copied A Short Collection of Buddhist Monastic Law Texts at Bao’en monastery in Dunhuang. On the twenty-eighth day in the third month in a mouse year, another unspecified scribe copied the third scroll of the Commentary on the Dharmaguptaka Prātimokṣa at Yongshou monastery in Shazhou. This copy was proofread and punctuated in red ink. On the twentieth day in the tenth month in the seventh year of a certain era, a Buddhist monk, Riding , copied The Dharmaguptaka Prātimokṣa for Ordained Buddhist Monks at Dayun monastery. In the twelfth month in a mouse year, a monk from Jinguangming monastery, who was also a Vinaya master, copied the Commentary on the Dharmaguptaka Prātimokṣa  for circulation. On the twentieth day in the fourth month in the second year during the Qianyuan era (759), monk Jingshen from Longxing monastery copied the Dharmaguptaka Prātimokṣa for Ordained Buddhist Monks. Another Longxing monastery monk, Zhizhao, copied the Dharmaguptaka Prātimokṣa for Ordained Buddhist Nuns. From the eighth day in the fifth month to the third day in the sixth month in a horse year, a Buddhist monk, Liji, from Jinguangming monastery copied one scroll of the Tang Buddhist monk Daoxuans (596–667) Randomly Selected Ecclesiastical Proceedings: Abridgements and Emendations to the Dharmaguptaka Vinaya for his monastery’s elder monk, Jinyao, at the beginning of that year’s rainy season retreat.\n\nAnother local site where multiple Buddhist legal texts were copied is the Dongshan solitary monastic dwelling, which was most likely one of many such dwellings built near the Dunhuang cave complex. At least three surviving Buddhist law texts were copied at this site in a tiger year. On the sixteenth day in the sixth month in a tiger year, an unspecified individual completed proofreading the Notes on Conduct: Abridgements and Emendations to the Dharmaguptaka Vinaya  at the Dongshan solitary monastic dwelling. One month later, on the fifteenth day in the seventh month of a tiger year, an unspecified scribe finished copying a single-scroll text, A Concise Copy of the Vinaya  at Dongshan, identifiable with the Dongshan solitary monastic dwelling mentioned above. The owner of this copied text was a Buddhist nun, Shengzang. A few months later, on the twentieth day in the tenth month in a tiger year, an unspecified scribe continued copying and proofreading the fourth scroll of the Commentary on the Dharmaguptaka Prātimokṣa.\n\nA bit further away from Dunhuang, the Xiuduo monastery in Ganzhou Prefecture in todays Gansu province was also an important site for the circulation of legal and other Buddhist knowledge in Dunhuang. A Buddhist monk, Huizhen, copied The Sūtra on the Twenty-four Precepts for the Faithful Bodhisattvas Told by the Buddha at this Xiuduo monastery. The date was unspecified. This monastery was also where the Tibetan Buddhist monk, Chos grub (Ch. Facheng), taught and translated texts.\n\nTurfan, located about 800 kilometers to the Northwest of Dunhuang, appeared to be another productive center for copying Buddhist law texts. On the fourth day in the seventh month in the second year during the Guangde era, a Buddhist monk, Yilin, copied Daoxuans Notes on Conduct: Abridgements and Emendations to the Dharmaguptaka Vinaya at a place specified as Peijiata in the Nanping city in the Xizhou Prefecture, in today’s Turfan. At the end of the third and last scroll of this text, the colophons mention the scribe’s name, where and when he copied it. At the end of the middle scroll of this text, an unspecified proofreader wrote in red ink that he proofread the copied text in the early half of the sixth month in a snake year  at the garden of a central Asian mound, whose exact location remains unknown. Because the nearest snake year after 764 was 765, this text was likely proofread in 765.\nSome of the Buddhist monastic law texts traveled to Dunhuang from central China. In the Dunhuang cave 17, we found at least two Buddhist monastic law texts previously owned by ordained Buddhists in central China. One is The Manual for Ordained Buddhists to Receive the Bodhisattva Precepts, which was copied under imperial order in the fifth month in the eighteenth year during the Tianjian era (519) during the Liang Dynasty. A layperson, Dai Mengtong, was the scribe, a certain Bi Xianzhi read the text, and its owner was a Buddhist monk, Huiming, from a well-known Waguan monastery located in todays Nanjing. Waguan monastery was first founded in 364 and was still in use during the Liang dynasty. Huiming was likely an influential monk. A few years before the copying of this text, monk Huiming from Waguan monastery collaborated with monk Fayun from Guangzhai monastery and others to preach on the need to stop eating meat during the Tianjian era.\n",
    "ori_text": "\n\nCave 17 at the Dunhuang cave complex is a cache of religious texts and social records sealed at the beginning of the eleventh century and discovered in 1900. Legal documents from this cave show that ordained Buddhist monks and nuns in Dunhuang actively engaged in legal practices as plaintiffs, defendants, witnesses, mediators, and representatives in the trial of various disputes. Where did these monks and nuns get their legal education? And what roles did they play in circulating legal knowledge in Dunhuang? Addressing these questions is crucial for my larger project on the interaction between religion and law in China as they can help paint a fuller picture of how Buddhism and the state interacted in the legal arena in pre-modern China. Elsewhere, I have discussed how the jurisdictional boundary between the state and the Buddhist monastic community shifted in central China and analyzed cases in which individual monks and nuns litigated in the lay courts in Dunhuang. This article aims to understand the legal landscape on the frontier in Dunhuang, with a particular focus on ordained Buddhists’ access to legal texts and the roles they played in producing and preserving them. My primary sources are colophons on the Chinese manuscripts of Buddhist monastic law texts (Vinaya) discovered in the Dunhuang cave 17.\n\nMy examination of the said colophons will reveal that ordained Buddhist monks and nuns played various roles in the circulation of legal knowledge in Dunhuang. They were patrons, scribes, and owners of various Buddhist monastic law texts circulated in Dunhuang. In cave 17, we can find Buddhist monastic law texts of all the major surviving traditions. The majority of them are law texts transmitted from the Dharmaguptaka tradition, but those of the Mahāsāṃghika, Sarvāstivāda, Mahīśāsaka, and Mūlasarvāstivāda traditions have also appeared in the same cave. These monastic law texts cover Buddhist liturgical and disciplinary guidelines ranging from the five precepts for the lay Buddhist householder, to the eight temporary fasting precepts, the 10 precepts for ordained novices, the six additional precepts for probationary Buddhist nuns, and the full set of disciplinary rules for fully ordained Buddhist monks and nuns.\n\nThis examination, however, is not comprehensive. Ideally, we need to combine this examination with a study on the Buddhist monastic law texts written in Tibetan and other languages found in cave 17. Since Shayne Clarke and his team at McMaster University are currently working on a project surveying the Tibetan Vinaya texts from the Dunhuang manuscript collection, I did not discuss the Tibetan materials in the present article. It is also important to note that while my discussion below focuses on Buddhist monastic law texts, those were not the only type of legal texts circulated in Dunhuang. In this cave, we also find fragments of the primary legal texts promulgated by the Tang court. These include code, statutes, regulations, and ordinances. Several judicial judgments  from the Tang, one of which I will discuss below, were also found in Dunhuang. Moreover, we have also found damaged copies of the section on The Penal Code  from The Book of the Han.\n\nBefore discussing how ordained Buddhists engaged in the copying, collecting, and preserving of Buddhist monastic law texts in Dunhuang, it is necessary to provide an overview of the workflow of text copying in Dunhuang. Scribes in Dunhuang copied Buddhist legal texts over several centuries. The earliest Buddhist monastic law text found in cave 17 is the Sarvāstivāda Prātimokṣa for Ordained Buddhist Monks . The scribe, a Buddhist monk Deyou, stated in the colophon that he copied this text in the southern part of Dunhuang during the summer rainy season retreat in 406, one year after he received his full ordination in 405. Copying of Buddhist monastic law texts continued in Dunhuang without interruption toward the end of the tenth century. Even after Dunhuang fell under Tibetan control, Buddhist text copying continued from 786 to 848.\n\nThe Tibetan scholar Zhang Yanqing’s extensive study on the copying of Tibetan Buddhist texts in Dunhuang helps unveil important aspects of the workflow of text copying in this area. At the beginning of the Tibetan occupation of Dunhuang, text-copying focused on Chinese Buddhist texts. With support from the Tibetan king Khri gtsug lde brtsan, massive copying of Tibetan Buddhist texts began in 822 and continued in Shazhou until 838. Teams stationed at a particular scriptorium (gur) with multiple scribes and proofreaders copied large texts. Before starting the copying, they would secure a mother copy (dpe’) and proofread it multiple times. Each scribe would receive a mother copy of their targeted text and paper, and an administrator would record the distribution of paper and mother copies. A loan record on Pelliot chinois 3010v illustrates this practice. This manuscript states that on the seventeenth day in the fifth month in a mouse year , Sanjie monastery, one of the local monasteries in Dunhuang, borrowed six bundles of the Chinese translation of the Dharmaguptaka Vinaya  and their brocade bundle covers for copying . When a scribe completed a copy, a proofreader would check the replica against the original. It was normal to proofread the copied Tibetan Buddhist texts at least three or four times, or 10 times in rare cases.\n\nIn contrast to proofreading the Buddhist text commissioned by the Tibetan king anywhere between three times and 10 times, proofreaders normally proofread the Chinese copies of Buddhist monastic law texts found in Dunhuang once, twice, or none. For instance, Jingtu monastery owned a copy of the Commentary on the Dharmaguptaka Prātimokṣa. Its colophon informs us that an unspecified proofreader proofread it once at the Mogao cave on the first day in the third month in a horse year.\n\nCopies of the Buddhist monastic law texts found in cave 17 were produced in various locations. Some of them were locally copied in Dunhuang. On the nineteenth day in the eleventh month in a dog year, an unspecified scribe copied A Short Collection of Buddhist Monastic Law Texts at Bao’en monastery in Dunhuang. On the twenty-eighth day in the third month in a mouse year, another unspecified scribe copied the third scroll of the Commentary on the Dharmaguptaka Prātimokṣa at Yongshou monastery in Shazhou. This copy was proofread and punctuated in red ink. On the twentieth day in the tenth month in the seventh year of a certain era, a Buddhist monk, Riding , copied The Dharmaguptaka Prātimokṣa for Ordained Buddhist Monks at Dayun monastery. In the twelfth month in a mouse year, a monk from Jinguangming monastery, who was also a Vinaya master, copied the Commentary on the Dharmaguptaka Prātimokṣa  for circulation. On the twentieth day in the fourth month in the second year during the Qianyuan era (759), monk Jingshen from Longxing monastery copied the Dharmaguptaka Prātimokṣa for Ordained Buddhist Monks. Another Longxing monastery monk, Zhizhao, copied the Dharmaguptaka Prātimokṣa for Ordained Buddhist Nuns. From the eighth day in the fifth month to the third day in the sixth month in a horse year, a Buddhist monk, Liji, from Jinguangming monastery copied one scroll of the Tang Buddhist monk Daoxuans (596–667) Randomly Selected Ecclesiastical Proceedings: Abridgements and Emendations to the Dharmaguptaka Vinaya for his monastery’s elder monk, Jinyao, at the beginning of that year’s rainy season retreat.\n\nAnother local site where multiple Buddhist legal texts were copied is the Dongshan solitary monastic dwelling, which was most likely one of many such dwellings built near the Dunhuang cave complex. At least three surviving Buddhist law texts were copied at this site in a tiger year. On the sixteenth day in the sixth month in a tiger year, an unspecified individual completed proofreading the Notes on Conduct: Abridgements and Emendations to the Dharmaguptaka Vinaya  at the Dongshan solitary monastic dwelling. One month later, on the fifteenth day in the seventh month of a tiger year, an unspecified scribe finished copying a single-scroll text, A Concise Copy of the Vinaya  at Dongshan, identifiable with the Dongshan solitary monastic dwelling mentioned above. The owner of this copied text was a Buddhist nun, Shengzang. A few months later, on the twentieth day in the tenth month in a tiger year, an unspecified scribe continued copying and proofreading the fourth scroll of the Commentary on the Dharmaguptaka Prātimokṣa.\n\nA bit further away from Dunhuang, the Xiuduo monastery in Ganzhou Prefecture in todays Gansu province was also an important site for the circulation of legal and other Buddhist knowledge in Dunhuang. A Buddhist monk, Huizhen, copied The Sūtra on the Twenty-four Precepts for the Faithful Bodhisattvas Told by the Buddha at this Xiuduo monastery. The date was unspecified. This monastery was also where the Tibetan Buddhist monk, Chos grub (Ch. Facheng), taught and translated texts.\n\nTurfan, located about 800 kilometers to the Northwest of Dunhuang, appeared to be another productive center for copying Buddhist law texts. On the fourth day in the seventh month in the second year during the Guangde era, a Buddhist monk, Yilin, copied Daoxuans Notes on Conduct: Abridgements and Emendations to the Dharmaguptaka Vinaya at a place specified as Peijiata in the Nanping city in the Xizhou Prefecture, in today’s Turfan. At the end of the third and last scroll of this text, the colophons mention the scribe’s name, where and when he copied it. At the end of the middle scroll of this text, an unspecified proofreader wrote in red ink that he proofread the copied text in the early half of the sixth month in a snake year  at the garden of a central Asian mound, whose exact location remains unknown. Because the nearest snake year after 764 was 765, this text was likely proofread in 765.\nSome of the Buddhist monastic law texts traveled to Dunhuang from central China. In the Dunhuang cave 17, we found at least two Buddhist monastic law texts previously owned by ordained Buddhists in central China. One is The Manual for Ordained Buddhists to Receive the Bodhisattva Precepts, which was copied under imperial order in the fifth month in the eighteenth year during the Tianjian era (519) during the Liang Dynasty. A layperson, Dai Mengtong, was the scribe, a certain Bi Xianzhi read the text, and its owner was a Buddhist monk, Huiming, from a well-known Waguan monastery located in todays Nanjing. Waguan monastery was first founded in 364 and was still in use during the Liang dynasty. Huiming was likely an influential monk. A few years before the copying of this text, monk Huiming from Waguan monastery collaborated with monk Fayun from Guangzhai monastery and others to preach on the need to stop eating meat during the Tianjian era.\n",
    "reference_list": "考点1：“Sarvāstivāda Prātimokṣa for Ordained Buddhist Monks”推荐译为“《十诵律比丘戒本》”\n考点2：“bundle”必须译为“帙”\n考点3：“Dharmaguptaka Vinaya”必须译为“《四分律》”\n考点4：“Randomly Selected Ecclesiastical Proceedings: Abridgements and Emendations to the Dharmaguptaka Vinaya”必须译为“《四分律删补随机羯磨》”\n考点5：“Notes on Conduct: Abridgements and Emendations to the Dharmaguptaka Vinaya”必须译为“《四分律删繁补阙行事钞》”\n考点6：“solitary monastic dwelling”必须译为“兰若”\n考点7：“in red ink”必须译为“朱笔”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "133"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n空间智能作为人工智能领域的前沿分支，其核心在于构建机器对三维物理世界的结构化认知与动态响应能力。这一概念突破了传统计算机视觉的平面局限，通过整合深度感知、几何推理与运动规划，实现从视觉输入到物理操作的完整闭环。在技术层面，空间智能的本质是通过多模态传感器数据解析三维拓扑结构、语义关联与动态变化规律，使智能体具备类人级的环境理解与行为决策能力。相较于二维视觉仅能捕捉色彩与纹理信息，空间智能通过深度估计、立体匹配与运动恢复结构等技术路径，构建包含度量尺度、空间方位与材质属性的三维表征体系，为自动驾驶、机器人操作等复杂任务提供认知基础。\n空间智能的发展历程呈现出从确定性几何建模向概率性神经感知的范式转变。早期探索聚焦于基于刚体运动假设的几何约束方法，其中同步定位与地图构建技术通过迭代优化传感器姿态与环境特征的空间关系，实现未知环境中的自主导航。该技术依赖扩展卡尔曼滤波或 Bundle Adjustment 等优化框架，通过最小化重投影误差实现状态估计，但在动态场景与特征缺失环境中易出现漂移现象。视觉里程计作为 SLAM 的前端模块，通过相邻帧特征点匹配计算运动变换矩阵，其精度直接取决于特征提取的鲁棒性 ——SIFT 与 ORB 等局部特征 descriptor 在光照变化与运动模糊场景中的性能差异，成为制约早期系统稳定性的关键因素。\n针对三维数据的稀疏性与高维度特性，NVIDIA 提出的 DeepVDB 框架基于体素化稀疏数据结构，通过层级化存储与索引机制，实现大规模三维卷积与注意力运算的高效加速。该框架在城市级数字孪生构建中，将 TB 级点云数据压缩比提升 30 倍，同时保持亚毫米级几何精度，为实时渲染与物理仿真提供支撑。多模态融合技术则通过摄像头、激光雷达与惯性测量单元的时空校准，构建冗余感知体系：视觉传感器提供丰富纹理信息，激光雷达保证恶劣天气下的测距精度，惯性测量单元则通过捷联惯导算法弥补传感器采样间隙，三者的紧耦合融合通过卡尔曼滤波或图优化实现状态互补，显著提升复杂环境下的感知鲁棒性。\n自动驾驶作为空间智能最成熟的应用场景，正经历从多传感器融合向端到端学习的范式转变。当最新研究表明，随着算力投入与训练数据规模的指数级增长，自动驾驶系统呈现显著的缩放定律 — 当训练里程超过 1000 万公里时，系统决策错误率随算力扩展呈幂律下降。特斯拉纯视觉方案基于 Transformer 架构的 BEV 空间特征融合，通过时序注意力机制聚合多帧图像信息，在城市道路场景中实现厘米级定位精度；而 Waymo 的激光雷达方案则通过高精地图与实时点云配准，在复杂路口场景中保持 99.9% 的障碍物识别准确率。尽管技术路线存在差异，但均通过强化学习优化决策策略，使系统在无保护左转、紧急避让等复杂场景中的表现逐步接近人类驾驶员水平。\n三维生成与数字孪生技术正推动虚拟世界构建从手工建模向自动化生成的转变。神经辐射场通过多层感知器参数化场景的辐射特性与密度分布，从二维图像集合中重建具有连续视图一致性的三维场景，其核心在于体积渲染方程的数值求解与位置编码机制对高频特征的捕捉。Mip-NeRF 通过锥形采样解决传统 NeRF 的模糊问题，将重建精度提升 40%；Instant NeRF 则引入多分辨率哈希编码，将训练时间从数天压缩至分钟级。这些技术突破使数字孪生从概念走向实用：在城市规划领域，通过机载激光雷达与航空影像融合构建的数字孪生模型，可精确模拟建筑群的日照阴影与风场分布；在工业制造中，基于机器视觉与机器人扫描的设备数字孪生，能实现毫米级的装配误差检测。目前该领域已积累超过 1000 万的三维模型数据，但存在表示形式碎片化问题 — 点云、网格、体素与隐式表示各有优劣，缺乏统一的标准格式，导致跨平台模型复用率不足 30%。\n具身智能作为空间智能的终极形态，致力于实现机器人与物理世界的深度交互。与传统工业机器人的预编程控制不同，具身智能系统通过视觉 - 触觉 - 力觉多模态感知，在未知环境中自主完成操作任务。最新研究采用深度强化学习训练机器人操作策略：通过触觉传感器获取物体表面纹理与接触力信息，结合视觉图像的目标姿态估计，在虚拟环境中进行千万次试错训练，再通过域适应技术迁移至物理世界。谷歌的 SayCan 系统将自然语言指令与视觉感知映射至机器人动作空间，在厨房场景中实现餐具整理、食材处理等复杂任务的零样本迁移；波士顿动力的 Atlas 机器人则通过全身运动规划与动态平衡控制，在野外地形中完成跳跃、攀爬等动态操作。尽管取得显著进展，具身智能仍面临诸多挑战：物理世界的无限状态空间导致训练数据采集成本高昂，机器人操作的安全性约束限制探索空间，而动态环境中的物体交互动力学建模仍是未解决的难题。当前研究正通过构建家庭与工业环境的数据闭环系统，实现机器人行为的持续评估与强化学习更新，逐步提升系统的环境适应能力。\n斯坦福大学李飞飞团队首次系统提出空间智能的理论框架，强调其核心在于构建 \"感知 - 推理 - 执行\" 的闭环认知体系。该团队开发的 SceneScape 模型通过单目图像的深度估计与语义分割，结合先验知识图谱推理物体空间关系，从单张图片中生成包含物理属性的完整三维场景，其创新点在于引入因果推理机制处理物体遮挡与空间布局歧义问题，使生成场景的物理合理性提升 65%。World Labs 公司基于该理论开发的商用模型，已在建筑设计领域实现从手绘草图到三维建筑模型的自动转换，设计效率提升 3 倍以上。\n清华大学提出的 SpatialBot 大模型，通过 Transformer 架构统一处理点云、图像与文本信息，在三维目标检测任务中实现 89.7% 的 mAP 值；北京大学团队开发的多模态空间注意力网络，创新性地将语言指令编码为空间注意力掩码，使机器人抓取成功率在未知物体上提升至 92%。企业层面，华为发布的 AR Engine 4.0 通过 SLAM 与环境光适应技术，实现手机端厘米级的空间定位精度，支撑虚实融合的导航与教育应用；百度 Apollo 的空间感知系统采用激光雷达与摄像头的紧耦合融合，在城市道路测试中实现 99.99% 的定位可用性；腾讯的数字孪生平台则整合游戏引擎与 AI 生成技术，构建的虚拟城市可实时模拟 10 万级人口的动态行为。\n扩展现实作为空间智能的原生交互界面，正重构人机交互范式。虚拟现实通过头显设备构建完全沉浸式的虚拟空间，其空间定位依赖 Inside-out 与 Outside-in 混合追踪技术 —— 前者通过头显内置的视觉惯性传感器实现六自由度定位，后者则通过外部基站的激光扫描提供亚毫米级精度。增强现实则通过光学透视眼镜将虚拟信息叠加于物理世界，微软 HoloLens 2 采用多层衍射波导与时间复用技术，实现明亮环境下的高对比度显示，其空间映射功能可实时构建房间尺度的三维网格。这些技术突破使 XR 成为空间智能的天然载体：在远程协作场景中，借助 XR 设备的空间感知能力，异地用户可共享虚拟工作台并进行三维物体的协同操作；在技能培训领域，基于空间智能的 XR 模拟器能精确还原手术器械或工业设备的操作手感与物理反馈。\n未来空间智能将通过与多学科技术的深度融合实现认知跃迁。与大语言模型的结合将赋予系统理解空间描述语言的能力，使 \"将沙发移至窗户左侧\" 等自然指令转化为精确的空间坐标与运动轨迹；机器人控制领域的阻抗控制与力位混合控制技术，将提升空间智能的物理执行精度，实现精密装配等微米级操作；脑机接口则可能成为终极交互方式，通过解析大脑运动皮层的空间意图信号，直接控制外部设备的三维运动。这些技术融合将最终实现从 \"视觉感知\" 到 \"物理行动\" 的完整闭环，使人工智能系统具备与人类相当的空间认知与操作能力，彻底重塑制造业、医疗健康、智能家居等领域的技术形态。\n",
    "ori_text": "\n\n空间智能作为人工智能领域的前沿分支，其核心在于构建机器对三维物理世界的结构化认知与动态响应能力。这一概念突破了传统计算机视觉的平面局限，通过整合深度感知、几何推理与运动规划，实现从视觉输入到物理操作的完整闭环。在技术层面，空间智能的本质是通过多模态传感器数据解析三维拓扑结构、语义关联与动态变化规律，使智能体具备类人级的环境理解与行为决策能力。相较于二维视觉仅能捕捉色彩与纹理信息，空间智能通过深度估计、立体匹配与运动恢复结构等技术路径，构建包含度量尺度、空间方位与材质属性的三维表征体系，为自动驾驶、机器人操作等复杂任务提供认知基础。\n空间智能的发展历程呈现出从确定性几何建模向概率性神经感知的范式转变。早期探索聚焦于基于刚体运动假设的几何约束方法，其中同步定位与地图构建技术通过迭代优化传感器姿态与环境特征的空间关系，实现未知环境中的自主导航。该技术依赖扩展卡尔曼滤波或 Bundle Adjustment 等优化框架，通过最小化重投影误差实现状态估计，但在动态场景与特征缺失环境中易出现漂移现象。视觉里程计作为 SLAM 的前端模块，通过相邻帧特征点匹配计算运动变换矩阵，其精度直接取决于特征提取的鲁棒性 ——SIFT 与 ORB 等局部特征 descriptor 在光照变化与运动模糊场景中的性能差异，成为制约早期系统稳定性的关键因素。\n针对三维数据的稀疏性与高维度特性，NVIDIA 提出的 DeepVDB 框架基于体素化稀疏数据结构，通过层级化存储与索引机制，实现大规模三维卷积与注意力运算的高效加速。该框架在城市级数字孪生构建中，将 TB 级点云数据压缩比提升 30 倍，同时保持亚毫米级几何精度，为实时渲染与物理仿真提供支撑。多模态融合技术则通过摄像头、激光雷达与惯性测量单元的时空校准，构建冗余感知体系：视觉传感器提供丰富纹理信息，激光雷达保证恶劣天气下的测距精度，惯性测量单元则通过捷联惯导算法弥补传感器采样间隙，三者的紧耦合融合通过卡尔曼滤波或图优化实现状态互补，显著提升复杂环境下的感知鲁棒性。\n自动驾驶作为空间智能最成熟的应用场景，正经历从多传感器融合向端到端学习的范式转变。当最新研究表明，随着算力投入与训练数据规模的指数级增长，自动驾驶系统呈现显著的缩放定律 — 当训练里程超过 1000 万公里时，系统决策错误率随算力扩展呈幂律下降。特斯拉纯视觉方案基于 Transformer 架构的 BEV 空间特征融合，通过时序注意力机制聚合多帧图像信息，在城市道路场景中实现厘米级定位精度；而 Waymo 的激光雷达方案则通过高精地图与实时点云配准，在复杂路口场景中保持 99.9% 的障碍物识别准确率。尽管技术路线存在差异，但均通过强化学习优化决策策略，使系统在无保护左转、紧急避让等复杂场景中的表现逐步接近人类驾驶员水平。\n三维生成与数字孪生技术正推动虚拟世界构建从手工建模向自动化生成的转变。神经辐射场通过多层感知器参数化场景的辐射特性与密度分布，从二维图像集合中重建具有连续视图一致性的三维场景，其核心在于体积渲染方程的数值求解与位置编码机制对高频特征的捕捉。Mip-NeRF 通过锥形采样解决传统 NeRF 的模糊问题，将重建精度提升 40%；Instant NeRF 则引入多分辨率哈希编码，将训练时间从数天压缩至分钟级。这些技术突破使数字孪生从概念走向实用：在城市规划领域，通过机载激光雷达与航空影像融合构建的数字孪生模型，可精确模拟建筑群的日照阴影与风场分布；在工业制造中，基于机器视觉与机器人扫描的设备数字孪生，能实现毫米级的装配误差检测。目前该领域已积累超过 1000 万的三维模型数据，但存在表示形式碎片化问题 — 点云、网格、体素与隐式表示各有优劣，缺乏统一的标准格式，导致跨平台模型复用率不足 30%。\n具身智能作为空间智能的终极形态，致力于实现机器人与物理世界的深度交互。与传统工业机器人的预编程控制不同，具身智能系统通过视觉 - 触觉 - 力觉多模态感知，在未知环境中自主完成操作任务。最新研究采用深度强化学习训练机器人操作策略：通过触觉传感器获取物体表面纹理与接触力信息，结合视觉图像的目标姿态估计，在虚拟环境中进行千万次试错训练，再通过域适应技术迁移至物理世界。谷歌的 SayCan 系统将自然语言指令与视觉感知映射至机器人动作空间，在厨房场景中实现餐具整理、食材处理等复杂任务的零样本迁移；波士顿动力的 Atlas 机器人则通过全身运动规划与动态平衡控制，在野外地形中完成跳跃、攀爬等动态操作。尽管取得显著进展，具身智能仍面临诸多挑战：物理世界的无限状态空间导致训练数据采集成本高昂，机器人操作的安全性约束限制探索空间，而动态环境中的物体交互动力学建模仍是未解决的难题。当前研究正通过构建家庭与工业环境的数据闭环系统，实现机器人行为的持续评估与强化学习更新，逐步提升系统的环境适应能力。\n斯坦福大学李飞飞团队首次系统提出空间智能的理论框架，强调其核心在于构建 \"感知 - 推理 - 执行\" 的闭环认知体系。该团队开发的 SceneScape 模型通过单目图像的深度估计与语义分割，结合先验知识图谱推理物体空间关系，从单张图片中生成包含物理属性的完整三维场景，其创新点在于引入因果推理机制处理物体遮挡与空间布局歧义问题，使生成场景的物理合理性提升 65%。World Labs 公司基于该理论开发的商用模型，已在建筑设计领域实现从手绘草图到三维建筑模型的自动转换，设计效率提升 3 倍以上。\n清华大学提出的 SpatialBot 大模型，通过 Transformer 架构统一处理点云、图像与文本信息，在三维目标检测任务中实现 89.7% 的 mAP 值；北京大学团队开发的多模态空间注意力网络，创新性地将语言指令编码为空间注意力掩码，使机器人抓取成功率在未知物体上提升至 92%。企业层面，华为发布的 AR Engine 4.0 通过 SLAM 与环境光适应技术，实现手机端厘米级的空间定位精度，支撑虚实融合的导航与教育应用；百度 Apollo 的空间感知系统采用激光雷达与摄像头的紧耦合融合，在城市道路测试中实现 99.99% 的定位可用性；腾讯的数字孪生平台则整合游戏引擎与 AI 生成技术，构建的虚拟城市可实时模拟 10 万级人口的动态行为。\n扩展现实作为空间智能的原生交互界面，正重构人机交互范式。虚拟现实通过头显设备构建完全沉浸式的虚拟空间，其空间定位依赖 Inside-out 与 Outside-in 混合追踪技术 —— 前者通过头显内置的视觉惯性传感器实现六自由度定位，后者则通过外部基站的激光扫描提供亚毫米级精度。增强现实则通过光学透视眼镜将虚拟信息叠加于物理世界，微软 HoloLens 2 采用多层衍射波导与时间复用技术，实现明亮环境下的高对比度显示，其空间映射功能可实时构建房间尺度的三维网格。这些技术突破使 XR 成为空间智能的天然载体：在远程协作场景中，借助 XR 设备的空间感知能力，异地用户可共享虚拟工作台并进行三维物体的协同操作；在技能培训领域，基于空间智能的 XR 模拟器能精确还原手术器械或工业设备的操作手感与物理反馈。\n未来空间智能将通过与多学科技术的深度融合实现认知跃迁。与大语言模型的结合将赋予系统理解空间描述语言的能力，使 \"将沙发移至窗户左侧\" 等自然指令转化为精确的空间坐标与运动轨迹；机器人控制领域的阻抗控制与力位混合控制技术，将提升空间智能的物理执行精度，实现精密装配等微米级操作；脑机接口则可能成为终极交互方式，通过解析大脑运动皮层的空间意图信号，直接控制外部设备的三维运动。这些技术融合将最终实现从 \"视觉感知\" 到 \"物理行动\" 的完整闭环，使人工智能系统具备与人类相当的空间认知与操作能力，彻底重塑制造业、医疗健康、智能家居等领域的技术形态。\n",
    "reference_list": "考点1：“BEV空间特征融合” 推荐译为 BEV spatial feature fusion\n考点2：“幂律缩放定律” 推荐译为scaling laws\n考点3：“时序注意力融合” 推荐译为 temporal attention fusion\n考点4：“视觉 - 触觉 - 力觉多模态感知” 推荐译为 vision‑tactile‑force multimodal perception",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "176"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n神圣空间受到了来自不同学科的学者的关注，这些不同的研究扩充了神圣空间的概念。这些定义可以大致可以分为两类：实质性的和情境性的。前者从内在的视角出发，说明神圣空间的本质特征为令人敬畏的、不可思议的和令人不安的。后者从外在的视角出发，将神圣空间定位在人类实践与社会活动的交叉点，并将其理论化为“空的能指” 。基于这些定义，神圣空间的研究对象从传统的宗教空间和祭祀空间扩展开来，学者开始关注盒子里的教堂、朝圣城市、人口稀少的农村地区的临时神圣空间和纪念碑等非传统神圣空间。“神圣”被理解为是人类行动的产物，因此任何空间都有可能成为神圣空间。\n孔庙是中国一种历史悠久的坛庙建筑。孔子（前551-前479），山东曲阜人，是中国古代伟大的思想家、政治家、教育家，儒家学派创始人。自汉武帝罢黜百家独尊儒术后，历代帝王多以儒学作为指导思想，孔子地位日崇，孔庙的规模也日益宏大壮丽。汉高祖十二年（前195）以太牢祀孔子庙堂，开创了帝王祭祀孔子的先例。唐贞观四年（630年），唐太宗下诏在京城和全国各地设立孔庙。唐开元二十六年（739年），《唐六典》成书，它是中国目前保存的最早的、最完整的、古代国家行政法典《唐六典》成书，该书将祭祀孔子列为于国家祭祀典礼之中。此书颁布是，宣告了孔庙祭祀制度的正式定型的里程碑 。此后孔庙的建设和祭孔礼仪规格不断扩大，各地文庙建设活动均在明清时达到顶峰。孔庙除了遍布中国外，还扩散到日本、韩国和东南亚许多国家。\n中国古代坛庙主要有三类：祭祀自然神（如天坛、地坛、先农坛等）、祭祀祖先（如太庙、家庙等）以及祭祀先贤（如武侯祠、关帝庙等）。孔庙兼有第二和第三类，以第三类数量最多。孔氏家庙是孔氏族人祭祀先祖孔子的重要场所，具有特殊地位和特殊内涵。《阙里文献考》记载：先圣殁世，弟子将其葬于鲁城北泗上。殁后二年（前478年），鲁哀公尊夫子为“尼父”，命将其居所改为庙堂，岁时祭奉，此为孔庙之始。中国，目前仅存三座孔氏家庙：山东曲阜孔庙，浙江衢州南宗孔氏家庙、浙江婺州南宗榉溪孔氏家庙。北魏时期，孝文帝于太和十三年（489年）在都城平城（今山西大同）修建孔庙，这是历史上第一座在曲阜以外的孔庙，为之后各地孔庙的建设开创了先例 。由官府修建的孔庙分为三级：国庙、州府庙、县庙。在一些县下面的乡镇也设有孔庙，如云南楚雄大石羊古镇姚县石羊古镇的文庙，这些都是民间修建的。\n孔庙与学宫两组建筑毗邻。魏黄初二年（221年），魏文帝于阙里孔庙之外修建了学宫，据说这是可查到的在孔庙旁边修建学宫的最早记录 。唐贞观四年（630年），太宗下命令在全国各州县的学宫里设立孔庙。学宫是各级政府在其所在城市里设立的最高等级的学府，相当于在首都的最高学府。 唐代后期，孔庙从学宫中分离开，成为独立的建筑群。至宋代，孔庙和学宫基本上成为毗邻的两组独立建筑群。如今在中国许多古城中，人们都可以看到孔庙和学宫两个相邻的建筑群。通常是站在学宫里面对大门，其左边的建筑群为孔庙，这是因为在中国传统中，左边的等级比右边高 。如图1 清代北京（当时国家的首都）下辖大兴县的学宫和孔庙建筑群平面图。也有例外，如顺天府的孔庙图所示（图2）。少数孔庙建筑群是在学宫的前面。\n孔庙经过2000多年的发展演变，到明代三级官府修建的孔庙基本形成了稳定的建筑群构成。从图1可以看到，建筑的中轴线上，从南到北依次是照壁；庙门；泮池，为一个半月形的水池，上面有一座桥连接中轴线上的主路；大成门，是进入主院的入口；大成殿，是供奉孔子牌位，或孔子塑像的主殿，有的还在孔子塑像两侧，供奉孔子的两位优秀的学生塑像 。“大成”的中文含义是“所有智慧的集合”，这个词来自孔子思想的追随者孟子。孟子将孔子称为圣人。因为孔子将所有前人智慧汇集在一起，所以供奉他的殿宇就称为“大成殿”。规模比较大的孔庙还要包括崇圣祠，是供奉孔子父母牌位的殿宇，有的也称启圣祠（见图3右侧最北面的建筑上的汉字）。在主要院落的东西两侧为附属建筑（另加图3右侧的孔庙图）。\n",
    "ori_text": "\n\n神圣空间受到了来自不同学科的学者的关注，这些不同的研究扩充了神圣空间的概念。这些定义可以大致可以分为两类：实质性的和情境性的。前者从内在的视角出发，说明神圣空间的本质特征为令人敬畏的、不可思议的和令人不安的。后者从外在的视角出发，将神圣空间定位在人类实践与社会活动的交叉点，并将其理论化为“空的能指” 。基于这些定义，神圣空间的研究对象从传统的宗教空间和祭祀空间扩展开来，学者开始关注盒子里的教堂、朝圣城市、人口稀少的农村地区的临时神圣空间和纪念碑等非传统神圣空间。“神圣”被理解为是人类行动的产物，因此任何空间都有可能成为神圣空间。\n孔庙是中国一种历史悠久的坛庙建筑。孔子（前551-前479），山东曲阜人，是中国古代伟大的思想家、政治家、教育家，儒家学派创始人。自汉武帝罢黜百家独尊儒术后，历代帝王多以儒学作为指导思想，孔子地位日崇，孔庙的规模也日益宏大壮丽。汉高祖十二年（前195）以太牢祀孔子庙堂，开创了帝王祭祀孔子的先例。唐贞观四年（630年），唐太宗下诏在京城和全国各地设立孔庙。唐开元二十六年（739年），《唐六典》成书，它是中国目前保存的最早的、最完整的、古代国家行政法典《唐六典》成书，该书将祭祀孔子列为于国家祭祀典礼之中。此书颁布是，宣告了孔庙祭祀制度的正式定型的里程碑 。此后孔庙的建设和祭孔礼仪规格不断扩大，各地文庙建设活动均在明清时达到顶峰。孔庙除了遍布中国外，还扩散到日本、韩国和东南亚许多国家。\n中国古代坛庙主要有三类：祭祀自然神（如天坛、地坛、先农坛等）、祭祀祖先（如太庙、家庙等）以及祭祀先贤（如武侯祠、关帝庙等）。孔庙兼有第二和第三类，以第三类数量最多。孔氏家庙是孔氏族人祭祀先祖孔子的重要场所，具有特殊地位和特殊内涵。《阙里文献考》记载：先圣殁世，弟子将其葬于鲁城北泗上。殁后二年（前478年），鲁哀公尊夫子为“尼父”，命将其居所改为庙堂，岁时祭奉，此为孔庙之始。中国，目前仅存三座孔氏家庙：山东曲阜孔庙，浙江衢州南宗孔氏家庙、浙江婺州南宗榉溪孔氏家庙。北魏时期，孝文帝于太和十三年（489年）在都城平城（今山西大同）修建孔庙，这是历史上第一座在曲阜以外的孔庙，为之后各地孔庙的建设开创了先例 。由官府修建的孔庙分为三级：国庙、州府庙、县庙。在一些县下面的乡镇也设有孔庙，如云南楚雄大石羊古镇姚县石羊古镇的文庙，这些都是民间修建的。\n孔庙与学宫两组建筑毗邻。魏黄初二年（221年），魏文帝于阙里孔庙之外修建了学宫，据说这是可查到的在孔庙旁边修建学宫的最早记录 。唐贞观四年（630年），太宗下命令在全国各州县的学宫里设立孔庙。学宫是各级政府在其所在城市里设立的最高等级的学府，相当于在首都的最高学府。 唐代后期，孔庙从学宫中分离开，成为独立的建筑群。至宋代，孔庙和学宫基本上成为毗邻的两组独立建筑群。如今在中国许多古城中，人们都可以看到孔庙和学宫两个相邻的建筑群。通常是站在学宫里面对大门，其左边的建筑群为孔庙，这是因为在中国传统中，左边的等级比右边高 。如图1 清代北京（当时国家的首都）下辖大兴县的学宫和孔庙建筑群平面图。也有例外，如顺天府的孔庙图所示（图2）。少数孔庙建筑群是在学宫的前面。\n孔庙经过2000多年的发展演变，到明代三级官府修建的孔庙基本形成了稳定的建筑群构成。从图1可以看到，建筑的中轴线上，从南到北依次是照壁；庙门；泮池，为一个半月形的水池，上面有一座桥连接中轴线上的主路；大成门，是进入主院的入口；大成殿，是供奉孔子牌位，或孔子塑像的主殿，有的还在孔子塑像两侧，供奉孔子的两位优秀的学生塑像 。“大成”的中文含义是“所有智慧的集合”，这个词来自孔子思想的追随者孟子。孟子将孔子称为圣人。因为孔子将所有前人智慧汇集在一起，所以供奉他的殿宇就称为“大成殿”。规模比较大的孔庙还要包括崇圣祠，是供奉孔子父母牌位的殿宇，有的也称启圣祠（见图3右侧最北面的建筑上的汉字）。在主要院落的东西两侧为附属建筑（另加图3右侧的孔庙图）。\n",
    "reference_list": "考点1：“太牢”必须翻译为“sacrificial ox”，因为清朝以后太牢祭祀才祭祀羊和猪，在此之前只祭祀牛，原文说的是清朝前而非清朝后。\n考点2：“唐六典”必须翻译为“Tang Liudian”，因为这是出版物译法\n考点3：“天坛”必须翻译为“the Temple of Heaven”，景点固定译法\n考点4：“地坛”必须翻译为“Temple of Earth”，景点固定译法\n考点5：“先农坛”必须翻译为“Xiannong Altar”，北京旅游网站固定译法\n考点6：“太庙”必须翻译为“the Imperial Ancestral Temple”，景点固定译法\n考点7：“家庙”推荐翻译为“clan temple”\n考点8：“武侯祠”必须译为“Wuhou Shrine”，景点固定译法\n考点9：“阙里文献考”必须译为“Study of Queli documents”，出版物译法\n考点10：“泮池”推荐翻译为“the Pan Chi”\n考点11：“大成门”必须译为“the Dacheng Gate”，景点固定译法\n考点12：“崇圣祠”必须译为“Chongsheng Shrine”，景点固定译法",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "161"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n社会主义市场经济制度优势可以实现“供给约束”突破通缩困局，调控行业供需平衡来规避经济下行风险。社会主义市场经济以国有经济为主体，提供强大的宏观调控能力，有能力实现避免资本主义市场经济周期波动。面对通货紧缩，传统凯恩斯主义的需求刺激政策因悲观预期固化而失效，如日本和欧洲案例所示，通缩环境难以通过需求刺激改善经济状况。而中国则可以发挥制度优势，通过“供给约束”策略，主动削减过剩产能或者约束产量，保护优质企业免于恶性竞争，这种制度驱动的“理性约束”不是历史的机械复归，并非回归“计划经济”。是对经济重建供需平衡，等待复苏春风的到来。\n供给侧改革已经得到验证，我国众多行业已经实现了产业升级，当前需要“供给约束”、“反内卷”来保护经济发展成果。2016年开启的供给侧结构性改革正是“供给约束”的一次成功实战验证，PPI止跌回升，企业扭亏为盈。当前在全球需求萎缩背景下，供给约束通过政策引导和法律工具，统筹各行业的产能产量，避免资源浪费和内卷，保存产业升级成果。历史证明，这不仅能缓冲经济下行，还为发展中国家提供新治理范式。\n钢铁行业产能严重过剩，央国企集中度较高利于行政手段实施，“反内卷”政策有望推动钢价修复，盈利抬升。1）钢铁行业供过于求，螺纹钢、线材产能严重过剩：中国钢铁行业2007-2024年国内持续处于供过于求状态，净出口量2024年位于近15年最高水平。2015-2021年中国钢铁企业五大钢材产能利用率在60%-80%之间波动，2021-2025年分品种来看，螺纹钢及线材产能利用率从70%左右下滑至50%左右，严重过剩。2）钢铁行业央国企产量占比显著高于民企，头部集中度较高，预期此次反内卷政策后续或约束5-10%产量：2024年钢铁重点企业中央国企产量超5亿吨，占总产量约63%，民企产量为3亿吨，占总产量约为37%。2024年钢铁重点企业产量前10家企业央国企占比7家，CR10为51%，集中度较高。目前我们预计供给侧改革2.0或约束粗钢产量5%-10%左右，下放指标主要考虑环保及碳排达标程度，我们预计政策落地后螺纹价格有望修复至3500-4000元/吨左右，盈利或增加50-100元/吨左右。3）建议关注3类标的：利润反转、利润稳定估值修复、利润稳定高分红：①利润反转：建议关注柳钢股份、太钢不锈、山东钢铁、三钢闽光、安阳钢铁等，假设在反内卷情况下，吨钢净利100元/吨，测算得出政策落地后年化PE（截至2025年7月15日）分别为5.9/6.4/8.8/10.7/13.3。②利润稳定、估值修复标的：建议关注PE＜15倍或PB＜1的钢铁企业：新钢股份、首钢股份、宝钢股份、华菱钢铁等。③利润稳定、高股息标的：建议关注鄂尔多斯、友发集团、久立特材、南钢股份、中信特钢等。\n工业金属“内卷”的本质是资源端的匮乏与冶炼端的过剩背景下的结构性失衡。1）铜冶炼：行业产能过剩，2018-2024年我国铜冶炼行业产能利用率在70-85%之间浮动，预计2025年铜冶炼上市公司增加产量85万吨，yoy+8%，行业内卷或进一步加剧，截至2025年7月TC/RC分别为-43美元/干吨、-4.3美分/磅，行业持续亏损，我们预计后续“反内卷”政策下加工费有望先恢复至近10年来最低水平——2024年均值水平，TC为11.3美元/干吨，RC为1.1美分/磅。建议关注2类标的：①规模优势企业估值修复：江西铜业、铜陵有色、紫金矿业、中金岭南等；②利润稳定高分红：西部矿业、江西铜业等。2）铅锌冶炼：我们认为铅锌行业的供给侧改革已在路上，后续具备进一步细则落实的政策空间，我们预计2025年下半年锌精矿TC预计将进一步有序回升至4000—4500元/金属吨；进口铅精矿TC预计将回升至-20美元/干吨；建议关注成本优势豫光金铅、自给率较高，具备完整产业链驰宏锌锗。3）氧化铝：氧化铝冶炼具备结构性产能优化空间，老旧产能的清退对行业盈利端的健康发展起到至关重要的作用，我们预计2025年下半年氧化铝价格将处于2800-3400元/吨区间运行，现阶段氧化铝价格的下行已充分计价，企业盈利已趋稳；建议关注有铝土矿权的中国宏桥、中国铝业、天山铝业、印尼建厂南山铝业。4）电解铝：电解铝供给端已于2017至2018年完成供给侧改革，并于今年迅速完成了其需求结构的优化，“反内卷”对其下游需求的影响较小，我们预计2025年下半年电解铝价格将处于20000—21000元/吨区间运行，企业盈利能力有望进一步增强。建议关注具备电解铝产能指标较高的中国宏桥、中国铝业；推荐绿电铝低耗能的云铝股份。",
    "ori_text": "\n\n社会主义市场经济制度优势可以实现“供给约束”突破通缩困局，调控行业供需平衡来规避经济下行风险。社会主义市场经济以国有经济为主体，提供强大的宏观调控能力，有能力实现避免资本主义市场经济周期波动。面对通货紧缩，传统凯恩斯主义的需求刺激政策因悲观预期固化而失效，如日本和欧洲案例所示，通缩环境难以通过需求刺激改善经济状况。而中国则可以发挥制度优势，通过“供给约束”策略，主动削减过剩产能或者约束产量，保护优质企业免于恶性竞争，这种制度驱动的“理性约束”不是历史的机械复归，并非回归“计划经济”。是对经济重建供需平衡，等待复苏春风的到来。\n供给侧改革已经得到验证，我国众多行业已经实现了产业升级，当前需要“供给约束”、“反内卷”来保护经济发展成果。2016年开启的供给侧结构性改革正是“供给约束”的一次成功实战验证，PPI止跌回升，企业扭亏为盈。当前在全球需求萎缩背景下，供给约束通过政策引导和法律工具，统筹各行业的产能产量，避免资源浪费和内卷，保存产业升级成果。历史证明，这不仅能缓冲经济下行，还为发展中国家提供新治理范式。\n钢铁行业产能严重过剩，央国企集中度较高利于行政手段实施，“反内卷”政策有望推动钢价修复，盈利抬升。1）钢铁行业供过于求，螺纹钢、线材产能严重过剩：中国钢铁行业2007-2024年国内持续处于供过于求状态，净出口量2024年位于近15年最高水平。2015-2021年中国钢铁企业五大钢材产能利用率在60%-80%之间波动，2021-2025年分品种来看，螺纹钢及线材产能利用率从70%左右下滑至50%左右，严重过剩。2）钢铁行业央国企产量占比显著高于民企，头部集中度较高，预期此次反内卷政策后续或约束5-10%产量：2024年钢铁重点企业中央国企产量超5亿吨，占总产量约63%，民企产量为3亿吨，占总产量约为37%。2024年钢铁重点企业产量前10家企业央国企占比7家，CR10为51%，集中度较高。目前我们预计供给侧改革2.0或约束粗钢产量5%-10%左右，下放指标主要考虑环保及碳排达标程度，我们预计政策落地后螺纹价格有望修复至3500-4000元/吨左右，盈利或增加50-100元/吨左右。3）建议关注3类标的：利润反转、利润稳定估值修复、利润稳定高分红：①利润反转：建议关注柳钢股份、太钢不锈、山东钢铁、三钢闽光、安阳钢铁等，假设在反内卷情况下，吨钢净利100元/吨，测算得出政策落地后年化PE（截至2025年7月15日）分别为5.9/6.4/8.8/10.7/13.3。②利润稳定、估值修复标的：建议关注PE＜15倍或PB＜1的钢铁企业：新钢股份、首钢股份、宝钢股份、华菱钢铁等。③利润稳定、高股息标的：建议关注鄂尔多斯、友发集团、久立特材、南钢股份、中信特钢等。\n工业金属“内卷”的本质是资源端的匮乏与冶炼端的过剩背景下的结构性失衡。1）铜冶炼：行业产能过剩，2018-2024年我国铜冶炼行业产能利用率在70-85%之间浮动，预计2025年铜冶炼上市公司增加产量85万吨，yoy+8%，行业内卷或进一步加剧，截至2025年7月TC/RC分别为-43美元/干吨、-4.3美分/磅，行业持续亏损，我们预计后续“反内卷”政策下加工费有望先恢复至近10年来最低水平——2024年均值水平，TC为11.3美元/干吨，RC为1.1美分/磅。建议关注2类标的：①规模优势企业估值修复：江西铜业、铜陵有色、紫金矿业、中金岭南等；②利润稳定高分红：西部矿业、江西铜业等。2）铅锌冶炼：我们认为铅锌行业的供给侧改革已在路上，后续具备进一步细则落实的政策空间，我们预计2025年下半年锌精矿TC预计将进一步有序回升至4000—4500元/金属吨；进口铅精矿TC预计将回升至-20美元/干吨；建议关注成本优势豫光金铅、自给率较高，具备完整产业链驰宏锌锗。3）氧化铝：氧化铝冶炼具备结构性产能优化空间，老旧产能的清退对行业盈利端的健康发展起到至关重要的作用，我们预计2025年下半年氧化铝价格将处于2800-3400元/吨区间运行，现阶段氧化铝价格的下行已充分计价，企业盈利已趋稳；建议关注有铝土矿权的中国宏桥、中国铝业、天山铝业、印尼建厂南山铝业。4）电解铝：电解铝供给端已于2017至2018年完成供给侧改革，并于今年迅速完成了其需求结构的优化，“反内卷”对其下游需求的影响较小，我们预计2025年下半年电解铝价格将处于20000—21000元/吨区间运行，企业盈利能力有望进一步增强。建议关注具备电解铝产能指标较高的中国宏桥、中国铝业；推荐绿电铝低耗能的云铝股份。",
    "reference_list": "考点1：复苏春风 推荐译为 economic recovery，原文表达的是经济复苏的意思，“春风”作为无实际意义的修辞可以选择不做直译\n考点2：反内卷 推荐译为 anti-rat-race\n考点3：中信特钢 必须译为 Citic Pacific Special Steel Group Co.,Ltd.，不可译为“CITIC Metal\"\n考点4：中金岭南 必须译为 Shenzhen Zhongjin Lingnan Nonfemet Co.Ltd.，不可译为“China Minmetals Corporation”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "181"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nSynthesis and characterization of BTO photocatalysts\nAs a layered structural two-dimensional material, BTO is characterized by regular stacking of bismuth oxygen [Bi2O2]2+ slabs and perovskite-like [Bi2Ti3O10]2– blocks, in which Bi–O bond can be etched via the interaction of proton and halide ion. Briefly, pristine single-crystal BTO was firstly prepared by a salt-assisted solid-state reaction. Due to the different structural stability of exposed crystal facets, the [Bi2O2]2+ structure of {001} crystal facet and Bi–O bond of {010} crystal facet of BTO can be selectively preferentially etched (Supplementary Fig. 1 and Supplementary Note 1). Also, the Ti–O bond of BTO {001} will prevent further etching of {001} crystal facet after etching [Bi2O2]2+, ultimately leading to the formation of a hollow structure along the edge region. Scanning electron microscopy (SEM) images show the pristine BTO with an evident nanosheet morphology. When HCl etching was conducted, the etched edge gradually became highly visible with the extension of the etching time to 2 h (Fig. 1a and Supplementary Fig. 2). However, the particle size or crystallite size of samples had no significant change, but the obvious difference of specific surface area occurs before and after acid etching (Supplementary Fig. 3 and Supplementary Table 1). When the etching time extended to 4 h, the BTO-4 shows that the nanosheets are broken with impurities due to nucleation of TiO2 (Supplementary Fig. 4). X-ray diffraction (XRD) pattern indicates the same crystal structure between the pristine and the etched BTO within 2 h (Fig. 1b). However, the crystallinity of the etched BTO is gradually weakened with further extension of etching time (Fig. 1c). Unsurprisingly, the over-etched BTO-4 shows a mixed structure of BTO and TiO2 (Supplementary Figs. 5 to 6 and Supplementary Note 2). Similarly, under the same concentration as HCl, the HBr-treated BTO sample shows similar crystal structure and morphology (Supplementary Figs. 7 and 8). The control experiments were performed with HNO3 and H2SO4 treated pristine BTO under the same concentration as HCl. The XRD results indicate the same crystal structure as BTO (Supplementary Fig. 9). And the edge region of BTO has not been etched (Supplementary Fig. 10). Further, an atomic force microscope (AFM) was used to investigate the thickness change before and after etching for different periods. No significant change appears in the overall thickness before and after etching and between the center and edge of the etched BTO (Supplementary Fig. 11). Furthermore, a highly hollow edge structure was observed by the SEM image, and the corresponding elemental mapping reveals the uniform distributions of Bi and Ti elements (Supplementary Fig. 12). Other SEM images, the corresponding elemental mapping, and linear scan elemental analysis are provided in Supplementary Figs. 13–15, and the results proved the uniform distributions of Bi, Ti, and O elements in both the center and the edge region of BTO with and without HCl treatment.\nFurther characterization of the local structure of the etched BTO was carried out under high-resolution transmission electron microscopy (HRTEM). An evident thickness variation contrast occurred between the central and the edge regions of transmission electron microscopy (TEM) image because of the etching effect (Fig. 2a). The HRTEM image exhibits the same lattice orientation and lattice fringes between the edge and the central regions of the etched BTO (Figs. 2b,c), indicating the single crystalline nature of the structure. Furthermore, the same diffraction patterns further confirm the single-crystal structure by selected area electron diffraction (SAED) at different locations (Figs. 2d and 2e). Accordingly, the chemical valence states of elements were also characterized by X-ray photoelectron spectroscopy (XPS). Due to the gradually etched depth of the structure, the chemical states of the surface elements change in a dynamically evolving manner, especially for Ti and Bi. Evidently, as shown in Fig. 2f, the binding energy of Ti 2p gradually shifts towards a higher value, which comes from the increasing proportion of the Ti–O structures exposed on the surface because of the Ti element binding more high-energy O (hydroxyls and water molecules). Due to the change of lattice oxygen (Bi–O and Ti–O) structure on the exposed surface, the binding energy of O 1 s shifts to higher value at the same time (Supplementary Fig. 16a). In contrast, the corresponding Bi 4 f peak slightly shifts downward in binding energy with increasing extent of the acid etching, because the outside high binding energy Bi of [Bi2O2]2+ layer and [Bi2Ti3O10]2– was etched away. Although the binding energies of Bi and Ti evolve, the main structure of samples keeps unchanged during the etching process (Fig. 2g). No Cl element was observed during the etching process, indicating that the nucleation of bismuth oxyhalide was inhibited (Supplementary Fig. 16b). In addition, the structural change should be accompanied by the evolution of the band structure. The band gap slightly increases with the extension of the etching, which is due to the change of the band structure by the spatial size effect, which is mainly from the ultrathin hollow edge (Supplementary Figs. 17–19). With the increase of edge etching depth, the trend of band structure change is more obvious. Meanwhile, the difference in the band structures between the unetched part and adjacent etched BTO will form “homojunction”, which are beneficial to the transfer of electrons to the surface of the photocatalyst. Also, due to TiO2 impurities resulting from structural destruction caused by the excessive etching, the BTO-4 further shows the bigger band gap and evident differences from BTO in light absorption behavior. However, such a small change of bandgaps is not expected to influence the photocatalytic performance.\nFurther understanding the charge distribution on the crystal surface is helpful to explore the process of photocatalytic water splitting. SPVM is an effective tool for spatial correlation between photogenerated charge distribution and structural morphology, as well as the dependence between light absorption and carrier migration and transfer46,47. As shown in Figs. 3a–f, photogenerated electrons were imaged in the surface due to negative SPV. With the increasing wavelength of illumination light, the intensity of the SPV decreases, which is consistent with the behavior of the light absorption spectrum, which proves that the charge generation is driven by light (Supplementary Fig. 17 and Fig. 3g). The difference is that when the light irradiated the surface of photocatalyst, the charge distribution intensity varies between the edge and the middle of the sample. This phenomenon is very interesting and differs from most of the results reported in the literatures. We speculate the carrier distribution is dependent on the space geometry. Differential SPV analysis was performed at different positions of a given facet and the differences were compared at the three positions. The corresponding results are shown in Figs. 3a–f. The SPV is significantly different with the change of light wavelength at the three locations of α1, α2 and α3. Therefore, the intensity of SPV varies from the edge to the middle position, which induces a directional movement of surface-generated electrons, leading to effective photogenerated carrier separation compared with pristine BTO (Supplementary Fig. 20). Combined with the previous results, we find that the electron transfer is related to the spatial morphology and structure. The hollow regions with etched edges possess abundant photogenerated electrons, which is mainly because the regions with thin edges can accelerate electron migration to the surface from the bulk and center. In order to further determine the transfer and the regional distribution of electrons, the deposition of Au on BTO was performed with and without acid treatment. The random distribution of Au nanoparticle can be observed on the surfaces of pristine BTO in Fig. 3h. Not surprisingly, it is found to be preferentially deposited on the edge area of surface crystal facets of BTO-2 in Fig. 3i, which shows a special behavior, that is, spatially differentiated structure induces the differentiated distribution of electrons. A fast electron transfer dynamic will be promoted due to the electron differentiated distribution, which is beneficial to photogenerated charge separation for efficient OWS (Fig. 3j).\nThe process of photocatalysis is largely limited by the separation and transfer of photogenerated charge carriers. The lifetime and transfer dynamic were characterized by photoluminescence (PL) and time-resolved photoluminescence (TRPL). Both pristine BTO and etched BTO show an evident PL peak at 485 nm (Supplementary Fig. 21). The PL intensity of the etched BTO gradually decreases with etching time, indicating a decrease in the number of excitons due to carries’ effective separation. We carried out TRPL to monitor the charge carrier dynamics on the nanosecond time-scale. As shown in the Fig. 4a, the carrier lifetime curve conforms to a multi-exponential decay function, which can be fitted by different parameters. The average lifetime is 3.64 ns for pristine BTO, which is longer than that of the etched BTO. And the average carrier lifetime gradually reduces with the duration of HCl treatment (3.28 ns for BTO-0.25, 2.71 ns for BTO-0.5, 2.34 ns for BTO-1, and 1.69 ns for BTO-2), representing that charge carriers’ transfer and lifetime is dependent on spatial morphology. Specifically, the faster decay lifetime of τ1 of etched BTO is longer than that of pristine BTO and the contribution of fast decay of τ1 increases largely from 34% for BTO to 85% for BTO-2, confirming the suppression of the inter-band recombination and fast electron transfer of the etched BTO due to the homojunction between the edge and the center. Also, combined with the morphological analysis, the decreased lifetime is gentle at the initial stages of etching, which is because the etching time is relatively short and only the surface Bi–O layer is etched (Fig. 4b). With increasing duration of the etching, the carrier’s lifetime of the sample rapidly declines, which is positively correlated to the etching depth due to the formation of the homojunction and the ultrathin edge, where the electrons of the etched edge will be accelerated and transferred to the surface compared with the center part of the BTO (Fig. 4c). Moreover, we further demonstrated the rapid interfacial electron transport performance. The etched BTO shows a larger photocurrent than that of the pristine BTO. And it is found that a positively correlation of the photocurrent with the etching depth for etched BTO (Supplementary Fig. 22a). The electrochemical impedance spectroscopy (EIS) measurements and analyses also reveal fast electron transport of the etched BTO. The radius of the fitted curve reflects the strength of the transfer of semiconductor electrons, that is, the smaller the radius indicates the faster the electron transfer. As shown in the impedance curves (Supplementary Fig. 22b), the BTO-2 shows the smallest electrochemical impedance, implying the fastest electron transport among the photocatalysts.\n\n",
    "ori_text": "\n\nSynthesis and characterization of BTO photocatalysts\nAs a layered structural two-dimensional material, BTO is characterized by regular stacking of bismuth oxygen [Bi2O2]2+ slabs and perovskite-like [Bi2Ti3O10]2– blocks, in which Bi–O bond can be etched via the interaction of proton and halide ion. Briefly, pristine single-crystal BTO was firstly prepared by a salt-assisted solid-state reaction. Due to the different structural stability of exposed crystal facets, the [Bi2O2]2+ structure of {001} crystal facet and Bi–O bond of {010} crystal facet of BTO can be selectively preferentially etched (Supplementary Fig. 1 and Supplementary Note 1). Also, the Ti–O bond of BTO {001} will prevent further etching of {001} crystal facet after etching [Bi2O2]2+, ultimately leading to the formation of a hollow structure along the edge region. Scanning electron microscopy (SEM) images show the pristine BTO with an evident nanosheet morphology. When HCl etching was conducted, the etched edge gradually became highly visible with the extension of the etching time to 2 h (Fig. 1a and Supplementary Fig. 2). However, the particle size or crystallite size of samples had no significant change, but the obvious difference of specific surface area occurs before and after acid etching (Supplementary Fig. 3 and Supplementary Table 1). When the etching time extended to 4 h, the BTO-4 shows that the nanosheets are broken with impurities due to nucleation of TiO2 (Supplementary Fig. 4). X-ray diffraction (XRD) pattern indicates the same crystal structure between the pristine and the etched BTO within 2 h (Fig. 1b). However, the crystallinity of the etched BTO is gradually weakened with further extension of etching time (Fig. 1c). Unsurprisingly, the over-etched BTO-4 shows a mixed structure of BTO and TiO2 (Supplementary Figs. 5 to 6 and Supplementary Note 2). Similarly, under the same concentration as HCl, the HBr-treated BTO sample shows similar crystal structure and morphology (Supplementary Figs. 7 and 8). The control experiments were performed with HNO3 and H2SO4 treated pristine BTO under the same concentration as HCl. The XRD results indicate the same crystal structure as BTO (Supplementary Fig. 9). And the edge region of BTO has not been etched (Supplementary Fig. 10). Further, an atomic force microscope (AFM) was used to investigate the thickness change before and after etching for different periods. No significant change appears in the overall thickness before and after etching and between the center and edge of the etched BTO (Supplementary Fig. 11). Furthermore, a highly hollow edge structure was observed by the SEM image, and the corresponding elemental mapping reveals the uniform distributions of Bi and Ti elements (Supplementary Fig. 12). Other SEM images, the corresponding elemental mapping, and linear scan elemental analysis are provided in Supplementary Figs. 13–15, and the results proved the uniform distributions of Bi, Ti, and O elements in both the center and the edge region of BTO with and without HCl treatment.\nFurther characterization of the local structure of the etched BTO was carried out under high-resolution transmission electron microscopy (HRTEM). An evident thickness variation contrast occurred between the central and the edge regions of transmission electron microscopy (TEM) image because of the etching effect (Fig. 2a). The HRTEM image exhibits the same lattice orientation and lattice fringes between the edge and the central regions of the etched BTO (Figs. 2b,c), indicating the single crystalline nature of the structure. Furthermore, the same diffraction patterns further confirm the single-crystal structure by selected area electron diffraction (SAED) at different locations (Figs. 2d and 2e). Accordingly, the chemical valence states of elements were also characterized by X-ray photoelectron spectroscopy (XPS). Due to the gradually etched depth of the structure, the chemical states of the surface elements change in a dynamically evolving manner, especially for Ti and Bi. Evidently, as shown in Fig. 2f, the binding energy of Ti 2p gradually shifts towards a higher value, which comes from the increasing proportion of the Ti–O structures exposed on the surface because of the Ti element binding more high-energy O (hydroxyls and water molecules). Due to the change of lattice oxygen (Bi–O and Ti–O) structure on the exposed surface, the binding energy of O 1 s shifts to higher value at the same time (Supplementary Fig. 16a). In contrast, the corresponding Bi 4 f peak slightly shifts downward in binding energy with increasing extent of the acid etching, because the outside high binding energy Bi of [Bi2O2]2+ layer and [Bi2Ti3O10]2– was etched away. Although the binding energies of Bi and Ti evolve, the main structure of samples keeps unchanged during the etching process (Fig. 2g). No Cl element was observed during the etching process, indicating that the nucleation of bismuth oxyhalide was inhibited (Supplementary Fig. 16b). In addition, the structural change should be accompanied by the evolution of the band structure. The band gap slightly increases with the extension of the etching, which is due to the change of the band structure by the spatial size effect, which is mainly from the ultrathin hollow edge (Supplementary Figs. 17–19). With the increase of edge etching depth, the trend of band structure change is more obvious. Meanwhile, the difference in the band structures between the unetched part and adjacent etched BTO will form “homojunction”, which are beneficial to the transfer of electrons to the surface of the photocatalyst. Also, due to TiO2 impurities resulting from structural destruction caused by the excessive etching, the BTO-4 further shows the bigger band gap and evident differences from BTO in light absorption behavior. However, such a small change of bandgaps is not expected to influence the photocatalytic performance.\nFurther understanding the charge distribution on the crystal surface is helpful to explore the process of photocatalytic water splitting. SPVM is an effective tool for spatial correlation between photogenerated charge distribution and structural morphology, as well as the dependence between light absorption and carrier migration and transfer46,47. As shown in Figs. 3a–f, photogenerated electrons were imaged in the surface due to negative SPV. With the increasing wavelength of illumination light, the intensity of the SPV decreases, which is consistent with the behavior of the light absorption spectrum, which proves that the charge generation is driven by light (Supplementary Fig. 17 and Fig. 3g). The difference is that when the light irradiated the surface of photocatalyst, the charge distribution intensity varies between the edge and the middle of the sample. This phenomenon is very interesting and differs from most of the results reported in the literatures. We speculate the carrier distribution is dependent on the space geometry. Differential SPV analysis was performed at different positions of a given facet and the differences were compared at the three positions. The corresponding results are shown in Figs. 3a–f. The SPV is significantly different with the change of light wavelength at the three locations of α1, α2 and α3. Therefore, the intensity of SPV varies from the edge to the middle position, which induces a directional movement of surface-generated electrons, leading to effective photogenerated carrier separation compared with pristine BTO (Supplementary Fig. 20). Combined with the previous results, we find that the electron transfer is related to the spatial morphology and structure. The hollow regions with etched edges possess abundant photogenerated electrons, which is mainly because the regions with thin edges can accelerate electron migration to the surface from the bulk and center. In order to further determine the transfer and the regional distribution of electrons, the deposition of Au on BTO was performed with and without acid treatment. The random distribution of Au nanoparticle can be observed on the surfaces of pristine BTO in Fig. 3h. Not surprisingly, it is found to be preferentially deposited on the edge area of surface crystal facets of BTO-2 in Fig. 3i, which shows a special behavior, that is, spatially differentiated structure induces the differentiated distribution of electrons. A fast electron transfer dynamic will be promoted due to the electron differentiated distribution, which is beneficial to photogenerated charge separation for efficient OWS (Fig. 3j).\nThe process of photocatalysis is largely limited by the separation and transfer of photogenerated charge carriers. The lifetime and transfer dynamic were characterized by photoluminescence (PL) and time-resolved photoluminescence (TRPL). Both pristine BTO and etched BTO show an evident PL peak at 485 nm (Supplementary Fig. 21). The PL intensity of the etched BTO gradually decreases with etching time, indicating a decrease in the number of excitons due to carries’ effective separation. We carried out TRPL to monitor the charge carrier dynamics on the nanosecond time-scale. As shown in the Fig. 4a, the carrier lifetime curve conforms to a multi-exponential decay function, which can be fitted by different parameters. The average lifetime is 3.64 ns for pristine BTO, which is longer than that of the etched BTO. And the average carrier lifetime gradually reduces with the duration of HCl treatment (3.28 ns for BTO-0.25, 2.71 ns for BTO-0.5, 2.34 ns for BTO-1, and 1.69 ns for BTO-2), representing that charge carriers’ transfer and lifetime is dependent on spatial morphology. Specifically, the faster decay lifetime of τ1 of etched BTO is longer than that of pristine BTO and the contribution of fast decay of τ1 increases largely from 34% for BTO to 85% for BTO-2, confirming the suppression of the inter-band recombination and fast electron transfer of the etched BTO due to the homojunction between the edge and the center. Also, combined with the morphological analysis, the decreased lifetime is gentle at the initial stages of etching, which is because the etching time is relatively short and only the surface Bi–O layer is etched (Fig. 4b). With increasing duration of the etching, the carrier’s lifetime of the sample rapidly declines, which is positively correlated to the etching depth due to the formation of the homojunction and the ultrathin edge, where the electrons of the etched edge will be accelerated and transferred to the surface compared with the center part of the BTO (Fig. 4c). Moreover, we further demonstrated the rapid interfacial electron transport performance. The etched BTO shows a larger photocurrent than that of the pristine BTO. And it is found that a positively correlation of the photocurrent with the etching depth for etched BTO (Supplementary Fig. 22a). The electrochemical impedance spectroscopy (EIS) measurements and analyses also reveal fast electron transport of the etched BTO. The radius of the fitted curve reflects the strength of the transfer of semiconductor electrons, that is, the smaller the radius indicates the faster the electron transfer. As shown in the impedance curves (Supplementary Fig. 22b), the BTO-2 shows the smallest electrochemical impedance, implying the fastest electron transport among the photocatalysts.\n\n",
    "reference_list": "考点1：“Homojunction” 必须译为 ”同质结”\n考点2：“Salt-assisted solid-state reaction” 推荐译为 ”熔盐辅助固相反应”\n考点3：“Over-etched” 必须译为 ”过度刻蚀”\n考点4：“Carrier migration and transfer” 必须译为”载流子迁移与传输”\n考点5：“Electron differentiated distribution” 必须译为 ”电子差异化分布”\n考点6：“Particle size” 推荐译为 ”粒径/颗粒尺寸”\n考点7：“Control experiments” 必须译为 ”对照实验”\n考点8：“Dynamically evolving manner” 必须译为 ”动态演化方式”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "144"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nSummary \nWhy did some (but not all) Chinese dynasties invest huge amounts of resources in the construction of ‘Great Walls’? The proposed project will focus on precisely that question, in an attempt to unravel what is, perhaps, the most enigmatic episode of ‘Great Wall’ construction. Roughly dated to the 10th-13th centuries CE and located far to the north of other ‘Great Wall’ lines, this Medieval Wall System (MWS) is one of the longest walls ever constructed in world history, stretching over more than 3,500 km and including large auxiliary structures. The amount of resources invested in this MWS must have been enormous, but historical sources are mute about its construction, and modern scholarship is unable to date it precisely or understand why it was built and how it functioned. \nThe motives behind the construction of the MWS, its political context and ecological implications, are highly relevant for the understanding of the complex history of China and Mongolia on the eve of Chinggis Khan’s rise to power. However, because in the past scholars have assumed that ‘Great Walls’ were fortified border lines designed to stop military incursions, such issues’ impetus and consequences were never addressed. Hence, the proposed project will put forward novel hypotheses, analyse them by using advanced recovery and analytical methods, and examine them against a broad archaeological, historical, environmental, and geographical background. The research hypothesis of the proposed project is that the MWS was not built as a defence against invading armies, but rather as a means to monitor and sometimes stop the movement of nomadic people and their herds. The large scale movements of nomadic people towards more central areas of the empire happened, I would suggest, in times of ecological stress in the Steppe.\n\nObjectives \nWhy did some (but not all) Chinese dynasties invest huge amounts of resources in the construction of ‘Great Walls’? The proposed project will focus on precisely that question, in an attempt to unravel what is, perhaps, the most enigmatic episode of ‘Great Wall’ construction. This wall system is located in North China and Mongolia and covers a distance of over 3,500 km. However, if one takes into account the different parallel lines, their accumulated length is probably closer to 6,500 km, making it one of the longest walls ever constructed in world history.\nNotwithstanding its huge size and the vast resources, material and human, that must have been invested in its construction, it is unclear who built it and for what purpose(s). The construction of this complex system, which includes long earthen walls and accompanying ditches, auxiliary structures (camps, beacon towers, etc.) and roads, is dated roughly to the 10th to 13th centuries CE, but its construction is not described in any of the relevant historical chronicles. Moreover, very little historical and archaeological research has been done on it. This Medieval Wall System (MWS) is enigmatic not only because its history is obscure, but also because it is located deep in the Steppe area, hundreds of kilometres north and west of earlier and later lines of the so-called ‘Great Wall of China’. \nThe proposed project shall address some of the fundamental questions regarding the MWS: When was it built and for how long was it in use? Who built it? For what purposes? What was the structure of the MWS (including the associated features) and how did it function? What amount of human labour and other resources were necessary in order to build it? On a more fundamental level, this project will attempt to answer the more basic question: What was the logic behind the construction of such long and enormously expensive linear barriers (‘Great Walls’) by several Chinese dynasties (and other polities in the pre-modern world)? What were the political preconditions for such monumental works? How, if at all, did wall construction relate to climatic changes and ecological conditions? These issues were not addressed properly in the past, first and foremost because scholars have assumed that ‘Great Walls’ were fortified border lines designed to stop military incursions. The proposed research will suggest novel hypotheses, never previously considered, and examine them using advanced recovery and analytical methods, integrating archaeological, historical, environmental, and geographical data.\n\nResearch Hypothesis and Expected Breakthroughs \nThe construction of long-walls is not a Chinese phenomenon, as they are also known from other ancient civilizations throughout the Old World. Notable examples are the Roman limes and the Sasanian Gorgān and Tammīsheh walls. However, the most extensive examples in time, space and amount of labour invested in their construction, are the walls built by Chinese empires. The so-called ‘Great Wall of China’ is, in fact, a series of walls constructed by different dynasties at different times. Each of those walls extends over hundreds, sometimes even thousands, of kilometres and is accompanied by auxiliary structures (camps, beacon towers, etc.) and roads. Estimates of the amount of work required to build these walls vary, but it was suggested, for example, that it took a working force of at least 300,000 men five years to construct the earliest, and by no means the most extensive, Chinese wall system. \nWhile Chinese dynasties constructed the most extensive wall-systems the world has ever seen, many dynasties in China did not construct long-walls. Apart from the construction of several different walls by pre-dynastic states of the Warring States period (481-221 BCE), long-walls were constructed during four main episodes over the last two millennia: the Qin and Western Han dynasties (the 3rd to 1st centuries BCE); the Northern Wei and Northern Qi dynasties (5th and 6th centuries CE); the Liao-Jin dynasties (11th or 12th and 13th centuries); and the Ming dynasty (15th and 16th centuries). \nA traditional view describes the ‘Great Wall’ as a symbolic and real demarcation of a cultural-ecological line that separates two distinct ways of life: the pastoral-nomadism of the Steppe and desert areas, on the one hand, and sedentary agricultural societies, on the other. Consequently, modern scholarship identifies the walls as a fortified border intended to stop nomadic armies from invading China. This paradigm of Chinese long-walls (including the MWS) as military installations has never been challenged, although disagreement regarding the motivation \nfor ‘Great Wall’ construction exists between scholars who see them as defensive structures against the aggression of nomadic tribes and those who argue that ‘Great Walls’ were part of the Chinese imperial expansion and conquest of lands previously inhabited by nomads. And yet, a superficial examination of the MWS suggests that it is at odds with many of the fundamental assumptions of the accepted paradigm. For example, the MWS is located deep in the Steppe zone (and, in a few of its southern parts, inside the desert area), and does not demarcate any cultural-ecological border. Moreover, although we do not know who constructed this wall, the two main candidates are the Liao and the Jin dynasties, both of which were founded by nomadic or semi-nomadic peoples, and subsequently their concept of empire had more to do with control over people, many of them nomads, rather than forming clearly defined land borders. In addition, a preliminary analysis based on pilot field work and GIS analysis suggests that the location and structure of the wall and the auxiliary structures associated with it are not compatible with what we might expect from a military installation that was meant to defend the border against invading armies. \nBased on this preliminary information, the research hypothesis of the proposed project is that the MWS, and probably many of the other episodes of ‘Great Wall’ construction in Chinese history, were built to monitor and sometimes stop movements of people rather than armies. It is highly plausible that the walls were built during periods of large-scale movements of nomadic people towards more central areas of the empire. An additional hypothesis, as to why such control was needed, suggests that extreme climatic anomalies, especially concentrations of cold spells and droughts, must have affected the fragile ecology of the Steppe. \nThe devastating effects of these climatic phenomena, known as dzud in Mongolian, on communities of nomadic pastoralists, are well documented in historical and modern periods. For example, between 2000-2002, and again in the winter of 2009-2010, intense cold conditions caused the death of 20% to 40% of all livestock, causing mass migration of herders to the Mongolian capital, Ulaanbaatar. Whereas sporadic and local occurrences of such events are common, a concentration of extreme events over a period of ten to twenty years must have an acute socio-economic impact. The 10th-14th centuries were a period of climatic instability, known as the Medieval Climate Anomaly. \nAlthough this global phenomenon did not have the same effect on the local ecologies of different places throughout Eurasia, recent research has started to flesh out the ways in which it catalysed economic crisis, socio-political unrest, and large-scale migration in the Mediterranean and West Asia, as well as in East Asia. If these hypotheses (or some of them) are confirmed for the MWS, it will change our understanding of the complex history of the region during the centuries prior to Chinggis Khan’s rise to power. These hypotheses may not account for all the episodes of ‘Great Wall’ construction in China. For example, the wall constructed by the Ming dynasty is much more massive than that of earlier periods. Although it was not successful in defending the Ming, there are historic accounts of it being a formidable military obstacle. However, the model developed by this research can serve to explain some of the other episodes of ‘Great Wall’ construction in Chinese history and change our perception of the conditions that triggered wall building in China, the purposes for which these walls were built, and their function. Understanding the background and reasons for wall construction will thus contribute to a better understanding of the decision and policy-making of Chinese dynasties, and of the dynastic system more generally. Such insights could be applicable to the analysis of long-walls of other civilizations. For example, the famous Hadrian’s Wall, which is seen by many as the fortified border line par excellence, has a gate every Roman mile (1,479 m). It is suggested that creating so many openings in the wall was intended to enable, but also to supervise, the civilian movement of traders and, perhaps, transhumance.",
    "ori_text": "\n\nSummary \nWhy did some (but not all) Chinese dynasties invest huge amounts of resources in the construction of ‘Great Walls’? The proposed project will focus on precisely that question, in an attempt to unravel what is, perhaps, the most enigmatic episode of ‘Great Wall’ construction. Roughly dated to the 10th-13th centuries CE and located far to the north of other ‘Great Wall’ lines, this Medieval Wall System (MWS) is one of the longest walls ever constructed in world history, stretching over more than 3,500 km and including large auxiliary structures. The amount of resources invested in this MWS must have been enormous, but historical sources are mute about its construction, and modern scholarship is unable to date it precisely or understand why it was built and how it functioned. \nThe motives behind the construction of the MWS, its political context and ecological implications, are highly relevant for the understanding of the complex history of China and Mongolia on the eve of Chinggis Khan’s rise to power. However, because in the past scholars have assumed that ‘Great Walls’ were fortified border lines designed to stop military incursions, such issues’ impetus and consequences were never addressed. Hence, the proposed project will put forward novel hypotheses, analyse them by using advanced recovery and analytical methods, and examine them against a broad archaeological, historical, environmental, and geographical background. The research hypothesis of the proposed project is that the MWS was not built as a defence against invading armies, but rather as a means to monitor and sometimes stop the movement of nomadic people and their herds. The large scale movements of nomadic people towards more central areas of the empire happened, I would suggest, in times of ecological stress in the Steppe.\n\nObjectives \nWhy did some (but not all) Chinese dynasties invest huge amounts of resources in the construction of ‘Great Walls’? The proposed project will focus on precisely that question, in an attempt to unravel what is, perhaps, the most enigmatic episode of ‘Great Wall’ construction. This wall system is located in North China and Mongolia and covers a distance of over 3,500 km. However, if one takes into account the different parallel lines, their accumulated length is probably closer to 6,500 km, making it one of the longest walls ever constructed in world history.\nNotwithstanding its huge size and the vast resources, material and human, that must have been invested in its construction, it is unclear who built it and for what purpose(s). The construction of this complex system, which includes long earthen walls and accompanying ditches, auxiliary structures (camps, beacon towers, etc.) and roads, is dated roughly to the 10th to 13th centuries CE, but its construction is not described in any of the relevant historical chronicles. Moreover, very little historical and archaeological research has been done on it. This Medieval Wall System (MWS) is enigmatic not only because its history is obscure, but also because it is located deep in the Steppe area, hundreds of kilometres north and west of earlier and later lines of the so-called ‘Great Wall of China’. \nThe proposed project shall address some of the fundamental questions regarding the MWS: When was it built and for how long was it in use? Who built it? For what purposes? What was the structure of the MWS (including the associated features) and how did it function? What amount of human labour and other resources were necessary in order to build it? On a more fundamental level, this project will attempt to answer the more basic question: What was the logic behind the construction of such long and enormously expensive linear barriers (‘Great Walls’) by several Chinese dynasties (and other polities in the pre-modern world)? What were the political preconditions for such monumental works? How, if at all, did wall construction relate to climatic changes and ecological conditions? These issues were not addressed properly in the past, first and foremost because scholars have assumed that ‘Great Walls’ were fortified border lines designed to stop military incursions. The proposed research will suggest novel hypotheses, never previously considered, and examine them using advanced recovery and analytical methods, integrating archaeological, historical, environmental, and geographical data.\n\nResearch Hypothesis and Expected Breakthroughs \nThe construction of long-walls is not a Chinese phenomenon, as they are also known from other ancient civilizations throughout the Old World. Notable examples are the Roman limes and the Sasanian Gorgān and Tammīsheh walls. However, the most extensive examples in time, space and amount of labour invested in their construction, are the walls built by Chinese empires. The so-called ‘Great Wall of China’ is, in fact, a series of walls constructed by different dynasties at different times. Each of those walls extends over hundreds, sometimes even thousands, of kilometres and is accompanied by auxiliary structures (camps, beacon towers, etc.) and roads. Estimates of the amount of work required to build these walls vary, but it was suggested, for example, that it took a working force of at least 300,000 men five years to construct the earliest, and by no means the most extensive, Chinese wall system. \nWhile Chinese dynasties constructed the most extensive wall-systems the world has ever seen, many dynasties in China did not construct long-walls. Apart from the construction of several different walls by pre-dynastic states of the Warring States period (481-221 BCE), long-walls were constructed during four main episodes over the last two millennia: the Qin and Western Han dynasties (the 3rd to 1st centuries BCE); the Northern Wei and Northern Qi dynasties (5th and 6th centuries CE); the Liao-Jin dynasties (11th or 12th and 13th centuries); and the Ming dynasty (15th and 16th centuries). \nA traditional view describes the ‘Great Wall’ as a symbolic and real demarcation of a cultural-ecological line that separates two distinct ways of life: the pastoral-nomadism of the Steppe and desert areas, on the one hand, and sedentary agricultural societies, on the other. Consequently, modern scholarship identifies the walls as a fortified border intended to stop nomadic armies from invading China. This paradigm of Chinese long-walls (including the MWS) as military installations has never been challenged, although disagreement regarding the motivation \nfor ‘Great Wall’ construction exists between scholars who see them as defensive structures against the aggression of nomadic tribes and those who argue that ‘Great Walls’ were part of the Chinese imperial expansion and conquest of lands previously inhabited by nomads. And yet, a superficial examination of the MWS suggests that it is at odds with many of the fundamental assumptions of the accepted paradigm. For example, the MWS is located deep in the Steppe zone (and, in a few of its southern parts, inside the desert area), and does not demarcate any cultural-ecological border. Moreover, although we do not know who constructed this wall, the two main candidates are the Liao and the Jin dynasties, both of which were founded by nomadic or semi-nomadic peoples, and subsequently their concept of empire had more to do with control over people, many of them nomads, rather than forming clearly defined land borders. In addition, a preliminary analysis based on pilot field work and GIS analysis suggests that the location and structure of the wall and the auxiliary structures associated with it are not compatible with what we might expect from a military installation that was meant to defend the border against invading armies. \nBased on this preliminary information, the research hypothesis of the proposed project is that the MWS, and probably many of the other episodes of ‘Great Wall’ construction in Chinese history, were built to monitor and sometimes stop movements of people rather than armies. It is highly plausible that the walls were built during periods of large-scale movements of nomadic people towards more central areas of the empire. An additional hypothesis, as to why such control was needed, suggests that extreme climatic anomalies, especially concentrations of cold spells and droughts, must have affected the fragile ecology of the Steppe. \nThe devastating effects of these climatic phenomena, known as dzud in Mongolian, on communities of nomadic pastoralists, are well documented in historical and modern periods. For example, between 2000-2002, and again in the winter of 2009-2010, intense cold conditions caused the death of 20% to 40% of all livestock, causing mass migration of herders to the Mongolian capital, Ulaanbaatar. Whereas sporadic and local occurrences of such events are common, a concentration of extreme events over a period of ten to twenty years must have an acute socio-economic impact. The 10th-14th centuries were a period of climatic instability, known as the Medieval Climate Anomaly. \nAlthough this global phenomenon did not have the same effect on the local ecologies of different places throughout Eurasia, recent research has started to flesh out the ways in which it catalysed economic crisis, socio-political unrest, and large-scale migration in the Mediterranean and West Asia, as well as in East Asia. If these hypotheses (or some of them) are confirmed for the MWS, it will change our understanding of the complex history of the region during the centuries prior to Chinggis Khan’s rise to power. These hypotheses may not account for all the episodes of ‘Great Wall’ construction in China. For example, the wall constructed by the Ming dynasty is much more massive than that of earlier periods. Although it was not successful in defending the Ming, there are historic accounts of it being a formidable military obstacle. However, the model developed by this research can serve to explain some of the other episodes of ‘Great Wall’ construction in Chinese history and change our perception of the conditions that triggered wall building in China, the purposes for which these walls were built, and their function. Understanding the background and reasons for wall construction will thus contribute to a better understanding of the decision and policy-making of Chinese dynasties, and of the dynastic system more generally. Such insights could be applicable to the analysis of long-walls of other civilizations. For example, the famous Hadrian’s Wall, which is seen by many as the fortified border line par excellence, has a gate every Roman mile (1,479 m). It is suggested that creating so many openings in the wall was intended to enable, but also to supervise, the civilian movement of traders and, perhaps, transhumance.",
    "reference_list": "考点1：“Roman limes”必须译为“罗马帝国界墙”或者“罗马帝国长城”，因为这是固定翻译，译文选取一种即可，保持译文一致性\n考点2：“Gorgān and Tammīsheh walls”必须译为“戈尔干长城和塔米舍长城”，固定景点翻译\n考点3：“pre-dynastic states”推荐译为“封建王朝形成之前的政权”，不能简单翻译成“前王朝时期”，会容易被非专业读者误解称为古埃及王朝形成之前的时期\n考点4：“dzud ” 推荐译为“严冬灾害期”\n考点5：“Roman mile”必须译为“罗里”，计数单位的固定译法",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "194"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nA client of mine, Melissa, the CEO of a tech company in the healthcare sector, vented to me about a conversation she’d had with her CHRO, Ben. He came to her and said, “I’m hearing frustrations on the team about how decisions are getting made.” Having prided herself on being a transparent, inclusive leader (which she is), she was perplexed. Ben went on to share several stories of team members who’d learned about critical decisions that affected them from their peers, not from Melissa. For example, the VP of engineering learned about a deprioritized product feature from the VP of marketing. The VP of quality learned about a new project to accelerate product delivery from the VP of operations. The VP of sales learned about a new budget shift from the CFO.\nMelissa explained to me that, indeed, based on new information that each of those executives had brought in their 1:1s, she supported their recommended decisions, and assumed they would loop in the requisite peers rather than waiting for the next monthly executive meeting. In her mind, she was empowering her team to accelerate needed decisions rather than being the bottleneck or playing messenger to the other VPs, thus slowing things down. Clearly her focus on efficiency blinded her to the disunity and conflict it might provoke on the team. In each case, she’d only gotten part of the story.\nI gave her the advice I’ve given countless CEOs and C-suite leaders: Stop having so many 1:1 meetings.\nThe Hidden Costs of Executive 1:1 Meetings\nIn most large organizations, a typical CEO’s or senior executive’s calendar is clogged with 1:1 meetings. These are usually seen as necessary for alignment, decision-making, or relationship management. But at the top of an enterprise, the very structure of these meetings is working against the organization’s best interests. While there’s lots of information available about how to optimize or improve your 1:1 meetings, no amount of improvement will help meetings that shouldn’t be happening in the first place.\nLower in the organization, 1:1 meetings serve different purposes that may make more sense when people are guiding middle managers, supervisors, or individual contributors. But here’s the counterintuitive truth: The more 1:1 meetings senior executives have, the more fragmented and functionally siloed the organization can become.\nIt might be easy to conclude that Melissa should have known better not to assume her functional VPs had consulted with key peers impacted by their decisions, or that she simply should have said, “Before we move ahead, why don’t you loop John in to make sure this doesn’t cause any issues for him.” Fair enough. But even if that had happened, it wouldn’t entirely eliminate the challenges of fragmentation caused by executive 1:1s. And worse, it may have led to five additional meetings she would have had to referee.\nAt the executive level, no meaningful decision exists in a vacuum. As was the case with Melissa’s team, what the engineering VP does is significantly impacted by a decision the VP of marketing makes. The VP of operations’ decision had significant implications for the VP of quality. Yet Melissa’s meetings with those key leaders resulted in decisions—and assumptions—that others didn’t hear, couldn’t weigh in on, or later had to be retroactively briefed about. There was no intended malice or attempt to usurp others’ influence. Just the natural centrifugal force of a myopic view of the world through one’s own function or region.\nThis creates four core problems:\nFragmented governance\nEach 1:1 functions like a mini steering committee, but with no one else in the room. Governance becomes informal and duplicative, requiring rework and follow-up meetings just to keep others up to speed. Worse, viewpoints that weren’t considered in the initial 1:1 then surface later on, leading to friction that could have been avoided. When too much time is spent in fragmented meetings, there’s little left for the work that only senior leaders can do: stewarding enterprise priorities, developing talent, and advancing culture.\nFunctional bias\nOne-on-ones reinforce a view of the organization as a set of departments rather than a web of capabilities. Over time, this strengthens silos instead of creating cross-functional coherence. And it forces the CEO or senior leader to act as the sole integrator of cross-functional perspectives.\nDecision repackaging\nExecutives waste valuable time repeating, translating, or defending decisions made privately. This not only slows momentum—it breeds misalignment and friction downstream. Trust erodes over time, and leaders become conditioned to use their 1:1s to game the system and distort the truth to ensure their views prevail.\nExecutive rivalry and collusion\nSuccession overhang and ambition can subtly foster competition among top leaders. One-on-ones become arenas for inside influence, where leaders can imply advantage by referencing private access (“In my 1:1 with Bill this morning…”), creating a sense of secrecy and status that erodes collective trust.\nCEOs can also be guilty of leveraging their 1:1s to extract information about other team members, creating a false sense of “insider intimacy” with direct reports that ultimately undermines psychological safety. One CEO I urged to reduce his 1:1s actually lamented to me, “But how will I get all of the inside scoops I don’t get anywhere else?”\nA Better Way to Use Executives’ Time: Capability Meetings\nThe alternative is to re-engineer the way executive time is used. Instead of relying on 1:1s for operational discussions, CEOs and senior executives should convene small, cross-functional “capability meetings”—1:2 or 1:3 conversations that reflect how value is actually created.\nFor example, innovation isn’t owned by R&D, marketing, or customer experience alone; it lives in the seams between them. Bringing those leaders together—at the same table—ensures strategic clarity, accelerates coordination, and strengthens shared ownership.\nHere are five ways to begin:\nReserve 1:1s for development.\nShift 1:1s to a quarterly cadence and use them solely for the individual’s growth, feedback, and career development. These conversations deserve focused, undivided attention—not to be diluted by operational updates or real-time firefighting.\nYou can block 90-minute quarterly sessions that are clearly labeled “development conversation.” Structure them around reflection, feedback, and future goals. Avoid sliding into tactical issues. Use prompts like “What are you learning about yourself as a leader this quarter?” or “What would stretch you in a meaningful way next year?”\nAt one global consumer goods company, the COO redesigned her 1:1 structure by implementing a “career check-in” model: quarterly sessions focused entirely on each direct report’s long-term goals, with zero slides or project updates. This shift dramatically improved retention and succession visibility within her team.\nConvene around capabilities.\nMap out your enterprise’s most critical capabilities like innovation, digital transformation, or customer loyalty, and structure standing meetings around the cross-functional intersections that enable them.\nIdentify the five to seven capabilities that create differentiated value in your business. For each, bring together the two to four functions most essential to delivering that value. These “capability councils” become the forums for near-term decision-making, trade-offs, and shared execution, saving the full executive team’s time for truly enterprise-wide strategies and opportunities.\nMelissa worked with her team to reframe their strategic priorities into capability areas—like “virtual care experience” and “clinical operations technologies”—and created standing 1:3 capability meetings that included product, operations, and engineering leaders. As a result, go-to-market cycles shortened by 20%, and duplication and friction across teams dropped significantly.\nEnsure the right people are listening.\nOne of the quiet inefficiencies of 1:1s is that they pull decisions into private channels, where the people most affected often aren’t present. That means leaders have to replay discussions for others later, or relitigate decisions once new information surfaces, leading to misunderstanding, misalignment, or delayed action.\nYou can use capability meetings to bring together the specific leaders whose functions intersect around a given issue. This ensures that the people who need to understand and act on the information are hearing it at the moment it matters. No one has to wait to be briefed later. This kind of targeted presence builds sharper shared judgment and eliminates the need to re-translate decisions across silos.\nAt a financial services firm I’ve consulted with, the CEO replaced many of his 1:1s with capability meetings like “go to market,” “operational efficiency,” or “enterprise talent,” convening various combinations of the heads of risk, compliance, sales, and human resources, as well as the business unit general managers, to discuss capability-focused topics. Because the right people were hearing the context in real time, execution accelerated. Leaders no longer had to “sell” decisions afterward or decipher what had happened behind closed doors because they were in the room when it happened.\nElevate executive team time.\nWhen too many decisions happen in private 1:1s, full executive team meetings often devolve into catch-up sessions, replaying decisions, clarifying miscommunications, or managing interpersonal fallout. That robs the team of the chance to focus on the truly enterprise-wide work only they can do.\nBy using capability meetings to handle cross-functional execution and trade-offs at the right level, executive team time can be reserved for strategic sensemaking, cultural stewardship, and long-horizon bets. Center agendas around questions like “What are the few issues that require the full weight of this team?” or “Where does our system need realignment?”\nOne Fortune 100 company overhauled its monthly executive team meeting after realizing that too much time was spent relitigating decisions made elsewhere. By reassigning operational decision-making to triads tied to core capabilities, they cleared the decks for their senior team to focus on systemic enterprise priorities—like cultural resilience, the innovation pipeline, scenario planning for disruptions, and global portfolio shifts. The result was faster execution at the edges and deeper strategic coherence at the center.",
    "ori_text": "A client of mine, Melissa, the CEO of a tech company in the healthcare sector, vented to me about a conversation she’d had with her CHRO, Ben. He came to her and said, “I’m hearing frustrations on the team about how decisions are getting made.” Having prided herself on being a transparent, inclusive leader (which she is), she was perplexed. Ben went on to share several stories of team members who’d learned about critical decisions that affected them from their peers, not from Melissa. For example, the VP of engineering learned about a deprioritized product feature from the VP of marketing. The VP of quality learned about a new project to accelerate product delivery from the VP of operations. The VP of sales learned about a new budget shift from the CFO.\nMelissa explained to me that, indeed, based on new information that each of those executives had brought in their 1:1s, she supported their recommended decisions, and assumed they would loop in the requisite peers rather than waiting for the next monthly executive meeting. In her mind, she was empowering her team to accelerate needed decisions rather than being the bottleneck or playing messenger to the other VPs, thus slowing things down. Clearly her focus on efficiency blinded her to the disunity and conflict it might provoke on the team. In each case, she’d only gotten part of the story.\nI gave her the advice I’ve given countless CEOs and C-suite leaders: Stop having so many 1:1 meetings.\nThe Hidden Costs of Executive 1:1 Meetings\nIn most large organizations, a typical CEO’s or senior executive’s calendar is clogged with 1:1 meetings. These are usually seen as necessary for alignment, decision-making, or relationship management. But at the top of an enterprise, the very structure of these meetings is working against the organization’s best interests. While there’s lots of information available about how to optimize or improve your 1:1 meetings, no amount of improvement will help meetings that shouldn’t be happening in the first place.\nLower in the organization, 1:1 meetings serve different purposes that may make more sense when people are guiding middle managers, supervisors, or individual contributors. But here’s the counterintuitive truth: The more 1:1 meetings senior executives have, the more fragmented and functionally siloed the organization can become.\nIt might be easy to conclude that Melissa should have known better not to assume her functional VPs had consulted with key peers impacted by their decisions, or that she simply should have said, “Before we move ahead, why don’t you loop John in to make sure this doesn’t cause any issues for him.” Fair enough. But even if that had happened, it wouldn’t entirely eliminate the challenges of fragmentation caused by executive 1:1s. And worse, it may have led to five additional meetings she would have had to referee.\nAt the executive level, no meaningful decision exists in a vacuum. As was the case with Melissa’s team, what the engineering VP does is significantly impacted by a decision the VP of marketing makes. The VP of operations’ decision had significant implications for the VP of quality. Yet Melissa’s meetings with those key leaders resulted in decisions—and assumptions—that others didn’t hear, couldn’t weigh in on, or later had to be retroactively briefed about. There was no intended malice or attempt to usurp others’ influence. Just the natural centrifugal force of a myopic view of the world through one’s own function or region.\nThis creates four core problems:\nFragmented governance\nEach 1:1 functions like a mini steering committee, but with no one else in the room. Governance becomes informal and duplicative, requiring rework and follow-up meetings just to keep others up to speed. Worse, viewpoints that weren’t considered in the initial 1:1 then surface later on, leading to friction that could have been avoided. When too much time is spent in fragmented meetings, there’s little left for the work that only senior leaders can do: stewarding enterprise priorities, developing talent, and advancing culture.\nFunctional bias\nOne-on-ones reinforce a view of the organization as a set of departments rather than a web of capabilities. Over time, this strengthens silos instead of creating cross-functional coherence. And it forces the CEO or senior leader to act as the sole integrator of cross-functional perspectives.\nDecision repackaging\nExecutives waste valuable time repeating, translating, or defending decisions made privately. This not only slows momentum—it breeds misalignment and friction downstream. Trust erodes over time, and leaders become conditioned to use their 1:1s to game the system and distort the truth to ensure their views prevail.\nExecutive rivalry and collusion\nSuccession overhang and ambition can subtly foster competition among top leaders. One-on-ones become arenas for inside influence, where leaders can imply advantage by referencing private access (“In my 1:1 with Bill this morning…”), creating a sense of secrecy and status that erodes collective trust.\nCEOs can also be guilty of leveraging their 1:1s to extract information about other team members, creating a false sense of “insider intimacy” with direct reports that ultimately undermines psychological safety. One CEO I urged to reduce his 1:1s actually lamented to me, “But how will I get all of the inside scoops I don’t get anywhere else?”\nA Better Way to Use Executives’ Time: Capability Meetings\nThe alternative is to re-engineer the way executive time is used. Instead of relying on 1:1s for operational discussions, CEOs and senior executives should convene small, cross-functional “capability meetings”—1:2 or 1:3 conversations that reflect how value is actually created.\nFor example, innovation isn’t owned by R&D, marketing, or customer experience alone; it lives in the seams between them. Bringing those leaders together—at the same table—ensures strategic clarity, accelerates coordination, and strengthens shared ownership.\nHere are five ways to begin:\nReserve 1:1s for development.\nShift 1:1s to a quarterly cadence and use them solely for the individual’s growth, feedback, and career development. These conversations deserve focused, undivided attention—not to be diluted by operational updates or real-time firefighting.\nYou can block 90-minute quarterly sessions that are clearly labeled “development conversation.” Structure them around reflection, feedback, and future goals. Avoid sliding into tactical issues. Use prompts like “What are you learning about yourself as a leader this quarter?” or “What would stretch you in a meaningful way next year?”\nAt one global consumer goods company, the COO redesigned her 1:1 structure by implementing a “career check-in” model: quarterly sessions focused entirely on each direct report’s long-term goals, with zero slides or project updates. This shift dramatically improved retention and succession visibility within her team.\nConvene around capabilities.\nMap out your enterprise’s most critical capabilities like innovation, digital transformation, or customer loyalty, and structure standing meetings around the cross-functional intersections that enable them.\nIdentify the five to seven capabilities that create differentiated value in your business. For each, bring together the two to four functions most essential to delivering that value. These “capability councils” become the forums for near-term decision-making, trade-offs, and shared execution, saving the full executive team’s time for truly enterprise-wide strategies and opportunities.\nMelissa worked with her team to reframe their strategic priorities into capability areas—like “virtual care experience” and “clinical operations technologies”—and created standing 1:3 capability meetings that included product, operations, and engineering leaders. As a result, go-to-market cycles shortened by 20%, and duplication and friction across teams dropped significantly.\nEnsure the right people are listening.\nOne of the quiet inefficiencies of 1:1s is that they pull decisions into private channels, where the people most affected often aren’t present. That means leaders have to replay discussions for others later, or relitigate decisions once new information surfaces, leading to misunderstanding, misalignment, or delayed action.\nYou can use capability meetings to bring together the specific leaders whose functions intersect around a given issue. This ensures that the people who need to understand and act on the information are hearing it at the moment it matters. No one has to wait to be briefed later. This kind of targeted presence builds sharper shared judgment and eliminates the need to re-translate decisions across silos.\nAt a financial services firm I’ve consulted with, the CEO replaced many of his 1:1s with capability meetings like “go to market,” “operational efficiency,” or “enterprise talent,” convening various combinations of the heads of risk, compliance, sales, and human resources, as well as the business unit general managers, to discuss capability-focused topics. Because the right people were hearing the context in real time, execution accelerated. Leaders no longer had to “sell” decisions afterward or decipher what had happened behind closed doors because they were in the room when it happened.\nElevate executive team time.\nWhen too many decisions happen in private 1:1s, full executive team meetings often devolve into catch-up sessions, replaying decisions, clarifying miscommunications, or managing interpersonal fallout. That robs the team of the chance to focus on the truly enterprise-wide work only they can do.\nBy using capability meetings to handle cross-functional execution and trade-offs at the right level, executive team time can be reserved for strategic sensemaking, cultural stewardship, and long-horizon bets. Center agendas around questions like “What are the few issues that require the full weight of this team?” or “Where does our system need realignment?”\nOne Fortune 100 company overhauled its monthly executive team meeting after realizing that too much time was spent relitigating decisions made elsewhere. By reassigning operational decision-making to triads tied to core capabilities, they cleared the decks for their senior team to focus on systemic enterprise priorities—like cultural resilience, the innovation pipeline, scenario planning for disruptions, and global portfolio shifts. The result was faster execution at the edges and deeper strategic coherence at the center.",
    "reference_list": "考点1： \"vented\"应该译为“透露”。\n考点2： \"VP\"应译为“副总监”。\n考点3：\" functionally siloed\"应译为“职能孤岛化”。\n考点4： \"Fragmented governance\"应译为“碎片化治理 ”。\n考点5： 'game the system\"应译为“钻制度的空子”。\n考点6： \"Succession overhang\"应译为“继任问题带来的潜在影响”。\n考点7：\"cleared the decks\"应译为“扫清障碍”。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "广告营销",
    "prompt_id": "65"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nComparison between pediatric and adult acute natural cannabinoids toxicity: A 5-year retrospective study with special consideration of acute synthetic cannabinoids toxicity\nAbstract\nAcute cannabinoids toxicity is an alarming toxicological problem. The current study aimed to compare children and adults with acute natural cannabinoids toxicity and highlight cases with acute synthetic cannabinoids (SCs) toxicity. This retrospective cross-sectional study was conducted on patients with acute cannabinoids toxicity admitted to Tanta University Poison Control Center from January 2019 to December 2023. Socio-demographic, toxicological, clinical, and laboratory data were retrieved from patients’ medical records. Patients were divided into a pediatric group (≤ 18 years) and an adult group (> 18 years). Out of 106 patients, 68 were children and 38 were adults. Impaired consciousness level and bradypnea were more significantly reported in children (P < 0.001, 0.007, respectively). Low oxygen saturation, tachycardia, hypokalemia, and leukocytosis were more significantly reported in adults (P < 0.001, for each). Delay time from exposure to medical intervention and potassium level were significantly valid to predict complications in children (Adjusted odds ratio: 1.393 and 4.139, respectively). Delay time to medical intervention and oxygen saturation were significant risk factors for prolonged hospital stay in children (Adjusted odds ratio: 1.255 and 0.677, respectively). Acute SCs toxicity was observed only in four cases presented mainly with seizures, tachycardia, hypertension, tachypnea, and hypoxemia. It could be concluded that natural cannabinoids toxicity is more prevalent than SCs. Presentation of acute natural cannabinoids toxicity exhibits variations between children and adults. Delay time to medical intervention, as well as potassium and oxygen saturation levels are significant risk factors for complications and prolonged hospitalization in children.\n\nKeywords: Acute cannabis poisoning, Synthetic cannabinoids, Prediction, Outcomes\n\n1. Introduction\nOver the last decades, substance abuse has emerged as a significant health issue that strongly affects all countries. As defined by the World Health Organization (WHO), substance abuse is the hazardous use of psychoactive substances, including alcohol and illicit drugs with substantial risk of morbidity and premature death [1].\n\nAs other countries, Egypt is witnessing increasing rates of substance abuse while the exact prevalence is unavailable, most probably due to substantial social stigma and underreporting [2]. Some reports highlight the magnitude of the problem; in 2016, about 6.8 % of Egyptians aged above 15 years were involved in substance abuse [3]. Furthermore, in 2022, the Egyptian Ministry of Social Solidarity estimated that about 5.9 % of the total population consumed illicit drugs [4].\n\nGlobally, cannabis ranks third among abused substances after alcohol and tobacco as it is widely cultivated and trafficked with an ancient history of both medicinal and recreational uses [5], [6] . The annual prevalence rate of cannabis consumption has been estimated to be nearly 2.5 % of the global population [7]. In Egypt, different reports are available considering the prevalence of cannabis abuse. For example, it was reported that more than 9 % of Egyptian students are using bango and 3 % are depending on hashish [8].\n\nDespite the fact that recreational cannabis use is known to be associated with a low risk of acute toxicity, recent reports indicate an increase in the potency of cannabis preparations, potentially leading to more visits to poison control centers due to accidental acute toxicity [9]. Furthermore, accidental ingestion of cannabis by children is also reported even in developed countries especially with legalization of medical and recreational marijuana [10]. Although it is an alarming toxicological problem, data regarding acute cannabis toxicity is still limited [11].\n\nIt is worth mentioning that the term cannabinoid refers to chemical substances that interact with cannabinoid receptors, producing effects similar to those of the Cannabis plant [12]. Depending on the source of production, cannabinoids are divided into endocannabinoids, phytocannabinoids and synthetic cannabinoids. The first group (endocannabinoids) is produced by mammalians while the second group (phytocannabinoids) is extracted from the cannabis plant and includes the most psychoactive Δ9-tetrahydrocannabinol (Δ9-THC) and non-psychoactive component cannabidiol. The third group involves a number of synthetic cannabinoids (SCs) which are sold for recreational use [13].\n\nToxicity from natural cannabinoids (marijuana) including hashish and bango can result from inhalation, smoking, or ingestion [14], [15], [16]. Manifestations are diverse depending on the patient’s age, cannabis potency, route of exposure, and combination with other psychoactive substances [17].\n\nBasic treatment of acute cannabis toxicity is mainly supportive to keep a patent airway with adequate ventilation and circulation. Children presented with apnea and risk of aspiration need to be intubated and mechanically ventilated. However, those who are presenting with lethargy, rapid electrolytes and arterial blood gases, as well as random blood sugar measurement is considered. For patients with mild toxicity, benzodiazepine may be enough to control anxiety and agitation [18].\n\nRegarding SCs, they are designer drugs with variable structure and potencies that mimic the psychoactive properties of Δ9-THC. In Egypt, they are traded under different names including strox and voodoo [16]. In 2014, they were added to Schedule No. 1 of the Egyptian Drugs Act [19]. Synthetic cannabinoids acquired their popularity because they are easily manufactured, so they are more accessible at low prices compared to cannabis. Additionally, they are not detected by standard toxicology screening for natural cannabis [15].\n\nDespite the cannabomimetic effects of SCs, their side effects cannot be expected and may be more serious than the natural cannabis [20]. Acute toxicity could be due to Δ9-THC and additives like anticholinergic agents and ketamine [21]. However, acute strox intoxication is manifested by visual and auditory hallucinations, fright, speech impairments, and paranoia leading to aggressive behavior [22], [15]. It may also cause loss of concentration, delirium, vomiting, and fainting, as well as extreme fear of death and fatal convulsions [23]. Pupillary dilatation, tachycardia, flushed dry skin, and other anticholinergic toxidrome were also reported. In severe cases, lethal cardiovascular collapse and deep coma could occur [24]. Supportive and symptomatic care is the main line considered in the treatment of acute strox toxicity [25].\n\nConsidering that age could affect the characteristics of acute toxicity and the introduction of SCs into the market of substance abuse, this study aimed to compare clinical and laboratory findings of acute natural cannabinoids toxicity in the adults and pediatric group, together with highlighting cases presented with acute SCs toxicity.\n\n2. Patients and methods\n2.1. Study design and settings\nThe current retrospective cross-sectional study was conducted on all patients with acute cannabis or SCs toxicity who were admitted to Tanta University Poison Control Center (TUPCC) throughout five years from January 2019 to December 2023.\n\n2.2. Ethical considerations\nThe current study was approved by our institution's ethics committee (approval code: 36264PR708/5/24) and followed the declaration of Helsinki. To secure confidentiality, patients’ data were coded for anonymous statistical analysis. The requirement for written informed consent was waived due to the retrospective nature of the study.\n\n2.3. Eligibility criteria\nAll patients, males and females, with acute cannabis or SCs toxicity were included in the study. Diagnosis was based on definite history as reported from the patients or witnesses besides clinical assessment of the attending physician and urine screening test [26]. On the other hand, patients with known medical illnesses such as cardiovascular or neuropsychological diseases, renal or hepatic impairment, respiratory disorders such as asthma or chronic obstructive pulmonary disorders, and diabetes were excluded. Additionally, the current study excluded patients with mixed intoxication or those who received medical intervention before admission. Pregnant and lactating females were also excluded.\n\n2.4. Data collection\nThe following variables were extracted from the medical records of each patient:\n\n1.Socio-demographics: age, sex, and residence.\n2.History of pre-existing medical disorders.\n3.Toxicological data: name of substance, route, manner, and place of exposure, and delay time from exposure to medical intervention.\n4.Findings of clinical examination:\n•Vital signs: systolic blood pressure (SBP), diastolic blood pressure (DBP), pulse rate (PR), respiratory rate (RR), temperature, and oxygen (O2) saturation.\n•Level of consciousness using the Glasgow Coma Scale (GCS).\n•Systemic examination: head & neck, neurological, chest, abdomen, skin, and extremities examination\n•Electrocardiographic (ECG) findings\n1.Results of laboratory investigations:\n•Arterial blood gases (ABG): pH, partial arterial carbon dioxide pressure (PaCO2), partial arterial oxygen pressure (PaO2).\n•Serum electrolytes: serum sodium (Na) and potassium (K) levels\n•Serum random blood glucose level\n•Glucose potassium (Glu/K) ratio was obtained by dividing serum random blood glucose level over serum potassium level\n•Renal functions: blood urea nitrogen and serum creatinine.\n•Liver enzymes: aspartate aminotransferase (AST) and alanine aminotransferase (ALT).\n2.Outcome measures: mortality, intensive care unit (ICU) admission, and duration of hospital stay.\nPatients were treated according to guidelines including emergency and supportive measures if indicated. Patients were divided according to their age into two groups: the pediatric group included patients whose age was 18 years or less and the adult group where the age of patients was above 18 years.\n\n2.5. Statistical analysis\nAll data were tabulated and analyzed by the statistical package for the social sciences software program, IBM SPSS Statistics for Windows, version 27 (IBM Corp., Armonk, N.Y., USA). Categorical data were presented as numbers and percentages, while numerical data were first tested for normality by the Shapiro-Wilk test. Normally distributed numerical data were expressed as the mean ± standard deviation, while skewed numerical data were represented as median and interquartile range (IQR: 25th −75th percentiles). Comparisons between the studied groups were done by applying Pearson’s Chi-Square test for categorical data. When more than 20 % of cells have expected count of less than 5 Fisher’s Exact and Fisher-Freeman-Halton Exact tests was adopted instead of Pearson’s Chi-Square test. Normally distributed numerical data were compared by the Independent Samples T-test. Alternatively, Mann-Whitney U test was performed to compare skewed data. For determining risk factors of complicated outcome and prolonged hospital stay among the studied children group, univariable and multivariable logistic regression analyses were performed. As regards multivariable logistic regression, all variables that showed significant results in the bivariate analysis were selected as covariates. Results were presented as adjusted odds ratio (AOR) and 95 % confidence interval. P < 0.05 was considered statistically significant.",
    "ori_text": "Comparison between pediatric and adult acute natural cannabinoids toxicity: A 5-year retrospective study with special consideration of acute synthetic cannabinoids toxicity\nAbstract\nAcute cannabinoids toxicity is an alarming toxicological problem. The current study aimed to compare children and adults with acute natural cannabinoids toxicity and highlight cases with acute synthetic cannabinoids (SCs) toxicity. This retrospective cross-sectional study was conducted on patients with acute cannabinoids toxicity admitted to Tanta University Poison Control Center from January 2019 to December 2023. Socio-demographic, toxicological, clinical, and laboratory data were retrieved from patients’ medical records. Patients were divided into a pediatric group (≤ 18 years) and an adult group (> 18 years). Out of 106 patients, 68 were children and 38 were adults. Impaired consciousness level and bradypnea were more significantly reported in children (P < 0.001, 0.007, respectively). Low oxygen saturation, tachycardia, hypokalemia, and leukocytosis were more significantly reported in adults (P < 0.001, for each). Delay time from exposure to medical intervention and potassium level were significantly valid to predict complications in children (Adjusted odds ratio: 1.393 and 4.139, respectively). Delay time to medical intervention and oxygen saturation were significant risk factors for prolonged hospital stay in children (Adjusted odds ratio: 1.255 and 0.677, respectively). Acute SCs toxicity was observed only in four cases presented mainly with seizures, tachycardia, hypertension, tachypnea, and hypoxemia. It could be concluded that natural cannabinoids toxicity is more prevalent than SCs. Presentation of acute natural cannabinoids toxicity exhibits variations between children and adults. Delay time to medical intervention, as well as potassium and oxygen saturation levels are significant risk factors for complications and prolonged hospitalization in children.\n\nKeywords: Acute cannabis poisoning, Synthetic cannabinoids, Prediction, Outcomes\n\n1. Introduction\nOver the last decades, substance abuse has emerged as a significant health issue that strongly affects all countries. As defined by the World Health Organization (WHO), substance abuse is the hazardous use of psychoactive substances, including alcohol and illicit drugs with substantial risk of morbidity and premature death [1].\n\nAs other countries, Egypt is witnessing increasing rates of substance abuse while the exact prevalence is unavailable, most probably due to substantial social stigma and underreporting [2]. Some reports highlight the magnitude of the problem; in 2016, about 6.8 % of Egyptians aged above 15 years were involved in substance abuse [3]. Furthermore, in 2022, the Egyptian Ministry of Social Solidarity estimated that about 5.9 % of the total population consumed illicit drugs [4].\n\nGlobally, cannabis ranks third among abused substances after alcohol and tobacco as it is widely cultivated and trafficked with an ancient history of both medicinal and recreational uses [5], [6] . The annual prevalence rate of cannabis consumption has been estimated to be nearly 2.5 % of the global population [7]. In Egypt, different reports are available considering the prevalence of cannabis abuse. For example, it was reported that more than 9 % of Egyptian students are using bango and 3 % are depending on hashish [8].\n\nDespite the fact that recreational cannabis use is known to be associated with a low risk of acute toxicity, recent reports indicate an increase in the potency of cannabis preparations, potentially leading to more visits to poison control centers due to accidental acute toxicity [9]. Furthermore, accidental ingestion of cannabis by children is also reported even in developed countries especially with legalization of medical and recreational marijuana [10]. Although it is an alarming toxicological problem, data regarding acute cannabis toxicity is still limited [11].\n\nIt is worth mentioning that the term cannabinoid refers to chemical substances that interact with cannabinoid receptors, producing effects similar to those of the Cannabis plant [12]. Depending on the source of production, cannabinoids are divided into endocannabinoids, phytocannabinoids and synthetic cannabinoids. The first group (endocannabinoids) is produced by mammalians while the second group (phytocannabinoids) is extracted from the cannabis plant and includes the most psychoactive Δ9-tetrahydrocannabinol (Δ9-THC) and non-psychoactive component cannabidiol. The third group involves a number of synthetic cannabinoids (SCs) which are sold for recreational use [13].\n\nToxicity from natural cannabinoids (marijuana) including hashish and bango can result from inhalation, smoking, or ingestion [14], [15], [16]. Manifestations are diverse depending on the patient’s age, cannabis potency, route of exposure, and combination with other psychoactive substances [17].\n\nBasic treatment of acute cannabis toxicity is mainly supportive to keep a patent airway with adequate ventilation and circulation. Children presented with apnea and risk of aspiration need to be intubated and mechanically ventilated. However, those who are presenting with lethargy, rapid electrolytes and arterial blood gases, as well as random blood sugar measurement is considered. For patients with mild toxicity, benzodiazepine may be enough to control anxiety and agitation [18].\n\nRegarding SCs, they are designer drugs with variable structure and potencies that mimic the psychoactive properties of Δ9-THC. In Egypt, they are traded under different names including strox and voodoo [16]. In 2014, they were added to Schedule No. 1 of the Egyptian Drugs Act [19]. Synthetic cannabinoids acquired their popularity because they are easily manufactured, so they are more accessible at low prices compared to cannabis. Additionally, they are not detected by standard toxicology screening for natural cannabis [15].\n\nDespite the cannabomimetic effects of SCs, their side effects cannot be expected and may be more serious than the natural cannabis [20]. Acute toxicity could be due to Δ9-THC and additives like anticholinergic agents and ketamine [21]. However, acute strox intoxication is manifested by visual and auditory hallucinations, fright, speech impairments, and paranoia leading to aggressive behavior [22], [15]. It may also cause loss of concentration, delirium, vomiting, and fainting, as well as extreme fear of death and fatal convulsions [23]. Pupillary dilatation, tachycardia, flushed dry skin, and other anticholinergic toxidrome were also reported. In severe cases, lethal cardiovascular collapse and deep coma could occur [24]. Supportive and symptomatic care is the main line considered in the treatment of acute strox toxicity [25].\n\nConsidering that age could affect the characteristics of acute toxicity and the introduction of SCs into the market of substance abuse, this study aimed to compare clinical and laboratory findings of acute natural cannabinoids toxicity in the adults and pediatric group, together with highlighting cases presented with acute SCs toxicity.\n\n2. Patients and methods\n2.1. Study design and settings\nThe current retrospective cross-sectional study was conducted on all patients with acute cannabis or SCs toxicity who were admitted to Tanta University Poison Control Center (TUPCC) throughout five years from January 2019 to December 2023.\n\n2.2. Ethical considerations\nThe current study was approved by our institution's ethics committee (approval code: 36264PR708/5/24) and followed the declaration of Helsinki. To secure confidentiality, patients’ data were coded for anonymous statistical analysis. The requirement for written informed consent was waived due to the retrospective nature of the study.\n\n2.3. Eligibility criteria\nAll patients, males and females, with acute cannabis or SCs toxicity were included in the study. Diagnosis was based on definite history as reported from the patients or witnesses besides clinical assessment of the attending physician and urine screening test [26]. On the other hand, patients with known medical illnesses such as cardiovascular or neuropsychological diseases, renal or hepatic impairment, respiratory disorders such as asthma or chronic obstructive pulmonary disorders, and diabetes were excluded. Additionally, the current study excluded patients with mixed intoxication or those who received medical intervention before admission. Pregnant and lactating females were also excluded.\n\n2.4. Data collection\nThe following variables were extracted from the medical records of each patient:\n\n1.Socio-demographics: age, sex, and residence.\n2.History of pre-existing medical disorders.\n3.Toxicological data: name of substance, route, manner, and place of exposure, and delay time from exposure to medical intervention.\n4.Findings of clinical examination:\n•Vital signs: systolic blood pressure (SBP), diastolic blood pressure (DBP), pulse rate (PR), respiratory rate (RR), temperature, and oxygen (O2) saturation.\n•Level of consciousness using the Glasgow Coma Scale (GCS).\n•Systemic examination: head & neck, neurological, chest, abdomen, skin, and extremities examination\n•Electrocardiographic (ECG) findings\n1.Results of laboratory investigations:\n•Arterial blood gases (ABG): pH, partial arterial carbon dioxide pressure (PaCO2), partial arterial oxygen pressure (PaO2).\n•Serum electrolytes: serum sodium (Na) and potassium (K) levels\n•Serum random blood glucose level\n•Glucose potassium (Glu/K) ratio was obtained by dividing serum random blood glucose level over serum potassium level\n•Renal functions: blood urea nitrogen and serum creatinine.\n•Liver enzymes: aspartate aminotransferase (AST) and alanine aminotransferase (ALT).\n2.Outcome measures: mortality, intensive care unit (ICU) admission, and duration of hospital stay.\nPatients were treated according to guidelines including emergency and supportive measures if indicated. Patients were divided according to their age into two groups: the pediatric group included patients whose age was 18 years or less and the adult group where the age of patients was above 18 years.\n\n2.5. Statistical analysis\nAll data were tabulated and analyzed by the statistical package for the social sciences software program, IBM SPSS Statistics for Windows, version 27 (IBM Corp., Armonk, N.Y., USA). Categorical data were presented as numbers and percentages, while numerical data were first tested for normality by the Shapiro-Wilk test. Normally distributed numerical data were expressed as the mean ± standard deviation, while skewed numerical data were represented as median and interquartile range (IQR: 25th −75th percentiles). Comparisons between the studied groups were done by applying Pearson’s Chi-Square test for categorical data. When more than 20 % of cells have expected count of less than 5 Fisher’s Exact and Fisher-Freeman-Halton Exact tests was adopted instead of Pearson’s Chi-Square test. Normally distributed numerical data were compared by the Independent Samples T-test. Alternatively, Mann-Whitney U test was performed to compare skewed data. For determining risk factors of complicated outcome and prolonged hospital stay among the studied children group, univariable and multivariable logistic regression analyses were performed. As regards multivariable logistic regression, all variables that showed significant results in the bivariate analysis were selected as covariates. Results were presented as adjusted odds ratio (AOR) and 95 % confidence interval. P < 0.05 was considered statistically significant.",
    "reference_list": "考点 1：\"Acute cannabinoids toxicity\" 应译为 \"急性大麻素毒性\"\n考点 2：\"Impaired consciousness level\" 应译为 \"意识障碍\"\n考点 3：\"leukocytosis\" 应译为 \"白细胞增多症\"\n考点 4：\"Adjusted odds ratio\" 应译为 \"校正后比值比\"\n考点 5：\"Outcomes\" 应译为 \"临床结局\"\n考点 6：\"morbidity and premature death\" 应译为 \"发病率和过早死亡\"\n考点 7：\"prevalence\" 应译为 \"流行率\"\n考点 8：\"bango and hashish\" 应译为 \"班戈和哈希什\"\n考点 9：\"poison control centers\" 应译为 \"中毒控制中心\"\n考点 10：\"patent airway\" 应译为 \"保持气道通畅\"\n考点 11：\"intubated and mechanically ventilated\" 应译为 \"气管插管和机械通气\"\n考点 12：\"designer drugs\" 应译为 \"设计毒品\"\n考点 13：\"strox and voodoo\" 应译为 \"斯特罗 和 巫毒\"\n考点 14：\"cannabomimetic effects\" 应译为 \"拟大麻素作用\"\n考点 15：\"anticholinergic toxidrome\" 应译为 \"抗胆碱能毒性症候群\"\n考点 33：\"lethal cardiovascular collapse\" 应译为 \"致死性心血管衰竭\"\n考点 34：\"waived\" 应译为 \"豁免\"\n考点 35：\"Eligibility criteria\" 应译为 \"纳入标准\"\n考点 36：\"mixed intoxication\" 应译为 \"混合中毒\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "90"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n核心观点：“房地产”是宏观经济研究绕不开的“锚”，在经济增长、产业发展、金融市场、居民资产负债表、财政税收等领域都扮演过重要的角色。2021年以来，宏观经济进入“去地产化”阶段，房地产市场景气变化对增长、就业、税收、物价、系统性风险等领域带来了不同程度的“扰动”，市场存在“地产见顶”的认识，也有所谓的“唯地产论”论调甚嚣尘上。24年924后高层提出“止跌回稳”的政策基调，我们也判断房地产市场“最悲观的阶段”已经过去、进入“见龙在田”阶段，房地产市场预期有所改观，25年房地产在经历了年初的小阳春后有所降温，二季度以来与地产相关的悲观叙事再度浮现，包括但不限于担心头部房企债务压力、金融体系的系统性风险，甚至是经济增长前景等等。\n在此背景下，我们认为不能以“悲观叙事”就否定房地产领域的积极变化和投资机会，不破不立，风险中暗藏着变化，变化中孕育着生机，我们希望通过“地产进化论”系列报告对房地产领域的系列问题进行探讨，为投资者掘金“新机”。\n本篇报告作为开篇，我们希望以长周期视角出发，从供给和需求两个方面梳理未来存量、增量的变化。可以看到，我国房地产供给端的“绝对增量”高峰已经过去，从“跑马圈地”的增量时代进入存量时代，居民城镇住房也从“有没有”逐步转向“好不好”和“够不够宽敞”的改善阶段。需求端，在总量“承压”的背景下，也仍有结构性的机会，一是市民化和城镇化率提升带来增量需求；二是我国老龄化程度逐步提升，意味着养老住房的需求也在逐步提升；三是房地产领域也呈现出“品质消费时代”特征，在主力购房人群规模边际下降的背景下，高品质的“好房子”需求显著提升，这也决定了房地产市场会出现“存量供给淘汰出清”并催生各类“更新”需求。\n一、地产供给\n增量视角：在供给端，我们认为最直接、最具代表性的切入点就是“户均住宅套数”或“套户比”这一指标：我们测算发现，在城镇家庭户口径下，2020年商品住宅套户比达到0.63、住宅套户比达到1.06（首次突破1）。进一步，截至2023年，商品住宅套户比达到0.70、住宅套户比达到1.17。此外，考虑到“户均住宅套数”这一指标仍无官方口径披露，我们的测算值仅为一个简单的参考，人口普查中的“人均住房间数”和“人均住房建筑面积”则是另两个值得重点关注的长周期指标。2020年第七次人口普查时人均住房间数达到1.0间/人，这意味着平均每位城镇居民已基本拥有一个独立房间，居住分隔水平相较20年前提升了约30%。人均住房建筑面积也在同步扩大，到2020年已经增长至38.62平方米/人，二十年累计增长超过70%。\n存量视角：从增量层面出发，我们认为“人均住宅新开工套数”是供给层面最直观的增量信号，也是对存量供给视角的重要补充，它决定了未来1-3年可供入市的新房供给节奏。从历史数据看，我国每千人的人均住宅新开工套数经历了典型的“快速放量-阶段性见顶-有序回落”三个阶段。到2023年，全国千人新开工套数已降至约4.9套，2024年进一步回落至3.8套；城镇人口口径同样从高点大幅回落到2023年的7.5套左右，2024年降至5.7套/千人左右。换言之，我国房地产供给端的“绝对增量”高峰已经过去，开发节奏正与人口增长和城镇化红利的边际收窄相适应，新增供给趋于理性。\n二、地产需求\n地产需求拆分：从长期视角看，房地产的需求亦可以分为存量与增量两大层面，我们认为在结构上可进一步拆解为四大主要来源：1）一是城镇化带来的新增购房需求，主要由农业转移人口进城购房形成；2）二是城镇主力购房人群的刚性与改善性需求，核心集中在25-44岁人群，其中25-34岁年龄段以首套购房为主，35-44岁人群则以改善性换房为主；3）三是养老住房需求，主要对应老龄人口规模增加所带来的以房换房或适老化改善需求；4）四是投机性购房需求，通常在房价预期持续上涨阶段出现，对市场热度有显著放大效应。\n存量视角：\n1）从存量角度看，城镇化是过去二十年推动中国住房需求增长的最大变量之一，累计带来数亿农民进城落户、购房、安居的需求。而从国际比较来看，中国的城镇化水平虽然已明显接近中高收入经济体的平均线，但与发达经济体仍有一定差距；\n2）在城镇化进程逐步迈入高位平台期的同时，另一项与住房需求息息相关的人口结构变量，也正悄然发生变化，即适龄购房人口群体的演变；\n3）我国65岁及以上人口占比已超过15%，进入中度老龄化社会。从趋势上看，预计老龄人口占比仍将持续上升，未来一段时期内，养老相关的居住需求将逐步上升为住房市场中的一个重要分支；\n4）投机性需求的存量部分，往往体现在房价预期带来的多套房持有行为和“囤房”现象。在过去房价持续上涨的周期中，部分家庭或机构投资者积累了多套住房，形成了对存量市场的额外“供给约束”。\n增量视角：\n对四类住房需求的展望：\n1）从整体上看，当前来看我国常住人口城镇化率已达到近65%，处于较高水平，但仍有进一步上行的空间，中西部地区和部分城市群外围的农村安居落户仍在继续，这背后会带来两种增量购房需求：一是市民化；二是常住人口城镇化率继续提升所带来的阶段性购房需求；从结构上看，“城镇化”对不同区域的影响存在差异；\n2）25-44岁人群历来是住房市场最核心的消费群体。25-34岁以首套刚需为主，35-44岁则以改善性换房为主。尽管适龄人口总体呈下降趋势，但人口净流入城市、经济活跃地区仍具备年轻人口积聚能力。此外，代际财富传承、房贷政策优化、消费观念转变等因素可能延缓购房节奏但不削弱购房意愿；\n3）随着人口老龄化持续推进，养老住房需求正在从边缘走向主流。老年人更多以“以房换房”或局部改善方式参与市场，核心诉求是改善适老条件、优化生活环境或靠近子女生活圈。未来，“银发经济”发展和养老住宅细分业态的成熟，将形成结构性增量；\n4）投机性购房需求具有典型顺周期特征，过去曾在房价上涨周期推动市场升温，但当前政策导向下其影响力大幅下降。未来在“弱周期+低杠杆”背景下，投机性需求的空间将更受约束，但在市场预期转向时仍可能阶段性抬头；\n5）在房地产市场由增量扩张转向存量优化的阶段，“好房子”正逐渐成为各类购房需求的重要共同指向。无论是主力购房人群的改善性需求、老年人口的养老置换，还是投机性需求，均表现出对高品质住房的高度偏好。“好房子”不仅是改善居住体验的目标，也正成为房地产需求侧的关键锚点。",
    "ori_text": "\n\n核心观点：“房地产”是宏观经济研究绕不开的“锚”，在经济增长、产业发展、金融市场、居民资产负债表、财政税收等领域都扮演过重要的角色。2021年以来，宏观经济进入“去地产化”阶段，房地产市场景气变化对增长、就业、税收、物价、系统性风险等领域带来了不同程度的“扰动”，市场存在“地产见顶”的认识，也有所谓的“唯地产论”论调甚嚣尘上。24年924后高层提出“止跌回稳”的政策基调，我们也判断房地产市场“最悲观的阶段”已经过去、进入“见龙在田”阶段，房地产市场预期有所改观，25年房地产在经历了年初的小阳春后有所降温，二季度以来与地产相关的悲观叙事再度浮现，包括但不限于担心头部房企债务压力、金融体系的系统性风险，甚至是经济增长前景等等。\n在此背景下，我们认为不能以“悲观叙事”就否定房地产领域的积极变化和投资机会，不破不立，风险中暗藏着变化，变化中孕育着生机，我们希望通过“地产进化论”系列报告对房地产领域的系列问题进行探讨，为投资者掘金“新机”。\n本篇报告作为开篇，我们希望以长周期视角出发，从供给和需求两个方面梳理未来存量、增量的变化。可以看到，我国房地产供给端的“绝对增量”高峰已经过去，从“跑马圈地”的增量时代进入存量时代，居民城镇住房也从“有没有”逐步转向“好不好”和“够不够宽敞”的改善阶段。需求端，在总量“承压”的背景下，也仍有结构性的机会，一是市民化和城镇化率提升带来增量需求；二是我国老龄化程度逐步提升，意味着养老住房的需求也在逐步提升；三是房地产领域也呈现出“品质消费时代”特征，在主力购房人群规模边际下降的背景下，高品质的“好房子”需求显著提升，这也决定了房地产市场会出现“存量供给淘汰出清”并催生各类“更新”需求。\n一、地产供给\n增量视角：在供给端，我们认为最直接、最具代表性的切入点就是“户均住宅套数”或“套户比”这一指标：我们测算发现，在城镇家庭户口径下，2020年商品住宅套户比达到0.63、住宅套户比达到1.06（首次突破1）。进一步，截至2023年，商品住宅套户比达到0.70、住宅套户比达到1.17。此外，考虑到“户均住宅套数”这一指标仍无官方口径披露，我们的测算值仅为一个简单的参考，人口普查中的“人均住房间数”和“人均住房建筑面积”则是另两个值得重点关注的长周期指标。2020年第七次人口普查时人均住房间数达到1.0间/人，这意味着平均每位城镇居民已基本拥有一个独立房间，居住分隔水平相较20年前提升了约30%。人均住房建筑面积也在同步扩大，到2020年已经增长至38.62平方米/人，二十年累计增长超过70%。\n存量视角：从增量层面出发，我们认为“人均住宅新开工套数”是供给层面最直观的增量信号，也是对存量供给视角的重要补充，它决定了未来1-3年可供入市的新房供给节奏。从历史数据看，我国每千人的人均住宅新开工套数经历了典型的“快速放量-阶段性见顶-有序回落”三个阶段。到2023年，全国千人新开工套数已降至约4.9套，2024年进一步回落至3.8套；城镇人口口径同样从高点大幅回落到2023年的7.5套左右，2024年降至5.7套/千人左右。换言之，我国房地产供给端的“绝对增量”高峰已经过去，开发节奏正与人口增长和城镇化红利的边际收窄相适应，新增供给趋于理性。\n二、地产需求\n地产需求拆分：从长期视角看，房地产的需求亦可以分为存量与增量两大层面，我们认为在结构上可进一步拆解为四大主要来源：1）一是城镇化带来的新增购房需求，主要由农业转移人口进城购房形成；2）二是城镇主力购房人群的刚性与改善性需求，核心集中在25-44岁人群，其中25-34岁年龄段以首套购房为主，35-44岁人群则以改善性换房为主；3）三是养老住房需求，主要对应老龄人口规模增加所带来的以房换房或适老化改善需求；4）四是投机性购房需求，通常在房价预期持续上涨阶段出现，对市场热度有显著放大效应。\n存量视角：\n1）从存量角度看，城镇化是过去二十年推动中国住房需求增长的最大变量之一，累计带来数亿农民进城落户、购房、安居的需求。而从国际比较来看，中国的城镇化水平虽然已明显接近中高收入经济体的平均线，但与发达经济体仍有一定差距；\n2）在城镇化进程逐步迈入高位平台期的同时，另一项与住房需求息息相关的人口结构变量，也正悄然发生变化，即适龄购房人口群体的演变；\n3）我国65岁及以上人口占比已超过15%，进入中度老龄化社会。从趋势上看，预计老龄人口占比仍将持续上升，未来一段时期内，养老相关的居住需求将逐步上升为住房市场中的一个重要分支；\n4）投机性需求的存量部分，往往体现在房价预期带来的多套房持有行为和“囤房”现象。在过去房价持续上涨的周期中，部分家庭或机构投资者积累了多套住房，形成了对存量市场的额外“供给约束”。\n增量视角：\n对四类住房需求的展望：\n1）从整体上看，当前来看我国常住人口城镇化率已达到近65%，处于较高水平，但仍有进一步上行的空间，中西部地区和部分城市群外围的农村安居落户仍在继续，这背后会带来两种增量购房需求：一是市民化；二是常住人口城镇化率继续提升所带来的阶段性购房需求；从结构上看，“城镇化”对不同区域的影响存在差异；\n2）25-44岁人群历来是住房市场最核心的消费群体。25-34岁以首套刚需为主，35-44岁则以改善性换房为主。尽管适龄人口总体呈下降趋势，但人口净流入城市、经济活跃地区仍具备年轻人口积聚能力。此外，代际财富传承、房贷政策优化、消费观念转变等因素可能延缓购房节奏但不削弱购房意愿；\n3）随着人口老龄化持续推进，养老住房需求正在从边缘走向主流。老年人更多以“以房换房”或局部改善方式参与市场，核心诉求是改善适老条件、优化生活环境或靠近子女生活圈。未来，“银发经济”发展和养老住宅细分业态的成熟，将形成结构性增量；\n4）投机性购房需求具有典型顺周期特征，过去曾在房价上涨周期推动市场升温，但当前政策导向下其影响力大幅下降。未来在“弱周期+低杠杆”背景下，投机性需求的空间将更受约束，但在市场预期转向时仍可能阶段性抬头；\n5）在房地产市场由增量扩张转向存量优化的阶段，“好房子”正逐渐成为各类购房需求的重要共同指向。无论是主力购房人群的改善性需求、老年人口的养老置换，还是投机性需求，均表现出对高品质住房的高度偏好。“好房子”不仅是改善居住体验的目标，也正成为房地产需求侧的关键锚点。",
    "reference_list": "考点1：见龙在田 推荐译为 a new begining，因为需要将这个词背后的含义翻译出来，表示新的开始\n考点2：小阳春 推荐译为 mini-boom，因为需要表达经济回暖的状况\n考点3：跑马圈地 推荐译为 land grabbing，因为需要表现出原文中对土地抢夺无序的状况\n考点4：适老化改善需求 推荐译为 age-friendly upgrade demand",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "159"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n宝钗自到荣府，因她美丽端方，行为豁达，入境随俗，不像黛玉那样清高自负，所以深得下人的喜爱，就是那些小丫头们也乐于和她说笑。黛玉心中有些不忿，她还不知。宝玉天性爱和女孩儿厮混，也看不出来，对她们都如姐妹，没有亲疏远近之分。\n东边宁府花园里梅花盛开，贾珍的妻子尤氏置办酒席，带着贾蓉夫妻去请贾母、邢夫人、王夫人等过来赏花。贾母等早饭后都过来，到会芳园游玩，先茶后酒。晌午时，宝玉困乏，想睡午觉。贾蓉的妻子秦氏就说：“我们有给宝叔收拾的房子，请老祖宗放心。”就带上宝玉一班人来到上房内间。宝玉见墙上挂着一幅鼓励人奋发勤学的《燃黎图》，还有一副对联：\n世事洞明皆学问，人情练达即文章。\n忙说：“快出去，快出去!”秦氏说：“宝叔嫌这里不好，就睡我屋里去吧。”一个嬷嬷说：“哪有小叔睡侄媳妇房里的?”秦氏笑着说：“哎哟，他有多大?别看宝叔和我弟弟同岁，两人站一起，还没有我弟弟高呢!”说着大家来到秦氏房中，只觉一股细细的甜香扑鼻。宝玉看墙上，挂着唐伯虎的《海棠春睡图》，两边是宋朝学士秦少游的对联：\n嫩寒锁梦因春冷，芳气袭人是酒香。\n再看房内摆设，没有一样不富丽堂皇。嬷嬷们服侍宝玉睡好，只留袭人、秋纹、晴雯、麝月四个丫头陪伴。秦氏出了房门，跟她的丫头们在廊檐下看猫儿打架。\n宝玉睡去，恍恍惚惚只觉得跟着秦氏，来到一个地方，但见朱栏玉砌，绿树清溪，是人间罕见之处。正高兴，忽听山后有人唱歌：\n春梦随云散，飞花逐水流。\n寄言众儿女，何必觅闲愁。\n宝玉听出是女孩儿的声音，放眼看去，见那边过来一位千娇百媚的丽人。再看她风姿翩翩，娉婷袅娜，与凡人不同，忙上前作揖，笑嘻嘻地问：“神仙姐姐，你从哪里来?到哪里去?能不能带上我?”仙姑说：“我住离恨天上，灌愁海中，乃是放春山遣香洞太虚幻境警幻仙姑，专司人间的风情月债，执掌尘世的女怨男痴。因近来风流冤孽，缠绵于此，所以来访察机会，布散相思。今日与你相逢，也非偶然。请跟我去一趟，听我新填《红楼梦》仙曲十二支。”宝玉欢喜踊跃，把秦氏忘到一边，跟着仙姑走到一个地方，见有一个石牌坊，上刻“太虚幻境”四字，两边是一副对联：\n假作真时真亦假，无为有处有还无。\n转过牌坊，是一座宫门，上书“孽海情天”四字，也有一副对联：\n厚地高天，堪叹古今情不尽；\n痴男怨女，可怜风月债难酬。\n宝玉心中迷惑，猜不透什么是“古今情”，解不开什么是“风月债”。他随仙姑进入二层门内，见两边配殿都有对联，一时看不过来，只见几处写着“痴情司”、“结怨司”、“朝啼司”、“暮哭司”、“春感司”、“秋感司”。他问：“仙姑能不能领我到各司游玩一下?”仙姑说：“各司存放的是普天下所有的女子过去未来的簿册，你肉眼凡胎，不便看。”宝玉不依，一定要看。仙姑见这是“薄命司”，就答应了。门上也有对联：\n春恨秋悲皆自惹，花容月貌为谁妍?\n宝玉感叹着进了门，见里面摆着十多个大橱，橱门上都贴着封条，封条上写着各种字。他见一个橱上的封条上书“金陵十二钗正册”，就问是什么意思。仙姑说：“就是贵省十二个冠首女子之册。”宝玉问：“金陵极大，怎么只十二个女子?”仙姑说：“贵省女子虽然多，不过择其名气大的录下来，两边二柜又差一等，那些平常人是不必记录的。”宝玉看下面一柜，写着“金陵十二钗副册”，又一柜上写着“金陵十二钗又副册”。他打开“又副册”橱门，取出一册来，翻开一页，见上面画的不是山水人物，而是一幅水墨渲染，如同乌云浊雾，后有几行字迹：\n霁月难逢，彩云易散。心比天高，身为下贱。风流灵巧招人怨。寿夭多因诽谤生，多情公子空牵念。\n宝玉又翻一页，画着一簇鲜花、一床破席，也有几句言辞：\n枉自温柔和顺，空云似桂如兰。\n堪羡优伶有福，谁知公子无缘。\n宝玉不解其意，扔了这册，开了“副册”橱门，拿出一册来，揭开一页，上画一枝桂花，下面有一干涸的池塘，荷叶枯败，写着：\n根并荷花一茎香，平生遭际实堪伤。\n自从两地生孤木，致使香魂返故乡。",
    "ori_text": "宝钗自到荣府，因她美丽端方，行为豁达，入境随俗，不像黛玉那样清高自负，所以深得下人的喜爱，就是那些小丫头们也乐于和她说笑。黛玉心中有些不忿，她还不知。宝玉天性爱和女孩儿厮混，也看不出来，对她们都如姐妹，没有亲疏远近之分。\n东边宁府花园里梅花盛开，贾珍的妻子尤氏置办酒席，带着贾蓉夫妻去请贾母、邢夫人、王夫人等过来赏花。贾母等早饭后都过来，到会芳园游玩，先茶后酒。晌午时，宝玉困乏，想睡午觉。贾蓉的妻子秦氏就说：“我们有给宝叔收拾的房子，请老祖宗放心。”就带上宝玉一班人来到上房内间。宝玉见墙上挂着一幅鼓励人奋发勤学的《燃黎图》，还有一副对联：\n世事洞明皆学问，人情练达即文章。\n忙说：“快出去，快出去!”秦氏说：“宝叔嫌这里不好，就睡我屋里去吧。”一个嬷嬷说：“哪有小叔睡侄媳妇房里的?”秦氏笑着说：“哎哟，他有多大?别看宝叔和我弟弟同岁，两人站一起，还没有我弟弟高呢!”说着大家来到秦氏房中，只觉一股细细的甜香扑鼻。宝玉看墙上，挂着唐伯虎的《海棠春睡图》，两边是宋朝学士秦少游的对联：\n嫩寒锁梦因春冷，芳气袭人是酒香。\n再看房内摆设，没有一样不富丽堂皇。嬷嬷们服侍宝玉睡好，只留袭人、秋纹、晴雯、麝月四个丫头陪伴。秦氏出了房门，跟她的丫头们在廊檐下看猫儿打架。\n宝玉睡去，恍恍惚惚只觉得跟着秦氏，来到一个地方，但见朱栏玉砌，绿树清溪，是人间罕见之处。正高兴，忽听山后有人唱歌：\n春梦随云散，飞花逐水流。\n寄言众儿女，何必觅闲愁。\n宝玉听出是女孩儿的声音，放眼看去，见那边过来一位千娇百媚的丽人。再看她风姿翩翩，娉婷袅娜，与凡人不同，忙上前作揖，笑嘻嘻地问：“神仙姐姐，你从哪里来?到哪里去?能不能带上我?”仙姑说：“我住离恨天上，灌愁海中，乃是放春山遣香洞太虚幻境警幻仙姑，专司人间的风情月债，执掌尘世的女怨男痴。因近来风流冤孽，缠绵于此，所以来访察机会，布散相思。今日与你相逢，也非偶然。请跟我去一趟，听我新填《红楼梦》仙曲十二支。”宝玉欢喜踊跃，把秦氏忘到一边，跟着仙姑走到一个地方，见有一个石牌坊，上刻“太虚幻境”四字，两边是一副对联：\n假作真时真亦假，无为有处有还无。\n转过牌坊，是一座宫门，上书“孽海情天”四字，也有一副对联：\n厚地高天，堪叹古今情不尽；\n痴男怨女，可怜风月债难酬。\n宝玉心中迷惑，猜不透什么是“古今情”，解不开什么是“风月债”。他随仙姑进入二层门内，见两边配殿都有对联，一时看不过来，只见几处写着“痴情司”、“结怨司”、“朝啼司”、“暮哭司”、“春感司”、“秋感司”。他问：“仙姑能不能领我到各司游玩一下?”仙姑说：“各司存放的是普天下所有的女子过去未来的簿册，你肉眼凡胎，不便看。”宝玉不依，一定要看。仙姑见这是“薄命司”，就答应了。门上也有对联：\n春恨秋悲皆自惹，花容月貌为谁妍?\n宝玉感叹着进了门，见里面摆着十多个大橱，橱门上都贴着封条，封条上写着各种字。他见一个橱上的封条上书“金陵十二钗正册”，就问是什么意思。仙姑说：“就是贵省十二个冠首女子之册。”宝玉问：“金陵极大，怎么只十二个女子?”仙姑说：“贵省女子虽然多，不过择其名气大的录下来，两边二柜又差一等，那些平常人是不必记录的。”宝玉看下面一柜，写着“金陵十二钗副册”，又一柜上写着“金陵十二钗又副册”。他打开“又副册”橱门，取出一册来，翻开一页，见上面画的不是山水人物，而是一幅水墨渲染，如同乌云浊雾，后有几行字迹：\n霁月难逢，彩云易散。心比天高，身为下贱。风流灵巧招人怨。寿夭多因诽谤生，多情公子空牵念。\n宝玉又翻一页，画着一簇鲜花、一床破席，也有几句言辞：\n枉自温柔和顺，空云似桂如兰。\n堪羡优伶有福，谁知公子无缘。\n宝玉不解其意，扔了这册，开了“副册”橱门，拿出一册来，揭开一页，上画一枝桂花，下面有一干涸的池塘，荷叶枯败，写着：\n根并荷花一茎香，平生遭际实堪伤。\n自从两地生孤木，致使香魂返故乡。",
    "reference_list": "考点1：尤氏 应译为 Madam You\n考点2：贾母 应译为 Grandmother Jia\n考点3：邢夫人 应译为 Lady Xing\n考点4：王夫人 应译为 Lady Wang\n考点5：会芳园 应译为 Huifang Garden\n考点6：秦氏 应译为 Madam Qin\n考点7：《燃黎图》 应译为 Painting of Burning Reeds\n考点8：嬷嬷 应译为 nursemaid 或 matron\n考点9：《海棠春睡图》 应译为 Crabapple Blossoms and Spring Slumber\n考点10：朱栏玉砌 应译为 vermilion balustrades and jade steps\n考点11：离恨天、灌愁海 应译为 Heaven of Parting Sorrows、Sea of Poured Grief\n考点12：太虚幻境 应译为 Illusory Land of Great Void\n考点13：孽海情天 应译为 Sea of Sin and Sky of Passion\n考点14：痴情司、结怨司、朝啼司、暮哭司、春感司、秋感司 应译为 Bureau of Infatuation, Bureau of Resentment, Bureau of Morning Lament, Bureau of Evening Weeping, Bureau of Spring Sentiment, Bureau of Autumn Sentiment\n考点15：薄命司 应译为 Registry of the Doomed Maidens 或 Office of Ill-Fated Beauties\n考点16：金陵十二钗正册 应译为 Primary Register of the Twelve Beauties of Jinling\n考点17：金陵十二钗副册 应译为 Secondary Register of the Twelve Beauties of Jinling\n考点18：金陵十二钗又副册 应译为 Supplementary Register of the Twelve Beauties of Jinling",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "小说",
    "prompt_id": "79"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThe U.S. dollar is the world’s primary reserve currency, and it is also the most widely used currency for trade and other international transactions. However, its hegemony has come into question in recent times due to geopolitical and geostrategic shifts. As a result, de-dollarization has increasingly become a substantive topic of discussion among investors, corporates and market participants more broadly.\n\nWhat are the potential implications of de-dollarization, and how is it playing out in global markets and trade? \n\nWhat is de-dollarization? \nIn short, de-dollarization entails a significant reduction in the use of dollars in world trade and financial transactions, decreasing national, institutional and corporate demand for the greenback.\n\n“The concept of de-dollarization relates to changes in the structural demand for the dollar that would relate to its status as a reserve currency. This encompasses areas that relate to the longer-term use of the dollar, such as transactional dominance in FX volumes or commodities trade, denomination of liabilities and share in central bank FX reserves,” said Luis Oganes, head of Global Macro Research at J.P. Morgan.\n\nImportantly, this structural shift is distinct from the cyclical demand for the greenback, which is shorter term and has in recent times been driven by U.S. exceptionalism, including the relative outperformance of the U.S. equity market. “The world has become long on the dollar in recent years, but as U.S. exceptionalism erodes, it should be reasonable to expect the overhang in USD longs to diminish as well,” Oganes said. \n\nWhat are the causes and implications of de-dollarization? \nThere are two main factors that could erode the dollar’s status. The first includes adverse events that undermine the perceived safety and stability of the greenback — and the U.S.’s overall standing as the world’s leading economic, political and military power. For instance, increased polarization in the U.S. could jeopardize its governance, which underpins its role as a global safe haven. Ongoing U.S. tariff policy could also cause investors to lose confidence in American assets.\n\nThe second factor involves positive developments outside the U.S. that boost the credibility of alternative currencies — economic and political reforms in China, for example. “A candidate reserve currency must be perceived as safe and stable and must provide a source of liquidity that is sufficient to meet growing global demand,” said Alexander Wise, who covers Long-Term Strategy at J.P. Morgan.\n\nFundamentally, de-dollarization could shift the balance of power among countries, and this could, in turn, reshape the global economy and markets. The impact would be most acutely felt in the U.S., where de-dollarization would likely lead to a broad depreciation and underperformance of U.S. financial assets versus the rest of the world.\n\n“For U.S. equities, outright and relative returns would be negatively impacted by divestment or reallocation away from U.S. markets and a severe loss in confidence. There would also likely be upward pressure on real yields due to the partial divestment of U.S. fixed income by investors, or the diversification or reduction of international reserve allocations,” Wise said. \n\n\n\n\nGlobal trade\nThe U.S.’s share in global exports and output has declined over the past three decades, while China’s has increased substantially. Nonetheless, the transactional dominance of the dollar is still evident in FX volumes, trade invoicing, cross-border liabilities denomination and foreign currency debt issuance.\n\nIn 2022, the greenback dominated 88% of traded FX volumes — close to record highs — while the Chinese yuan (CNY) made up just 7%, according to data from the Bank for International Settlements (BIS).\n\nLikewise, there is little sign of USD erosion in trade invoicing. “The share of USD and EUR has held steady over the past two decades at around 40–50%. While the share of CNY is increasing in China’s cross-border transactions as it moves to conduct bilateral trade in its own currency terms, it is still low from a global standpoint,” Oganes observed.\n\nThe dollar has also stoutly maintained its superiority when it comes to cross-border liabilities, where its market share stands at 48%. And in foreign currency debt issuance, its share has remained constant since the global financial crisis, at around 70%. “The daylight from the euro, whose share is at 20%, is even greater on this front,” Oganes added. \n\nFX reserves\nOn the other hand, de-dollarization is unfolding in central bank FX reserves, where the share of USD has slid to a two-decade low in tandem with its macro footprint. “However, the dollar share in FX reserves was lower in the early 1990s, so the recent decline to just under 60% is not completely out of the norm,” said Meera Chandan, co-head of Global FX Strategy at J.P. Morgan.\n\nWhile much of the reallocation of FX reserves has gone to CNY and other currencies, USD and EUR still dominate levels. “The CNY footprint is still very small, even if growing, and its push for bilateral invoicing is likely to keep this trend on the upswing,” Chandan noted.\n\nThe main de-dollarization trend in FX reserves, however, pertains to the growing demand for gold. Seen as an alternative to heavily indebted fiat currencies, the share of gold in FX reserves has increased, led by emerging market (EM) central banks — China, Russia and Türkiye have been the largest buyers in the last decade. Overall, while the share of gold in FX reserves in EM is still low at 9%, the figure is more than double the 4% seen a decade ago; the corresponding share for DM countries is much larger at 20%. This increased demand has in turn partly driven the current bull market in gold, with prices forecast to climb toward $4,000/oz by mid-2026.\n\n\nBond markets\nIn a sign of de-dollarization in bond markets, the share of foreign ownership in the U.S. Treasury market has been declining over the last 15 years.\n\nUSD assets, principally liquid Treasuries, account for the majority of allocated FX reserves. However, demand for Treasuries has stagnated among foreign official institutions, as the growth of FX reserves has slowed and the USD’s share of reserves has dropped from its recent peak. Similarly, the backdrop for foreign private demand has weakened — as yields have risen across DM government bond markets, Treasuries have become relatively less attractive. While foreign investors remain the largest constituent within the Treasury market, their share of ownership has fallen to 30% as of early 2025 — down from a peak of above 50% during the GFC.\n\n“Although foreign demand has not kept pace with the growth of the Treasury market for more than a decade, we must consider what more aggressive action could mean. Japan is the largest foreign creditor and alone holds more than $1.1 trillion Treasuries, or nearly 4% of the market. Accordingly, any significant foreign selling would be impactful, driving yields higher,” said Jay Barry, head of Global Rates Strategy at J.P. Morgan.\n\nAccording to estimates by J.P. Morgan Research, each 1-percentage-point decline in foreign holdings relative to GDP (or approximately $300 billion of Treasuries) would result in yields rising by more than 33 basis points (bp). “While this is not our base case, it nonetheless underscores the impact of foreign investment on risk-free rates,” Barry added.\n\n\n\nCommodity markets \nDe-dollarization is most visible in commodity markets, where the greenback’s influence on pricing has diminished. “Today, a large and growing proportion of energy is being priced in non-dollar-denominated contracts,” said Natasha Kaneva, head of Global Commodities Strategy at J.P. Morgan.\n\nFor example, due to Western sanctions, Russian oil products exported eastward and southward are being sold in the local currencies of buyers, or in the currencies of countries Russia perceives as friendly. Among buyers, India, China and Turkey are all either using or seeking alternatives to the dollar. Saudi Arabia is also considering adding yuan-denominated futures contracts in the pricing model of Saudi Arabian oil, though progress has been slow.\n\nNotably, cross-border trade settlement in yuan is gaining ground outside of oil too. Some Indian companies have started paying for Russian coal imports in yuan, even without the involvement of Chinese intermediaries. Bangladesh also recently decided to pay Russia for its 1.4 GW nuclear power plant in yuan.\n\n“The de-dollarization trend in the commodity trade is a boon for countries like India, China, Brazil, Thailand and Indonesia, which can now not only buy oil at a discount, but also pay for it with their own local currencies,” Kaneva noted. “This reduces the need for precautionary reserves of U.S. dollars, U.S. Treasuries and oil, which might in turn free up capital to be deployed in growth-boosting domestic projects.” \n\nDeposit dollarization in emerging markets \nAt the other end of the spectrum, deposit dollarization — where a significant portion of a country’s bank deposits are denominated in the U.S. dollar instead of the local currency — is still evident in many EM countries. “The tendency of EM residents to dollarize in times of stress appears to be correlated across markets,” said Jonny Goulden, head of EM Fixed Income Strategy at J.P. Morgan.\n\nAccording to J.P. Morgan Research, dollar deposits have grown mostly uninterrupted over the last decade in EM, reaching around $830 billion for a sample set of 18 EM countries (excluding China, Singapore and Hong Kong). “While there are large regional divergences in deposit dollarization across EM, all regions are more dollarized now than they were a decade ago,” Goulden noted. Latin America is the most dollarized region, with an aggregate dollarization rate of 19.1%. EMEA’s rate stands at 15.2%, while Asia (excluding China, Singapore and Hong Kong) has the lowest rate at 9.7%.\n\nChina is the exception, as its dollarization rate has been persistently falling since 2017. “This is not surprising, as this was around the time when U.S.–China relations began shifting into their current state, marked by the trade war and growing diplomatic, security and geopolitical tensions,” Goulden said. “This suggests that China, alongside progress on de-dollarizing its own cross-border transactions, has effectively been de-dollarizing the deposits of Chinese residents, adding another dimension to its efforts to separate from U.S. dominance.” ",
    "ori_text": "\n\nThe U.S. dollar is the world’s primary reserve currency, and it is also the most widely used currency for trade and other international transactions. However, its hegemony has come into question in recent times due to geopolitical and geostrategic shifts. As a result, de-dollarization has increasingly become a substantive topic of discussion among investors, corporates and market participants more broadly.\n\nWhat are the potential implications of de-dollarization, and how is it playing out in global markets and trade? \n\nWhat is de-dollarization? \nIn short, de-dollarization entails a significant reduction in the use of dollars in world trade and financial transactions, decreasing national, institutional and corporate demand for the greenback.\n\n“The concept of de-dollarization relates to changes in the structural demand for the dollar that would relate to its status as a reserve currency. This encompasses areas that relate to the longer-term use of the dollar, such as transactional dominance in FX volumes or commodities trade, denomination of liabilities and share in central bank FX reserves,” said Luis Oganes, head of Global Macro Research at J.P. Morgan.\n\nImportantly, this structural shift is distinct from the cyclical demand for the greenback, which is shorter term and has in recent times been driven by U.S. exceptionalism, including the relative outperformance of the U.S. equity market. “The world has become long on the dollar in recent years, but as U.S. exceptionalism erodes, it should be reasonable to expect the overhang in USD longs to diminish as well,” Oganes said. \n\nWhat are the causes and implications of de-dollarization? \nThere are two main factors that could erode the dollar’s status. The first includes adverse events that undermine the perceived safety and stability of the greenback — and the U.S.’s overall standing as the world’s leading economic, political and military power. For instance, increased polarization in the U.S. could jeopardize its governance, which underpins its role as a global safe haven. Ongoing U.S. tariff policy could also cause investors to lose confidence in American assets.\n\nThe second factor involves positive developments outside the U.S. that boost the credibility of alternative currencies — economic and political reforms in China, for example. “A candidate reserve currency must be perceived as safe and stable and must provide a source of liquidity that is sufficient to meet growing global demand,” said Alexander Wise, who covers Long-Term Strategy at J.P. Morgan.\n\nFundamentally, de-dollarization could shift the balance of power among countries, and this could, in turn, reshape the global economy and markets. The impact would be most acutely felt in the U.S., where de-dollarization would likely lead to a broad depreciation and underperformance of U.S. financial assets versus the rest of the world.\n\n“For U.S. equities, outright and relative returns would be negatively impacted by divestment or reallocation away from U.S. markets and a severe loss in confidence. There would also likely be upward pressure on real yields due to the partial divestment of U.S. fixed income by investors, or the diversification or reduction of international reserve allocations,” Wise said. \n\n\n\n\nGlobal trade\nThe U.S.’s share in global exports and output has declined over the past three decades, while China’s has increased substantially. Nonetheless, the transactional dominance of the dollar is still evident in FX volumes, trade invoicing, cross-border liabilities denomination and foreign currency debt issuance.\n\nIn 2022, the greenback dominated 88% of traded FX volumes — close to record highs — while the Chinese yuan (CNY) made up just 7%, according to data from the Bank for International Settlements (BIS).\n\nLikewise, there is little sign of USD erosion in trade invoicing. “The share of USD and EUR has held steady over the past two decades at around 40–50%. While the share of CNY is increasing in China’s cross-border transactions as it moves to conduct bilateral trade in its own currency terms, it is still low from a global standpoint,” Oganes observed.\n\nThe dollar has also stoutly maintained its superiority when it comes to cross-border liabilities, where its market share stands at 48%. And in foreign currency debt issuance, its share has remained constant since the global financial crisis, at around 70%. “The daylight from the euro, whose share is at 20%, is even greater on this front,” Oganes added. \n\nFX reserves\nOn the other hand, de-dollarization is unfolding in central bank FX reserves, where the share of USD has slid to a two-decade low in tandem with its macro footprint. “However, the dollar share in FX reserves was lower in the early 1990s, so the recent decline to just under 60% is not completely out of the norm,” said Meera Chandan, co-head of Global FX Strategy at J.P. Morgan.\n\nWhile much of the reallocation of FX reserves has gone to CNY and other currencies, USD and EUR still dominate levels. “The CNY footprint is still very small, even if growing, and its push for bilateral invoicing is likely to keep this trend on the upswing,” Chandan noted.\n\nThe main de-dollarization trend in FX reserves, however, pertains to the growing demand for gold. Seen as an alternative to heavily indebted fiat currencies, the share of gold in FX reserves has increased, led by emerging market (EM) central banks — China, Russia and Türkiye have been the largest buyers in the last decade. Overall, while the share of gold in FX reserves in EM is still low at 9%, the figure is more than double the 4% seen a decade ago; the corresponding share for DM countries is much larger at 20%. This increased demand has in turn partly driven the current bull market in gold, with prices forecast to climb toward $4,000/oz by mid-2026.\n\n\nBond markets\nIn a sign of de-dollarization in bond markets, the share of foreign ownership in the U.S. Treasury market has been declining over the last 15 years.\n\nUSD assets, principally liquid Treasuries, account for the majority of allocated FX reserves. However, demand for Treasuries has stagnated among foreign official institutions, as the growth of FX reserves has slowed and the USD’s share of reserves has dropped from its recent peak. Similarly, the backdrop for foreign private demand has weakened — as yields have risen across DM government bond markets, Treasuries have become relatively less attractive. While foreign investors remain the largest constituent within the Treasury market, their share of ownership has fallen to 30% as of early 2025 — down from a peak of above 50% during the GFC.\n\n“Although foreign demand has not kept pace with the growth of the Treasury market for more than a decade, we must consider what more aggressive action could mean. Japan is the largest foreign creditor and alone holds more than $1.1 trillion Treasuries, or nearly 4% of the market. Accordingly, any significant foreign selling would be impactful, driving yields higher,” said Jay Barry, head of Global Rates Strategy at J.P. Morgan.\n\nAccording to estimates by J.P. Morgan Research, each 1-percentage-point decline in foreign holdings relative to GDP (or approximately $300 billion of Treasuries) would result in yields rising by more than 33 basis points (bp). “While this is not our base case, it nonetheless underscores the impact of foreign investment on risk-free rates,” Barry added.\n\n\n\nCommodity markets \nDe-dollarization is most visible in commodity markets, where the greenback’s influence on pricing has diminished. “Today, a large and growing proportion of energy is being priced in non-dollar-denominated contracts,” said Natasha Kaneva, head of Global Commodities Strategy at J.P. Morgan.\n\nFor example, due to Western sanctions, Russian oil products exported eastward and southward are being sold in the local currencies of buyers, or in the currencies of countries Russia perceives as friendly. Among buyers, India, China and Turkey are all either using or seeking alternatives to the dollar. Saudi Arabia is also considering adding yuan-denominated futures contracts in the pricing model of Saudi Arabian oil, though progress has been slow.\n\nNotably, cross-border trade settlement in yuan is gaining ground outside of oil too. Some Indian companies have started paying for Russian coal imports in yuan, even without the involvement of Chinese intermediaries. Bangladesh also recently decided to pay Russia for its 1.4 GW nuclear power plant in yuan.\n\n“The de-dollarization trend in the commodity trade is a boon for countries like India, China, Brazil, Thailand and Indonesia, which can now not only buy oil at a discount, but also pay for it with their own local currencies,” Kaneva noted. “This reduces the need for precautionary reserves of U.S. dollars, U.S. Treasuries and oil, which might in turn free up capital to be deployed in growth-boosting domestic projects.” \n\nDeposit dollarization in emerging markets \nAt the other end of the spectrum, deposit dollarization — where a significant portion of a country’s bank deposits are denominated in the U.S. dollar instead of the local currency — is still evident in many EM countries. “The tendency of EM residents to dollarize in times of stress appears to be correlated across markets,” said Jonny Goulden, head of EM Fixed Income Strategy at J.P. Morgan.\n\nAccording to J.P. Morgan Research, dollar deposits have grown mostly uninterrupted over the last decade in EM, reaching around $830 billion for a sample set of 18 EM countries (excluding China, Singapore and Hong Kong). “While there are large regional divergences in deposit dollarization across EM, all regions are more dollarized now than they were a decade ago,” Goulden noted. Latin America is the most dollarized region, with an aggregate dollarization rate of 19.1%. EMEA’s rate stands at 15.2%, while Asia (excluding China, Singapore and Hong Kong) has the lowest rate at 9.7%.\n\nChina is the exception, as its dollarization rate has been persistently falling since 2017. “This is not surprising, as this was around the time when U.S.–China relations began shifting into their current state, marked by the trade war and growing diplomatic, security and geopolitical tensions,” Goulden said. “This suggests that China, alongside progress on de-dollarizing its own cross-border transactions, has effectively been de-dollarizing the deposits of Chinese residents, adding another dimension to its efforts to separate from U.S. dominance.” ",
    "reference_list": "考点1：“overhang in USD longs” 在这个语境里应该翻译成“过剩的美元多头头寸”或者“超额美元多头头寸”\n考点2：“base case”推荐译为““基准情形”、“基本预测”或“基本假设”\n考点3：“the share of foreign ownership in the U.S. Treasury market ” 中的share不能被翻译成“持股比例”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "177"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 更让人困惑的是，有报道称神经干细胞（NSCs）可去分化为分化程度更低的祖细胞，甚至可分化为通常来源于其他两个胚层的细胞类型。\n成熟生物体中的正常二倍体细胞含有几乎相同的DNA，而细胞类型是由特定基因的选择性转录或抑制所决定的。如今越来越明确的是，任何体细胞都有可能被重编程为分化程度更低的状态，尽管这一过程的潜在机制尚未明确。细胞融合研究已证实，多能干细胞中含有可重编程宿主体细胞核的因子，使其分化潜能的限制减少。例如，胸腺细胞与胚胎癌细胞融合后，可重新激活雄性来源胸腺细胞中的X染色体。同样，将室管膜下区（SVZ）神经干细胞与肌肉细胞共培养，可诱导其分化为表达特定肌肉标志物的肌细胞。\n这种可塑性并非神经干细胞所特有，有大量报道显示非神经干细胞可转分化为神经前体形式。更有趣的是，从骨髓基质中分离出的间充质干细胞群可被诱导生成神经元、少突胶质细胞和星形胶质细胞。\n也有证据表明体内存在生长因子介导的去分化现象。近藤（Kondo）和拉夫（Raff）通过骨形态发生蛋白（BMPs）处理纯化的少突胶质细胞祖细胞，使其成为神经干细胞。由此产生的细胞能够生成神经元和星形胶质细胞，不过尚未正式排除原始视神经制备物中存在微量污染干细胞的可能性。在另一项研究中，为帮助腿部溃疡愈合而接受人表皮生长因子（EGF）治疗的患者，其再生表皮中含有表达β-1整合素和角蛋白19的细胞，而这两种蛋白是表皮干细胞的标志物。然而，这些实验并未排除现有干细胞被募集到伤口部位的可能性。\n不过，干细胞转分化的概念并未得到普遍认可。在一项研究中，比约森（Bjornson）等人将克隆来源的神经干细胞静脉注射到经辐射处理的小鼠尾静脉中，发现这些干细胞生成了大量造血细胞。但范德库伊（Van der Kooy）及其同事的研究未能重复上述结果——他们给128只宿主动物每只的尾静脉注射100万个神经球细胞，却未检测到来自标记神经球的大量造血细胞，研究认为早期实验中干细胞的长期培养可能是导致结果差异的原因。\n最近，两项独立研究为转分化提供了另一种解释。第一项研究中，将绿色荧光蛋白（GFP）标记的神经元与潮霉素抗性胚胎干细胞（ES细胞）共培养，获得了具有神经元和ES细胞双重分子特征的未分化杂交细胞。第二项研究中，将GFP标记的骨髓细胞与ES细胞共培养，产生了GFP阳性的融合细胞，这些细胞表达多种ES细胞基因。值得注意的是，这些杂交细胞主要为四倍体，这表明骨髓细胞可与其他细胞类型自发融合并获得其表型。\n当然，从伦理角度而言，转分化的争议备受关注。有观点认为，若成体干细胞可被诱导分化为任何细胞类型，那么对胚胎干细胞研究的需求就会减少。然而，大量研究仍表明，胎儿干细胞的可塑性显著高于成体干细胞。\n神经发生与脑损伤\n当前，许多研究聚焦于理解神经退行性疾病及脑损伤后的神经发生。这类研究既探究内源性修复的潜力，也旨在深入了解受损脑内的许可性和限制性信号——这对于未来考虑细胞替代疗法至关重要。现已明确，中枢神经系统（CNS）损伤确实会导致神经前体细胞增殖。\n多项研究结合BrdU标记与神经元特异性标志物，证实了实验性卒中后内源性神经前体细胞的增殖与分化。例如，在沙鼠脑缺血模型中，研究人员利用BrdU结合多唾液酸神经细胞黏附分子（PSA-NCAM）和神经元核抗原（NeuN）分别标记神经干细胞和神经元，以探究神经干细胞的增殖、迁移和分化情况。损伤后20天，首先在齿状回颗粒下区检测到BrdU标记的神经干细胞，而NeuN阳性神经元的数量在损伤后60天内持续增加。\n同样，沙鼠全脑缺血后，齿状回颗粒下区的神经发生增加了10倍。\n卒中后的内源性修复还可能涉及室管膜下区（SVZ）神经祖细胞的增殖。大脑中动脉闭塞后，注射BrdU可特异性标记室管膜层和室管膜下层的细胞。有趣的是，这些细胞在卒中后立即被染色为星形胶质细胞，但在损伤后后期获得了神经元的特征性抗原标志物，这进一步支持了阿尔瓦雷斯-布伊拉（Alvarez-Buylla）的室管膜下区干细胞假说。在另一项采用化学诱导啮齿类动物癫痫发作的模型中，研究报道室管膜下区神经前体细胞的生成显著增加，且这些细胞随后向嗅球迁移并整合。BrdU标记证实了细胞增殖，逆转录病毒示踪证实了细胞迁移。尽管有人提出缺血诱导的神经发生可能有助于损伤后缺失的特定记忆功能恢复，但在损伤后的数周内，大部分分裂细胞会丢失。此类反应是特异性的，还是在已有成年神经发生的区域出现的一般性整体反应，仍有待证实。损伤后神经细胞类型的生成与存活现象，引发了人们对能否利用外源性细胞在细胞缺失的疾病和损伤中进行细胞替代的关注。\n利用干细胞修复受损神经系统\n如上所述，有令人振奋的证据表明，健康成年脑内存在神经细胞的增殖与分化，且损伤可进一步刺激这一过程。然而，神经细胞的再生能力有限，内源性神经干细胞数量较少，似乎无法在损伤后完全重建并恢复功能。这促使多个研究团队探究脑损伤后细胞替代疗法的潜力。\n这些研究充分表明，在适宜条件下，细胞移植物可在脑内整合并发挥功能。\n细胞替代的主要来源有三种：胎儿神经组织、永生化细胞系和胚胎干细胞（ES细胞）。胎儿神经细胞移植已用于多种脑损伤模型。在成年大鼠局灶性前脑缺血损伤后，胎儿皮质移植物可在梗死区域存活，且似乎能接收来自周围脑组织的连接，进而改善运动功能、空间学习和记忆能力。在患有神经退行性疾病的人类中，胎儿神经细胞移植已有应用经验。目前，已有300多名帕金森病患者接受了移植到纹状体的胎儿中脑前体细胞。这些移植物具有自主活性，可将多巴胺释放恢复至接近正常水平，并改善症状。然而，存在一个弊端：在丹佛和纽约的近期临床试验中，15%的移植患者出现了难以接受的运动障碍。此外，胎儿神经组织的供应有限，因此可获得的神经元数量较少。这一问题可通过体外扩增部分解决。令人鼓舞的是，培养扩增的胚胎12天神经干细胞仍保留分化为多巴胺能神经元的能力，并能改善帕金森病大鼠模型的结局。移植物的免疫排斥及后续失败也是一个问题，尤其是在胎儿多巴胺能神经元异种移植中，移植物存活率低且无临床改善。胚胎细胞的一个潜在优势是可通过克隆技术进行修饰，以表达患者自身的基因型。该技术可用于提供免疫相容性细胞用于移植。然而，有观点认为，ES细胞在培养中无限增殖的能力并非导致移植排斥，而是给受者带来了肿瘤发生的实际风险。因此，使用成体干细胞而非胚胎来源干细胞可能不仅出于伦理原因。\n作为胎儿组织的替代物，永生化细胞系已用于脑损伤的动物研究。将人畸胎瘤细胞系来源的神经元移植到局灶性缺血大鼠体内，实现了组织学整合并改善了功能；将海马神经上皮细胞系移植到小鼠受损海马中也得到了类似结果。多项研究还证实，少突胶质细胞祖细胞（OPCs）可成功移植用于治疗脱髓鞘疾病。在通过注射髓鞘碱性蛋白诱导实验性自身免疫性脑脊髓炎（EAE）前，将OPCs移植到大鼠脊髓中，其可长期存活。令人印象深刻的是，所用细胞系（CG4）在健康大鼠中可迁移至6厘米远的神经纤维束，且尽管经过转化，仍未出现失控增殖。移植的祖细胞与反应性星形胶质细胞的密切联系表明，与当前的传统观点相反，受损中枢神经系统内的炎症信号实际上可促进整合。这些结果与富兰克林（Franklin）等人的研究一致，他们发现CG4细胞也可整合到溴化乙锭诱导的脊髓脱髓鞘病灶中。在该研究中，细胞同样从注射部位迁移至脱髓鞘区域重新定植，且再次无法穿透未受损的白质组织。然而，人们严重担忧永生化细胞系易发生肿瘤发生，且无法重建脑损伤中丢失的多种细胞类型。这使得它们在临床应用中仅具有有限价值。\n\n\n",
    "ori_text": "\n\n 更让人困惑的是，有报道称神经干细胞（NSCs）可去分化为分化程度更低的祖细胞，甚至可分化为通常来源于其他两个胚层的细胞类型。\n成熟生物体中的正常二倍体细胞含有几乎相同的DNA，而细胞类型是由特定基因的选择性转录或抑制所决定的。如今越来越明确的是，任何体细胞都有可能被重编程为分化程度更低的状态，尽管这一过程的潜在机制尚未明确。细胞融合研究已证实，多能干细胞中含有可重编程宿主体细胞核的因子，使其分化潜能的限制减少。例如，胸腺细胞与胚胎癌细胞融合后，可重新激活雄性来源胸腺细胞中的X染色体。同样，将室管膜下区（SVZ）神经干细胞与肌肉细胞共培养，可诱导其分化为表达特定肌肉标志物的肌细胞。\n这种可塑性并非神经干细胞所特有，有大量报道显示非神经干细胞可转分化为神经前体形式。更有趣的是，从骨髓基质中分离出的间充质干细胞群可被诱导生成神经元、少突胶质细胞和星形胶质细胞。\n也有证据表明体内存在生长因子介导的去分化现象。近藤（Kondo）和拉夫（Raff）通过骨形态发生蛋白（BMPs）处理纯化的少突胶质细胞祖细胞，使其成为神经干细胞。由此产生的细胞能够生成神经元和星形胶质细胞，不过尚未正式排除原始视神经制备物中存在微量污染干细胞的可能性。在另一项研究中，为帮助腿部溃疡愈合而接受人表皮生长因子（EGF）治疗的患者，其再生表皮中含有表达β-1整合素和角蛋白19的细胞，而这两种蛋白是表皮干细胞的标志物。然而，这些实验并未排除现有干细胞被募集到伤口部位的可能性。\n不过，干细胞转分化的概念并未得到普遍认可。在一项研究中，比约森（Bjornson）等人将克隆来源的神经干细胞静脉注射到经辐射处理的小鼠尾静脉中，发现这些干细胞生成了大量造血细胞。但范德库伊（Van der Kooy）及其同事的研究未能重复上述结果——他们给128只宿主动物每只的尾静脉注射100万个神经球细胞，却未检测到来自标记神经球的大量造血细胞，研究认为早期实验中干细胞的长期培养可能是导致结果差异的原因。\n最近，两项独立研究为转分化提供了另一种解释。第一项研究中，将绿色荧光蛋白（GFP）标记的神经元与潮霉素抗性胚胎干细胞（ES细胞）共培养，获得了具有神经元和ES细胞双重分子特征的未分化杂交细胞。第二项研究中，将GFP标记的骨髓细胞与ES细胞共培养，产生了GFP阳性的融合细胞，这些细胞表达多种ES细胞基因。值得注意的是，这些杂交细胞主要为四倍体，这表明骨髓细胞可与其他细胞类型自发融合并获得其表型。\n当然，从伦理角度而言，转分化的争议备受关注。有观点认为，若成体干细胞可被诱导分化为任何细胞类型，那么对胚胎干细胞研究的需求就会减少。然而，大量研究仍表明，胎儿干细胞的可塑性显著高于成体干细胞。\n神经发生与脑损伤\n当前，许多研究聚焦于理解神经退行性疾病及脑损伤后的神经发生。这类研究既探究内源性修复的潜力，也旨在深入了解受损脑内的许可性和限制性信号——这对于未来考虑细胞替代疗法至关重要。现已明确，中枢神经系统（CNS）损伤确实会导致神经前体细胞增殖。\n多项研究结合BrdU标记与神经元特异性标志物，证实了实验性卒中后内源性神经前体细胞的增殖与分化。例如，在沙鼠脑缺血模型中，研究人员利用BrdU结合多唾液酸神经细胞黏附分子（PSA-NCAM）和神经元核抗原（NeuN）分别标记神经干细胞和神经元，以探究神经干细胞的增殖、迁移和分化情况。损伤后20天，首先在齿状回颗粒下区检测到BrdU标记的神经干细胞，而NeuN阳性神经元的数量在损伤后60天内持续增加。\n同样，沙鼠全脑缺血后，齿状回颗粒下区的神经发生增加了10倍。\n卒中后的内源性修复还可能涉及室管膜下区（SVZ）神经祖细胞的增殖。大脑中动脉闭塞后，注射BrdU可特异性标记室管膜层和室管膜下层的细胞。有趣的是，这些细胞在卒中后立即被染色为星形胶质细胞，但在损伤后后期获得了神经元的特征性抗原标志物，这进一步支持了阿尔瓦雷斯-布伊拉（Alvarez-Buylla）的室管膜下区干细胞假说。在另一项采用化学诱导啮齿类动物癫痫发作的模型中，研究报道室管膜下区神经前体细胞的生成显著增加，且这些细胞随后向嗅球迁移并整合。BrdU标记证实了细胞增殖，逆转录病毒示踪证实了细胞迁移。尽管有人提出缺血诱导的神经发生可能有助于损伤后缺失的特定记忆功能恢复，但在损伤后的数周内，大部分分裂细胞会丢失。此类反应是特异性的，还是在已有成年神经发生的区域出现的一般性整体反应，仍有待证实。损伤后神经细胞类型的生成与存活现象，引发了人们对能否利用外源性细胞在细胞缺失的疾病和损伤中进行细胞替代的关注。\n利用干细胞修复受损神经系统\n如上所述，有令人振奋的证据表明，健康成年脑内存在神经细胞的增殖与分化，且损伤可进一步刺激这一过程。然而，神经细胞的再生能力有限，内源性神经干细胞数量较少，似乎无法在损伤后完全重建并恢复功能。这促使多个研究团队探究脑损伤后细胞替代疗法的潜力。\n这些研究充分表明，在适宜条件下，细胞移植物可在脑内整合并发挥功能。\n细胞替代的主要来源有三种：胎儿神经组织、永生化细胞系和胚胎干细胞（ES细胞）。胎儿神经细胞移植已用于多种脑损伤模型。在成年大鼠局灶性前脑缺血损伤后，胎儿皮质移植物可在梗死区域存活，且似乎能接收来自周围脑组织的连接，进而改善运动功能、空间学习和记忆能力。在患有神经退行性疾病的人类中，胎儿神经细胞移植已有应用经验。目前，已有300多名帕金森病患者接受了移植到纹状体的胎儿中脑前体细胞。这些移植物具有自主活性，可将多巴胺释放恢复至接近正常水平，并改善症状。然而，存在一个弊端：在丹佛和纽约的近期临床试验中，15%的移植患者出现了难以接受的运动障碍。此外，胎儿神经组织的供应有限，因此可获得的神经元数量较少。这一问题可通过体外扩增部分解决。令人鼓舞的是，培养扩增的胚胎12天神经干细胞仍保留分化为多巴胺能神经元的能力，并能改善帕金森病大鼠模型的结局。移植物的免疫排斥及后续失败也是一个问题，尤其是在胎儿多巴胺能神经元异种移植中，移植物存活率低且无临床改善。胚胎细胞的一个潜在优势是可通过克隆技术进行修饰，以表达患者自身的基因型。该技术可用于提供免疫相容性细胞用于移植。然而，有观点认为，ES细胞在培养中无限增殖的能力并非导致移植排斥，而是给受者带来了肿瘤发生的实际风险。因此，使用成体干细胞而非胚胎来源干细胞可能不仅出于伦理原因。\n作为胎儿组织的替代物，永生化细胞系已用于脑损伤的动物研究。将人畸胎瘤细胞系来源的神经元移植到局灶性缺血大鼠体内，实现了组织学整合并改善了功能；将海马神经上皮细胞系移植到小鼠受损海马中也得到了类似结果。多项研究还证实，少突胶质细胞祖细胞（OPCs）可成功移植用于治疗脱髓鞘疾病。在通过注射髓鞘碱性蛋白诱导实验性自身免疫性脑脊髓炎（EAE）前，将OPCs移植到大鼠脊髓中，其可长期存活。令人印象深刻的是，所用细胞系（CG4）在健康大鼠中可迁移至6厘米远的神经纤维束，且尽管经过转化，仍未出现失控增殖。移植的祖细胞与反应性星形胶质细胞的密切联系表明，与当前的传统观点相反，受损中枢神经系统内的炎症信号实际上可促进整合。这些结果与富兰克林（Franklin）等人的研究一致，他们发现CG4细胞也可整合到溴化乙锭诱导的脊髓脱髓鞘病灶中。在该研究中，细胞同样从注射部位迁移至脱髓鞘区域重新定植，且再次无法穿透未受损的白质组织。然而，人们严重担忧永生化细胞系易发生肿瘤发生，且无法重建脑损伤中丢失的多种细胞类型。这使得它们在临床应用中仅具有有限价值。\n\n\n",
    "reference_list": "考点1：“间充质干细胞” 只能翻译为 “mesenchymal stem cells”，因为这是医学术语\n考点2：“骨形态发生蛋白（BMPs）”  只能翻译为 “bone morphogenetic proteins (BMPs)”，因为这是医学术语\n考点3：“绿色荧光蛋白（GFP）”  只能翻译为 “green fluorescent protein (GFP)”，因为这是医学术语\n考点4：“少突胶质细胞祖细胞（OPCs）”  只能翻译为 “oligodendrocyte progenitor cells (OPCs)”，因为这是医学术语\n考点5：“多唾液酸神经细胞黏附分子（PSA-NCAM）”  只能翻译为 “polysialylated neural cell adhesion molecule (PSA-NCAM)”，因为这是医学术语\n考点6：“神经元核抗原（NeuN）” 只能翻译为 “neuronal nuclear antigen (NeuN)”，因为这是医学术语\n考点7：“大脑中动脉闭塞”  只能翻译为 middle cerebral artery occlusion”，因为这是医学术语\n考点8：“多巴胺能神经元”  只能翻译为 “dopaminergic neurones”，因为这是医学术语\n考点9：“畸胎瘤” 只能翻译为 “teratocarcinoma”，因为这是医学术语\n考点10：“全脑缺血”  只能翻译为 “global cerebral ischemia ”，因为这是医学术语\n考点11：“运动障碍”  只能翻译为 “dyskinesias”，强调患者是病理性不自主运动。不可翻译为 “motor disturbances”，\n考点12：“传统观点” 在文中指神经科学领域中长期公认的学术观点，在科学文献中常用 “dogma” 表示这类“被普遍接受的教条式观点”。需要翻译为 “current dogma”。不能翻译为 “current conventional views”，“conventional views” 仅指“传统看法”，无法体现文中语境表现的“学术领域内长期公认的教条式观点”这一深层含义。\n考点13：“异种移植”  只能翻译为“xenotransplantation”。\n考点14：“前神经体细胞”  只能翻译为 “neural progenitor cell”，因为这是医学术语",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "197"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nSummary\nCompanies want to rapidly digitize procurement by exploiting emerging technologies like AI. However, traditional IT investment and adoption processes are often too slow and rigid. To overcome the obstacles, BP, Otto Group, and Walmart have developed new approaches. BP’s procurement technology garage conducts rapid pilots to explore emerging technologies and assess their ROI potential. Otto Group’s new-technology ventures team engages with startups to experiment and co-develop solutions. Walmart’s procurement center of excellence scales proven technologies globally and maximizes their ROI.close\n\nCompanies have ambitious plans for rapidly digitizing the procurement function, especially through emerging technologies like AI. That was a finding of a study that we conducted with Digital Procurement World in October 2024, which included a survey of over 200 procurement executives around the world. However, in separate in-depth interviews we conducted with over two dozen procurement executives and a few of their colleagues in the supply chain and IT functions, we discovered obstacles that can get in the way of these ambitions. But we also found ways that three companies featured in this article are successfully employing to overcome them:\nBP has a procurement technology garage to quickly explore emerging technologies from multiple startups simultaneously and to develop a fact-based understanding of their ROI potential.\nOtto Group, an e-commerce and retail company based in Hamburg, Germany, whose businesses include Crate and Barrel and Bonprix, has a new-technology ventures team to engage with startups and emerging technologies to accelerate experimentation and co-develop applications.\nWalmart has a procurement technology center of excellence whose mission is to roll out proven technologies globally at scale and maximize their ROI.\nThe Need for New Approaches\nOne big obstacle we discovered is the traditional IT investment and adoption process. “Traditional contract negotiation processes managed by IT are not geared for startup environments,” Arno Baltruschat, head of Otto’s new-technology ventures team, told us.\nConventional approaches—often centered on large vendors and marked by lengthy negotiation and contracting cycles—are ill-suited for exploring promising digital innovations that startups are developing. Companies historically use rigid contract templates that are more than 50 pages long, and it often takes months to finalize them. That is overkill and much too slow when dealing with startups. The rigidity of these contracts, which typically involve a multi-year commitment to a technology based upon anticipated benefits and a predetermined rollout plan, limits the innovation potential of the relationships and ignores the need to experiment to explore the full potential of the new technologies.\nAnother challenge is scaling a successful pilot project that focused on a handful of use cases for a new technology to the broader global organization. Procurement functions often struggle to do this.\nNow let’s look at BP’s, Otto’s, and Walmart’s remedies.\nBP’s Procurement Technology Garage\nThis BP unit conducts rapid small-scale pilots to explore emerging technologies that might provide a solution for an existing procurement challenge. In doing so, the garage also develops a fact-based understanding of the technology’s ROI potential (or lack thereof).\nAfter a pilot has been concluded, the garage team offers a recommendation to the chief procurement officer that can range from “do not recommend further evaluation” to “recommend full-scale adoption” (with the results of the pilot, the insights it generated, and the business case). When a pilot does not deliver promising results, it is seen as a learning experience, not a failure. Intermediate options include refining the pilot and collaborating with the technology provider to co-develop additional features.\nThe garage has been in existence since late 2023 and has conducted pilots in a variety of technology areas, from sustainable procurement to AI-supported contractor invoicing to procurement strategy development. Pilots typically last between three to six months. Three technologies have already been given the green light for either further development or full-scale adoption.\nHow the Garage Works\nBefore launching a pilot, the garage team identifies significant procurement challenges or opportunities, then seeks out potential technology solutions to address them. Nicholas Wright, head of BP’s garage, states: “Our ethos is problem first, solution search after. We are data-led in the selection of problems.”\nFor example, the team found that procurement managers were spending weeks, sometimes months, on the development of category strategies for their categories of spend. (A category strategy captures the organization’s approach for getting the best out of the supplier market given its business needs and supply market characteristics and provides the basis for tendering, contracting, and managing supplier relationships.) The garage team found that upon completion, strategies would often remain unused until it was time to update them. “The strategies were not realizing their full potential and were not ‘lived’ in the organization,” Wright said.\nThe garage team scanned the technology landscape and found a promising AI-enabled tool called Cirtuo that supports the development of category strategies and proposed to the procurement leaders that it be allowed to pilot this technology for a three-month period. They agreed and nominated categories and buyer teams from across the business for inclusion in the pilot. During the pilot, the buyer teams used the tool to develop new strategies for their categories.\nThe strategies created during the pilot were of significantly higher quality than those developed without the tool, featuring, on average, 10 times more insights. The strategies were also more multi-dimensional, addressing all areas of potential value creation—not only cost savings but also company priorities like sustainability. The AI features of the tool that support the collection and analysis of external supplier market data not only enriched strategies but also reduced development time by 50%, on average. Crucially, the time savings have allowed category managers to spend less time on research and strategy documentation and more on driving organizational engagement with the strategies, reducing the risk of them being shelved and unused. Based upon the evaluation report of the garage team, BP’s chief procurement officer gave the green light for scaling the tool across the global procurement organization.\nOtto’s Ventures Client Unit\nOtto’s unit, called OTTO DOCK 6, offers an approach for engaging with startups and emerging technologies to experiment and possibly even co-develop technology. Unlike traditional internal venture capital groups, this group does not invest financially in startups; instead it co-develops and pilots applications with startup solutions to pressing business challenges before handing the technology over to the business. Arno Baltruschat, co-leader of the unit, told us: “Startups can react fast to our needs and we can move faster to partner with startups because we don’t need the due diligence check and overhead required for a Series A investment by a venture capital firm.” In the last four years, the venture client unit established non-investment partnerships with 50 startups.\nHow the Venture Client Unit Works\nThe unit’s approach begins with a sizable, strategically important business problem, not with a promising startup or interesting technology. Once high-value problems are identified, the unit scouts startups and pilots and may co-develop an application of the technology in collaboration with the startup and business colleagues to use the technology in Otto operations. The contracts for these engagements are three- to six-page agreements that typically take no more than a few weeks to finalize.\nGiven that the aim of pilots is rapid learning and development, they are intentionally limited in scale, scope, and duration (two to three months). After a pilot has ended, the group evaluates results and may recommend a further rollout if substantial ROI hurdles are likely to be met. Currently, only about 40% of technologies are adopted. Successful projects with tech startups include automated product damage checks and ESG scoring of products.\nAI-based automated negotiations became a recent focus of the venture client unit. In 2023, it began seeking tech startups to help more efficiently manage long-tail suppliers, the large number of companies with low-value agreements to provide non-strategic things. It selected Pactum, a startup specializing in AI-powered negotiations software. In early 2024, the unit partnered with Pactum and collaborated with leaders and buyers from Otto’s corporate procurement department and supply-chain-management function to test whether the AI chatbot could negotiate simple terms like payment days and discounts with suppliers.\nBuyer involvement was essential to the success of the pilot, particularly in communicating with suppliers and selecting suitable participants. Buyers played a key role in identifying spend categories and suppliers that would ensure the pilot was minimally disruptive to core business operations. To reduce operational risk, they focused on less-strategic products and services. To limit financial exposure, they selected suppliers with annual spend levels between €100,000 and €250,000. In total, the pilot encompassed approximately €24 million in spending across all qualifying suppliers. Of the suppliers invited to participate, nearly 65% accepted. Among those who engaged in the pilot, 70% successfully closed agreements, generating incremental savings for Otto.\nBased on the success of the first pilot, the team next invited larger suppliers, involving greater amounts of external spend. This first phase was successfully completed in just three months. By the end of 2024, Otto presented a strategic implementation plan to senior management that proposed expanding automated negotiations to more complex categories and to more intricate terms, including pricing and bonuses. This year, the project will transition from the venture client unit to an operational excellence center responsible for rolling out digital technologies throughout the procurement organization and further enhancing the technology for new applications.",
    "ori_text": "Summary\nCompanies want to rapidly digitize procurement by exploiting emerging technologies like AI. However, traditional IT investment and adoption processes are often too slow and rigid. To overcome the obstacles, BP, Otto Group, and Walmart have developed new approaches. BP’s procurement technology garage conducts rapid pilots to explore emerging technologies and assess their ROI potential. Otto Group’s new-technology ventures team engages with startups to experiment and co-develop solutions. Walmart’s procurement center of excellence scales proven technologies globally and maximizes their ROI.close\n\nCompanies have ambitious plans for rapidly digitizing the procurement function, especially through emerging technologies like AI. That was a finding of a study that we conducted with Digital Procurement World in October 2024, which included a survey of over 200 procurement executives around the world. However, in separate in-depth interviews we conducted with over two dozen procurement executives and a few of their colleagues in the supply chain and IT functions, we discovered obstacles that can get in the way of these ambitions. But we also found ways that three companies featured in this article are successfully employing to overcome them:\nBP has a procurement technology garage to quickly explore emerging technologies from multiple startups simultaneously and to develop a fact-based understanding of their ROI potential.\nOtto Group, an e-commerce and retail company based in Hamburg, Germany, whose businesses include Crate and Barrel and Bonprix, has a new-technology ventures team to engage with startups and emerging technologies to accelerate experimentation and co-develop applications.\nWalmart has a procurement technology center of excellence whose mission is to roll out proven technologies globally at scale and maximize their ROI.\nThe Need for New Approaches\nOne big obstacle we discovered is the traditional IT investment and adoption process. “Traditional contract negotiation processes managed by IT are not geared for startup environments,” Arno Baltruschat, head of Otto’s new-technology ventures team, told us.\nConventional approaches—often centered on large vendors and marked by lengthy negotiation and contracting cycles—are ill-suited for exploring promising digital innovations that startups are developing. Companies historically use rigid contract templates that are more than 50 pages long, and it often takes months to finalize them. That is overkill and much too slow when dealing with startups. The rigidity of these contracts, which typically involve a multi-year commitment to a technology based upon anticipated benefits and a predetermined rollout plan, limits the innovation potential of the relationships and ignores the need to experiment to explore the full potential of the new technologies.\nAnother challenge is scaling a successful pilot project that focused on a handful of use cases for a new technology to the broader global organization. Procurement functions often struggle to do this.\nNow let’s look at BP’s, Otto’s, and Walmart’s remedies.\nBP’s Procurement Technology Garage\nThis BP unit conducts rapid small-scale pilots to explore emerging technologies that might provide a solution for an existing procurement challenge. In doing so, the garage also develops a fact-based understanding of the technology’s ROI potential (or lack thereof).\nAfter a pilot has been concluded, the garage team offers a recommendation to the chief procurement officer that can range from “do not recommend further evaluation” to “recommend full-scale adoption” (with the results of the pilot, the insights it generated, and the business case). When a pilot does not deliver promising results, it is seen as a learning experience, not a failure. Intermediate options include refining the pilot and collaborating with the technology provider to co-develop additional features.\nThe garage has been in existence since late 2023 and has conducted pilots in a variety of technology areas, from sustainable procurement to AI-supported contractor invoicing to procurement strategy development. Pilots typically last between three to six months. Three technologies have already been given the green light for either further development or full-scale adoption.\nHow the Garage Works\nBefore launching a pilot, the garage team identifies significant procurement challenges or opportunities, then seeks out potential technology solutions to address them. Nicholas Wright, head of BP’s garage, states: “Our ethos is problem first, solution search after. We are data-led in the selection of problems.”\nFor example, the team found that procurement managers were spending weeks, sometimes months, on the development of category strategies for their categories of spend. (A category strategy captures the organization’s approach for getting the best out of the supplier market given its business needs and supply market characteristics and provides the basis for tendering, contracting, and managing supplier relationships.) The garage team found that upon completion, strategies would often remain unused until it was time to update them. “The strategies were not realizing their full potential and were not ‘lived’ in the organization,” Wright said.\nThe garage team scanned the technology landscape and found a promising AI-enabled tool called Cirtuo that supports the development of category strategies and proposed to the procurement leaders that it be allowed to pilot this technology for a three-month period. They agreed and nominated categories and buyer teams from across the business for inclusion in the pilot. During the pilot, the buyer teams used the tool to develop new strategies for their categories.\nThe strategies created during the pilot were of significantly higher quality than those developed without the tool, featuring, on average, 10 times more insights. The strategies were also more multi-dimensional, addressing all areas of potential value creation—not only cost savings but also company priorities like sustainability. The AI features of the tool that support the collection and analysis of external supplier market data not only enriched strategies but also reduced development time by 50%, on average. Crucially, the time savings have allowed category managers to spend less time on research and strategy documentation and more on driving organizational engagement with the strategies, reducing the risk of them being shelved and unused. Based upon the evaluation report of the garage team, BP’s chief procurement officer gave the green light for scaling the tool across the global procurement organization.\nOtto’s Ventures Client Unit\nOtto’s unit, called OTTO DOCK 6, offers an approach for engaging with startups and emerging technologies to experiment and possibly even co-develop technology. Unlike traditional internal venture capital groups, this group does not invest financially in startups; instead it co-develops and pilots applications with startup solutions to pressing business challenges before handing the technology over to the business. Arno Baltruschat, co-leader of the unit, told us: “Startups can react fast to our needs and we can move faster to partner with startups because we don’t need the due diligence check and overhead required for a Series A investment by a venture capital firm.” In the last four years, the venture client unit established non-investment partnerships with 50 startups.\nHow the Venture Client Unit Works\nThe unit’s approach begins with a sizable, strategically important business problem, not with a promising startup or interesting technology. Once high-value problems are identified, the unit scouts startups and pilots and may co-develop an application of the technology in collaboration with the startup and business colleagues to use the technology in Otto operations. The contracts for these engagements are three- to six-page agreements that typically take no more than a few weeks to finalize.\nGiven that the aim of pilots is rapid learning and development, they are intentionally limited in scale, scope, and duration (two to three months). After a pilot has ended, the group evaluates results and may recommend a further rollout if substantial ROI hurdles are likely to be met. Currently, only about 40% of technologies are adopted. Successful projects with tech startups include automated product damage checks and ESG scoring of products.\nAI-based automated negotiations became a recent focus of the venture client unit. In 2023, it began seeking tech startups to help more efficiently manage long-tail suppliers, the large number of companies with low-value agreements to provide non-strategic things. It selected Pactum, a startup specializing in AI-powered negotiations software. In early 2024, the unit partnered with Pactum and collaborated with leaders and buyers from Otto’s corporate procurement department and supply-chain-management function to test whether the AI chatbot could negotiate simple terms like payment days and discounts with suppliers.\nBuyer involvement was essential to the success of the pilot, particularly in communicating with suppliers and selecting suitable participants. Buyers played a key role in identifying spend categories and suppliers that would ensure the pilot was minimally disruptive to core business operations. To reduce operational risk, they focused on less-strategic products and services. To limit financial exposure, they selected suppliers with annual spend levels between €100,000 and €250,000. In total, the pilot encompassed approximately €24 million in spending across all qualifying suppliers. Of the suppliers invited to participate, nearly 65% accepted. Among those who engaged in the pilot, 70% successfully closed agreements, generating incremental savings for Otto.\nBased on the success of the first pilot, the team next invited larger suppliers, involving greater amounts of external spend. This first phase was successfully completed in just three months. By the end of 2024, Otto presented a strategic implementation plan to senior management that proposed expanding automated negotiations to more complex categories and to more intricate terms, including pricing and bonuses. This year, the project will transition from the venture client unit to an operational excellence center responsible for rolling out digital technologies throughout the procurement organization and further enhancing the technology for new applications.",
    "reference_list": "考点 1：【procurement technology garage】应译为 【采购技术车库】\n考点 2：【new-technology ventures team】 应译为 【新技术创投团队】\n考点 3：【tendering, contracting, and managing supplier relationships】应译为 【招标、签约及供应商关系管理】\n考点 4：【AI-enabled tool】应译为 【AI赋能工具】\n考点 5：【venture client unit】应译为 【创投客户单元】\n考点 6：【AI-based automated negotiations】应译为【基于AI的自动化谈判】\n考点 7：【long-tail suppliers】应译为 【长尾供应商】\n考点 8：【AI-powered negotiations software】应译为 【AI驱动谈判软件 / AI赋能谈判软件】\n考点 9：【spend categories】应译为 【支出品类】\n考点 10：【less-strategic products and services】应译为 【非战略性产品和服务】",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "88"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nWhat is the keto diet, and can it be beneficial for you?\nYou may have heard of friends and family trying the keto diet. It's a strict, high-fat diet with varying levels of protein and generally very low levels of carbohydrate.\n\nThe keto diet was first used as a treatment for pediatric drug-resistant epilepsy to reduce seizures in the 1920s. It's still used for help prevent seizures in the U.S. when medications alone aren't enough. However, it can also help you lose weight if you stick with the plan long term. It may also provide other health benefits that come with weight loss.\n\nIf you're wondering if the keto diet is right for you, our registered dietitians explain the eating plan and its pros and cons.\n\nWhat is the keto diet?\nThe ketogenic or keto diet includes eating high-fat, low-carbohydrate foods to reach ketosis. In ketosis, the body uses fat for fuel, instead of sugar (glucose). This produces acids known as ketones.\n\n\nWhat are the basic rules of the keto diet?\nThere are several different styles of keto diets. Each calls for eating different amounts of fat, protein and carbs in a day.\n\nClassic Keto Diet\nThis is the original and best-studied of the different diet strategies. It's recommended that you work with a registered dietitian as it's the strictest, most difficult diet to follow.\n\nThis diet is very in high fat, very low in carbs and relatively low in protein.\nAll foods must be weighed on a scale to achieve a relative weight distribution of 4 grams of fat for every 1 gram of combined protein and carb eaten throughout the day. In other words, you will likely need to avoid all carb-rich foods (like pasta, potatoes, fruit, etc.). Also, for every serving of protein-rich food, you need four servings of a fatty food (heavy cream, avocado, olive oil, full fat cheese, etc.).\nA typical meal might look like half an avocado with a small piece of salmon cooked in a lot of olive oil with a side salad. It will all be topped with a cream sauce made with heavy cream and cheese. You would need to eat all of the oils and creams.\n\nModified Keto Diet\nThis is a modified form of the classic keto diet, allowing slightly more protein and carbs.\n\nThis diet generally still requires a scale for weighing food. It's defined by a ratio closer to 3 grams of fat for every 1 gram of combined protein and carb (generally with a focus on more protein than carbs). In other words, you'll still avoid most carb-rich foods except for maybe one or two servings per day. For every serving of a protein- or carb-rich food, you'll need three servings of very high-fat food.\nModified Atkins Diet\nThis diet is the more user-friendly keto diet and likely the most popular. It's a high-fat, low-carb diet where you can choose to eat as much protein as you like.\n\n\nWhat foods can you eat on the keto diet?\nHere's a list of foods you should eat on the keto diet:\n\nDairy and unsweetened dairy alternatives such as full fat cheese, plain full fat yogurt, cottage cheese and unsweetened plant-based milk.\nLow-carb vegetables like leafy greens, peppers and broccoli.\nOther plant-based foods including nuts, seeds and avocados.\nOils and fats like olive and coconut oils, as well as whole olives and avocados.\nModerate amounts of high protein foods such as seafood, meat, poultry and eggs.\nSometimes small amounts of berries can be eaten.\nThese diets generally avoid all starchy foods (pasta, rice, potatoes, bread, corn, peas, beans and legumes). Desserts and any other high-carb foods are also not part of the diet. Fruits can sometimes be included if they are high in fiber, such as raspberries.\n\n\n\nWhat are the pros and cons of the keto diet?\nHere are some benefits of the keto diet for your health:\n\nHelps with weight loss: Research suggests that the keto diet helps people cut calories because the diet doesn't include many foods that people are likely to overeat. However, it can be difficult to transition off of the keto diet without regaining weight. That's because people typically start eating more high-carb foods. Some data supports going from the keto diet to the Mediterranean diet or MIND diet may help maintain healthier weight once weight loss goals are achieved.\nBenefits people with type 2 diabetes: Some people with diabetes find that reducing their carb intake can help with blood sugar and medication management.\nEpilepsy management: Data shows that the keto diet can have positive effects for people with epilepsy in helping with seizure management.\nSome cons of the keto diet include:\n\nCan lead to nutrient deficiencies: The keto diet is very low in carbs which means you can't eat many fruits and vegetables. That can lead to low levels of vitamins A, E and B6, as well as folate, calcium, magnesium, and potassium.\nPossible negative effects on heart health: There are mixed results in studies that examine the specific effects of the keto diet on heart health. This is likely because much of it depends on individual food choices. Generally, foods high in saturated fat and a high-fat diet have negative consequences on heart health factors such as your lipid panel.\nConstipation and other gastrointestinal (GI) troubles: Constipation is likely the greatest long-term complication of the keto diet because of a low fiber intake. Fiber is a form of carb that is digested not by our human cells, but by the microbes in our gut. Any high-fiber foods (like beans, whole grains, and certain fruits) are also high in carbs, which is not typically part of the keto diet. An ongoing diet that is low in fiber (including the typical Western diet) may leave you at higher risk for certain cancers like colon cancer.\n\nWhat are some side effects of the keto diet?\nBefore starting the keto diet, you should get a blood test to look at your lipids. You should then take another blood test after three to six months on the keto diet.\n\nSome people will actually find that their high-density lipoproteins (HDL) – the good cholesterol – go up and their triglycerides go down. But some people won't see a positive shift in those markers and may find their low-density lipoproteins (LDL) – the bad cholesterol – go up to unhealthy levels.\n\nThere can be issues with bone health when people switch to low-carb keto diets. Researchers see that markers for bone breakdown are higher and markers for bone building are lower. This is a common side effect in kids who are fed the keto diet to treat epilepsy.\n\nAlso, when people start the keto diet, they go through the keto flu. Keto flu symptoms appear a few days after starting the diet. This eventually goes away once your body adjusts to your eating changes. People on the keto diet also tend to lose more salt/sodium than those on a higher carb diet and may need more salt than the average person.\n\nMost people following a strict keto diet should take a multivitamin with minerals to ensure they're meeting those vitamin and mineral needs. The diet itself generally is not enough.\n\nDoes the keto diet improve brain functions, such as learning and memory?\nThe keto diet can show positive results for helping the brain. It's been used for years to treat epilepsy. Researchers are looking to see if the keto diet can help treat age-related brain decline and potentially Alzheimer's disease. There are mixed results on if the keto diet can help those with neuromuscular diseases such as Parkinson's disease.\n\nThere are many different theories as to why the keto diet may be beneficial for brain health. These include the direct benefit from the presence of ketone bodies, especially one called beta hydroxybutyrate. Other theories suggest a possible benefit in changing the microbiome for certain conditions, like epilepsy.\n\nIs the keto diet good for athletes?\nOur bodies use multiple energy systems to exercise. The type of energy system used depends on the exercise intensity and duration. At lower intensities, our bodies use a mix of both burning fat and carbs for fuel. When we transition to high intensities (such as a scheduled workout), our bodies start to rely primarily on carbs.\n\nMost studies involving endurance athletes showed the keto diet hurts their performance. The keto diet has also been shown to increase losses of lean tissue when compared to a higher-carb diet.\n\nThe bottom line is that the keto diet impairs athletic performance and are not recommended for athletes because they restrict carbs.\n\n\nWhat other eating plans might be right for me?\nIf the keto diet doesn't sound like the right fit for you, you may want to consider one of these other eating plans.\n\nIntermittent fasting\nThis weight-loss trend dates back to ancient times where fasting helps heal the body. The idea behind intermittent fasting is that by restricting food, our bodies will more quickly tap into fat stores for energy. It's not necessarily an eating plan that outlines what types of foods to eat but instead focuses on when to eat. There are a couple of different ways to implement intermittent fasting.\n\n\nMediterranean diet\nThis way of eating focuses on whole, plant-based foods and healthy fat. The Mediterranean diet's methods are scientifically proven to reduce the risk of chronic conditions like heart disease.\n\n\nMIND Diet\nShort for \"Mediterranean-DASH Intervention for Neurodegenerative Delay,\" this diet is similar to the Mediterranean diet, but with stricter requirements for what you can eat. It emphasizes eating more vegetables, fruits (specifically berries), high-fiber foods, beans, nuts, seafood, poultry and olive oil. The MIND diet can possibly help reduce the cognitive decline associated with aging. It also may help slow disease progression for conditions like Parkinson's disease.",
    "ori_text": "What is the keto diet, and can it be beneficial for you?\nYou may have heard of friends and family trying the keto diet. It's a strict, high-fat diet with varying levels of protein and generally very low levels of carbohydrate.\n\nThe keto diet was first used as a treatment for pediatric drug-resistant epilepsy to reduce seizures in the 1920s. It's still used for help prevent seizures in the U.S. when medications alone aren't enough. However, it can also help you lose weight if you stick with the plan long term. It may also provide other health benefits that come with weight loss.\n\nIf you're wondering if the keto diet is right for you, our registered dietitians explain the eating plan and its pros and cons.\n\nWhat is the keto diet?\nThe ketogenic or keto diet includes eating high-fat, low-carbohydrate foods to reach ketosis. In ketosis, the body uses fat for fuel, instead of sugar (glucose). This produces acids known as ketones.\n\n\nWhat are the basic rules of the keto diet?\nThere are several different styles of keto diets. Each calls for eating different amounts of fat, protein and carbs in a day.\n\nClassic Keto Diet\nThis is the original and best-studied of the different diet strategies. It's recommended that you work with a registered dietitian as it's the strictest, most difficult diet to follow.\n\nThis diet is very in high fat, very low in carbs and relatively low in protein.\nAll foods must be weighed on a scale to achieve a relative weight distribution of 4 grams of fat for every 1 gram of combined protein and carb eaten throughout the day. In other words, you will likely need to avoid all carb-rich foods (like pasta, potatoes, fruit, etc.). Also, for every serving of protein-rich food, you need four servings of a fatty food (heavy cream, avocado, olive oil, full fat cheese, etc.).\nA typical meal might look like half an avocado with a small piece of salmon cooked in a lot of olive oil with a side salad. It will all be topped with a cream sauce made with heavy cream and cheese. You would need to eat all of the oils and creams.\n\nModified Keto Diet\nThis is a modified form of the classic keto diet, allowing slightly more protein and carbs.\n\nThis diet generally still requires a scale for weighing food. It's defined by a ratio closer to 3 grams of fat for every 1 gram of combined protein and carb (generally with a focus on more protein than carbs). In other words, you'll still avoid most carb-rich foods except for maybe one or two servings per day. For every serving of a protein- or carb-rich food, you'll need three servings of very high-fat food.\nModified Atkins Diet\nThis diet is the more user-friendly keto diet and likely the most popular. It's a high-fat, low-carb diet where you can choose to eat as much protein as you like.\n\n\nWhat foods can you eat on the keto diet?\nHere's a list of foods you should eat on the keto diet:\n\nDairy and unsweetened dairy alternatives such as full fat cheese, plain full fat yogurt, cottage cheese and unsweetened plant-based milk.\nLow-carb vegetables like leafy greens, peppers and broccoli.\nOther plant-based foods including nuts, seeds and avocados.\nOils and fats like olive and coconut oils, as well as whole olives and avocados.\nModerate amounts of high protein foods such as seafood, meat, poultry and eggs.\nSometimes small amounts of berries can be eaten.\nThese diets generally avoid all starchy foods (pasta, rice, potatoes, bread, corn, peas, beans and legumes). Desserts and any other high-carb foods are also not part of the diet. Fruits can sometimes be included if they are high in fiber, such as raspberries.\n\n\n\nWhat are the pros and cons of the keto diet?\nHere are some benefits of the keto diet for your health:\n\nHelps with weight loss: Research suggests that the keto diet helps people cut calories because the diet doesn't include many foods that people are likely to overeat. However, it can be difficult to transition off of the keto diet without regaining weight. That's because people typically start eating more high-carb foods. Some data supports going from the keto diet to the Mediterranean diet or MIND diet may help maintain healthier weight once weight loss goals are achieved.\nBenefits people with type 2 diabetes: Some people with diabetes find that reducing their carb intake can help with blood sugar and medication management.\nEpilepsy management: Data shows that the keto diet can have positive effects for people with epilepsy in helping with seizure management.\nSome cons of the keto diet include:\n\nCan lead to nutrient deficiencies: The keto diet is very low in carbs which means you can't eat many fruits and vegetables. That can lead to low levels of vitamins A, E and B6, as well as folate, calcium, magnesium, and potassium.\nPossible negative effects on heart health: There are mixed results in studies that examine the specific effects of the keto diet on heart health. This is likely because much of it depends on individual food choices. Generally, foods high in saturated fat and a high-fat diet have negative consequences on heart health factors such as your lipid panel.\nConstipation and other gastrointestinal (GI) troubles: Constipation is likely the greatest long-term complication of the keto diet because of a low fiber intake. Fiber is a form of carb that is digested not by our human cells, but by the microbes in our gut. Any high-fiber foods (like beans, whole grains, and certain fruits) are also high in carbs, which is not typically part of the keto diet. An ongoing diet that is low in fiber (including the typical Western diet) may leave you at higher risk for certain cancers like colon cancer.\n\nWhat are some side effects of the keto diet?\nBefore starting the keto diet, you should get a blood test to look at your lipids. You should then take another blood test after three to six months on the keto diet.\n\nSome people will actually find that their high-density lipoproteins (HDL) – the good cholesterol – go up and their triglycerides go down. But some people won't see a positive shift in those markers and may find their low-density lipoproteins (LDL) – the bad cholesterol – go up to unhealthy levels.\n\nThere can be issues with bone health when people switch to low-carb keto diets. Researchers see that markers for bone breakdown are higher and markers for bone building are lower. This is a common side effect in kids who are fed the keto diet to treat epilepsy.\n\nAlso, when people start the keto diet, they go through the keto flu. Keto flu symptoms appear a few days after starting the diet. This eventually goes away once your body adjusts to your eating changes. People on the keto diet also tend to lose more salt/sodium than those on a higher carb diet and may need more salt than the average person.\n\nMost people following a strict keto diet should take a multivitamin with minerals to ensure they're meeting those vitamin and mineral needs. The diet itself generally is not enough.\n\nDoes the keto diet improve brain functions, such as learning and memory?\nThe keto diet can show positive results for helping the brain. It's been used for years to treat epilepsy. Researchers are looking to see if the keto diet can help treat age-related brain decline and potentially Alzheimer's disease. There are mixed results on if the keto diet can help those with neuromuscular diseases such as Parkinson's disease.\n\nThere are many different theories as to why the keto diet may be beneficial for brain health. These include the direct benefit from the presence of ketone bodies, especially one called beta hydroxybutyrate. Other theories suggest a possible benefit in changing the microbiome for certain conditions, like epilepsy.\n\nIs the keto diet good for athletes?\nOur bodies use multiple energy systems to exercise. The type of energy system used depends on the exercise intensity and duration. At lower intensities, our bodies use a mix of both burning fat and carbs for fuel. When we transition to high intensities (such as a scheduled workout), our bodies start to rely primarily on carbs.\n\nMost studies involving endurance athletes showed the keto diet hurts their performance. The keto diet has also been shown to increase losses of lean tissue when compared to a higher-carb diet.\n\nThe bottom line is that the keto diet impairs athletic performance and are not recommended for athletes because they restrict carbs.\n\n\nWhat other eating plans might be right for me?\nIf the keto diet doesn't sound like the right fit for you, you may want to consider one of these other eating plans.\n\nIntermittent fasting\nThis weight-loss trend dates back to ancient times where fasting helps heal the body. The idea behind intermittent fasting is that by restricting food, our bodies will more quickly tap into fat stores for energy. It's not necessarily an eating plan that outlines what types of foods to eat but instead focuses on when to eat. There are a couple of different ways to implement intermittent fasting.\n\n\nMediterranean diet\nThis way of eating focuses on whole, plant-based foods and healthy fat. The Mediterranean diet's methods are scientifically proven to reduce the risk of chronic conditions like heart disease.\n\n\nMIND Diet\nShort for \"Mediterranean-DASH Intervention for Neurodegenerative Delay,\" this diet is similar to the Mediterranean diet, but with stricter requirements for what you can eat. It emphasizes eating more vegetables, fruits (specifically berries), high-fiber foods, beans, nuts, seafood, poultry and olive oil. The MIND diet can possibly help reduce the cognitive decline associated with aging. It also may help slow disease progression for conditions like Parkinson's disease.",
    "reference_list": "考点1： “keto diet”应该译为“生酮饮食”。\n考点2： ”cottage cheese”应译为“茅屋奶酪”或“考特吉奶酪”或“乡村奶酪”\n考点3： “MIND diet”推荐翻译为“麦得”或“Mind饮食”\n考点4：“Mediterranean-DASH Intervention for Neurodegenerative Delay”推荐译为“地中海-DASH干预延迟神经变性饮食”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "68"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\nAI视频生成技术正成为连接古今、沟通中外的崭新纽带，让尘封的历史记忆焕发出新的活力，也让文化的交流更加生动可及。\n如果陈子昂活在今天，或许不需要怆然涕下了——近日，“AI穿越直播”火了。\n视频中，AI记者“穿越”至古代场景：或在烽火连天的赤壁战场奔走解说，或“现身”唐朝玄武门之变现场，或“参与”秦朝长城修筑……这样的作品如雨后春笋般涌现，凭借“第一人称Vlog视角+历史名场面”的独特叙事，营造出强烈的“在场感”，让观众在虚实交融中沉浸式感受历史的鲜活脉搏。\n那些耳熟能详的历史事件，以前所未有的方式“活”了起来，这要得益于AI视频生成技术的突破性发展。技术手段有效弥合了时空隔阂带来的疏离感，今人才能通过AI视频“亲历”那些惊心动魄的名场面。这种深度沉浸的体验，精准回应了人们对历史的渴求——历史不再是书本上静止的文字和图片，而变得可感、可知，仿佛触手可及，成为我们理解过去的一把钥匙。\n这种鲜活的科技呈现方式，为文化传播架起了一座新桥梁。对青少年学生而言，AI视频以其生动的画面和沉浸的视角，将课本上的知识变得引人入胜。比如，动态重现的“玄武门之变”，远比文字描述更能点燃他们探究历史的兴趣。对海外观众来说，配备多语种的AI历史短片，成为他们了解中国历史与文化的直观窗口，让中国故事更易抵达全球受众。可以说，AI视频生成技术正成为连接古今、沟通中外的崭新纽带，让尘封的历史记忆焕发出新的活力，也让文化的交流更加生动可及。\n更重要的是，这种AI视频赋予了普通人前所未有的创作自由。曾几何时，制作一部穿越历史的影视作品，需要耗费大量人力物力。如今，数字技术的普及大大降低了创作门槛，众多网友得以亲身参与。他们不再是单向的受众，而是拿起AI工具，成为历史文化内容的创作者和传播者，能动地参与到讲述历史、传承文化的潮流中来。这种技术对创造力的极大解放，让更多元的视角、更多样的故事得以更新奇地呈现，为文化的繁荣发展注入了源源不断的新活力。\n技术是把双刃剑，热闹之下也有隐忧。如果说，网上冒出一些让人哭笑不得的内容，比如“秦始皇直播卖瓷砖”“屈原代言粽子”，将历史娱乐化，还能让人一眼看破、一笑置之的话，有些AI作品把不同历史时期的东西凑在一起，却又“一本正经”地讲述，则有可能误导儿童青少年，容易将AI生成的“历史八卦”当成真实历史，失去对历史的敬畏感。\n技术在进步，人也需要进步。技术迭代向前的每一步，都呼唤着社会认知与法规体系的同步演进。提高AI素养，教育系统已开始行动。例如，北京中小学从今年秋天起，将把AI素养纳入课程体系，培育批判思维与责任伦理并重的技术观。另一方面，监管也在跟进，《生成式人工智能服务管理暂行办法》明确要求标识合成内容，广电等部门也曾对歪曲历史、误导公众的“AI魔改”视频开展专项整治。\n当然，技术创新用对了地方，就是好事。君不见，浙江温州用AI“复活”了宋元时期古港千帆竞发的盛景，让沉寂的码头重新响起商贾云集的喧嚣；苏州博物馆借助AI技术“复活”唐伯虎并推出“回答我”系列视频，让网友直呼过瘾；各地博物馆应用AI、VR（虚拟现实）、裸眼3D等技术，打破时空壁垒，让沉睡千年的文物“开口讲故事”……这说明，只要我们心里装着对历史的尊重，用好技术这把“钥匙”，就能打开创新传承的新大门。",
    "ori_text": "AI视频生成技术正成为连接古今、沟通中外的崭新纽带，让尘封的历史记忆焕发出新的活力，也让文化的交流更加生动可及。\n如果陈子昂活在今天，或许不需要怆然涕下了——近日，“AI穿越直播”火了。\n视频中，AI记者“穿越”至古代场景：或在烽火连天的赤壁战场奔走解说，或“现身”唐朝玄武门之变现场，或“参与”秦朝长城修筑……这样的作品如雨后春笋般涌现，凭借“第一人称Vlog视角+历史名场面”的独特叙事，营造出强烈的“在场感”，让观众在虚实交融中沉浸式感受历史的鲜活脉搏。\n那些耳熟能详的历史事件，以前所未有的方式“活”了起来，这要得益于AI视频生成技术的突破性发展。技术手段有效弥合了时空隔阂带来的疏离感，今人才能通过AI视频“亲历”那些惊心动魄的名场面。这种深度沉浸的体验，精准回应了人们对历史的渴求——历史不再是书本上静止的文字和图片，而变得可感、可知，仿佛触手可及，成为我们理解过去的一把钥匙。\n这种鲜活的科技呈现方式，为文化传播架起了一座新桥梁。对青少年学生而言，AI视频以其生动的画面和沉浸的视角，将课本上的知识变得引人入胜。比如，动态重现的“玄武门之变”，远比文字描述更能点燃他们探究历史的兴趣。对海外观众来说，配备多语种的AI历史短片，成为他们了解中国历史与文化的直观窗口，让中国故事更易抵达全球受众。可以说，AI视频生成技术正成为连接古今、沟通中外的崭新纽带，让尘封的历史记忆焕发出新的活力，也让文化的交流更加生动可及。\n更重要的是，这种AI视频赋予了普通人前所未有的创作自由。曾几何时，制作一部穿越历史的影视作品，需要耗费大量人力物力。如今，数字技术的普及大大降低了创作门槛，众多网友得以亲身参与。他们不再是单向的受众，而是拿起AI工具，成为历史文化内容的创作者和传播者，能动地参与到讲述历史、传承文化的潮流中来。这种技术对创造力的极大解放，让更多元的视角、更多样的故事得以更新奇地呈现，为文化的繁荣发展注入了源源不断的新活力。\n技术是把双刃剑，热闹之下也有隐忧。如果说，网上冒出一些让人哭笑不得的内容，比如“秦始皇直播卖瓷砖”“屈原代言粽子”，将历史娱乐化，还能让人一眼看破、一笑置之的话，有些AI作品把不同历史时期的东西凑在一起，却又“一本正经”地讲述，则有可能误导儿童青少年，容易将AI生成的“历史八卦”当成真实历史，失去对历史的敬畏感。\n技术在进步，人也需要进步。技术迭代向前的每一步，都呼唤着社会认知与法规体系的同步演进。提高AI素养，教育系统已开始行动。例如，北京中小学从今年秋天起，将把AI素养纳入课程体系，培育批判思维与责任伦理并重的技术观。另一方面，监管也在跟进，《生成式人工智能服务管理暂行办法》明确要求标识合成内容，广电等部门也曾对歪曲历史、误导公众的“AI魔改”视频开展专项整治。\n当然，技术创新用对了地方，就是好事。君不见，浙江温州用AI“复活”了宋元时期古港千帆竞发的盛景，让沉寂的码头重新响起商贾云集的喧嚣；苏州博物馆借助AI技术“复活”唐伯虎并推出“回答我”系列视频，让网友直呼过瘾；各地博物馆应用AI、VR（虚拟现实）、裸眼3D等技术，打破时空壁垒，让沉睡千年的文物“开口讲故事”……这说明，只要我们心里装着对历史的尊重，用好技术这把“钥匙”，就能打开创新传承的新大门。",
    "reference_list": "考点1：【多语种AI历史短片】 应译为 【multilingual AI historical short videos】\n考点2：【AI魔改】 应译为【 AI-modified content】\n考点3：【裸眼3D】 应译为 【glasses-free 3D】\n考点4：【开口讲故事】 应译为 【make relics “speak” their stories】",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "91"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nGenome-wide analysis identifies molecular systems and 149 genetic loci associated with income\nAbstract\nSocioeconomic position (SEP) is a multi-dimensional construct reflecting (and influencing) multiple socio-cultural, physical, and environmental factors. In a sample of 286,301 participants from UK Biobank, we identify 30 (29 previously unreported) independent-loci associated with income. Using a method to meta-analyze data from genetically-correlated traits, we identify an additional 120 income-associated loci. These loci show clear evidence of functionality, with transcriptional differences identified across multiple cortical tissues, and links to GABAergic and serotonergic neurotransmission. By combining our genome wide association study on income with data from eQTL studies and chromatin interactions, 24 genes are prioritized for follow up, 18 of which were previously associated with intelligence. We identify intelligence as one of the likely causal, partly-heritable phenotypes that might bridge the gap between molecular genetic inheritance and phenotypicconsequence in terms of income differences. These results indicate that, in modern era Great Britain, genetic effects contribute towards some of the observed socioeconomic inequalities.\nIntroduction\nPeople with advantaged socioeconomic backgrounds, on average, live longer, and have better mental and physical health than those from more deprived environments. An understanding of the causes underlying the association between socioeconomic position (SEP) and health is likely to be helpful to minimize social disparities in health and well-being.\nThe link between SEP and health is typically thought to be due to environmental factors, including, but not limited to access to resources, exposure to harmful or stressful environments, adverse health behaviours, such as smoking, poor diet and excessive alcohol consumption, and a lack of physical exercise5. However, genetic factors (most likely via mediated pleiotropy, Fig. 1) have been discussed as a partial explanation for the SEP–health gradient; for example, genetic predispositions towards certain diseases and/or genetic influences on what foods people like, could lead to poor diet, which in turn could lead to both lower SEP and poorer health6. It has recently been demonstrated that genome-wide association studies (GWASs) can capture shared genetic associations between measures of health and SEP7. Potential pleiotropic effects are highlighted in the observed genetic correlations between SEP variables, such as years of education completed, household income and social deprivation, and physical and mental health traits including longevity.\nLoci associated with two SEP phenotypes, education and household income, have been identified via GWASs7,9,10,11, but—consistent with other complex traits, such as height—these loci collectively account for only a small fraction of the total heritability of the traits in question. For household income, an analysis of a sample of 96,900 individuals from Great Britain found that additive genetic effects tagged by common single-nucleotide polymorphisms (SNPs) accounted for ~11% (SE = 0.7%) of differences in household income7. Two loci attained genome-wide significance in that study, but they collectively accounted for <0.005% of the total SNP heritability.\nHere, we use the UK Biobank data set12 to examine genetic associations with household income (n = 286,301) in a contemporary British sample. We identify 30 independent genome-wide significant loci, 29 of which are unreported in previous work. Using a method that leverages power from genetically correlated traits, multi-trait analysis of GWAS (MTAG), an additional 120 loci are found to be associated with income. We identify neurogenesis and the components of the synapse as being associated with income. Furthermore, we link transcription differences across multiple cortical tissue types, as well as both GABAergic and serotonergic neurotransmission, to income differences. We also show that the genes linked to differences in income are predominantly those that have been previously linked with intelligence8, and that intelligence is one of the likely causal factors leading to differences in income. We compare the genetic correlations derived using income with those derived using another measure of SEP, educational attainment, to show that the genetic variants associated with income are related to better mental health than those related to education. Finally, we predict 2.5% of income differences using genetic data alone in an independent sample.\nResults\nGraphical representation of statistical analysis\nA flow chart summarizing all statistical analyses conducted is displayed in Fig. 2.\nSNP-based analysis of income\nFor household income, 3712 SNPs attained genome-wide significance (P < 5 × 10−8), across 30 independent loci (Fig. 3a and Supplementary Data 1), which contained 68 independent significant SNPs and 31 lead SNPs. A total of 29 of these 30 loci were not identified in the previous UK Biobank analysis of income (Supplementary Data 2). The 30 loci predominantly contained SNPs found within intronic regions (47%) as well as non-coding RNA introns (29%). A total of 17% of the SNPs within the independent loci were found in intergenic regions, and only 1.2% were found in exons (Fig. 3b). Many of the loci contained SNPs showing evidence of influencing gene regulation with 33% having a Regulome DB score of <2 (Fig. 3c) and 86% having evidence of being in an open-chromatin state (indicated by a minimum chromatin state of <8, in Fig. 3d). Additionally, these loci were linked to intelligence (11 loci), mental health (schizophrenia, 1 locus; bipolar disorder, 2 loci; neuroticism, 4 loci) and neurological variables (corticobasal degeneration, 1 locus; subcortical brain volumes, 1 locus; and Parkinson’s disease, 1 locus) (Supplementary Data 3).\nLinkage disequilibrium score (LDSC) regression showed that the mean χ2 statistic was 1.45 and the intercept of the LDSC regression was 1.04. These statistics indicate that around 92% of the inflation in the GWAS test statistics was due to a polygenic signal rather than residual stratification or confounding. The LDSC regression estimate of the heritability of household income was 7.39% (SE = 0.33%).\nGene prioritization\nThree methods of mapping allelic variation to genes were used to better understand the functional consequences of the 30 independent loci linked to income (positional mapping, expression quantitative trait loci (eQTL) analysis and chromatin mapping). Using positional mapping, SNPs from the GWAS were aligned to 117 genes. eQTL mapping was used to match cis-eQTL SNPs to 186 genes, and chromatin interaction mapping linked the SNPs to 277 genes (Fig. 3e and Supplementary Data 4 and Supplementary Fig. 1). These mapping strategies identified a total of 400 unique genes, of which 133 (Fig. 3e cells 14 + 23 + 26 + 3 + 24 + 11 + 2 + 30) were implicated by at least two mapping strategies and 47 (Fig. 3e cells 23 + 24) were implicated by all three. Of the 133 implicated by two mapping strategies, two showed evidence of a chromatin interactions with two independent genomic risk loci (Supplementary Data 5). Both HOXB2 and HOXB7 showed interactions with loci 24 and loci 25. HOXB2 showed interactions in mesendoderm (an embryonic tissue layer) tissue and IMR90 (foetal lung fibroblasts)tissue, whereas HOXB7 showed associations in the tissues of hESC (human embryonic stem cell), mesenchymal (multipotent stromal cells which differentiate into a variety of different cell types) stem cell, IMR90, left ventricle, GM12878, and trophoblast-like cells.",
    "ori_text": "Genome-wide analysis identifies molecular systems and 149 genetic loci associated with income\nAbstract\nSocioeconomic position (SEP) is a multi-dimensional construct reflecting (and influencing) multiple socio-cultural, physical, and environmental factors. In a sample of 286,301 participants from UK Biobank, we identify 30 (29 previously unreported) independent-loci associated with income. Using a method to meta-analyze data from genetically-correlated traits, we identify an additional 120 income-associated loci. These loci show clear evidence of functionality, with transcriptional differences identified across multiple cortical tissues, and links to GABAergic and serotonergic neurotransmission. By combining our genome wide association study on income with data from eQTL studies and chromatin interactions, 24 genes are prioritized for follow up, 18 of which were previously associated with intelligence. We identify intelligence as one of the likely causal, partly-heritable phenotypes that might bridge the gap between molecular genetic inheritance and phenotypicconsequence in terms of income differences. These results indicate that, in modern era Great Britain, genetic effects contribute towards some of the observed socioeconomic inequalities.\nIntroduction\nPeople with advantaged socioeconomic backgrounds, on average, live longer, and have better mental and physical health than those from more deprived environments. An understanding of the causes underlying the association between socioeconomic position (SEP) and health is likely to be helpful to minimize social disparities in health and well-being.\nThe link between SEP and health is typically thought to be due to environmental factors, including, but not limited to access to resources, exposure to harmful or stressful environments, adverse health behaviours, such as smoking, poor diet and excessive alcohol consumption, and a lack of physical exercise5. However, genetic factors (most likely via mediated pleiotropy, Fig. 1) have been discussed as a partial explanation for the SEP–health gradient; for example, genetic predispositions towards certain diseases and/or genetic influences on what foods people like, could lead to poor diet, which in turn could lead to both lower SEP and poorer health6. It has recently been demonstrated that genome-wide association studies (GWASs) can capture shared genetic associations between measures of health and SEP7. Potential pleiotropic effects are highlighted in the observed genetic correlations between SEP variables, such as years of education completed, household income and social deprivation, and physical and mental health traits including longevity.\nLoci associated with two SEP phenotypes, education and household income, have been identified via GWASs7,9,10,11, but—consistent with other complex traits, such as height—these loci collectively account for only a small fraction of the total heritability of the traits in question. For household income, an analysis of a sample of 96,900 individuals from Great Britain found that additive genetic effects tagged by common single-nucleotide polymorphisms (SNPs) accounted for ~11% (SE = 0.7%) of differences in household income7. Two loci attained genome-wide significance in that study, but they collectively accounted for <0.005% of the total SNP heritability.\nHere, we use the UK Biobank data set12 to examine genetic associations with household income (n = 286,301) in a contemporary British sample. We identify 30 independent genome-wide significant loci, 29 of which are unreported in previous work. Using a method that leverages power from genetically correlated traits, multi-trait analysis of GWAS (MTAG), an additional 120 loci are found to be associated with income. We identify neurogenesis and the components of the synapse as being associated with income. Furthermore, we link transcription differences across multiple cortical tissue types, as well as both GABAergic and serotonergic neurotransmission, to income differences. We also show that the genes linked to differences in income are predominantly those that have been previously linked with intelligence8, and that intelligence is one of the likely causal factors leading to differences in income. We compare the genetic correlations derived using income with those derived using another measure of SEP, educational attainment, to show that the genetic variants associated with income are related to better mental health than those related to education. Finally, we predict 2.5% of income differences using genetic data alone in an independent sample.\nResults\nGraphical representation of statistical analysis\nA flow chart summarizing all statistical analyses conducted is displayed in Fig. 2.\nSNP-based analysis of income\nFor household income, 3712 SNPs attained genome-wide significance (P < 5 × 10−8), across 30 independent loci (Fig. 3a and Supplementary Data 1), which contained 68 independent significant SNPs and 31 lead SNPs. A total of 29 of these 30 loci were not identified in the previous UK Biobank analysis of income (Supplementary Data 2). The 30 loci predominantly contained SNPs found within intronic regions (47%) as well as non-coding RNA introns (29%). A total of 17% of the SNPs within the independent loci were found in intergenic regions, and only 1.2% were found in exons (Fig. 3b). Many of the loci contained SNPs showing evidence of influencing gene regulation with 33% having a Regulome DB score of <2 (Fig. 3c) and 86% having evidence of being in an open-chromatin state (indicated by a minimum chromatin state of <8, in Fig. 3d). Additionally, these loci were linked to intelligence (11 loci), mental health (schizophrenia, 1 locus; bipolar disorder, 2 loci; neuroticism, 4 loci) and neurological variables (corticobasal degeneration, 1 locus; subcortical brain volumes, 1 locus; and Parkinson’s disease, 1 locus) (Supplementary Data 3).\nLinkage disequilibrium score (LDSC) regression showed that the mean χ2 statistic was 1.45 and the intercept of the LDSC regression was 1.04. These statistics indicate that around 92% of the inflation in the GWAS test statistics was due to a polygenic signal rather than residual stratification or confounding. The LDSC regression estimate of the heritability of household income was 7.39% (SE = 0.33%).\nGene prioritization\nThree methods of mapping allelic variation to genes were used to better understand the functional consequences of the 30 independent loci linked to income (positional mapping, expression quantitative trait loci (eQTL) analysis and chromatin mapping). Using positional mapping, SNPs from the GWAS were aligned to 117 genes. eQTL mapping was used to match cis-eQTL SNPs to 186 genes, and chromatin interaction mapping linked the SNPs to 277 genes (Fig. 3e and Supplementary Data 4 and Supplementary Fig. 1). These mapping strategies identified a total of 400 unique genes, of which 133 (Fig. 3e cells 14 + 23 + 26 + 3 + 24 + 11 + 2 + 30) were implicated by at least two mapping strategies and 47 (Fig. 3e cells 23 + 24) were implicated by all three. Of the 133 implicated by two mapping strategies, two showed evidence of a chromatin interactions with two independent genomic risk loci (Supplementary Data 5). Both HOXB2 and HOXB7 showed interactions with loci 24 and loci 25. HOXB2 showed interactions in mesendoderm (an embryonic tissue layer) tissue and IMR90 (foetal lung fibroblasts)tissue, whereas HOXB7 showed associations in the tissues of hESC (human embryonic stem cell), mesenchymal (multipotent stromal cells which differentiate into a variety of different cell types) stem cell, IMR90, left ventricle, GM12878, and trophoblast-like cells.",
    "reference_list": "考点1： \"genetic loci\"应该译为“基因座”。\n考点2： \"meta-analyze\"应译为“统合分析”。\n考点3： \"GABAergic '应译为“迦瑪胺基丁酸”。\n考点4：\" eQTL\" 应该译为“表达数量性状位点”。\n考点5：\" pleiotropy'应译为“基因多效性”。\n考点6： \"synapse'应译为“突触”。\n考点7：\"exons'应译为“外显子”。\n考点8：\"RNA'应译为“核糖核酸”。\n考点9：\"HOXB2\"应译为“同源核基因B2”。\n考点10：\"Linkage disequilibrium score\"应译为“连锁不平衡分数”。 \n考点11：'foetal lung fibroblasts\"应译为“胎儿肺成纤维细胞 ”，其中foetal应该是拼写错误。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "67"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n从\"北大废物\"到暴瘦女神：李雪琴用30斤体重，找回了“自己”\n谁能想到，那个曾经胖乎乎的李雪琴，如今竟成了众人口中的 \" 美貌女神 \"？\n2025 年，当她再次出现在《你好星期六》的舞台上时，观众们几乎认不出眼前这个气质出众的女子。\n腰线纤细，皮肤紧致，网友都震惊了：\" 这还是我们认识的那个李雪琴吗？\"\n三十斤的体重，她说减就减了。\n她曾在节目中坦言，暗恋的男生因为她胖，随口说出 \" 瘦到一百斤才能抱你 \" 这样的话。\n那时的她卑微到尘埃里，自尊心支离破碎。\n而现在，她甚至被传有了同样高学历背景的男友。据说此人是《宇宙探索编辑部》的编剧，在马路上牵着她的手，非常甜蜜。\n这么多年过去了，她终于不再是那个被人嘲笑 \" 没人抱 \" 的女孩，开始闪闪发光。\n网红时代，意外爆红\n2019 年夏天，李雪琴走红了。\n她穿着一件普通 T 恤，杵在清华校门前，立好了拍摄的设备。随后便向某明星喊话：\" 你看这清华大学的校门，多白！\"\n就是这样一个简单到近乎粗糙的视频，突然在网络上火了。\n人们议论着这个女孩，说她跟其他网红一样装疯卖傻。\n质疑声此起彼伏：\" 顶尖学校毕业的精英竟然拍这种低趣味视频，简直浪费了国家的栽培。\"\n面对质疑，她淡然回应：\" 北大就不能养废物吗？\" 这种自嘲式的反击，反而让她获得了更多关注。\n用最朴实的方式展现了普通人的真实状态，这种反差感恰好击中了人们的审美疲劳。\n没有精致滤镜、华丽包装，她给出了最接地气的表达、最真实的自己。\n这种真实，成了她最大的武器。\n脱口秀舞台，天才绽放\n2020 年，她以 \" 脱口秀天才少女 \" 的身份再次火出圈。\n舞台上的她，把生活中的平淡日常改写成了一个个让人哈哈大笑的段子。\n吐槽老板半夜三点打电话，说她这大半夜的怎么还睡觉；吐槽妈妈催婚，结果妈妈自己先再婚了。\n\" 宇宙的尽头是铁岭 \" 这句话，从她口中说出后迅速成为网络金句。\n很多人觉得她应该是个乐天派，殊不知喜剧的内核是悲剧。\n因为成长背景和学业压力，她曾经患过抑郁症，幽默不过是解构痛苦的一种方式。\n铁岭女孩，敏感童年\n1995 年，她出生在东北铁岭。\n小时候她就是个“圆球”，长得也不上相。上小学时，很多同学因为她的身材嘲笑孤立她，敏感的她因此变得自卑内向。\n为了弥补身材和长相的不足，她在学习上特别上进。每次考试都能拿第一，因此获得了 \" 李第一 \" 的绰号。\n14 岁那年，做生意失败的父亲选择离开这个家，原本幸福的三口之家坍塌了。母亲情绪变得极度不稳定，芝麻小事也有可能突然乱发脾气。\n \n\" 我妈是一个小女生，她是我带着长大的，这个家是我撑起来的。\" 她练就了“高情商”，不自觉地就会安抚别人的情绪。\n让妈妈开心，成了她做事的唯一准则。\n有一次考试她只拿了第二名，邻居无意说了一句 \" 可能是受父母离婚影响 \"，母亲当场崩溃痛哭。从此之后，她每次考试都是第一，最终考入北大。\n可是，光顾着治愈母亲情绪的她，没有意识到自己的情绪也 \" 生病 \" 了，内心的快乐却越来越少。\n她曾经到纽约大学继续求学之路。但是陌生的环境和巨大的压力让她的抑郁症愈发严重。\n她经常整日瘫在床上，望着天花板发呆流泪，直到精疲力竭地睡去。\n走在国外的大街上，也会止不住嚎啕大哭。最严重的时候，她甚至用小刀在手腕上划下伤痕。\n最终，学业无法继续的她选择了退学。有时候，退一步不是懦弱，而是为了更好地找准方向。\n学新闻的她，对网络平台很感兴趣，便开始尝试短视频。谁知一发不可收拾，走上了网红之路，深受网友欢迎。\n而这些努力，也让她渐渐走上了治愈自己的道路。自此拍综艺、讲脱口秀、演戏，一发不可收拾。\n从铁岭的胖女孩到到网络的搞笑红人，她用三十年的时间完成了一场漫长的自我和解。\n人生从来不是一条直线，跌跌撞撞才是常态。\n重要的是，无论走过多少弯路，都要记得最初的那个自己，那个敢于做梦、敢于发光的自己。\n如今的她，终于活成了自己想要的样子——有才华的光芒，更有内心的平静与自信。",
    "ori_text": "从\"北大废物\"到暴瘦女神：李雪琴用30斤体重，找回了“自己”\n谁能想到，那个曾经胖乎乎的李雪琴，如今竟成了众人口中的 \" 美貌女神 \"？\n2025 年，当她再次出现在《你好星期六》的舞台上时，观众们几乎认不出眼前这个气质出众的女子。\n腰线纤细，皮肤紧致，网友都震惊了：\" 这还是我们认识的那个李雪琴吗？\"\n三十斤的体重，她说减就减了。\n她曾在节目中坦言，暗恋的男生因为她胖，随口说出 \" 瘦到一百斤才能抱你 \" 这样的话。\n那时的她卑微到尘埃里，自尊心支离破碎。\n而现在，她甚至被传有了同样高学历背景的男友。据说此人是《宇宙探索编辑部》的编剧，在马路上牵着她的手，非常甜蜜。\n这么多年过去了，她终于不再是那个被人嘲笑 \" 没人抱 \" 的女孩，开始闪闪发光。\n网红时代，意外爆红\n2019 年夏天，李雪琴走红了。\n她穿着一件普通 T 恤，杵在清华校门前，立好了拍摄的设备。随后便向某明星喊话：\" 你看这清华大学的校门，多白！\"\n就是这样一个简单到近乎粗糙的视频，突然在网络上火了。\n人们议论着这个女孩，说她跟其他网红一样装疯卖傻。\n质疑声此起彼伏：\" 顶尖学校毕业的精英竟然拍这种低趣味视频，简直浪费了国家的栽培。\"\n面对质疑，她淡然回应：\" 北大就不能养废物吗？\" 这种自嘲式的反击，反而让她获得了更多关注。\n用最朴实的方式展现了普通人的真实状态，这种反差感恰好击中了人们的审美疲劳。\n没有精致滤镜、华丽包装，她给出了最接地气的表达、最真实的自己。\n这种真实，成了她最大的武器。\n脱口秀舞台，天才绽放\n2020 年，她以 \" 脱口秀天才少女 \" 的身份再次火出圈。\n舞台上的她，把生活中的平淡日常改写成了一个个让人哈哈大笑的段子。\n吐槽老板半夜三点打电话，说她这大半夜的怎么还睡觉；吐槽妈妈催婚，结果妈妈自己先再婚了。\n\" 宇宙的尽头是铁岭 \" 这句话，从她口中说出后迅速成为网络金句。\n很多人觉得她应该是个乐天派，殊不知喜剧的内核是悲剧。\n因为成长背景和学业压力，她曾经患过抑郁症，幽默不过是解构痛苦的一种方式。\n铁岭女孩，敏感童年\n1995 年，她出生在东北铁岭。\n小时候她就是个“圆球”，长得也不上相。上小学时，很多同学因为她的身材嘲笑孤立她，敏感的她因此变得自卑内向。\n为了弥补身材和长相的不足，她在学习上特别上进。每次考试都能拿第一，因此获得了 \" 李第一 \" 的绰号。\n14 岁那年，做生意失败的父亲选择离开这个家，原本幸福的三口之家坍塌了。母亲情绪变得极度不稳定，芝麻小事也有可能突然乱发脾气。\n \n\" 我妈是一个小女生，她是我带着长大的，这个家是我撑起来的。\" 她练就了“高情商”，不自觉地就会安抚别人的情绪。\n让妈妈开心，成了她做事的唯一准则。\n有一次考试她只拿了第二名，邻居无意说了一句 \" 可能是受父母离婚影响 \"，母亲当场崩溃痛哭。从此之后，她每次考试都是第一，最终考入北大。\n可是，光顾着治愈母亲情绪的她，没有意识到自己的情绪也 \" 生病 \" 了，内心的快乐却越来越少。\n她曾经到纽约大学继续求学之路。但是陌生的环境和巨大的压力让她的抑郁症愈发严重。\n她经常整日瘫在床上，望着天花板发呆流泪，直到精疲力竭地睡去。\n走在国外的大街上，也会止不住嚎啕大哭。最严重的时候，她甚至用小刀在手腕上划下伤痕。\n最终，学业无法继续的她选择了退学。有时候，退一步不是懦弱，而是为了更好地找准方向。\n学新闻的她，对网络平台很感兴趣，便开始尝试短视频。谁知一发不可收拾，走上了网红之路，深受网友欢迎。\n而这些努力，也让她渐渐走上了治愈自己的道路。自此拍综艺、讲脱口秀、演戏，一发不可收拾。\n从铁岭的胖女孩到到网络的搞笑红人，她用三十年的时间完成了一场漫长的自我和解。\n人生从来不是一条直线，跌跌撞撞才是常态。\n重要的是，无论走过多少弯路，都要记得最初的那个自己，那个敢于做梦、敢于发光的自己。\n如今的她，终于活成了自己想要的样子——有才华的光芒，更有内心的平静与自信。",
    "reference_list": "考点1：“废物”应该译为“loser”。\n考点2： “你好星期六”应译为“Hello Saturday”或“H!6”。 \n考点3： “气质出众”应译为“exceptional poise”。\n考点4： “宇宙探索编辑部”应译为“Journey to the West”。\n考点5： “装疯卖傻”应译为“play dumb and act crazy for attention”。\n考点6： “接地气”应译为“unpretencious”。\n考点7： “火出圈”应译为“go viral”。\n考点8： “金句”应译为“catchphrase”。\n考点9：“不上相”应译为“not photogenic”。\n考点10：“一发不可收拾”应译为“unstoppable”。\n考点11：“弯路中”应译为“setbacks”。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "传记",
    "prompt_id": "62"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nNew method combines imaging and sequencing to study gene function in intact tissue\nThe approach collects multiple types of imaging and sequencing data from the same cells, leading to new insights into mouse liver biology.\nImagine that you want to know the plot of a movie, but you only have access to either the visuals or the sound. With visuals alone, you’ll miss all the dialogue. With sound alone, you will miss the action. Understanding our biology can be similar. Measuring one kind of data — such as which genes are being expressed — can be informative, but it only captures one facet of a multifaceted story. For many biological processes and disease mechanisms, the entire “plot” can’t be fully understood without combining data types. However, capturing both the “visuals and sound” of biological data, such as gene expression and cell structure data, from the same cells requires researchers to develop new approaches. They also have to make sure that the data they capture accurately reflects what happens in living organisms, including how cells interact with each other and their environments. Whitehead Institute for Biomedical Research and Harvard University researchers have taken on these challenges and developed Perturb-Multimodal (Perturb-Multi), a powerful new approach that simultaneously measures how genetic changes such as turning off individual genes affect both gene expression and cell structure in intact liver tissue. The method, described in Cell on June 12, aims to accelerate discovery of how genes control organ function and disease. The research team, led by Whitehead Institute Member Jonathan Weissman and then-graduate student in his lab Reuben Saunders, along with Xiaowei Zhuang, the David B. Arnold Professor of Science at Harvard University, and then-postdoc in her lab Will Allen, created a system that can test hundreds of different genetic modifications within a single mouse liver while capturing multiple types of data from the same cells. “Understanding how our organs work requires looking at many different aspects of cell biology at once,” Saunders says. “With Perturb-Multi, we can see how turning off specific genes changes not just what other genes are active, but also how proteins are distributed within cells, how cellular structures are organized, and where cells are located in the tissue. It’s like having multiple specialized microscopes all focused on the same experiment.” “This approach accelerates discovery by both allowing us to test the functions of many different genes at once, and then for each gene, allowing us to measure many different functional outputs or cell properties at once — and we do that in intact tissue from animals,” says Zhuang, who is also a Howard Hughes Medical Institute (HHMI) investigator. A more efficient approach to genetic studies Traditional genetic studies in mice often turn off one gene and then observe what changes in that gene’s absence to learn about what the gene does. The researchers designed their approach to turn off hundreds of different genes across a single liver, while still only turning off one gene per cell — using what is known as a mosaic approach. This allowed them to study the roles of hundreds of individual genes at once in a single individual. The researchers then collected diverse types of data from cells across the same liver to get a full picture of the consequences of turning off the genes. “Each cell serves as its own experiment, and because all the cells are in the same animal, we eliminate the variability that comes from comparing different mice,” Saunders says. “Every cell experiences the same physiological conditions, diet, and environment, making our comparisons much more precise.” “The challenge we faced was that tissues, to perform their functions, rely on thousands of genes, expressed in many different cells, working together. Each gene, in turn, can control many aspects of a cell’s function. Testing these hundreds of genes in mice using current methods would be extremely slow and expensive — near impossible, in practice.” Allen says. Revealing new biology through combined measurements The team applied Perturb-Multi to study genetic controls of liver physiology and function. Their study led to discoveries in three important aspects of liver biology: fat accumulation in liver cells — a precursor to liver disease; stress responses; and hepatocyte zonation (how liver cells specialize, assuming different traits and functions, based on their location within the liver). One striking finding emerged from studying genes that, when disrupted, cause fat accumulation in liver cells. The imaging data revealed that four different genes all led to similar fat droplet accumulation, but the sequencing data showed they did so through three completely different mechanisms. “Without combining imaging and sequencing, we would have missed this complexity entirely,” Saunders says. “The imaging told us which genes affect fat accumulation, while the sequencing revealed whether this was due to increased fat production, cellular stress, or other pathways. This kind of mechanistic insight could be crucial for developing targeted therapies for fatty liver disease.” The researchers also discovered new regulators of liver cell zonation. Unexpectedly, the newly discovered regulators include genes involved in modifying the extracellular matrix — the scaffolding between cells. “We found that cells can change their specialized functions without physically moving to a different zone,” Saunders says. “This suggests that liver cell identity is more flexible than previously thought.” Technical innovation enables new science Developing Perturb-Multi required solving several technical challenges. The team created new methods for preserving the content of interest in cells — RNA and proteins — during tissue processing, for collecting many types of imaging data and single-cell gene expression data from tissue samples that have been fixed with a preservative, and for integrating multiple types of data from the same cells. “Overcoming the inherent complexity of biology in living animals required developing new tools that bridge multiple disciplines — including, in this case, genomics, imaging, and AI,” Allen says. The two components of Perturb-Multi — the imaging and sequencing assays — together, applied to the same tissue, provide insights that are unattainable through either assay alone. “Each component had to work perfectly while not interfering with the others,” says Weissman, who is also a professor of biology at MIT and an HHMI investigator. “The technical development took considerable effort, but the payoff is a system that can reveal biology we simply couldn’t see before.” Expanding to new organs and other contexts The researchers plan to expand Perturb-Multi to other organs, including the brain, and to study how genetic changes affect organ function under different conditions like disease states or dietary changes. “We’re also excited about using the data we generate to train machine learning models,” adds Saunders. “With enough examples of how genetic changes affect cells, we could eventually predict the effects of mutations without having to test them experimentally — a ‘virtual cell’ that could accelerate both research and drug development.” “Perturbation data are critical for training such AI models and the paucity of existing perturbation data represents a major hindrance in such ‘virtual cell’ efforts,” Zhuang says. “We hope Perturb-Multi will fill this gap by accelerating the collection of perturbation data.” The approach is designed to be scalable, with the potential for genome-wide studies that test thousands of genes simultaneously. As sequencing and imaging technologies continue to improve, the researchers anticipate that Perturb-Multi will become even more powerful and accessible to the broader research community. “Our goal is to keep scaling up. We plan to do genome-wide perturbations, study different physiological conditions, and look at different organs,” says Weissman. “That we can now collect so many types of data from so many cells, at speed, is going to be critical for building AI models like virtual cells, and I think it’s going to help us answer previously unsolvable questions about health and disease.”",
    "ori_text": "New method combines imaging and sequencing to study gene function in intact tissue\nThe approach collects multiple types of imaging and sequencing data from the same cells, leading to new insights into mouse liver biology.\nImagine that you want to know the plot of a movie, but you only have access to either the visuals or the sound. With visuals alone, you’ll miss all the dialogue. With sound alone, you will miss the action. Understanding our biology can be similar. Measuring one kind of data — such as which genes are being expressed — can be informative, but it only captures one facet of a multifaceted story. For many biological processes and disease mechanisms, the entire “plot” can’t be fully understood without combining data types. However, capturing both the “visuals and sound” of biological data, such as gene expression and cell structure data, from the same cells requires researchers to develop new approaches. They also have to make sure that the data they capture accurately reflects what happens in living organisms, including how cells interact with each other and their environments. Whitehead Institute for Biomedical Research and Harvard University researchers have taken on these challenges and developed Perturb-Multimodal (Perturb-Multi), a powerful new approach that simultaneously measures how genetic changes such as turning off individual genes affect both gene expression and cell structure in intact liver tissue. The method, described in Cell on June 12, aims to accelerate discovery of how genes control organ function and disease. The research team, led by Whitehead Institute Member Jonathan Weissman and then-graduate student in his lab Reuben Saunders, along with Xiaowei Zhuang, the David B. Arnold Professor of Science at Harvard University, and then-postdoc in her lab Will Allen, created a system that can test hundreds of different genetic modifications within a single mouse liver while capturing multiple types of data from the same cells. “Understanding how our organs work requires looking at many different aspects of cell biology at once,” Saunders says. “With Perturb-Multi, we can see how turning off specific genes changes not just what other genes are active, but also how proteins are distributed within cells, how cellular structures are organized, and where cells are located in the tissue. It’s like having multiple specialized microscopes all focused on the same experiment.” “This approach accelerates discovery by both allowing us to test the functions of many different genes at once, and then for each gene, allowing us to measure many different functional outputs or cell properties at once — and we do that in intact tissue from animals,” says Zhuang, who is also a Howard Hughes Medical Institute (HHMI) investigator. A more efficient approach to genetic studies Traditional genetic studies in mice often turn off one gene and then observe what changes in that gene’s absence to learn about what the gene does. The researchers designed their approach to turn off hundreds of different genes across a single liver, while still only turning off one gene per cell — using what is known as a mosaic approach. This allowed them to study the roles of hundreds of individual genes at once in a single individual. The researchers then collected diverse types of data from cells across the same liver to get a full picture of the consequences of turning off the genes. “Each cell serves as its own experiment, and because all the cells are in the same animal, we eliminate the variability that comes from comparing different mice,” Saunders says. “Every cell experiences the same physiological conditions, diet, and environment, making our comparisons much more precise.” “The challenge we faced was that tissues, to perform their functions, rely on thousands of genes, expressed in many different cells, working together. Each gene, in turn, can control many aspects of a cell’s function. Testing these hundreds of genes in mice using current methods would be extremely slow and expensive — near impossible, in practice.” Allen says. Revealing new biology through combined measurements The team applied Perturb-Multi to study genetic controls of liver physiology and function. Their study led to discoveries in three important aspects of liver biology: fat accumulation in liver cells — a precursor to liver disease; stress responses; and hepatocyte zonation (how liver cells specialize, assuming different traits and functions, based on their location within the liver). One striking finding emerged from studying genes that, when disrupted, cause fat accumulation in liver cells. The imaging data revealed that four different genes all led to similar fat droplet accumulation, but the sequencing data showed they did so through three completely different mechanisms. “Without combining imaging and sequencing, we would have missed this complexity entirely,” Saunders says. “The imaging told us which genes affect fat accumulation, while the sequencing revealed whether this was due to increased fat production, cellular stress, or other pathways. This kind of mechanistic insight could be crucial for developing targeted therapies for fatty liver disease.” The researchers also discovered new regulators of liver cell zonation. Unexpectedly, the newly discovered regulators include genes involved in modifying the extracellular matrix — the scaffolding between cells. “We found that cells can change their specialized functions without physically moving to a different zone,” Saunders says. “This suggests that liver cell identity is more flexible than previously thought.” Technical innovation enables new science Developing Perturb-Multi required solving several technical challenges. The team created new methods for preserving the content of interest in cells — RNA and proteins — during tissue processing, for collecting many types of imaging data and single-cell gene expression data from tissue samples that have been fixed with a preservative, and for integrating multiple types of data from the same cells. “Overcoming the inherent complexity of biology in living animals required developing new tools that bridge multiple disciplines — including, in this case, genomics, imaging, and AI,” Allen says. The two components of Perturb-Multi — the imaging and sequencing assays — together, applied to the same tissue, provide insights that are unattainable through either assay alone. “Each component had to work perfectly while not interfering with the others,” says Weissman, who is also a professor of biology at MIT and an HHMI investigator. “The technical development took considerable effort, but the payoff is a system that can reveal biology we simply couldn’t see before.” Expanding to new organs and other contexts The researchers plan to expand Perturb-Multi to other organs, including the brain, and to study how genetic changes affect organ function under different conditions like disease states or dietary changes. “We’re also excited about using the data we generate to train machine learning models,” adds Saunders. “With enough examples of how genetic changes affect cells, we could eventually predict the effects of mutations without having to test them experimentally — a ‘virtual cell’ that could accelerate both research and drug development.” “Perturbation data are critical for training such AI models and the paucity of existing perturbation data represents a major hindrance in such ‘virtual cell’ efforts,” Zhuang says. “We hope Perturb-Multi will fill this gap by accelerating the collection of perturbation data.” The approach is designed to be scalable, with the potential for genome-wide studies that test thousands of genes simultaneously. As sequencing and imaging technologies continue to improve, the researchers anticipate that Perturb-Multi will become even more powerful and accessible to the broader research community. “Our goal is to keep scaling up. We plan to do genome-wide perturbations, study different physiological conditions, and look at different organs,” says Weissman. “That we can now collect so many types of data from so many cells, at speed, is going to be critical for building AI models like virtual cells, and I think it’s going to help us answer previously unsolvable questions about health and disease.”",
    "reference_list": "考点 1：\"facet of a multifaceted story\" 应译为 \"多方面故事的一个侧面\"\n考点 2：\"Perturb-Multimodal (Perturb-Multi)\" 应译为 \"扰动 - 多模态方法\"\n考点 3：\"multiple types of imaging and sequencing data\" 应译为 \"多类型成像和测序数据\"\n考点 4：'living organisms\" 应译为 \"活体生物\"\n考点 5：\"functional outputs\" 应译为 \"功能性输出 / 功能结果\"\n考点 6：\"cell properties\" 应译为 \"细胞特性\"\n考点 7：\"mosaic approach\" 应译为 \"镶嵌方法 / 镶嵌策略\"\n考点 8：\"variability\" 应译为 \"变异性 / 差异性\"\n考点 9：\"striking finding\" 应译为 \"一个引人注目的发现 / 一项惊人的发现\"\n考点 10：\"mechanistic insight\" 应译为 \"机制性洞见 / 对作用机制的深入理解\"\n考点 11：\"fatty liver disease\" 应译为 \"脂肪肝疾病\"\n考点 12：\"extracellular matrix — the scaffolding between cells\" 应译为 \"细胞外基质 — 细胞间的 '支架' \"\n考点 13：\"single-cell gene expression data\" 应译为 \"单细胞基因表达数据\"\n考点 14：\"bridge multiple disciplines\" 应译为 \"跨越多个学科 / 在多个学科间架起桥梁\"\n考点 15：\"genomics, imaging, and AI\" 应译为 \"基因组学、成像与人工智能\"\n考点 16：\"specialized microscopes\" 应译为 \"专用显微镜\"\n考点 17：\"targeted therapies\" 应译为 \"靶向疗法\"\n考点 18：\"mechanistic insight\" 应译为 \"机制性洞见\"\n考点 19：\"cellular stress\" 应译为 \"细胞应激\"\n考点 20：\"perturbation data\" 应译为 \"扰动数据\"",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "95"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n2025年6月16日，最高人民检察院发布《未成年人检察工作白皮书（2024）》（简称《白皮书》）显示，2024年，最高检依法核准追诉初中生杀害同学埋尸案等低龄未成年人严重暴力犯罪34人。\n\n2024年，多起低龄未成年实施严重暴力犯罪案件引发广泛关注。其中，2024年3月，河北省邯郸市肥乡区北高镇发生一起3名初中生将同学残忍杀害并将尸体掩埋在蔬菜大棚的恶性案件。最高人民检察院经审查，依法决定对3名犯罪嫌疑人核准追诉。2024年12月30日，邯郸市中级人民法院一审公开宣判该案。3名被告人中，张某某被以故意杀人罪判处无期徒刑，剥夺政治权利终身，李某被以故意杀人罪判处有期徒刑十二年。被告人马某某依法不予刑事处罚。\n\n去年以来，最高检已多次明确，对低龄未成年人严重暴力犯罪，符合核准追诉条件的，要依法核准追诉。最高检还透露，今年将会同相关部门研究出台加强未成年人罪错行为分级干预矫治的意见，研究制定办理低龄未成年人严重暴力犯罪核准追诉案件的意见。\n\n最高检在《白皮书》中表示，检察机关全面准确贯彻宽严相济刑事政策，依法该严则严、当宽则宽。对主观恶性大、犯罪手段残忍的未成年人犯罪依法惩处，决不纵容。同时，对情节较轻、社会危害性较小的犯罪，或者较轻犯罪的初犯、偶犯，依法从宽，最大限度教育挽救，防止再犯。\n\n事件背景\n\n2024年3月10日，河北邯郸肥乡区北高镇张庄村3名初中生霸凌同学，随后将王某某残忍杀害并将尸体掩埋在蔬菜大棚里。3名犯罪嫌疑人心理素质极强，直到调出监控视频，其中的主犯才被指认。找到尸体后发现，受害者已经面目全非。\n\n案件发生后，肥乡区公安机关立即开展侦破工作。2024年3月11日，涉案犯罪嫌疑人被全部抓获，现已依法采取刑事强制措施；3月15日，邯郸市3名涉嫌杀害同学的初中生被刑拘；3月18日，河北邯郸肥乡区警方回应初一学生王某某被杀害案：犯罪嫌疑人为有预谋作案；4月，经最高人民检察院审查，依法决定对犯罪嫌疑人张某某、李某及马某某核准追诉。检察机关审查认为，3名犯罪嫌疑人作案时已满12周岁不满14周岁，故意杀人致被害人死亡，情节恶劣，应当追究刑事责任。\n\n2024年12月30日，河北省邯郸市中级人民法院一审公开宣判被告人张某某、李某、马某某故意杀人一案，对被告人张某某以故意杀人罪判处无期徒刑，剥夺政治权利终身；对被告人李某以故意杀人罪判处有期徒刑十二年；被告人马某某依法不予刑事处罚。邯郸市中级人民法院、邯郸市人民检察院提出司法建议、检察建议，经专门教育指导委员会评估同意，相关公安机关和教育部门依法决定对马某某进行专门矫治教育。",
    "ori_text": "2025年6月16日，最高人民检察院发布《未成年人检察工作白皮书（2024）》（简称《白皮书》）显示，2024年，最高检依法核准追诉初中生杀害同学埋尸案等低龄未成年人严重暴力犯罪34人。\n\n2024年，多起低龄未成年实施严重暴力犯罪案件引发广泛关注。其中，2024年3月，河北省邯郸市肥乡区北高镇发生一起3名初中生将同学残忍杀害并将尸体掩埋在蔬菜大棚的恶性案件。最高人民检察院经审查，依法决定对3名犯罪嫌疑人核准追诉。2024年12月30日，邯郸市中级人民法院一审公开宣判该案。3名被告人中，张某某被以故意杀人罪判处无期徒刑，剥夺政治权利终身，李某被以故意杀人罪判处有期徒刑十二年。被告人马某某依法不予刑事处罚。\n\n去年以来，最高检已多次明确，对低龄未成年人严重暴力犯罪，符合核准追诉条件的，要依法核准追诉。最高检还透露，今年将会同相关部门研究出台加强未成年人罪错行为分级干预矫治的意见，研究制定办理低龄未成年人严重暴力犯罪核准追诉案件的意见。\n\n最高检在《白皮书》中表示，检察机关全面准确贯彻宽严相济刑事政策，依法该严则严、当宽则宽。对主观恶性大、犯罪手段残忍的未成年人犯罪依法惩处，决不纵容。同时，对情节较轻、社会危害性较小的犯罪，或者较轻犯罪的初犯、偶犯，依法从宽，最大限度教育挽救，防止再犯。\n\n事件背景\n\n2024年3月10日，河北邯郸肥乡区北高镇张庄村3名初中生霸凌同学，随后将王某某残忍杀害并将尸体掩埋在蔬菜大棚里。3名犯罪嫌疑人心理素质极强，直到调出监控视频，其中的主犯才被指认。找到尸体后发现，受害者已经面目全非。\n\n案件发生后，肥乡区公安机关立即开展侦破工作。2024年3月11日，涉案犯罪嫌疑人被全部抓获，现已依法采取刑事强制措施；3月15日，邯郸市3名涉嫌杀害同学的初中生被刑拘；3月18日，河北邯郸肥乡区警方回应初一学生王某某被杀害案：犯罪嫌疑人为有预谋作案；4月，经最高人民检察院审查，依法决定对犯罪嫌疑人张某某、李某及马某某核准追诉。检察机关审查认为，3名犯罪嫌疑人作案时已满12周岁不满14周岁，故意杀人致被害人死亡，情节恶劣，应当追究刑事责任。\n\n2024年12月30日，河北省邯郸市中级人民法院一审公开宣判被告人张某某、李某、马某某故意杀人一案，对被告人张某某以故意杀人罪判处无期徒刑，剥夺政治权利终身；对被告人李某以故意杀人罪判处有期徒刑十二年；被告人马某某依法不予刑事处罚。邯郸市中级人民法院、邯郸市人民检察院提出司法建议、检察建议，经专门教育指导委员会评估同意，相关公安机关和教育部门依法决定对马某某进行专门矫治教育。",
    "reference_list": "考点1：“低龄未成年人”推荐译为“ minors of a younger age group; low-age minors”\n考点2：“恶性案件”推荐译为“heinous case; vicious case; grave case”\n考点3：“罪错行为分级干预矫治”推荐译为“tiered intervention and correction for delinquent and criminal behaviors”\n考点4：“宽严相济”推荐译为“ a policy of balancing leniency and severity”\n考点5：“主观恶性”推荐译为“subjective malice”\n考点6：“心理素质极强”此处形容罪犯，不可译为积极词汇\n考点7：“出台……意见”，意见不可用opinion",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "7"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n黄仁勋越来越焦虑\n\n关注AI产业发展的都能感受到，掌舵英伟达“算力帝国”的黄仁勋，最近越来越焦虑了，开始频繁地提起“中国”和“华为”。\n\n“中国做得太棒了，全球50%的人工智能研究人员都是中国人，你无法阻止他们，也无法阻止他们推进人工智能的发展。如果有人以为，一招就能切断中国发展人工智能的能力，那他绝对是无知的。”黄仁勋近期在台北电脑展上表示。\n\n今年4月，美国政府再度对英伟达中国“特供版”芯片H20发出禁令。公告一出，黄仁勋立刻把皮衣换成西装，飞往中国，这是他3个月里第二次来华。在与政府官员的会面中，黄仁勋多次强调中国市场的重要性，表示希望继续与中国合作。\n\n最新禁令，导致英伟达计提了55亿美元的库存损失，令黄仁勋“深感痛苦”。\n\n事实上，如果仅仅是数十亿美元的损失，对英伟达并不算“伤筋动骨”。这家市值超过3万亿美元的巨头，在AI风口下赚得盆满钵满，2025财年收入达到了1305亿美元，同比增长114%；净利润达到729亿美元，同比增长145%；毛利率达到惊人的75%。\n\n真正让黄仁勋感到焦虑的，是中国自主技术正在美国禁令逼迫下快速突围。在英伟达的关键护城河中，不仅有GPU这种硬件，还有并行计算平台和编程模型CUDA，以及高速互联技术NVLink。在单点竞争上，中国企业可能很难撼动英伟达地位，但系统竞争并不一定。\n\n近期，华为对外详细介绍了昇腾CLoudMatrix 384超节点技术，该技术使用国产昇腾芯片，在算力规模、训推效率和可靠性等关键维度上，全面超越了英伟达最强的NVL72系统。其中的核心在于，华为跳出了单卡算力的竞争，通过计算、存储、网络和架构的协同创新，弥补了硬件和芯片工艺的局限性，最大化发挥了芯片和系统能力。\n\n中国建立了替代英伟达的方案，才是黄仁勋最担心的。这不仅可能导致该公司在中国遭受永久性损失，更可能动摇其“算力帝国”的统治根基。他喊话美国政府：赢得开发者的平台才能最终获胜，出口管制应该强化美国平台，而不是迫使全球一半的AI人才流向竞争对手。\n\n看到中国再度突破，美国政客其实也很着急，但他们显然忽视了黄仁勋放宽管制的呼声。在严格限制英伟达对华出口的同时，美商务部最近还试图在全球封杀华为昇腾芯片，同时逼迫EDA巨头对华断供。但就像黄仁勋说的，这样只会激活中国企业绝处逢生的能力。\n\n就在今年4月，美国对华断供H20之际，华为云率先在芜湖商用了CLoudMatrix 384超节点，随后又在贵安和乌兰察布等地商用，内部人士将其称为“核弹级创新”，今年上半年还将有数万卡规模上线，目标是“彻底终结行业算力焦虑”。而近日华为再度重磅宣布，已经成功在昇腾平台上实现了准万亿MoE模型的全流程训练，集群训练系统的性能上实现了业界领先，进一步验证了国产AI基础设施的自主创新能力。\n\n“四年前，英伟达在中国的市场份额高达95%，如今只有50%。如果我们不在中国竞争，而是让中国开发出新的平台，建立一个丰富的生态系统，并且它们不是美国的，在世界推广人工智能技术的时候，他们的技术和领导力将会传播到世界各地。”不难看出，黄仁勋的焦虑感正越来越重，但美国政客仍在一意孤行，行业对老黄说辞也逐步失去了新鲜感。\n\n现在更令人感兴趣的是，华为是如何在没有先进工艺的情况下，用超节点反超英伟达的？",
    "ori_text": "黄仁勋越来越焦虑\n\n关注AI产业发展的都能感受到，掌舵英伟达“算力帝国”的黄仁勋，最近越来越焦虑了，开始频繁地提起“中国”和“华为”。\n\n“中国做得太棒了，全球50%的人工智能研究人员都是中国人，你无法阻止他们，也无法阻止他们推进人工智能的发展。如果有人以为，一招就能切断中国发展人工智能的能力，那他绝对是无知的。”黄仁勋近期在台北电脑展上表示。\n\n今年4月，美国政府再度对英伟达中国“特供版”芯片H20发出禁令。公告一出，黄仁勋立刻把皮衣换成西装，飞往中国，这是他3个月里第二次来华。在与政府官员的会面中，黄仁勋多次强调中国市场的重要性，表示希望继续与中国合作。\n\n最新禁令，导致英伟达计提了55亿美元的库存损失，令黄仁勋“深感痛苦”。\n\n事实上，如果仅仅是数十亿美元的损失，对英伟达并不算“伤筋动骨”。这家市值超过3万亿美元的巨头，在AI风口下赚得盆满钵满，2025财年收入达到了1305亿美元，同比增长114%；净利润达到729亿美元，同比增长145%；毛利率达到惊人的75%。\n\n真正让黄仁勋感到焦虑的，是中国自主技术正在美国禁令逼迫下快速突围。在英伟达的关键护城河中，不仅有GPU这种硬件，还有并行计算平台和编程模型CUDA，以及高速互联技术NVLink。在单点竞争上，中国企业可能很难撼动英伟达地位，但系统竞争并不一定。\n\n近期，华为对外详细介绍了昇腾CLoudMatrix 384超节点技术，该技术使用国产昇腾芯片，在算力规模、训推效率和可靠性等关键维度上，全面超越了英伟达最强的NVL72系统。其中的核心在于，华为跳出了单卡算力的竞争，通过计算、存储、网络和架构的协同创新，弥补了硬件和芯片工艺的局限性，最大化发挥了芯片和系统能力。\n\n中国建立了替代英伟达的方案，才是黄仁勋最担心的。这不仅可能导致该公司在中国遭受永久性损失，更可能动摇其“算力帝国”的统治根基。他喊话美国政府：赢得开发者的平台才能最终获胜，出口管制应该强化美国平台，而不是迫使全球一半的AI人才流向竞争对手。\n\n看到中国再度突破，美国政客其实也很着急，但他们显然忽视了黄仁勋放宽管制的呼声。在严格限制英伟达对华出口的同时，美商务部最近还试图在全球封杀华为昇腾芯片，同时逼迫EDA巨头对华断供。但就像黄仁勋说的，这样只会激活中国企业绝处逢生的能力。\n\n就在今年4月，美国对华断供H20之际，华为云率先在芜湖商用了CLoudMatrix 384超节点，随后又在贵安和乌兰察布等地商用，内部人士将其称为“核弹级创新”，今年上半年还将有数万卡规模上线，目标是“彻底终结行业算力焦虑”。而近日华为再度重磅宣布，已经成功在昇腾平台上实现了准万亿MoE模型的全流程训练，集群训练系统的性能上实现了业界领先，进一步验证了国产AI基础设施的自主创新能力。\n\n“四年前，英伟达在中国的市场份额高达95%，如今只有50%。如果我们不在中国竞争，而是让中国开发出新的平台，建立一个丰富的生态系统，并且它们不是美国的，在世界推广人工智能技术的时候，他们的技术和领导力将会传播到世界各地。”不难看出，黄仁勋的焦虑感正越来越重，但美国政客仍在一意孤行，行业对老黄说辞也逐步失去了新鲜感。\n\n现在更令人感兴趣的是，华为是如何在没有先进工艺的情况下，用超节点反超英伟达的？",
    "reference_list": "考点1：“算力帝国”可译为“computing power empire; compute empire”\n考点2：“ 计提”需译为“write down”\n考点3：“护城河”需译为“moat; competitive moat”\n考点4：“单点竞争”推荐译为“ single-point competition”\n考点5：“ 训推效率”应译为“ training and inference efficiency”\n考点6：“ 核弹级创新”译为“ nuclear-level innovation; game-changing innovation”\n考点7：“昇腾”必须译为“Ascend”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "5"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n既往研究中探索了历史街区元素整合的途径。大多数研究未提出营造混合功能的历史街区维持意象一致性的办法。本研究则针对功能混合式历史街区，探讨如何整合不同类型的功能形成的街区意象。本文采用了蒙太奇理论和西蒙的环境经验三分体，选择北京国子监街历史街区为研究对象，分四个步骤分析外来者对该街区的感悟过程，找出那些可以将不同功能的意象整合为完整的历史街区意象的途径。本文得出以下结论：第一, 国子监历史街区内部是文物建筑群、居住区和商业区混合的街区。三类不同的功能区之间有“切断”，不利于该历史街区形成统一的意象. 第二，被试发现四种要素有助于将切断缝合在一起。它们分别是街道两端的大门、商业店铺的招牌、居民区的标语和道路两侧种植的国槐树。基于这两个结论，本文建议对于功能混合的历史街区，可以增加一些具有弥合镜头之间切断作用的要素。 从而让历史街区的意象具有整体性。\n历史街区风貌保护是历史街区保护的重要内容。1933年，《雅典宪章》中首次提出保护“历史街区”：“对有历史价值的建筑和街区，均应妥为保存，不可加以破坏”。中国保护历史街区工作开始较晚。1986年中国国务院在公布第二批国家级历史文化名城时，正式提出了保护“历史地段”的概念，古迹比较集中或能较完整地体现出某一历史时期传统风貌和民族地方特色的街区正式列入保护范围。历史性建筑的内外面貌在1987年由国际古迹遗址理事会在华盛顿通过的《保护历史城镇与城区宪章》中被列为历史街区中应该保护的内容中，具体包括体量、形式、建筑风格、材料、建筑装饰等与地段、周围环境的关系，包括与自然和人工环境的关系。注重完整性和和谐性是国外历史街区风貌保护的要点之一，具体方法包括文脉统合 、文脉并置和文脉延续 。\n在当下语境中对历史文化街区整体形象的重新构建，能够为保护街区风貌的典型性和完整性找到更有效的手段。林奇提出了可以定义意象的五个元素，分别是：节点、路径、区域、边缘和地标。在历史文化街区中，发展历史“意象”需要更多地关注历史街区的整体形象，历史建筑应与形象背景融合。因而历史街区形象可以被视为由街区风貌的各个维度构成的整体意义或意象。\n对于混合功能的历史街区，目前还没有成熟的风格控制方法。既往的研究中探索了历史街区元素整合的途径，大多数研究都强调街区功能和物理要素的一致性。但是遗产需要在主要的社会和文化背景下不断地被重新定义。在现代化与城市化背景下，很多历史文化街区不再是单一的文物保护功能或者居住功能，位于中心城区的历史街区中普遍加入了现代商业、休闲业。之前的方法在混合功能的历史街区中并不适用。人们对功能混杂的历史文化街区的感知具有多种类型，类型之间可能是相互违和的，这造成了街区形象的分裂。关于混合功能的历史街区的形象整合，有学者已经意识到需要将商业服务设施和核心区域的空间配置一起规划，同时适度地控制与分散人流，最大程度保护核心区域。但是尚未有研究提出如何进行统一规划来控制街区风格与形象的整体性。\n分析历史街区中外来者整体场所感的形成特征，有助于找到形象整合的途径。 Fakeye和Croupton认为，形象是游客根据自己的印象形成的心理结构。如果想要生成完整立体的街区形象，同时找到破坏形象和利于形象整合的景观要素，需要调查人们流动的地方感。景观意义是由流动性构成的，街道空间也具有明显的流动性和方向性，人们在历史街区中的游览在移动中进行的，相应生成了动态变化的地方感。遗憾的是，之前的研究大多忽视了地方感的动态生成过程，仅调查最后的生成结果。因而，很难准确找到破坏和有利于街区形象整合的景观要素，进行下一步的管控。\n因此，本文运用蒙太奇理论，分析外来者能否将被调查街区中不同土地利用的每一个“镜头”整合成一个整体的影像，以及整合的方法是什么，从而为历史街区风貌的保护提出新的建议。\n我们使用西蒙的三分体和蒙太奇方法分析了北京文化街区的街区形象。具体分为四个步骤：首先，拍摄国子监街区中每隔约20米的照片，将街区分解成一系列的镜头，根据物理蒙太奇和意义蒙太奇两种蒙太奇逻辑，将镜头拼合成意象，发现其中的切断；然后，在悬隔中找到国子监街的关键主题；接着寻找能够缝合切断的元素；最后，根据这些分析提出一些改善街区形象的建议。\n本研究有两个主要结论。第一，国子监历史街区内部是文物建筑群、居住区和商业区混合的街区，建筑形制及听觉嗅觉也不同。不同功能区、不同的建筑形制以及不同的感受之间有“切断”，不利于该历史街区形成统一的意象。第二，我们发现了有助于将切断缝合在一起的要素。它们分别是能够缝合功能区之间切断的商业店铺的招牌和居民区的标语；能够缝合不同建筑形制之间切断街道两段的大门；以及能够消弭噪音带来的切断的国槐。这些要素分别是通过引发外来者的注意或加强外来者与街区之间的强联系来达到消弭切断的效果的。基于这两个结论，本文建议对于功能混合的历史街区，可以增加一些具有弥合镜头之间切断的元素，从而让历史街区的意象具有整体性。而要找到这些具有弥合作用的元素，就需要不断反复与历史街区相遇、悬隔并感悟，在一次次的反思中找到更优路径。",
    "ori_text": "\n\n既往研究中探索了历史街区元素整合的途径。大多数研究未提出营造混合功能的历史街区维持意象一致性的办法。本研究则针对功能混合式历史街区，探讨如何整合不同类型的功能形成的街区意象。本文采用了蒙太奇理论和西蒙的环境经验三分体，选择北京国子监街历史街区为研究对象，分四个步骤分析外来者对该街区的感悟过程，找出那些可以将不同功能的意象整合为完整的历史街区意象的途径。本文得出以下结论：第一, 国子监历史街区内部是文物建筑群、居住区和商业区混合的街区。三类不同的功能区之间有“切断”，不利于该历史街区形成统一的意象. 第二，被试发现四种要素有助于将切断缝合在一起。它们分别是街道两端的大门、商业店铺的招牌、居民区的标语和道路两侧种植的国槐树。基于这两个结论，本文建议对于功能混合的历史街区，可以增加一些具有弥合镜头之间切断作用的要素。 从而让历史街区的意象具有整体性。\n历史街区风貌保护是历史街区保护的重要内容。1933年，《雅典宪章》中首次提出保护“历史街区”：“对有历史价值的建筑和街区，均应妥为保存，不可加以破坏”。中国保护历史街区工作开始较晚。1986年中国国务院在公布第二批国家级历史文化名城时，正式提出了保护“历史地段”的概念，古迹比较集中或能较完整地体现出某一历史时期传统风貌和民族地方特色的街区正式列入保护范围。历史性建筑的内外面貌在1987年由国际古迹遗址理事会在华盛顿通过的《保护历史城镇与城区宪章》中被列为历史街区中应该保护的内容中，具体包括体量、形式、建筑风格、材料、建筑装饰等与地段、周围环境的关系，包括与自然和人工环境的关系。注重完整性和和谐性是国外历史街区风貌保护的要点之一，具体方法包括文脉统合 、文脉并置和文脉延续 。\n在当下语境中对历史文化街区整体形象的重新构建，能够为保护街区风貌的典型性和完整性找到更有效的手段。林奇提出了可以定义意象的五个元素，分别是：节点、路径、区域、边缘和地标。在历史文化街区中，发展历史“意象”需要更多地关注历史街区的整体形象，历史建筑应与形象背景融合。因而历史街区形象可以被视为由街区风貌的各个维度构成的整体意义或意象。\n对于混合功能的历史街区，目前还没有成熟的风格控制方法。既往的研究中探索了历史街区元素整合的途径，大多数研究都强调街区功能和物理要素的一致性。但是遗产需要在主要的社会和文化背景下不断地被重新定义。在现代化与城市化背景下，很多历史文化街区不再是单一的文物保护功能或者居住功能，位于中心城区的历史街区中普遍加入了现代商业、休闲业。之前的方法在混合功能的历史街区中并不适用。人们对功能混杂的历史文化街区的感知具有多种类型，类型之间可能是相互违和的，这造成了街区形象的分裂。关于混合功能的历史街区的形象整合，有学者已经意识到需要将商业服务设施和核心区域的空间配置一起规划，同时适度地控制与分散人流，最大程度保护核心区域。但是尚未有研究提出如何进行统一规划来控制街区风格与形象的整体性。\n分析历史街区中外来者整体场所感的形成特征，有助于找到形象整合的途径。 Fakeye和Croupton认为，形象是游客根据自己的印象形成的心理结构。如果想要生成完整立体的街区形象，同时找到破坏形象和利于形象整合的景观要素，需要调查人们流动的地方感。景观意义是由流动性构成的，街道空间也具有明显的流动性和方向性，人们在历史街区中的游览在移动中进行的，相应生成了动态变化的地方感。遗憾的是，之前的研究大多忽视了地方感的动态生成过程，仅调查最后的生成结果。因而，很难准确找到破坏和有利于街区形象整合的景观要素，进行下一步的管控。\n因此，本文运用蒙太奇理论，分析外来者能否将被调查街区中不同土地利用的每一个“镜头”整合成一个整体的影像，以及整合的方法是什么，从而为历史街区风貌的保护提出新的建议。\n我们使用西蒙的三分体和蒙太奇方法分析了北京文化街区的街区形象。具体分为四个步骤：首先，拍摄国子监街区中每隔约20米的照片，将街区分解成一系列的镜头，根据物理蒙太奇和意义蒙太奇两种蒙太奇逻辑，将镜头拼合成意象，发现其中的切断；然后，在悬隔中找到国子监街的关键主题；接着寻找能够缝合切断的元素；最后，根据这些分析提出一些改善街区形象的建议。\n本研究有两个主要结论。第一，国子监历史街区内部是文物建筑群、居住区和商业区混合的街区，建筑形制及听觉嗅觉也不同。不同功能区、不同的建筑形制以及不同的感受之间有“切断”，不利于该历史街区形成统一的意象。第二，我们发现了有助于将切断缝合在一起的要素。它们分别是能够缝合功能区之间切断的商业店铺的招牌和居民区的标语；能够缝合不同建筑形制之间切断街道两段的大门；以及能够消弭噪音带来的切断的国槐。这些要素分别是通过引发外来者的注意或加强外来者与街区之间的强联系来达到消弭切断的效果的。基于这两个结论，本文建议对于功能混合的历史街区，可以增加一些具有弥合镜头之间切断的元素，从而让历史街区的意象具有整体性。而要找到这些具有弥合作用的元素，就需要不断反复与历史街区相遇、悬隔并感悟，在一次次的反思中找到更优路径。",
    "reference_list": "考点1：“元素” 推荐翻译为 “element”\n考点2：“历史街区” 推荐翻译为 “historic district”\n考点3：“文脉并置” 推荐翻译为 “contextual juxtaposition”\n考点4：“历史地段” 推荐翻译为 “historic areas”，不可译为“historic sites”\n考点5：“悬隔” 必须翻译为 “epoche”，术语译法固定，不可译为其他\n考点6：“感悟” 推荐翻译为 “aware”\n考点7：“物理蒙太奇和意义蒙太奇”必须译为“physical logic and meaning logic”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "180"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 2.1 LAG-3功能的早期研究  \n早期使用LAG-3单克隆抗体的研究表明，在体外阻断LAG-3时，人CD4⁺T细胞克隆的增殖更持久。这种增殖伴随着混合模式的细胞因子产生增强。这些促炎效应仅限于抗原依赖性刺激，在CD8⁺T细胞中未观察到。  \n这些数据首次提示LAG-3对T细胞功能具有负调控作用，后续使用人细胞的研究证实了这一作用。然而，LAG-3基因敲除动物的构建为探究LAG-3在小鼠模型中T细胞上的作用提供了更精确的手段。这些实验表明，LAG-3在调控CD4⁺和CD8⁺T细胞的体外及体内扩增中发挥作用，从而证实了其负调控因子的身份。  \n对缺失KIEELE结构域的LAG-3分子的进一步研究显示，该基序在LAG-3的负调控功能中起关键作用，即缺失该结构域的LAG-3分子无法在体外或体内对T细胞功能产生负调控作用。  \n然而，LAG-3与Ⅱ类MHC分子相互作用的负调控角色存在争议。通过一系列混合淋巴细胞反应，一组研究显示可溶性LAG-3在体外可显著下调人CD4⁺T细胞功能，提示在这些培养条件下，LAG-3与Ⅱ类MHC分子的相互作用具有刺激性。  \n有趣的是，在人CD8⁺T细胞中未观察到这种对MLR反应的下调，表明CD8⁺T细胞上Ⅱ类分子与LAG-3的相互作用可能在功能上有别于CD4⁺T细胞。这些结果与后续一系列实验存在明显矛盾，在后续实验中，可溶性LAG-3-Ig在体外和体内均被证明可激活树突状细胞。  \n 2.2 LAG-3在调节性T细胞中的作用  \n通过微阵列分析，我们团队发现，在体内接触自身抗原并呈现调节表型的CD4⁺T细胞上，LAG-3的表达相对上调。在这种自身耐受模型中，我们发现LAG-3阻断抗体可在体内减弱调节性T细胞（Treg）的功能，且用全长而非截短的LAG-3转染抗原特异性CD4⁺T细胞可赋予其体外调节特性。  \n霍奇金淋巴瘤患者的研究支持这一发现，即患者病情活动时Treg水平升高。体外研究显示，清除LAG-3⁺CD4⁺T细胞可增强肿瘤特异性CD8⁺T细胞的反应性，这与LAG-3在抑制抗肿瘤免疫中的作用一致。  \n近期研究进一步支持该发现，即来自癌症患者肿瘤部位的LAG-3⁺CD4⁺CD25⁺细胞比LAG-3⁻细胞具有更强的抑制能力。另有研究报道，LAG-3在具有调节功能的FoxP3⁺CD8⁺T细胞亚群中发挥作用，这一新颖发现尤为引人关注，因为调节性CD8⁺T细胞正重新受到重视。  \n 2.3 LAG-3在CD8⁺T细胞中的作用  \n尽管早期研究对LAG-3在CD8⁺T细胞中的作用提出质疑，但鉴于活化的CD8⁺T细胞中LAG-3的表达量是CD4⁺T细胞的5-8倍，且LAG-3与CD8在活化T细胞中存在相对共定位，这些发现显得颇为奇怪。  \n利用LAG-3基因敲除动物的研究证实，LAG-3在调控CD8⁺T细胞的稳态增殖以及对超抗原的体内反应中发挥作用。我们通过将抗原特异性CD8⁺T细胞过继转移到携带自身抗原或肿瘤抗原的小鼠体内，进一步证实了这一作用。  \n在此模型中，LAG-3基因敲除的CD8⁺T细胞显示出增强的增殖和细胞因子产生能力。有趣的是，在过继性T细胞转移前后施用LAG-3阻断抗体也能产生类似的免疫功能增强效果，提示该阻断抗体可能直接作用于CD8⁺T细胞。通过对接受LAG-3基因敲除T细胞过继转移的小鼠施用阻断抗体，这一点得到验证，尽管在该情况下未观察到额外效应。  \n近期使用CTLA-4阻断抗体的研究发现，其对效应T细胞也存在类似的直接作用，证实免疫检查点阻断在某些情况下可能通过细胞内在机制发挥作用。  \n关于LAG-3与其他免疫检查点的交叉作用，值得关注的是一项针对慢性病毒感染模型中耗竭CD8⁺T细胞的开创性研究。该研究发现，无功能的CD8⁺T细胞可表达多种检查点分子，部分细胞共表达LAG-3和已知的免疫检查点分子PD-1。在该模型中，同时阻断PD-1和LAG-3比单独阻断任一分子能更有效地改善抗病毒免疫应答。  \n我们在自身抗原耐受模型中观察到类似表型，即存在一群共表达LAG-3和PD-1的无功能CD8⁺T细胞。这些研究近期已扩展到人类卵巢癌样本，发现在肿瘤抗原特异性CD8⁺T细胞中，有相当比例的细胞共表达LAG-3和PD-1。综上，这些重要研究提示，慢性感染和癌症的免疫治疗可能需要阻断多个免疫检查点。  \n 2.4 LAG-3的作用机制  \nLAG-3负调控T细胞功能的确切机制尚未完全阐明。如前所述，独特的胞内KIELLE结构域是介导这些效应所必需的。然而，早期对LAG-3的研究发现，在某些患者的血清中存在该分子的可溶性形式，提示LAG-3的 cleavage可能具有一定生理作用。  \nVignali团队通过一系列严谨的研究扩展了这些发现，证实LAG-3在细胞表面附近被肿瘤坏死因子α转换酶家族的两个金属蛋白酶（ADAM10和ADAM17）切割。表达不可切割形式的LAG-3会导致T细胞功能出现不可逆缺陷，表明LAG-3的切割是其负调控功能被减弱的主要机制。有趣的是，这些研究未发现切割后的LAG-3片段具有任何作用，这与下文涉及LAG-3-Ig融合蛋白的研究形成鲜明对比。  \n 3 LAG-3在癌症免疫治疗中的应用  \n 3.1 临床前研究  \n在制备用于生化和功能研究的LAG-3-Ig融合蛋白后不久，研究人员即在小鼠肿瘤模型中对该试剂进行了体内研究。与人类混合淋巴细胞反应的结果以及涉及切割片段的研究不同，可溶性LAG-3-Ig在携带RENCA（肾癌）、MCA205（肉瘤）或TS/A（乳腺癌）肿瘤的小鼠中可介导肿瘤控制和消退。  \n通过LAG-3转导肿瘤细胞可重复上述发现，提示LAG-3可能通过结合抗原呈递细胞上的Ⅱ类MHC分子并潜在介导其成熟或功能，从而发挥抗肿瘤作用。事实上，利用人单核细胞来源的树突状细胞进行的体外研究证实了这一假设，即LAG-3-Ig可上调共刺激分子的表达并增加树突状细胞中IL-12的产生。  \n这些表型变化使经LAG-3-Ig成熟的树突状细胞更易介导Th1型应答，表现为应答性T细胞产生的IFN-γ增加。这些结果还提示，LAG-3-Ig可能作为佐剂增强疫苗应答。  \n事实的确如此，研究显示LAG-3-Ig可显著增强小鼠对可溶性抗原疫苗的CD8⁺T细胞应答以及对颗粒性抗原的体液应答。这种佐剂效应已扩展到癌症疫苗领域，在HER-2/neu转基因小鼠中，LAG-3-Ig与弱DNA疫苗联合施用可预防乳腺癌变。  \n需要注意的是，这些结果虽令人振奋，但与LAG-3在T细胞增殖和功能中已被充分证实的负调控作用存在一定矛盾。实际上，LAG-3与Ⅱ类分子的相互作用一方面可下调T细胞功能，另一方面却能向表达Ⅱ类分子的树突状细胞传递促炎成熟信号，这一看似矛盾的现象仍有待解释。在此背景下，近期一项研究对LAG-3与Ⅱ类分子结合的促免疫效应提出质疑，认为调节性CD4⁺T细胞上的LAG-3实际上可抑制树突状细胞功能。  \n 3.2 临床研究  \nLAG-3发现后不久，研究人员注意到部分肾细胞癌（RCC）患者的LAG-3⁺CD4⁺肿瘤浸润淋巴细胞显著扩增。后续研究发现，RCC肿瘤浸润淋巴细胞中LAG-3的表达率为11%-48%，而未检测到明显水平的CTLA-4或检查点分子4-1BB。然而，在这些研究中，LAG-3阻断并未增强CD8⁺T细胞的裂解活性，这提示LAG-3阻断可能在T细胞活化的早期（即起始阶段）更为重要，或反映了使用扩增的人肿瘤浸润淋巴细胞作为试剂存在的技术局限性。  \n基于LAG-3-Ig在小鼠中的有趣研究结果，该试剂已进入商业化开发并在多项临床试验中接受测试（IMP321，Immutep公司，巴黎）。在首个Ⅰ期试验中，IMP321与标准流感疫苗联合使用，剂量递增。研究未观察到剂量限制性毒性，不良反应轻微。虽未发现体液疫苗应答增强，但在部分受试者中检测到Th1型CD4⁺T细胞应答。  \n第二项类似试验将IMP321与商用乙肝疫苗联合使用。有趣的是，在较高剂量水平下，单次IMP321处理后即可检测到CD4⁺和CD8⁺T细胞应答。这些结果随后在一项针对肾细胞癌患者的单药剂量递增试验中得到扩展。该药物再次显示出良好的耐受性，且治疗似乎与外周血中CD8⁺（而非CD4⁺）T细胞效应表型的形成相关。  \n与癌症免疫治疗领域的Ⅰ期试验通常情况一致，本研究未观察到客观应答，但部分患者出现疾病稳定。一项更具创新性的试验将IMP321与紫杉烷类化疗联合用于乳腺癌女性患者。这项单臂试验显示客观缓解率为50%，而历史缓解率约为25%。尽管癌症免疫治疗中的单臂研究需谨慎解读，但多项Ⅱ期试验已在进行中或处于规划阶段。\n",
    "ori_text": "\n\n 2.1 LAG-3功能的早期研究  \n早期使用LAG-3单克隆抗体的研究表明，在体外阻断LAG-3时，人CD4⁺T细胞克隆的增殖更持久。这种增殖伴随着混合模式的细胞因子产生增强。这些促炎效应仅限于抗原依赖性刺激，在CD8⁺T细胞中未观察到。  \n这些数据首次提示LAG-3对T细胞功能具有负调控作用，后续使用人细胞的研究证实了这一作用。然而，LAG-3基因敲除动物的构建为探究LAG-3在小鼠模型中T细胞上的作用提供了更精确的手段。这些实验表明，LAG-3在调控CD4⁺和CD8⁺T细胞的体外及体内扩增中发挥作用，从而证实了其负调控因子的身份。  \n对缺失KIEELE结构域的LAG-3分子的进一步研究显示，该基序在LAG-3的负调控功能中起关键作用，即缺失该结构域的LAG-3分子无法在体外或体内对T细胞功能产生负调控作用。  \n然而，LAG-3与Ⅱ类MHC分子相互作用的负调控角色存在争议。通过一系列混合淋巴细胞反应，一组研究显示可溶性LAG-3在体外可显著下调人CD4⁺T细胞功能，提示在这些培养条件下，LAG-3与Ⅱ类MHC分子的相互作用具有刺激性。  \n有趣的是，在人CD8⁺T细胞中未观察到这种对MLR反应的下调，表明CD8⁺T细胞上Ⅱ类分子与LAG-3的相互作用可能在功能上有别于CD4⁺T细胞。这些结果与后续一系列实验存在明显矛盾，在后续实验中，可溶性LAG-3-Ig在体外和体内均被证明可激活树突状细胞。  \n 2.2 LAG-3在调节性T细胞中的作用  \n通过微阵列分析，我们团队发现，在体内接触自身抗原并呈现调节表型的CD4⁺T细胞上，LAG-3的表达相对上调。在这种自身耐受模型中，我们发现LAG-3阻断抗体可在体内减弱调节性T细胞（Treg）的功能，且用全长而非截短的LAG-3转染抗原特异性CD4⁺T细胞可赋予其体外调节特性。  \n霍奇金淋巴瘤患者的研究支持这一发现，即患者病情活动时Treg水平升高。体外研究显示，清除LAG-3⁺CD4⁺T细胞可增强肿瘤特异性CD8⁺T细胞的反应性，这与LAG-3在抑制抗肿瘤免疫中的作用一致。  \n近期研究进一步支持该发现，即来自癌症患者肿瘤部位的LAG-3⁺CD4⁺CD25⁺细胞比LAG-3⁻细胞具有更强的抑制能力。另有研究报道，LAG-3在具有调节功能的FoxP3⁺CD8⁺T细胞亚群中发挥作用，这一新颖发现尤为引人关注，因为调节性CD8⁺T细胞正重新受到重视。  \n 2.3 LAG-3在CD8⁺T细胞中的作用  \n尽管早期研究对LAG-3在CD8⁺T细胞中的作用提出质疑，但鉴于活化的CD8⁺T细胞中LAG-3的表达量是CD4⁺T细胞的5-8倍，且LAG-3与CD8在活化T细胞中存在相对共定位，这些发现显得颇为奇怪。  \n利用LAG-3基因敲除动物的研究证实，LAG-3在调控CD8⁺T细胞的稳态增殖以及对超抗原的体内反应中发挥作用。我们通过将抗原特异性CD8⁺T细胞过继转移到携带自身抗原或肿瘤抗原的小鼠体内，进一步证实了这一作用。  \n在此模型中，LAG-3基因敲除的CD8⁺T细胞显示出增强的增殖和细胞因子产生能力。有趣的是，在过继性T细胞转移前后施用LAG-3阻断抗体也能产生类似的免疫功能增强效果，提示该阻断抗体可能直接作用于CD8⁺T细胞。通过对接受LAG-3基因敲除T细胞过继转移的小鼠施用阻断抗体，这一点得到验证，尽管在该情况下未观察到额外效应。  \n近期使用CTLA-4阻断抗体的研究发现，其对效应T细胞也存在类似的直接作用，证实免疫检查点阻断在某些情况下可能通过细胞内在机制发挥作用。  \n关于LAG-3与其他免疫检查点的交叉作用，值得关注的是一项针对慢性病毒感染模型中耗竭CD8⁺T细胞的开创性研究。该研究发现，无功能的CD8⁺T细胞可表达多种检查点分子，部分细胞共表达LAG-3和已知的免疫检查点分子PD-1。在该模型中，同时阻断PD-1和LAG-3比单独阻断任一分子能更有效地改善抗病毒免疫应答。  \n我们在自身抗原耐受模型中观察到类似表型，即存在一群共表达LAG-3和PD-1的无功能CD8⁺T细胞。这些研究近期已扩展到人类卵巢癌样本，发现在肿瘤抗原特异性CD8⁺T细胞中，有相当比例的细胞共表达LAG-3和PD-1。综上，这些重要研究提示，慢性感染和癌症的免疫治疗可能需要阻断多个免疫检查点。  \n 2.4 LAG-3的作用机制  \nLAG-3负调控T细胞功能的确切机制尚未完全阐明。如前所述，独特的胞内KIELLE结构域是介导这些效应所必需的。然而，早期对LAG-3的研究发现，在某些患者的血清中存在该分子的可溶性形式，提示LAG-3的 cleavage可能具有一定生理作用。  \nVignali团队通过一系列严谨的研究扩展了这些发现，证实LAG-3在细胞表面附近被肿瘤坏死因子α转换酶家族的两个金属蛋白酶（ADAM10和ADAM17）切割。表达不可切割形式的LAG-3会导致T细胞功能出现不可逆缺陷，表明LAG-3的切割是其负调控功能被减弱的主要机制。有趣的是，这些研究未发现切割后的LAG-3片段具有任何作用，这与下文涉及LAG-3-Ig融合蛋白的研究形成鲜明对比。  \n 3 LAG-3在癌症免疫治疗中的应用  \n 3.1 临床前研究  \n在制备用于生化和功能研究的LAG-3-Ig融合蛋白后不久，研究人员即在小鼠肿瘤模型中对该试剂进行了体内研究。与人类混合淋巴细胞反应的结果以及涉及切割片段的研究不同，可溶性LAG-3-Ig在携带RENCA（肾癌）、MCA205（肉瘤）或TS/A（乳腺癌）肿瘤的小鼠中可介导肿瘤控制和消退。  \n通过LAG-3转导肿瘤细胞可重复上述发现，提示LAG-3可能通过结合抗原呈递细胞上的Ⅱ类MHC分子并潜在介导其成熟或功能，从而发挥抗肿瘤作用。事实上，利用人单核细胞来源的树突状细胞进行的体外研究证实了这一假设，即LAG-3-Ig可上调共刺激分子的表达并增加树突状细胞中IL-12的产生。  \n这些表型变化使经LAG-3-Ig成熟的树突状细胞更易介导Th1型应答，表现为应答性T细胞产生的IFN-γ增加。这些结果还提示，LAG-3-Ig可能作为佐剂增强疫苗应答。  \n事实的确如此，研究显示LAG-3-Ig可显著增强小鼠对可溶性抗原疫苗的CD8⁺T细胞应答以及对颗粒性抗原的体液应答。这种佐剂效应已扩展到癌症疫苗领域，在HER-2/neu转基因小鼠中，LAG-3-Ig与弱DNA疫苗联合施用可预防乳腺癌变。  \n需要注意的是，这些结果虽令人振奋，但与LAG-3在T细胞增殖和功能中已被充分证实的负调控作用存在一定矛盾。实际上，LAG-3与Ⅱ类分子的相互作用一方面可下调T细胞功能，另一方面却能向表达Ⅱ类分子的树突状细胞传递促炎成熟信号，这一看似矛盾的现象仍有待解释。在此背景下，近期一项研究对LAG-3与Ⅱ类分子结合的促免疫效应提出质疑，认为调节性CD4⁺T细胞上的LAG-3实际上可抑制树突状细胞功能。  \n 3.2 临床研究  \nLAG-3发现后不久，研究人员注意到部分肾细胞癌（RCC）患者的LAG-3⁺CD4⁺肿瘤浸润淋巴细胞显著扩增。后续研究发现，RCC肿瘤浸润淋巴细胞中LAG-3的表达率为11%-48%，而未检测到明显水平的CTLA-4或检查点分子4-1BB。然而，在这些研究中，LAG-3阻断并未增强CD8⁺T细胞的裂解活性，这提示LAG-3阻断可能在T细胞活化的早期（即起始阶段）更为重要，或反映了使用扩增的人肿瘤浸润淋巴细胞作为试剂存在的技术局限性。  \n基于LAG-3-Ig在小鼠中的有趣研究结果，该试剂已进入商业化开发并在多项临床试验中接受测试（IMP321，Immutep公司，巴黎）。在首个Ⅰ期试验中，IMP321与标准流感疫苗联合使用，剂量递增。研究未观察到剂量限制性毒性，不良反应轻微。虽未发现体液疫苗应答增强，但在部分受试者中检测到Th1型CD4⁺T细胞应答。  \n第二项类似试验将IMP321与商用乙肝疫苗联合使用。有趣的是，在较高剂量水平下，单次IMP321处理后即可检测到CD4⁺和CD8⁺T细胞应答。这些结果随后在一项针对肾细胞癌患者的单药剂量递增试验中得到扩展。该药物再次显示出良好的耐受性，且治疗似乎与外周血中CD8⁺（而非CD4⁺）T细胞效应表型的形成相关。  \n与癌症免疫治疗领域的Ⅰ期试验通常情况一致，本研究未观察到客观应答，但部分患者出现疾病稳定。一项更具创新性的试验将IMP321与紫杉烷类化疗联合用于乳腺癌女性患者。这项单臂试验显示客观缓解率为50%，而历史缓解率约为25%。尽管癌症免疫治疗中的单臂研究需谨慎解读，但多项Ⅱ期试验已在进行中或处于规划阶段。\n",
    "reference_list": "考点1：“无功能的 CD8⁺T 细胞” 中的 “无功能”，不可以翻译为“non-functional”，必须译为“dysfunctional”或“exhausted”\n考点2：“裂解活性” 必须译为“lytic activity (against target cells)”或“cytolytic activity”。\n考点3：文中的“不良反应轻微” 描述的是临床试验中的不良事件，不可以翻译为“adverse reactions” 。\n考点4：“紫杉烷类化疗” 不能直接翻译为“taxane chemotherapy” ，必须译为“taxane-based chemotherapy”\n考点5：“调节性 T 细胞（Treg）” 推荐译为 “regulatory T cell (Treg)”\n考点6：“Ⅱ 类 MHC 分子” 推荐译为 “Class II MHC molecule”\n考点7：“混合淋巴细胞反应（MLR）” 必须译为 “mixed lymphocyte reaction (MLR)”\n考点8：“KIEELE 结构域” 必须译为 “KIEELE domain”不可误译为 “KIEELE motif”，以免引起生物学概念错误。\n考点9：“树突状细胞” 推荐译为 “dendritic cell”\n考点10：“肿瘤浸润淋巴细胞（TILs）” 推荐译为 “tumor-infiltrating lymphocytes (TILs)”\n考点11：“过继转移” 推荐译为 “adoptive transfer”\n考点12：“Th1 型应答” 推荐译为 “Th1 response”\n考点13：“负调控” 不可翻译为 “negative regulatory effect”。\n考点14：混合淋巴细胞反应的缩写是 “MLR”，在专有名词第一次出现之后，后续如果用缩略词，需要在第一次出现该专有名词之后，使用缩写表述。\n考点15：“单核细胞来源的树突状细胞”推荐译为“monocyte-derived dendritic cells”\n考点16：“转基因小鼠”推荐译为“transgenic mice”\n考点17：“免疫检查点阻断”推荐译为“immune checkpoint blockade”\n考点18：“促炎成熟信号”推荐译为“pro-inflammatory maturation signal”\n考点19：“单臂试验”推荐译为“single-arm trial”\n考点20：“促炎效应”强调“促进炎症的生物学效应”，在免疫学中有固定搭配：“pro-inflammatory”\n考点21：“调节表型”中，“表型”在生物学中对应“phenotype”。不可翻译为 “type”。\n考点22：“抗肿瘤免疫”可译为“antitumor immunity”\n考点23：“剂量递增”固定译法为“dose-escalation”。不可翻译为 “increasing dose”。\n考点24：“细胞因子产生能力”在免疫学文献中常直接表达为 “cytokine production”，不推荐译为 “cytokine production capacity”，以保持简洁和学术规范。\n考点25：“反映出使用……的技术限制” 推荐译为 “reflecting the technical limitations associated with using...” 或 “reflecting technical limitations inherent in the use of...”，不推荐直译为 “reflecting technical limitations of using...”。\n考点26：表达“显得奇怪”时，学术写作中应译为 “unexpected” 或 “surprising”，避免使用过于口语化的 “strange” 或 “quite strange”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "115"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n近年来，自动驾驶领域革新迭起，世界模型研究在决策推理与安全保障中愈发彰显关键价值，其核心要义在于通过对环境动态结构及隐含规律进行层级化解构与重构，构建多层次深度表征体系，从而赋予系统跨场景环境预测推理能力，为高维动作空间中的可解释规划控制提供核心支撑。传统依托几何约束与物理规则的导航算法，高度依赖高精地图与经典图搜索技术生成全局最优路径，此类方法虽能在受控道路网络中完成路径可行性验证，却因缺乏对环境时变要素的高效自适应机制，难以应对多交通参与主体行为的非线性耦合及突发临界事件。\n随着深度学习理论与算力资源的突破性发展，学术界率先探索神经网络与逆向强化学习范式的融合路径，实现决策与世界模型结构的同步训练。此类框架通过采集海量仿真或实车轨迹数据反演潜在奖励函数，并借助时序隐变量生成模型学习状态转移概率密度函数。其中最具代表性的研究方案，采用条件变分自编码器对观测序列进行端到端重建，同时融合对抗生成模型提升样本空间覆盖度，结合信息瓶颈约束强化模型抽象表征的效率与鲁棒性。与此同时，多模态感知融合技术步入成熟阶段，其演进路径从单一摄像头与激光雷达的信号级拼接，逐步拓展至整合毫米波雷达、超声波传感器及高精度实时定位信息，并通过自注意力机制在各传感通道间实现动态加权，进而在极端光照、复杂气象及高密度交通场景下保持鲁棒感知与低时延响应性能。\n在此基础上，研究社区进一步推动世界模型与可微分规划控制算法的深度耦合，创新性提出端到端微分物理仿真管道。该架构通过集成微分动力学求解器，在前向推断过程中融合运动学约束与碰撞检测模块，并以内嵌梯度下降算法优化感知、预测、控制子模块的联合更新机制，实现对不确定性场景的可解释联合优化。这一创新思路打破传统黑箱策略网络的局限，将决策过程映射为显式优化问题，赋予系统高度可验证性与多场景泛化能力。\n伴随工业界对安全测试与场景覆盖率需求的激增，CARLA、LGSVL 等大规模联合仿真平台及自研数字孪生环境应运而生。这些平台支持多源高精地图全局叠加、物理光照光谱模型与仿真行为体部署，并可加载交通流热力学平衡模型，实现对城市级道路网络多时空维度的全景式仿真推演。部分顶尖研究团队更将自监督预训练与对比学习范式引入世界模型训练流程，利用动态伪标签生成与编码器蒸馏技术，在低标注成本下实现高精度特征提取，并通过少样本自适应算法加速新场景迁移适配。\n在架构设计层面，当前学术与产业界的主流技术路线可划分为三大阵营：纯强化学习世界模型、混合结构化神经符号模型及纯端到端深度网络。其中，纯强化学习范式依托隐状态嵌入与价值迭代算法，实现对高维连续动作空间的无模型控制，但其在样本效率与收敛速度方面存在固有瓶颈；混合结构化模型通过物理知识图神经网络与符号推理模块的协同，实现先验知识与数据驱动的有机融合，可解释性表现优异，却需设计者投入大量领域专业知识进行模型构建；纯端到端深度网络阵营聚焦大规模 Transformer 架构与序列决策流程的结合，虽具备空前的表达能力，却需承担海量标注数据与算力成本，且在安全性验证与实时性控制方面面临严峻挑战。\n当前研究焦点集中于如何在保障微秒级决策时延与动态场景实时响应的前提下，提升对罕见关键场景的前瞻性风险评估能力。学者们通过引入风险敏感度损失函数与信息熵驱动探索策略，使模型在训练过程中自动聚焦潜在高危状态；多智能体协同共享世界模型成为另一研究热点，相关团队正借助联邦学习与在线知识蒸馏框架，在保障数据隐私的前提下实现跨车队表征共享，并结合分布式边缘计算将联合推理模块部署至车载终端，以降低通信时延并提升系统鲁棒性。\n工业界领军企业已在二级高速及城市复杂路口部署多款世界模型驱动系统，在百万公里实车测试中实现平均决策时延低于 25 毫秒、危急事件预警误报率低于 1%，同时通过事件驱动最优控制策略与多模态对齐算法，在拥堵场景下最大限度降低能耗与碳排放，并支持持续在线升级迭代。\n尽管上述突破为安全驾驶与可解释决策奠定了坚实基础，但世界模型仍面临长时序预测误差累积、形式化验证工具匮乏、法律伦理边界未明及计算资源与标签成本制约等多重挑战。未来，多学科交叉的形式化验证方法、可解释性增强技术及自治伦理评估体系的构建，将是突破当前发展瓶颈的关键方向。",
    "ori_text": "\n\n近年来，自动驾驶领域革新迭起，世界模型研究在决策推理与安全保障中愈发彰显关键价值，其核心要义在于通过对环境动态结构及隐含规律进行层级化解构与重构，构建多层次深度表征体系，从而赋予系统跨场景环境预测推理能力，为高维动作空间中的可解释规划控制提供核心支撑。传统依托几何约束与物理规则的导航算法，高度依赖高精地图与经典图搜索技术生成全局最优路径，此类方法虽能在受控道路网络中完成路径可行性验证，却因缺乏对环境时变要素的高效自适应机制，难以应对多交通参与主体行为的非线性耦合及突发临界事件。\n随着深度学习理论与算力资源的突破性发展，学术界率先探索神经网络与逆向强化学习范式的融合路径，实现决策与世界模型结构的同步训练。此类框架通过采集海量仿真或实车轨迹数据反演潜在奖励函数，并借助时序隐变量生成模型学习状态转移概率密度函数。其中最具代表性的研究方案，采用条件变分自编码器对观测序列进行端到端重建，同时融合对抗生成模型提升样本空间覆盖度，结合信息瓶颈约束强化模型抽象表征的效率与鲁棒性。与此同时，多模态感知融合技术步入成熟阶段，其演进路径从单一摄像头与激光雷达的信号级拼接，逐步拓展至整合毫米波雷达、超声波传感器及高精度实时定位信息，并通过自注意力机制在各传感通道间实现动态加权，进而在极端光照、复杂气象及高密度交通场景下保持鲁棒感知与低时延响应性能。\n在此基础上，研究社区进一步推动世界模型与可微分规划控制算法的深度耦合，创新性提出端到端微分物理仿真管道。该架构通过集成微分动力学求解器，在前向推断过程中融合运动学约束与碰撞检测模块，并以内嵌梯度下降算法优化感知、预测、控制子模块的联合更新机制，实现对不确定性场景的可解释联合优化。这一创新思路打破传统黑箱策略网络的局限，将决策过程映射为显式优化问题，赋予系统高度可验证性与多场景泛化能力。\n伴随工业界对安全测试与场景覆盖率需求的激增，CARLA、LGSVL 等大规模联合仿真平台及自研数字孪生环境应运而生。这些平台支持多源高精地图全局叠加、物理光照光谱模型与仿真行为体部署，并可加载交通流热力学平衡模型，实现对城市级道路网络多时空维度的全景式仿真推演。部分顶尖研究团队更将自监督预训练与对比学习范式引入世界模型训练流程，利用动态伪标签生成与编码器蒸馏技术，在低标注成本下实现高精度特征提取，并通过少样本自适应算法加速新场景迁移适配。\n在架构设计层面，当前学术与产业界的主流技术路线可划分为三大阵营：纯强化学习世界模型、混合结构化神经符号模型及纯端到端深度网络。其中，纯强化学习范式依托隐状态嵌入与价值迭代算法，实现对高维连续动作空间的无模型控制，但其在样本效率与收敛速度方面存在固有瓶颈；混合结构化模型通过物理知识图神经网络与符号推理模块的协同，实现先验知识与数据驱动的有机融合，可解释性表现优异，却需设计者投入大量领域专业知识进行模型构建；纯端到端深度网络阵营聚焦大规模 Transformer 架构与序列决策流程的结合，虽具备空前的表达能力，却需承担海量标注数据与算力成本，且在安全性验证与实时性控制方面面临严峻挑战。\n当前研究焦点集中于如何在保障微秒级决策时延与动态场景实时响应的前提下，提升对罕见关键场景的前瞻性风险评估能力。学者们通过引入风险敏感度损失函数与信息熵驱动探索策略，使模型在训练过程中自动聚焦潜在高危状态；多智能体协同共享世界模型成为另一研究热点，相关团队正借助联邦学习与在线知识蒸馏框架，在保障数据隐私的前提下实现跨车队表征共享，并结合分布式边缘计算将联合推理模块部署至车载终端，以降低通信时延并提升系统鲁棒性。\n工业界领军企业已在二级高速及城市复杂路口部署多款世界模型驱动系统，在百万公里实车测试中实现平均决策时延低于 25 毫秒、危急事件预警误报率低于 1%，同时通过事件驱动最优控制策略与多模态对齐算法，在拥堵场景下最大限度降低能耗与碳排放，并支持持续在线升级迭代。\n尽管上述突破为安全驾驶与可解释决策奠定了坚实基础，但世界模型仍面临长时序预测误差累积、形式化验证工具匮乏、法律伦理边界未明及计算资源与标签成本制约等多重挑战。未来，多学科交叉的形式化验证方法、可解释性增强技术及自治伦理评估体系的构建，将是突破当前发展瓶颈的关键方向。",
    "reference_list": "考点1 ：“环境动态结构及隐含规律” 推荐译为 environmental dynamics structure and implicit laws\n考点2 ：“多层次深度表征体系” 推荐译为 multi‑level deep representation framework\n考点3 ：“多模态感知融合技术” 必须译为 multimodal perception fusion technology\n考点4 :“少样本自适应算法” 必须译为 few‑shot adaptation algorithm",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "149"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nSection One------ How to teach reading\nI. Why teach reading\nThere are many reasons why getting students to read English texts is an important part of the teacher’s job. In the first place, many of them want to be able to read texts in English either for their careers, for study purposes or simply for pleasure. Anything we can do to make reading easier for them must be a good idea.\n  Reading texts provide good models for English writing, provide opportunities to study language vocabulary, grammar, punctuation, and the way to construct sentences, paragraphs and texts. Lastly, good reading texts can introduce interesting topics, stimulate discussion, excite imaginative responses and be the springboard for well-rounded, fascinating lessons.\n  The last but not the least, students must read widely because only a fraction of knowledge about the world can come from other experiences in their short lives.\nII. What kind of reading should students do?\n  When the teachers give reading class to students, they should notice a balance----a balance to be struck between real English on the one hand and the students’ capabilities and interests on the other. There is some authentic written material which beginner students can understand to some degree: menus, timetables, signs and basic instructions, for example, and, where appropriate, teachers can use these. But for longer prose, teachers can offer their students texts, which, while being like English, are nevertheless written or adapted especially for their level. Anyway, the materials to be read should be interesting and meaningful. Teachers should become better acquainted with books written specially for teenagers and dealing with their problems.\nIII. What are the principles behind the teaching of reading?\ni) Permit Students To Read \nNo one has learned to swim by practicing the skills of backstrokes, flutter kicks or treading water while staying on the edge of the swimming pool. Yet, in the teaching of reading teachers often do just that. Rather than let the students into “the water”, teachers keep them in skills books learning rules about letters, syllables or definitions of words rather than letting them into the book itself, permitting them to be   immersed in the language which comes from the authors as the readers try to reconstruct the written message.\nii) Encourage students to respond to the content of a reading text, not just to the language\nOf course, it is important to study reading texts for the way they use language, how many paragraphs they contain and how many times they use relative clauses. But the meaning, the message of the text, is much more important. Teachers should help students understand that the main reason to read is for them. They have to have their own purpose to read and reading must make sense, they have to find ways of doing something about it. They should be encouraged either to reread or to continue reading to gain meaning. But they must realize that the meaning is not in the teacher, but in the interaction between the reader and author. Students should be encouraged to ask themselves repeatedly, “Does this make sense to me?” Students should be encouraged to reject and to be intolerant of reading materials that do not make sense.\n  iii) Encourage students to guess or predict\n  Readers’ guesses or predictions are based on the cumulative information and syntactic structure they have been learning as they have been reading. Therefore, their guesses are more often than not appropriate to the materials. Students have to realize that risk taking in reading is appropriate; that using context to decide what words mean is a proficient reading strategy and that they have the language sense to make appropriate guesses which can fit both the grammatical and semantic sense of what they are reading.\n  iv) Match the task to the topic\n  Once a decision has been taken about what kind of reading text the students are going to read, teachers need to choose good reading tasks—the right kind of questions and useful puzzles, etc. Asking boring and inappropriate questions can undermine the most interesting text; the most commonplace passage can be made really exciting with imaginative and challenging tasks. Working in groups, the English teacher and students take turns asking each other questions following the reading. The teacher may ask, “ What is the significance of the character’s age?” These questions require inferences based on details from the reading text.\nSection Two------How to teach writing (Developing correctness in students’ writing)\n   “Students learn to write by writing, and they learn to write correctly by writing, revising, and proofreading their own work”---with some help or direction from the teacher when it is necessary. They do not learn to write correctly by studying about writing or doing isolated workbook exercises unrelated to their own writing. So, the most important technique a teacher can use to guide students toward grammatically correct writing is to let them write, let them write things related to their own experiences. There is no limit to the kinds of text the teacher can ask students to write. Teachers’ decisions, though, should based on how much language the students know, what their interests are.\n  “Do I read a paper and ignore all punctuation, what good is that for students?\n   We spend hours at night with papers---I’m not sure the students get as much from it as the time I spend on it.”\n   These comments by senior high school English teachers discussing the process of marking student papers reflect the dissatisfaction and frustration of many teachers over the problem of dealing with the errors in student writing-----the obvious mistakes in spelling, punctuation----Traditionally, teachers have worked to correct errors in two ways: by teaching grammatically correctness through exercise in grammar texts; by pointing out all errors when making student papers.\n   Most students find it very dispiriting if they get a piece of written work back and it is covered in red ink, underlings and crossing-out. It is a powerful visual statement of the fact that their written English is terrible. Of course, some pieces of written work are completely full of mistakes, but even in these cases, the teacher has to achieve a balance between being accurate and truthful on the one hand and treating students sensitively and sympathetically on the other.",
    "ori_text": "Section One------ How to teach reading\nI. Why teach reading\nThere are many reasons why getting students to read English texts is an important part of the teacher’s job. In the first place, many of them want to be able to read texts in English either for their careers, for study purposes or simply for pleasure. Anything we can do to make reading easier for them must be a good idea.\n  Reading texts provide good models for English writing, provide opportunities to study language vocabulary, grammar, punctuation, and the way to construct sentences, paragraphs and texts. Lastly, good reading texts can introduce interesting topics, stimulate discussion, excite imaginative responses and be the springboard for well-rounded, fascinating lessons.\n  The last but not the least, students must read widely because only a fraction of knowledge about the world can come from other experiences in their short lives.\nII. What kind of reading should students do?\n  When the teachers give reading class to students, they should notice a balance----a balance to be struck between real English on the one hand and the students’ capabilities and interests on the other. There is some authentic written material which beginner students can understand to some degree: menus, timetables, signs and basic instructions, for example, and, where appropriate, teachers can use these. But for longer prose, teachers can offer their students texts, which, while being like English, are nevertheless written or adapted especially for their level. Anyway, the materials to be read should be interesting and meaningful. Teachers should become better acquainted with books written specially for teenagers and dealing with their problems.\nIII. What are the principles behind the teaching of reading?\ni) Permit Students To Read \nNo one has learned to swim by practicing the skills of backstrokes, flutter kicks or treading water while staying on the edge of the swimming pool. Yet, in the teaching of reading teachers often do just that. Rather than let the students into “the water”, teachers keep them in skills books learning rules about letters, syllables or definitions of words rather than letting them into the book itself, permitting them to be   immersed in the language which comes from the authors as the readers try to reconstruct the written message.\nii) Encourage students to respond to the content of a reading text, not just to the language\nOf course, it is important to study reading texts for the way they use language, how many paragraphs they contain and how many times they use relative clauses. But the meaning, the message of the text, is much more important. Teachers should help students understand that the main reason to read is for them. They have to have their own purpose to read and reading must make sense, they have to find ways of doing something about it. They should be encouraged either to reread or to continue reading to gain meaning. But they must realize that the meaning is not in the teacher, but in the interaction between the reader and author. Students should be encouraged to ask themselves repeatedly, “Does this make sense to me?” Students should be encouraged to reject and to be intolerant of reading materials that do not make sense.\n  iii) Encourage students to guess or predict\n  Readers’ guesses or predictions are based on the cumulative information and syntactic structure they have been learning as they have been reading. Therefore, their guesses are more often than not appropriate to the materials. Students have to realize that risk taking in reading is appropriate; that using context to decide what words mean is a proficient reading strategy and that they have the language sense to make appropriate guesses which can fit both the grammatical and semantic sense of what they are reading.\n  iv) Match the task to the topic\n  Once a decision has been taken about what kind of reading text the students are going to read, teachers need to choose good reading tasks—the right kind of questions and useful puzzles, etc. Asking boring and inappropriate questions can undermine the most interesting text; the most commonplace passage can be made really exciting with imaginative and challenging tasks. Working in groups, the English teacher and students take turns asking each other questions following the reading. The teacher may ask, “ What is the significance of the character’s age?” These questions require inferences based on details from the reading text.\nSection Two------How to teach writing (Developing correctness in students’ writing)\n   “Students learn to write by writing, and they learn to write correctly by writing, revising, and proofreading their own work”---with some help or direction from the teacher when it is necessary. They do not learn to write correctly by studying about writing or doing isolated workbook exercises unrelated to their own writing. So, the most important technique a teacher can use to guide students toward grammatically correct writing is to let them write, let them write things related to their own experiences. There is no limit to the kinds of text the teacher can ask students to write. Teachers’ decisions, though, should based on how much language the students know, what their interests are.\n  “Do I read a paper and ignore all punctuation, what good is that for students?\n   We spend hours at night with papers---I’m not sure the students get as much from it as the time I spend on it.”\n   These comments by senior high school English teachers discussing the process of marking student papers reflect the dissatisfaction and frustration of many teachers over the problem of dealing with the errors in student writing-----the obvious mistakes in spelling, punctuation----Traditionally, teachers have worked to correct errors in two ways: by teaching grammatically correctness through exercise in grammar texts; by pointing out all errors when making student papers.\n   Most students find it very dispiriting if they get a piece of written work back and it is covered in red ink, underlings and crossing-out. It is a powerful visual statement of the fact that their written English is terrible. Of course, some pieces of written work are completely full of mistakes, but even in these cases, the teacher has to achieve a balance between being accurate and truthful on the one hand and treating students sensitively and sympathetically on the other.",
    "reference_list": "考点1：“reading texts provide good models for English writing”推荐译为“阅读材料为英语写作提供良好范式”，“good models”不可译为“写作模板”或“写作模型”。\n \n考点2：“permit students to read”推荐译为“让学生真正进行实际阅读”，不可直译为“允许学生读书”或“许可学生阅读”。\n \n考点3：“the meaning is not in the teacher”推荐译为“意义不在教师本身”，不可理解为“老师不讲意义”或“教师无意义”。\n \n考点4：“balance between being accurate and being sympathetic”推荐译为“在准确指出错误与富有同理心之间取得平衡”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "教育",
    "prompt_id": "25"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nFOR DECADES Sweden was seen as the epitome of sexual freedom, so much so that President Dwight Eisenhower fulminated in 1960 that its people tended towards “sin, nudity, drunkenness”. In 1971 it followed Denmark to become the second country in the world to legalise all forms of pornography. Yet Sweden has been altogether more prudish when it comes to prostitution, having originated the so-called Nordic Model in 1999, which criminalised the purchase of sex, but not its sale, with the intention of reducing demand while protecting vulnerable women. This model has since spread widely. In the past decade, France, Ireland, Israel and the American state of Maine have all adopted it; Scotland is considering it.\nNow Sweden is trying to apply its real-world Nordic model to the digital world.On July 1st a new Swedish law will come into force that criminalises paying for live porn on sites like OnlyFans, the platform best known for its adult content, but not those who perform the online sex acts. Those breaking the new law face a penalty of up to a year in prison.\nThe new law comes as sex workers increasingly embrace technology and move online. Many of those selling physical sex have already transitioned from soliciting on street corners to advertising on the internet. More recently the sale of virtual sex has gained momentum.\nBuying sex and sexual content has also become easier-and more accepted-than ever. Fully 14% of young Americans say they would consider selling content on OnlyFans; 16% say they would become a \"sugar baby\", selling companionship (and very often sex) to older men. In May 2024 one in ten British adults who were online visited Chaturbate, a live webcam-sex site. And the boundaries of what people consider to be sex work are becoming blurry, notes Teela Sanders of the University of Leicester. In Sweden, 8% of girls aged 15-19 say they have sent sexual content or met someone for sex in exchange for money often via the social-media app Snapchat. On the gay dating app Grindr, it is common to trade sex for gifts or drugs. In an age where sex and relationships are often more overtly transactional , many in Generation Z do not see what they are doing as \"sex work\" at all (unlike, for example, work in brothels, which is usually perceived as more exploitative). Only 56% of Britons aged 18-25 say that\"sugaring\" counts as sex work, compared with 70% of over-65s.\nThese changes raise two important questions. Does the Swedish model work in the real world? And should it also apply to virtual sex work? Supporters of the Nordic model in relation to old-school prostitution argue that the purchase of sex is always exploitative, and that restrictions are needed not only to protect the vulnerable but also to crush demand. In this they hark back to abolitionist views of the 1920s, when the League of Nations sent undercover agents to infiltrate brothels, where they found examples of foreign women in debt bondage. Denying sex workers agency over their own bodies, they declared that many were \"mentally abnormal\" and of \"poor heredity and poor environment\" Though attitudes have softened since, some of the stigma and denial of agency persist in the Nordic model, which is based on the idea that many prostitutes go\ninto sex work because of childhood abuse or poverty rather than free choice, and that they should be \"rehabilitated\".\nTo be sure, there are many sex workers like Samuel Vahlund, who turned to prostitution after childhood bullying and a traumatic sexual assault destroyed his self-esteem, and because he needed money for drugs. At the time, he believed he was consenting, but would dissociate during sex with other men. “I hated myself,” he says.\nAnd similar trends appear to be the case for many of those entering online sex work. Meghan Donevan, a researcher at Talita, a Swedish charity, interviewed 120 people who had appeared in “commercial pornography”. Of those, 88% had been sexually abused as children and 69% had attempted suicide. Virtual sex work also creates the possibility for other sorts of harm. In thousands of webcam “studios” across Colombia, women work 12-hour shifts streaming from cramped, often filthy cubicles, keeping only a fraction of their earnings. “Doxxing”, whereby personal information is published on the internet, is common. “I know a lot of people who prefer old-school sex work because it’s safer,” says one Italian sex worker.\nSweden’s government argues that since virtual sex work also carries the risk of harm, it should get the same legal treatment as the sale of actual sex. Moreover, says Nina Larson, Sweden’s minister for gender equality, “digital prostitution” can be a “gateway” to selling sex in person. Does the argument have merit?\nSupporters of the existing Nordic model tout a fall in the share of Swedish men who say they have ever paid for sex, from 14% in 1996 to 9% in 2017. They also point to falling street prostitution as proof of its success. But that may well be because sex work has moved underground or out of the country. The government reckons that 80% of Swedish men who pay for sex do so when they are abroad. Janna Davidson, Sweden’s national rapporteur on human trafficking and prostitution, argues that the most important effect of the Nordic model has been normative: Swedes are far more likely than their rich-world peers to say prostitution can “never be justified”.\nYet there is little firm evidence that the Nordic model is achieving its main goals of protecting vulnerable sex workers or of putting a lasting dent in demand, especially since a growing proportion of men suspected of buying sex are under 30\nWorse, the policies in force since 1999 may have distracted authorities from reducing the genuinely harmful aspects of the sex trade. This is because police often find it easier to arrest johns than to pursue pimps and traffickers. Prosecutions for buying sex have risen in Sweden, but there were no convictions for trafficking in 2024.\nFar from protecting vulnerable people, the existing laws may well be harming them. The stigmatisation of sex work means prostitutes and their clients are less likely to seek treatment for sexually transmitted infections. Migrants—who may make up 70-80% of those selling sex—are particularly vulnerable, because even though the sale of sex is not criminalised, it can be grounds for deportation. Paulina Bolton, who co-ordinates investigations into prostitution and human trafficking at the Swedish Gender Equality Agency, admits that support for victims is lacking.\nThe European Sex Workers Rights Alliance says that Sweden’s new law “will further isolate sex workers, particularly migrants and trans people”. It will also be hard to enforce. Instead of expanding the Nordic model online, Sweden should be looking at better alternatives for both the real and digital worlds.\nRecently, in a church in Brussels, stalls offered lube, condoms and leaflets with titles such as: “So you’re dating a sex worker”; and “Anal health”. The event, arranged by the Belgian union of sex workers to mark International Whores’ Day, closed with a performance by a dominatrix, who stripped in front of the altar before hypnotising attendees with her whips.\nIn 2022 Belgium became the first European country to fully decriminalise sex work (and the second globally after New Zealand). Last December it granted sex workers formal labour rights, entitling them to sick leave, maternity pay and pensions, and obliging brothels to get a permit and comply with health and safety standards. In the past few years, the Australian states of Victoria and Queensland have decriminalised sex work; South Africa and Thailand have drafted similar bills. In contrast to the Nordic model, this approach is supported by many academics, who argue that full decriminalisation helps to reduce stigma, deters police harassment and helps separate the willing from the coerced.",
    "ori_text": "FOR DECADES Sweden was seen as the epitome of sexual freedom, so much so that President Dwight Eisenhower fulminated in 1960 that its people tended towards “sin, nudity, drunkenness”. In 1971 it followed Denmark to become the second country in the world to legalise all forms of pornography. Yet Sweden has been altogether more prudish when it comes to prostitution, having originated the so-called Nordic Model in 1999, which criminalised the purchase of sex, but not its sale, with the intention of reducing demand while protecting vulnerable women. This model has since spread widely. In the past decade, France, Ireland, Israel and the American state of Maine have all adopted it; Scotland is considering it.\nNow Sweden is trying to apply its real-world Nordic model to the digital world.On July 1st a new Swedish law will come into force that criminalises paying for live porn on sites like OnlyFans, the platform best known for its adult content, but not those who perform the online sex acts. Those breaking the new law face a penalty of up to a year in prison.\nThe new law comes as sex workers increasingly embrace technology and move online. Many of those selling physical sex have already transitioned from soliciting on street corners to advertising on the internet. More recently the sale of virtual sex has gained momentum.\nBuying sex and sexual content has also become easier-and more accepted-than ever. Fully 14% of young Americans say they would consider selling content on OnlyFans; 16% say they would become a \"sugar baby\", selling companionship (and very often sex) to older men. In May 2024 one in ten British adults who were online visited Chaturbate, a live webcam-sex site. And the boundaries of what people consider to be sex work are becoming blurry, notes Teela Sanders of the University of Leicester. In Sweden, 8% of girls aged 15-19 say they have sent sexual content or met someone for sex in exchange for money often via the social-media app Snapchat. On the gay dating app Grindr, it is common to trade sex for gifts or drugs. In an age where sex and relationships are often more overtly transactional , many in Generation Z do not see what they are doing as \"sex work\" at all (unlike, for example, work in brothels, which is usually perceived as more exploitative). Only 56% of Britons aged 18-25 say that\"sugaring\" counts as sex work, compared with 70% of over-65s.\nThese changes raise two important questions. Does the Swedish model work in the real world? And should it also apply to virtual sex work? Supporters of the Nordic model in relation to old-school prostitution argue that the purchase of sex is always exploitative, and that restrictions are needed not only to protect the vulnerable but also to crush demand. In this they hark back to abolitionist views of the 1920s, when the League of Nations sent undercover agents to infiltrate brothels, where they found examples of foreign women in debt bondage. Denying sex workers agency over their own bodies, they declared that many were \"mentally abnormal\" and of \"poor heredity and poor environment\" Though attitudes have softened since, some of the stigma and denial of agency persist in the Nordic model, which is based on the idea that many prostitutes go\ninto sex work because of childhood abuse or poverty rather than free choice, and that they should be \"rehabilitated\".\nTo be sure, there are many sex workers like Samuel Vahlund, who turned to prostitution after childhood bullying and a traumatic sexual assault destroyed his self-esteem, and because he needed money for drugs. At the time, he believed he was consenting, but would dissociate during sex with other men. “I hated myself,” he says.\nAnd similar trends appear to be the case for many of those entering online sex work. Meghan Donevan, a researcher at Talita, a Swedish charity, interviewed 120 people who had appeared in “commercial pornography”. Of those, 88% had been sexually abused as children and 69% had attempted suicide. Virtual sex work also creates the possibility for other sorts of harm. In thousands of webcam “studios” across Colombia, women work 12-hour shifts streaming from cramped, often filthy cubicles, keeping only a fraction of their earnings. “Doxxing”, whereby personal information is published on the internet, is common. “I know a lot of people who prefer old-school sex work because it’s safer,” says one Italian sex worker.\nSweden’s government argues that since virtual sex work also carries the risk of harm, it should get the same legal treatment as the sale of actual sex. Moreover, says Nina Larson, Sweden’s minister for gender equality, “digital prostitution” can be a “gateway” to selling sex in person. Does the argument have merit?\nSupporters of the existing Nordic model tout a fall in the share of Swedish men who say they have ever paid for sex, from 14% in 1996 to 9% in 2017. They also point to falling street prostitution as proof of its success. But that may well be because sex work has moved underground or out of the country. The government reckons that 80% of Swedish men who pay for sex do so when they are abroad. Janna Davidson, Sweden’s national rapporteur on human trafficking and prostitution, argues that the most important effect of the Nordic model has been normative: Swedes are far more likely than their rich-world peers to say prostitution can “never be justified”.\nYet there is little firm evidence that the Nordic model is achieving its main goals of protecting vulnerable sex workers or of putting a lasting dent in demand, especially since a growing proportion of men suspected of buying sex are under 30\nWorse, the policies in force since 1999 may have distracted authorities from reducing the genuinely harmful aspects of the sex trade. This is because police often find it easier to arrest johns than to pursue pimps and traffickers. Prosecutions for buying sex have risen in Sweden, but there were no convictions for trafficking in 2024.\nFar from protecting vulnerable people, the existing laws may well be harming them. The stigmatisation of sex work means prostitutes and their clients are less likely to seek treatment for sexually transmitted infections. Migrants—who may make up 70-80% of those selling sex—are particularly vulnerable, because even though the sale of sex is not criminalised, it can be grounds for deportation. Paulina Bolton, who co-ordinates investigations into prostitution and human trafficking at the Swedish Gender Equality Agency, admits that support for victims is lacking.\nThe European Sex Workers Rights Alliance says that Sweden’s new law “will further isolate sex workers, particularly migrants and trans people”. It will also be hard to enforce. Instead of expanding the Nordic model online, Sweden should be looking at better alternatives for both the real and digital worlds.\nRecently, in a church in Brussels, stalls offered lube, condoms and leaflets with titles such as: “So you’re dating a sex worker”; and “Anal health”. The event, arranged by the Belgian union of sex workers to mark International Whores’ Day, closed with a performance by a dominatrix, who stripped in front of the altar before hypnotising attendees with her whips.\nIn 2022 Belgium became the first European country to fully decriminalise sex work (and the second globally after New Zealand). Last December it granted sex workers formal labour rights, entitling them to sick leave, maternity pay and pensions, and obliging brothels to get a permit and comply with health and safety standards. In the past few years, the Australian states of Victoria and Queensland have decriminalised sex work; South Africa and Thailand have drafted similar bills. In contrast to the Nordic model, this approach is supported by many academics, who argue that full decriminalisation helps to reduce stigma, deters police harassment and helps separate the willing from the coerced.",
    "reference_list": "考点1：“criminalise the purchase of sex”应译为【将购买性服务行为入罪】\n考点2：“live porn”推荐译为【在线色情直播】或【实时成人视频】\n考点3：“sugar baby”推荐译为【甜心宝贝】\n考点4：“doxxing”应译为【人肉搜索】或【恶意信息曝光】\n考点5：“debt bondage”应译为【债役】或【债务奴役】\n考点6：“abolitionist views”推荐译为【禁娼主义观点】或【废除主义立场】\n考点7：“digital prostitution”应译为【数字性交易】或【数字性服务】\n考点8：“sex trafficking”推荐译为【性交易人口贩运】\n考点9：“International Whores’ Day”应统一译为【国际妓女节】\n考点10：“dominatrix”推荐译为【女施虐者】或【女王调教者】\n考点11：“decriminalise sex work”推荐译为【将性工作非刑事化】或【废除刑事处罚】\n考点12：“police harassment”推荐译为【警方骚扰】或【执法骚扰】\n考点13：“rehabilitated”推荐译为表述【改造】【改过自新】、【重新融入社会】等，不可直译为【康复】\n考点14： “Only 56% of Britons aged 18-25 say that\"sugaring\" counts as sex work, compared with 70% of over-65s.”中“sugaring”推荐译为【包养】，不应译为【糖交】\n考点15：“poor heredity and poor environment”推荐翻译为【出身和生长环境很差】",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "74"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n   在当代智能交通技术快速演进的背景下，端到端自动驾驶系统基于深度神经网络的方案日益成为研究与工业界的焦点。相较于传统架构中将感知、决策制定与运动控制明确划分为多个独立的功能模块，这种端到端方法力图将整条自动驾驶处理链整合进一个统一的神经网络模型中，直接由原始多模态传感器输入（如摄像头图像、雷达点云或车辆历史状态）输出连续的驾驶指令（如转向角、加减速命令、急刹车信号），从而大幅减少中间接口的工程复杂性，简化调试流程，并显著降低感知与控制之间可能发生的不一致性所带来的系统隐患。\n    然而，端到端方法的实际部署远非“结构简化”这么简单。要在工业级别的自动驾驶平台上投入应用，其首先需要满足一个关键前提：实时性。也就是说，系统从输入图像接收到生成控制命令的延迟必须足够低，以满足高速行驶车辆的动态响应要求。在满足这一严苛条件的过程中，研究者不仅要在算法层面对神经网络进行结构压缩与推理加速，如使用稀疏注意力机制、通道剪枝、深度可分离卷积或层级特征重用等手段，同时还需从底层软硬件协同角度入手，针对不同部署平台（如数据中心、车载边缘设备）设计异构优化策略。例如，在数据中心的训练和推理阶段，研究团队普遍采用TensorRT或ONNX Runtime等主流高效推理引擎，配合NVIDIA GPU的Tensor Core或AMD ROCm平台，进行混合精度训练与INT8低延迟推理；而对于部署在车载终端的轻量级边缘模型，则常借助FPGA的高度可编程性和专用NPU（如寒武纪、地平线）的流式处理特性，通过深度流水线调度、内存片上缓存重用等策略将感知延迟压缩至毫秒级别甚至更低。\n    在网络结构方面，近年来兴起的视觉–语言–动作（VLA）三模态融合架构，为端到端自动驾驶系统带来了前所未有的语义泛化能力。其核心在于构建一个支持图像感知、语言理解与动作决策统一表示的多模态融合网络。该结构通常包含以下几个关键子模块：\n（1）视觉编码器模块，基于改进后的ResNet-101、EfficientNetV2或新兴的Vision Transformer（ViT/DeiT），负责从原始RGB图像中提取尺度丰富、时空相关的图像特征张量；\n（2）语言编码器模块，通常采用基于Transformer或GPT结构的序列建模器，将高层次的语义指令（如“在下一个交通灯左转后并道”或“避让前方施工车辆”）转化为可嵌入的高维语义向量；\n（3）多模态对齐与融合模块，该模块常采用Cross-Attention机制对视觉与语言特征进行相互对齐，随后通过多个堆叠的Transformer Encoder层提取跨模态语义表征；\n（4）动作解码器，使用如一维卷积网络（TemporalConvNet）、LSTM 或 GRU 等时序建模单元预测未来两秒内每100毫秒一个离散采样点的轨迹控制命令。\n    值得注意的是，这类多模态架构中语言的加入使得驾驶系统具备某种程度的“高层可控性”，即用户或系统设计者可以通过语言指令引导行为意图。例如，在城市工况下可以通过指令指定特殊策略（如“靠右行驶”、“优先保持直行”等），显著提高驾驶系统的可解释性与策略灵活性。\n数据是决定模型性能的根本性因素。一个高质量、具有代表性、可扩展的数据集，不仅关系到模型训练阶段的收敛效果，更对最终泛化性能起到决定性作用。当前的数据集建设方法通常包括两大类：仿真合成数据与真实车辆采集数据。前者依赖高保真的模拟平台（如CARLA、LGSVL、MetaDrive等），可生成多样化的极端天气（暴雪、浓雾、夜间雨天）、稀有交通行为（逆行、鬼探头、非规范掉头）与异常路况（车道消失、交通灯失效等），且每一帧数据都自带准确的语义分割、检测框、轨迹注释等标签；后者则往往需要动用多车队列采集，借助高精度IMU/GPS组合导航系统、128线激光雷达、多角度鱼眼摄像头等多传感器融合技术，获得同步、高分辨率的传感信息与精确标注。为了保证训练数据与验证数据分布的一致性，标注团队通常需要构建细致的标注手册，并定期进行交叉校验，以降低“标签漂移”或“语义漂移”的风险。\n在数据预处理过程中，还常引入诸如几何变换（旋转、缩放、仿射扰动）、光照变化模拟、色彩扰动、镜像反转、目标遮挡等增强策略，以提升模型在不同场景与摄像机角度下的鲁棒性与泛化能力。\n  模型训练阶段一般分为两个主要阶段：第一阶段为有监督的预训练，采用大规模公开数据集（如nuScenes、Waymo Open Dataset、Argoverse 2.0等）进行目标识别、轨迹预测或行为分类任务的学习；第二阶段则引入强化学习（RL）进行策略微调，通过构建闭环仿真环境、定义奖励函数，并使用如DDPG、SAC、PPO等策略梯度算法训练Agent，在具体交通情景下学习最优行为边界。这一阶段的目标并非单纯提高轨迹准确率，而是让系统在高维状态空间中掌握对复杂交通互动关系的动态决策能力，如在车流密集交汇区域如何插队、在无信号交叉路口如何让行等。\n  模型部署阶段则是将训练完成的系统集成至车载平台中的关键一环。首先，需要在嵌入式系统上安装适配的实时操作系统（如QNX、Linux RT Patch）与自研中间件，负责调度处理器资源、协调各传感器采样频率，保证雷达、摄像头、超声波等设备在统一时间线上输出。系统需持续监控推理帧率、内存占用、模型漂移率、控制响应延迟等鲁棒性指标；一旦检测到关键性能指标跌出安全阈值区间，便会触发“安全降级”机制，即自动将控制权从主系统转交至冗余控制器或传统的规则系统（如基于PID的紧急停车控制），以避免“算法在正常情况下如火箭般展现性能，而在边缘情况下一败涂地”的风险。\n此外，在真实道路环境中进行测试时，还必须构建完善的回放与重构系统。每辆测试车需具备本地日志记录与高速无线数据上传能力，所有运行日志需回传至云端平台，由仿真回放系统（如RESim或OpenReplay）进行逐帧复刻与行为审计。这类系统常用于挖掘“边缘案例”——即发生概率极低但具有极大安全风险的特殊情况，如小孩突然冲入路口、车辆遭遇紧急制动但被后车追尾等。\n  最终，在正式版本上线前，工程团队通常需进行大规模在线A/B测试，以对比不同版本模型在用户体验、安全冗余、策略鲁棒性等方面的实际差异。只有当所有指标显著优于旧版本且无新增失败案例时，系统才会完成灰度上线，确保每一次更新都稳定、透明、可追溯，从而实现真正可落地的“全栈端到端自动驾驶体验”。\n",
    "ori_text": "\n\n   在当代智能交通技术快速演进的背景下，端到端自动驾驶系统基于深度神经网络的方案日益成为研究与工业界的焦点。相较于传统架构中将感知、决策制定与运动控制明确划分为多个独立的功能模块，这种端到端方法力图将整条自动驾驶处理链整合进一个统一的神经网络模型中，直接由原始多模态传感器输入（如摄像头图像、雷达点云或车辆历史状态）输出连续的驾驶指令（如转向角、加减速命令、急刹车信号），从而大幅减少中间接口的工程复杂性，简化调试流程，并显著降低感知与控制之间可能发生的不一致性所带来的系统隐患。\n    然而，端到端方法的实际部署远非“结构简化”这么简单。要在工业级别的自动驾驶平台上投入应用，其首先需要满足一个关键前提：实时性。也就是说，系统从输入图像接收到生成控制命令的延迟必须足够低，以满足高速行驶车辆的动态响应要求。在满足这一严苛条件的过程中，研究者不仅要在算法层面对神经网络进行结构压缩与推理加速，如使用稀疏注意力机制、通道剪枝、深度可分离卷积或层级特征重用等手段，同时还需从底层软硬件协同角度入手，针对不同部署平台（如数据中心、车载边缘设备）设计异构优化策略。例如，在数据中心的训练和推理阶段，研究团队普遍采用TensorRT或ONNX Runtime等主流高效推理引擎，配合NVIDIA GPU的Tensor Core或AMD ROCm平台，进行混合精度训练与INT8低延迟推理；而对于部署在车载终端的轻量级边缘模型，则常借助FPGA的高度可编程性和专用NPU（如寒武纪、地平线）的流式处理特性，通过深度流水线调度、内存片上缓存重用等策略将感知延迟压缩至毫秒级别甚至更低。\n    在网络结构方面，近年来兴起的视觉–语言–动作（VLA）三模态融合架构，为端到端自动驾驶系统带来了前所未有的语义泛化能力。其核心在于构建一个支持图像感知、语言理解与动作决策统一表示的多模态融合网络。该结构通常包含以下几个关键子模块：\n（1）视觉编码器模块，基于改进后的ResNet-101、EfficientNetV2或新兴的Vision Transformer（ViT/DeiT），负责从原始RGB图像中提取尺度丰富、时空相关的图像特征张量；\n（2）语言编码器模块，通常采用基于Transformer或GPT结构的序列建模器，将高层次的语义指令（如“在下一个交通灯左转后并道”或“避让前方施工车辆”）转化为可嵌入的高维语义向量；\n（3）多模态对齐与融合模块，该模块常采用Cross-Attention机制对视觉与语言特征进行相互对齐，随后通过多个堆叠的Transformer Encoder层提取跨模态语义表征；\n（4）动作解码器，使用如一维卷积网络（TemporalConvNet）、LSTM 或 GRU 等时序建模单元预测未来两秒内每100毫秒一个离散采样点的轨迹控制命令。\n    值得注意的是，这类多模态架构中语言的加入使得驾驶系统具备某种程度的“高层可控性”，即用户或系统设计者可以通过语言指令引导行为意图。例如，在城市工况下可以通过指令指定特殊策略（如“靠右行驶”、“优先保持直行”等），显著提高驾驶系统的可解释性与策略灵活性。\n数据是决定模型性能的根本性因素。一个高质量、具有代表性、可扩展的数据集，不仅关系到模型训练阶段的收敛效果，更对最终泛化性能起到决定性作用。当前的数据集建设方法通常包括两大类：仿真合成数据与真实车辆采集数据。前者依赖高保真的模拟平台（如CARLA、LGSVL、MetaDrive等），可生成多样化的极端天气（暴雪、浓雾、夜间雨天）、稀有交通行为（逆行、鬼探头、非规范掉头）与异常路况（车道消失、交通灯失效等），且每一帧数据都自带准确的语义分割、检测框、轨迹注释等标签；后者则往往需要动用多车队列采集，借助高精度IMU/GPS组合导航系统、128线激光雷达、多角度鱼眼摄像头等多传感器融合技术，获得同步、高分辨率的传感信息与精确标注。为了保证训练数据与验证数据分布的一致性，标注团队通常需要构建细致的标注手册，并定期进行交叉校验，以降低“标签漂移”或“语义漂移”的风险。\n在数据预处理过程中，还常引入诸如几何变换（旋转、缩放、仿射扰动）、光照变化模拟、色彩扰动、镜像反转、目标遮挡等增强策略，以提升模型在不同场景与摄像机角度下的鲁棒性与泛化能力。\n  模型训练阶段一般分为两个主要阶段：第一阶段为有监督的预训练，采用大规模公开数据集（如nuScenes、Waymo Open Dataset、Argoverse 2.0等）进行目标识别、轨迹预测或行为分类任务的学习；第二阶段则引入强化学习（RL）进行策略微调，通过构建闭环仿真环境、定义奖励函数，并使用如DDPG、SAC、PPO等策略梯度算法训练Agent，在具体交通情景下学习最优行为边界。这一阶段的目标并非单纯提高轨迹准确率，而是让系统在高维状态空间中掌握对复杂交通互动关系的动态决策能力，如在车流密集交汇区域如何插队、在无信号交叉路口如何让行等。\n  模型部署阶段则是将训练完成的系统集成至车载平台中的关键一环。首先，需要在嵌入式系统上安装适配的实时操作系统（如QNX、Linux RT Patch）与自研中间件，负责调度处理器资源、协调各传感器采样频率，保证雷达、摄像头、超声波等设备在统一时间线上输出。系统需持续监控推理帧率、内存占用、模型漂移率、控制响应延迟等鲁棒性指标；一旦检测到关键性能指标跌出安全阈值区间，便会触发“安全降级”机制，即自动将控制权从主系统转交至冗余控制器或传统的规则系统（如基于PID的紧急停车控制），以避免“算法在正常情况下如火箭般展现性能，而在边缘情况下一败涂地”的风险。\n此外，在真实道路环境中进行测试时，还必须构建完善的回放与重构系统。每辆测试车需具备本地日志记录与高速无线数据上传能力，所有运行日志需回传至云端平台，由仿真回放系统（如RESim或OpenReplay）进行逐帧复刻与行为审计。这类系统常用于挖掘“边缘案例”——即发生概率极低但具有极大安全风险的特殊情况，如小孩突然冲入路口、车辆遭遇紧急制动但被后车追尾等。\n  最终，在正式版本上线前，工程团队通常需进行大规模在线A/B测试，以对比不同版本模型在用户体验、安全冗余、策略鲁棒性等方面的实际差异。只有当所有指标显著优于旧版本且无新增失败案例时，系统才会完成灰度上线，确保每一次更新都稳定、透明、可追溯，从而实现真正可落地的“全栈端到端自动驾驶体验”。\n",
    "reference_list": "考点1：“深度可分离卷积 ”必须译为Depthwise Separable Convolution，固定译法\n考点2：“灰度上线”应该译为gray release或者dark launch，行业内熟知的说法",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "196"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nConfidentiality\n1. Each Party undertakes with the other Party that it shall treat as strictly confidential all information received or obtained by it or its employees agents or advisers as a result of ente-ring into or performing this Agreement including information relating to the provisions of this Agreement, the negotiations leading up to this Agreement, the subject matter of this Agreement or the business or affairs of the other Party or any member of the other Party's group of companies and that it shall not at any time hereafter make use of or disclose or divulge to any person any such information andshall use its best endeavors to prevent the publication or disclosure of any such information.\n2. From and after the date of this Agreement, Party A shall, and shall cause its affiliates and successors to, use the same efforts to maintain the confidentiality of any Confidential Information as Party A used to maintain the confidentiality of such information prior to the date hereof.Notwithstanding the foregoing, Party A and its affiliates and successors shall after prior notice to, and consultation with Party B, be permitted to disclose any such Confidential Information to the extent legally required or necessary for obtaining appropriate regulatory licenses or approvals.3. All Proprietary Information disclosed by either Party or its affiliates to the CJV in accordance with the provisions of this Contract and the Technology License Agreement and/ or the Trademark License Agreement to be entered into between an affiliate of Party B and the CJV on or about the date hereof substantially in the form attached hereto as Appendix X shall be used by the CJV and its personnel solely for the CIV's account and purposes. Each Party and any of its affiliates shall maintain the secrecy of all Proprietary.Information that may be disclosed or furnished to it by the CJV or the other Party and its affiliates, and neither of the Parties or their affiliates shall disclose or reveal any such Proprietary Information to any third party without explicit written authorization from the other Party. Any Proprietary.Information obtained by the CIV or a Party or its affiliates may be disclosed only to the designated employees of the CIV or that Party and its affiliates whose duties so require for the implementation of this Contract. The CJV and each Party and its affiliates shall take all reasonable precautions(including the conclusion of confidentiality contracts with each such employee)to prevent such employees from using and disclosing the Proprietary Information in contravention of this Article 3.\n4.\"Confidential Information\"means all documents.software and documentation, reports, financial or other data, records, forms, tools.products, services, methodologies, present and future research, technical knowledge, marketing plans, trade secrets, and other materials obtained by Consultant and Client from each other in the course of performing any Services, whether tangible or intangible and whether or not stored, compiled or memorized physically, electronically, graphically, in writing, or by any means now known or later invented. Confidential Information includes without limitation records and information and Consultant's Information (i)that has been marked as proprietary or confidential; (ii) whose confidential nature has been made known by Client or Consultant; or (iii) that due to its character and nature, a reasonable person under like circumstances would treat as confidential. Notwithstanding the foregoing. Confidential Information does not include information which (i) is already known to the recipient at the time of disclosure, (ii) is or becomes publicly known through no wrongful act or failure of the recipient; (iii) is independently developed by the recipient without benefit of the other party's Confidential Information.or (iv) is received from a third party which is not under and does not thereby breach an obligation of confidentiality. Each party agrees to protect the other's Confidential Information at all times and in the same manner as each protects the confidentiality of its own proprietary and confidential materials.but in no event with less than a reasonable standard of care. Consultant will deliver to Client all Confidential Information and all copies thereof (and all other property obtained from or through Client) when Client requests the same or immediately upon termination of this Agreement, whichever occur searlier, except for one copy thereof that Consultant, may retain for its records. Neither party shall, except with respect to those of its employees with a need to know under this Agreement, use or disclose to any person firm or entity any Confidential Information of the other party without such other party's express, prior written permission; provided, however, that not withstanding the foregoing, Consultant may disclose Confidential Information to the extent that it is required to be disclosed pursuant to a statutory or regulatory provision or court order. The confidentiality restrictions and obligations imposed by this Section 4 shall terminate two(2)years after the expiration or termination of this Agreement.\n\n Definition and Interpretation\n1. \"Affiliate\" means any person or company that directly or indirectly controls a Party or is directly or indirectly controlled by a Party, including a Party's parent or subsidiary, or is under direct or indirect common control with such Party. For the purpose of this Agreement, \"control\" shall mean either the ownership of fifty per cent (50%) or more of the ordinary share capital of the company carrying the right to vote at general meetings or the power to nominate a majority of the board of directors of the Company.\"Proprietary Know-how\" shall mean processes,methods and manufacturing techniques, experience and other information and materials including but not limited to the Technical Information and Technical Assistance supplied or rendered by the Licensor to the Licensee here under which have been developed by and are known to the Licensor on the date here of and/or which may be further developed by the Licensor or become known to it during the continuance of this Agreement excepting, howeve rany secret know-how acquired by the Licensor from third parties which the Licensor is precluded from disclosing to the Licensee.\n3. \"\"Proprietary Information\" means the information, whether patentable or not, disclosed to the CJV by either Party or its Affiliates or disclosed by the CJV to either Party or its Affiliates during the term of this Contract,including technology, inventions, creations, know-how, formulations recipes, specifications, designs, methods, processes, techniques, data, rights devices, drawings, instructions, expertise, trade practices, trade secrets and such commercial, economic, financial or other information as is generally treated as confidential by the disclosing Party, its Affiliates, or the CJV, as the case may be; provided that when such information is in unwritten or intangible form, the disclosing Party, its Affiliates or the CJV shall, within one month of making the disclosure, provide the other Party and/or the CJV with a written confirmation that such information constitutes its Proprietary Information.\n4. \"Encumbrances\" include any option, right to acquire, right of preemption mortgage, charge, pledge, lien, hypothecation, title creation, right of set-off counter claim, trust arrangement or other security or any equity or restriction(including any relevant restriction imposed under the relevant law).\n5. In this Agreement, unless the context otherwise requires:\na) headings are for convenience only and shall not affect the interpretation\nof this Agreement;\nb) words importing the singular include the plural and vice versa;c) words importing a gender include any gender;d) an expression importing a natural person includes any company partnership, joint venture, association, corporation or other body corporate and any governmental agency;\ne)a reference to any law, regulation or rule includes all laws, regulations, or rules amending, consolidating or replacing them, and a reference to a law includes all regulations and rules under that law;\nf) a reference to a document includes an amendment or supplement to, or replacement or novation of, that document;g)a reference to a party to any document includes that party's successors and permitted assigns;\nh) a reference to an agreement includes an undertaking, agreement or legally enforceable arrangement or understanding whether or not in writing,i) a warranty, representation, undertaking, indemnity, covenant or agreement on the part of two or more persons binds them jointly and severally; and j) the schedules, annexures and appendices to this Agreement shall form an integral part of this Agreement.\n\n1. \"Control\" means the power of any entity to direct the affairs of another entity whether by any of the following means or otherwise:.a) beneficial ownership of or entitlement to acquire shares or assets of the other;\nb) power to exercise voting rights in relation to the other;c)power to appoint members of the supervisory board, board of directors or bodies legally representing the other; or\nd) power to operate, direct or manage the general affairs of the other.2. \"Technical Information\" shall mean all technical data, drawings, designs,formulae, specifications, processes, methods of manufacture, computer programs or other software or technical documents and similar intellectual property rights of or developed by the Licensor as of the date hereof or to be developed by the Licensor during the term of this Agreement relating to the Product, including improvements thereto.\n3. The headings used in this Contract are for ease of reference only, and in no event shall the substance of any paragraph or the intent of the Parties be interpreted or controlled by such headings.4.References to:\na)Clauses and Schedules are to clauses in and schedules to this Agreement(unless the context otherwise requires) and the Recitals and Schedules to this Agreement shall be deemed to form part of this Agreement;\nb)\"person\" shall include body corporate》 unincorporated association and partnership (whether or not having separate legal personality);c) writing shall include any methods of producing or reproducing words in a legible and non-transitory form; and\nd) masculine gender shall include the feminine and neuter and the singular number shall include the plural and vice versa.\n",
    "ori_text": "\n\nConfidentiality\n1. Each Party undertakes with the other Party that it shall treat as strictly confidential all information received or obtained by it or its employees agents or advisers as a result of ente-ring into or performing this Agreement including information relating to the provisions of this Agreement, the negotiations leading up to this Agreement, the subject matter of this Agreement or the business or affairs of the other Party or any member of the other Party's group of companies and that it shall not at any time hereafter make use of or disclose or divulge to any person any such information andshall use its best endeavors to prevent the publication or disclosure of any such information.\n2. From and after the date of this Agreement, Party A shall, and shall cause its affiliates and successors to, use the same efforts to maintain the confidentiality of any Confidential Information as Party A used to maintain the confidentiality of such information prior to the date hereof.Notwithstanding the foregoing, Party A and its affiliates and successors shall after prior notice to, and consultation with Party B, be permitted to disclose any such Confidential Information to the extent legally required or necessary for obtaining appropriate regulatory licenses or approvals.3. All Proprietary Information disclosed by either Party or its affiliates to the CJV in accordance with the provisions of this Contract and the Technology License Agreement and/ or the Trademark License Agreement to be entered into between an affiliate of Party B and the CJV on or about the date hereof substantially in the form attached hereto as Appendix X shall be used by the CJV and its personnel solely for the CIV's account and purposes. Each Party and any of its affiliates shall maintain the secrecy of all Proprietary.Information that may be disclosed or furnished to it by the CJV or the other Party and its affiliates, and neither of the Parties or their affiliates shall disclose or reveal any such Proprietary Information to any third party without explicit written authorization from the other Party. Any Proprietary.Information obtained by the CIV or a Party or its affiliates may be disclosed only to the designated employees of the CIV or that Party and its affiliates whose duties so require for the implementation of this Contract. The CJV and each Party and its affiliates shall take all reasonable precautions(including the conclusion of confidentiality contracts with each such employee)to prevent such employees from using and disclosing the Proprietary Information in contravention of this Article 3.\n4.\"Confidential Information\"means all documents.software and documentation, reports, financial or other data, records, forms, tools.products, services, methodologies, present and future research, technical knowledge, marketing plans, trade secrets, and other materials obtained by Consultant and Client from each other in the course of performing any Services, whether tangible or intangible and whether or not stored, compiled or memorized physically, electronically, graphically, in writing, or by any means now known or later invented. Confidential Information includes without limitation records and information and Consultant's Information (i)that has been marked as proprietary or confidential; (ii) whose confidential nature has been made known by Client or Consultant; or (iii) that due to its character and nature, a reasonable person under like circumstances would treat as confidential. Notwithstanding the foregoing. Confidential Information does not include information which (i) is already known to the recipient at the time of disclosure, (ii) is or becomes publicly known through no wrongful act or failure of the recipient; (iii) is independently developed by the recipient without benefit of the other party's Confidential Information.or (iv) is received from a third party which is not under and does not thereby breach an obligation of confidentiality. Each party agrees to protect the other's Confidential Information at all times and in the same manner as each protects the confidentiality of its own proprietary and confidential materials.but in no event with less than a reasonable standard of care. Consultant will deliver to Client all Confidential Information and all copies thereof (and all other property obtained from or through Client) when Client requests the same or immediately upon termination of this Agreement, whichever occur searlier, except for one copy thereof that Consultant, may retain for its records. Neither party shall, except with respect to those of its employees with a need to know under this Agreement, use or disclose to any person firm or entity any Confidential Information of the other party without such other party's express, prior written permission; provided, however, that not withstanding the foregoing, Consultant may disclose Confidential Information to the extent that it is required to be disclosed pursuant to a statutory or regulatory provision or court order. The confidentiality restrictions and obligations imposed by this Section 4 shall terminate two(2)years after the expiration or termination of this Agreement.\n\n Definition and Interpretation\n1. \"Affiliate\" means any person or company that directly or indirectly controls a Party or is directly or indirectly controlled by a Party, including a Party's parent or subsidiary, or is under direct or indirect common control with such Party. For the purpose of this Agreement, \"control\" shall mean either the ownership of fifty per cent (50%) or more of the ordinary share capital of the company carrying the right to vote at general meetings or the power to nominate a majority of the board of directors of the Company.\"Proprietary Know-how\" shall mean processes,methods and manufacturing techniques, experience and other information and materials including but not limited to the Technical Information and Technical Assistance supplied or rendered by the Licensor to the Licensee here under which have been developed by and are known to the Licensor on the date here of and/or which may be further developed by the Licensor or become known to it during the continuance of this Agreement excepting, howeve rany secret know-how acquired by the Licensor from third parties which the Licensor is precluded from disclosing to the Licensee.\n3. \"\"Proprietary Information\" means the information, whether patentable or not, disclosed to the CJV by either Party or its Affiliates or disclosed by the CJV to either Party or its Affiliates during the term of this Contract,including technology, inventions, creations, know-how, formulations recipes, specifications, designs, methods, processes, techniques, data, rights devices, drawings, instructions, expertise, trade practices, trade secrets and such commercial, economic, financial or other information as is generally treated as confidential by the disclosing Party, its Affiliates, or the CJV, as the case may be; provided that when such information is in unwritten or intangible form, the disclosing Party, its Affiliates or the CJV shall, within one month of making the disclosure, provide the other Party and/or the CJV with a written confirmation that such information constitutes its Proprietary Information.\n4. \"Encumbrances\" include any option, right to acquire, right of preemption mortgage, charge, pledge, lien, hypothecation, title creation, right of set-off counter claim, trust arrangement or other security or any equity or restriction(including any relevant restriction imposed under the relevant law).\n5. In this Agreement, unless the context otherwise requires:\na) headings are for convenience only and shall not affect the interpretation\nof this Agreement;\nb) words importing the singular include the plural and vice versa;c) words importing a gender include any gender;d) an expression importing a natural person includes any company partnership, joint venture, association, corporation or other body corporate and any governmental agency;\ne)a reference to any law, regulation or rule includes all laws, regulations, or rules amending, consolidating or replacing them, and a reference to a law includes all regulations and rules under that law;\nf) a reference to a document includes an amendment or supplement to, or replacement or novation of, that document;g)a reference to a party to any document includes that party's successors and permitted assigns;\nh) a reference to an agreement includes an undertaking, agreement or legally enforceable arrangement or understanding whether or not in writing,i) a warranty, representation, undertaking, indemnity, covenant or agreement on the part of two or more persons binds them jointly and severally; and j) the schedules, annexures and appendices to this Agreement shall form an integral part of this Agreement.\n\n1. \"Control\" means the power of any entity to direct the affairs of another entity whether by any of the following means or otherwise:.a) beneficial ownership of or entitlement to acquire shares or assets of the other;\nb) power to exercise voting rights in relation to the other;c)power to appoint members of the supervisory board, board of directors or bodies legally representing the other; or\nd) power to operate, direct or manage the general affairs of the other.2. \"Technical Information\" shall mean all technical data, drawings, designs,formulae, specifications, processes, methods of manufacture, computer programs or other software or technical documents and similar intellectual property rights of or developed by the Licensor as of the date hereof or to be developed by the Licensor during the term of this Agreement relating to the Product, including improvements thereto.\n3. The headings used in this Contract are for ease of reference only, and in no event shall the substance of any paragraph or the intent of the Parties be interpreted or controlled by such headings.4.References to:\na)Clauses and Schedules are to clauses in and schedules to this Agreement(unless the context otherwise requires) and the Recitals and Schedules to this Agreement shall be deemed to form part of this Agreement;\nb)\"person\" shall include body corporate》 unincorporated association and partnership (whether or not having separate legal personality);c) writing shall include any methods of producing or reproducing words in a legible and non-transitory form; and\nd) masculine gender shall include the feminine and neuter and the singular number shall include the plural and vice versa.\n",
    "reference_list": "考点1：“use its best endeavors”建议译为“竭力。\n考点2：“without explicit written authorization”需译为“未经明示书面授权”。\n考点3：“affiliates and successors”推荐译为“关联公司和承继人”。\n考点4：“solely for the... purposes”译为“仅供……之目的”。\n考点5：“reasonable precautions”建议译为“合理的预防措施”。\n考点6：“terminate two (2) years after”译为“于……后二(2)年终止”。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "120"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n三维（3D）复合材料是一种基于三维机织整体成型技术的先进材料，其结构由上下层织物面层与交叉呈\"8\"字形的绒经纤维组成。这种独特的设计通过Z向纤维在毛细作用下形成三维整体框架结构，利用织物中空结构瞬间吸收树脂，赋予材料轻质高强、抗分层剥离的优异特性。材料的制造工艺是采用了环氧树脂注入增强筋孔并与三维织物复合模压固化，成品面密度为4kg/m²，可承载500kg/m²荷载及45m/s风压。通过调节织物密度、层数及空间形态，可以灵活设计适配不同强度需求，同时中空层可通过填充泡沫或预埋功能组件实现隔音、阻燃等附加性能。\n在应用方面，三维（3D）复合材料凭借其卓越的强度、增强的刚度、延长的抗疲劳性和低密度等优势，在航空航天、轨道交通和生物医学领域发挥着重要作用。然而，复合材料的疲劳损伤行为具有高度复杂性和不确定性，其潜在损伤机制至今未能充分阐明。但研究表明，在拉伸-压缩疲劳载荷下的疲劳寿命明显短于拉伸-拉伸疲劳，其损伤过程通常始于基体开裂，继而发展为分层、微屈曲、纤维扭结，最终导致纤维断裂。基于前人的研究，复合材料的疲劳性能与传统金属材料有很大程度上的不同，失效机理和失效模式也比金属材料复杂得多。这种复杂的失效机理与传统金属材料有本质区别，金属材料通常以单一主控裂纹为主导，而复合材料则可能出现多种损伤模式同时存在的情况。\n目前，研究三维复合材料疲劳性能的主要方法是实验研究，但这种方法耗时费力，且难以全面评估不同应力水平下的疲劳寿命。为克服这些限制，将现有的复合材料疲劳模型分类，主要包括三类：疲劳寿命模型、预测残余刚度/强度的现象学模型和渐进损伤模型。疲劳寿命模型主要基于应力水平-疲劳循环关系表征复合材料的疲劳性能,该方法需要大量的实验数据，没有关注复合材料结构在疲劳过程中的实际损伤机理,它只能通过预测特定类型复合材料结构在特定工况下的疲劳寿命。而预测残余刚度/强度的现象学模型基于复合材料的疲劳理论，没有关注疲劳过程中的实际损伤机理，缺乏对纤维断裂、基体开裂、分层等多种损伤模式的全面描述。渐进式损伤模型应用疲劳失效准则来确定和定量描述失效模式，例如基体开裂、基体压缩、纤维断裂、纤维压缩、基体/纤维剪切和分层。同时，从疲劳性能出发，建立了各主要方向疲劳载荷的残余强度和残余刚度退化模型，用于材料性能退化分析，为有限元模型中的刚度矩阵退化提供了依据。该预测模型可以描述疲劳加载过程中的具体损伤模式，有利于分析损伤机理。此外，基于复合材料疲劳损伤理论，适用于预测不同疲劳载荷条件和层形的寿命。\n随着计算机技术的进步，有限元分析（FEA）在复合材料研究中的应用日益广泛。有限元分析的基本思想是将复杂问题离散化为有限个互连的子域进行分析求解。在复合材料领域，研究者已成功将Hashin准则与Murakami-Ohno理论相结合，建立了渐进损伤分析模型，准确地预测了三维编织复合材料的单轴拉伸特性。此外，有限元分析还被应用于热物理性能研究，比较不同结构复合材料的导热系数，并分析各参数对导热性能的影响规律。值得注意的是，随着有限元分析技术的发展，该方法已从早期的拉伸和热物理性能表征，进而扩展到复合材料疲劳行为的研究领域。例如，通过建立代表性体积单元（RVE）预测模型，研究者成功模拟了二维编织复合材料在双轴交替循环载荷下的疲劳寿命。另外，还有研究者基于介尺度代表性晶胞（RUC）模型分析了三维四向编织复合材料的疲劳特性，并研究了编织参数对线性或简化应力状态下疲劳行为的影响。\n这些研究进展为三维复合材料的性能优化和工程应用提供了重要理论基础，特别是通过计算机模拟技术，可以在设计阶段预测材料性能，有效避免过度设计和安全系数过大等问题，对推动三维(3D)复合材料在各工业领域的应用具有重要意义。",
    "ori_text": "\n\n三维（3D）复合材料是一种基于三维机织整体成型技术的先进材料，其结构由上下层织物面层与交叉呈\"8\"字形的绒经纤维组成。这种独特的设计通过Z向纤维在毛细作用下形成三维整体框架结构，利用织物中空结构瞬间吸收树脂，赋予材料轻质高强、抗分层剥离的优异特性。材料的制造工艺是采用了环氧树脂注入增强筋孔并与三维织物复合模压固化，成品面密度为4kg/m²，可承载500kg/m²荷载及45m/s风压。通过调节织物密度、层数及空间形态，可以灵活设计适配不同强度需求，同时中空层可通过填充泡沫或预埋功能组件实现隔音、阻燃等附加性能。\n在应用方面，三维（3D）复合材料凭借其卓越的强度、增强的刚度、延长的抗疲劳性和低密度等优势，在航空航天、轨道交通和生物医学领域发挥着重要作用。然而，复合材料的疲劳损伤行为具有高度复杂性和不确定性，其潜在损伤机制至今未能充分阐明。但研究表明，在拉伸-压缩疲劳载荷下的疲劳寿命明显短于拉伸-拉伸疲劳，其损伤过程通常始于基体开裂，继而发展为分层、微屈曲、纤维扭结，最终导致纤维断裂。基于前人的研究，复合材料的疲劳性能与传统金属材料有很大程度上的不同，失效机理和失效模式也比金属材料复杂得多。这种复杂的失效机理与传统金属材料有本质区别，金属材料通常以单一主控裂纹为主导，而复合材料则可能出现多种损伤模式同时存在的情况。\n目前，研究三维复合材料疲劳性能的主要方法是实验研究，但这种方法耗时费力，且难以全面评估不同应力水平下的疲劳寿命。为克服这些限制，将现有的复合材料疲劳模型分类，主要包括三类：疲劳寿命模型、预测残余刚度/强度的现象学模型和渐进损伤模型。疲劳寿命模型主要基于应力水平-疲劳循环关系表征复合材料的疲劳性能,该方法需要大量的实验数据，没有关注复合材料结构在疲劳过程中的实际损伤机理,它只能通过预测特定类型复合材料结构在特定工况下的疲劳寿命。而预测残余刚度/强度的现象学模型基于复合材料的疲劳理论，没有关注疲劳过程中的实际损伤机理，缺乏对纤维断裂、基体开裂、分层等多种损伤模式的全面描述。渐进式损伤模型应用疲劳失效准则来确定和定量描述失效模式，例如基体开裂、基体压缩、纤维断裂、纤维压缩、基体/纤维剪切和分层。同时，从疲劳性能出发，建立了各主要方向疲劳载荷的残余强度和残余刚度退化模型，用于材料性能退化分析，为有限元模型中的刚度矩阵退化提供了依据。该预测模型可以描述疲劳加载过程中的具体损伤模式，有利于分析损伤机理。此外，基于复合材料疲劳损伤理论，适用于预测不同疲劳载荷条件和层形的寿命。\n随着计算机技术的进步，有限元分析（FEA）在复合材料研究中的应用日益广泛。有限元分析的基本思想是将复杂问题离散化为有限个互连的子域进行分析求解。在复合材料领域，研究者已成功将Hashin准则与Murakami-Ohno理论相结合，建立了渐进损伤分析模型，准确地预测了三维编织复合材料的单轴拉伸特性。此外，有限元分析还被应用于热物理性能研究，比较不同结构复合材料的导热系数，并分析各参数对导热性能的影响规律。值得注意的是，随着有限元分析技术的发展，该方法已从早期的拉伸和热物理性能表征，进而扩展到复合材料疲劳行为的研究领域。例如，通过建立代表性体积单元（RVE）预测模型，研究者成功模拟了二维编织复合材料在双轴交替循环载荷下的疲劳寿命。另外，还有研究者基于介尺度代表性晶胞（RUC）模型分析了三维四向编织复合材料的疲劳特性，并研究了编织参数对线性或简化应力状态下疲劳行为的影响。\n这些研究进展为三维复合材料的性能优化和工程应用提供了重要理论基础，特别是通过计算机模拟技术，可以在设计阶段预测材料性能，有效避免过度设计和安全系数过大等问题，对推动三维(3D)复合材料在各工业领域的应用具有重要意义。",
    "reference_list": "考点1：“绒经纤维”必须译为“ warp pile fabrics”不可译为“pile warp fabrics”因为“绒经纤维”的固定表达就是“warp pile fabrics”\n考点2：“增强筋孔”推荐译为“reinforcement rib holes”\n考点3：“模压固化”推荐译为“compression curing”或者“compression molding and curing”，二者选其一即可，保持译文一致性\n考点4：“主控裂纹”必须译为“dominant crack”不可译为“primary crack”因为这种裂纹表示的是会引起纤维结构被完全破坏的裂纹，有固定术语进行表达\n考点5：“三维机织整体成型技术”推荐译为“Integrated 3D Weaving Technology”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "154"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n荔枝花期具有花穗大、花量多等特点，合理调控花朵雌雄比例是荔枝果园保质增产的关键作业环节。为实现荔枝花雌雄快速检测，减少人工统计误差并满足药肥精准调控需求，该文提出一种适合于部署到低功耗嵌入式平台的荔枝花雌雄智能检测方法。该方法采用Multi-Teacher Pre-Activation Features Distillation (MPFD)架构，选用结构相对复杂的YOLOv4、YOLOv5-l作为教师模型，并选用结构相对简单的YOLOv4-Tiny作为学生模型，通过动态学习不同教师模型的中间特征知识，使得学生模型在满足低功耗和实时性等嵌入式平台应用需求的基础上进一步提升其检测性能。该文的主要工作包括：优化激活函数前的蒸馏位置以降低特征蒸馏损失，使用LogCosh-Squared函数作为蒸馏距离损失函数以提高蒸馏性能，采用Margin-Activation的方法使教师模型的更多有效特征传递给学生模型，同时提出采用Conv-GN结构对学生模型进行特征转换以防止有效信息丢失。将蒸馏后的学生模型量化并移植部署到FPGA嵌入式平台，设计实现了荔枝花雌雄快速智能检测系统。实验结果表明，与未经蒸馏的学生模型相比，经过MPFD特征蒸馏后得到的学生模型mAP值提升了4.42%，达到94.21%；移植部署到FPGA嵌入式平台的检测模型大小为5.91 MB，功耗仅为10 W，较服务器平台的检测模型分别降低了73.85%和94.54%，能够更好满足荔枝花雌雄快速检测与精准统计的应用需求。\n荔枝是亚热带地区广泛栽培的特产果树，因其营养丰富、口感好而具有高商业价值[1-2]。荔枝花期较短，具有花穗大、花量多等特征，并且在同一花序中，雌雄花朵异熟异开，雌花比例相对较低。因此，荔枝果园管理要监测花期信息并调控花穗花量，通过药、水、肥合理施用来提高雌花比例，为授粉受精创造有利条件，以提升荔枝坐果率[3-4]。其中，如何快速、精准采集花期信息是荔枝果园科学管理需要解决的必要技术问题。\n近年来，针对荔枝果园花期信息采集与花朵检测等问题，国内外研究人员相继提出了多种基于机器视觉技术的解决方法。针对复杂自然环境下稠密聚集的荔枝花检测需求，熊俊涛等[5]提出了一种检测荔枝花、叶像素的深度语义分割网络，实现了自然环境下的荔枝花、叶等目标分割。Lin等[6]利用无人机（UAV）图像与计算机视觉技术，结合YOLOv4模型和方程拟合的方式，构建了单棵荔枝树上花簇和花丛数量的估测模型，实现了自然环境下荔枝花簇和花丛的数量自动统计。为了更好的统计荔枝花期开花强度以实现产量估计，Lin等[7]将荔枝花数及其密度图进行组合，通过使用雄性荔枝花的图像作为多列卷积神经网络的输入，生成荔枝花的密度图和数量，实现了一种优于目标检测的荔枝雄花计数方法。Ye等[8]提出了一种聚集损失和分割损失相结合的聚合损失函数，提高了检测密集花朵的鲁棒性，实现了密集环境下的荔枝花朵识别。针对其他果园花期信息采集需求，Ambrozio等[9]和Sun等[10]为了检测自然环境下落叶果树的花朵，分别应用语义分割方法，提出了端到端的残留卷积神经网络和微调后）的DeepLab-ResNet网络，实现了面向苹果、梨和桃等多场景花朵的自动检测。Wu等[11]结合通道剪枝方法提出改进YOLOv4模型，并将其应用于自然环境下不同果树品种和光照方向的苹果花检测。Dorj等[12]和Lyu等[13]分别应用颜色检测算法和级联融合的目标检测方法，设计了能够在自然环境下自动检测柑橘花的嵌入式系统。\n当前的相关研究验证了自然环境下应用机器视觉技术采集荔枝花朵、果实及病虫害等信息的可行性[14-16]。然而, 荔枝花期信息统计工作存在一定困难。一方面，荔枝花量多，单支花穗的花朵数量可达数千朵，花朵目标小且相互遮挡[17-18]；另一方面，受品种、树龄、气候等条件影响，不同荔枝果园的花穗花量存在显著差异，并且荔枝花期具有多批次开花的特点 [19-20]。因此，仅对荔枝花期内单一时刻的花穗花量进行检测缺少统计学意义。一般地，园艺专家会选取若干典型花穗，并使用高密度尼龙网进行套袋，待花朵全部自然脱落后，再对荔枝干花进行人工统计。另外, 为提升统计效率，收集到的荔枝花通常先人工区分为雌、雄集合，再采用称重的方式估算花量和雌雄比例，但这不可避免将导致统计数据误差。因此，研究如何实现荔枝花快速检测与精准统计更加符合荔枝果园花期信息采集的实际应用需求。",
    "ori_text": "\n\n荔枝花期具有花穗大、花量多等特点，合理调控花朵雌雄比例是荔枝果园保质增产的关键作业环节。为实现荔枝花雌雄快速检测，减少人工统计误差并满足药肥精准调控需求，该文提出一种适合于部署到低功耗嵌入式平台的荔枝花雌雄智能检测方法。该方法采用Multi-Teacher Pre-Activation Features Distillation (MPFD)架构，选用结构相对复杂的YOLOv4、YOLOv5-l作为教师模型，并选用结构相对简单的YOLOv4-Tiny作为学生模型，通过动态学习不同教师模型的中间特征知识，使得学生模型在满足低功耗和实时性等嵌入式平台应用需求的基础上进一步提升其检测性能。该文的主要工作包括：优化激活函数前的蒸馏位置以降低特征蒸馏损失，使用LogCosh-Squared函数作为蒸馏距离损失函数以提高蒸馏性能，采用Margin-Activation的方法使教师模型的更多有效特征传递给学生模型，同时提出采用Conv-GN结构对学生模型进行特征转换以防止有效信息丢失。将蒸馏后的学生模型量化并移植部署到FPGA嵌入式平台，设计实现了荔枝花雌雄快速智能检测系统。实验结果表明，与未经蒸馏的学生模型相比，经过MPFD特征蒸馏后得到的学生模型mAP值提升了4.42%，达到94.21%；移植部署到FPGA嵌入式平台的检测模型大小为5.91 MB，功耗仅为10 W，较服务器平台的检测模型分别降低了73.85%和94.54%，能够更好满足荔枝花雌雄快速检测与精准统计的应用需求。\n荔枝是亚热带地区广泛栽培的特产果树，因其营养丰富、口感好而具有高商业价值[1-2]。荔枝花期较短，具有花穗大、花量多等特征，并且在同一花序中，雌雄花朵异熟异开，雌花比例相对较低。因此，荔枝果园管理要监测花期信息并调控花穗花量，通过药、水、肥合理施用来提高雌花比例，为授粉受精创造有利条件，以提升荔枝坐果率[3-4]。其中，如何快速、精准采集花期信息是荔枝果园科学管理需要解决的必要技术问题。\n近年来，针对荔枝果园花期信息采集与花朵检测等问题，国内外研究人员相继提出了多种基于机器视觉技术的解决方法。针对复杂自然环境下稠密聚集的荔枝花检测需求，熊俊涛等[5]提出了一种检测荔枝花、叶像素的深度语义分割网络，实现了自然环境下的荔枝花、叶等目标分割。Lin等[6]利用无人机（UAV）图像与计算机视觉技术，结合YOLOv4模型和方程拟合的方式，构建了单棵荔枝树上花簇和花丛数量的估测模型，实现了自然环境下荔枝花簇和花丛的数量自动统计。为了更好的统计荔枝花期开花强度以实现产量估计，Lin等[7]将荔枝花数及其密度图进行组合，通过使用雄性荔枝花的图像作为多列卷积神经网络的输入，生成荔枝花的密度图和数量，实现了一种优于目标检测的荔枝雄花计数方法。Ye等[8]提出了一种聚集损失和分割损失相结合的聚合损失函数，提高了检测密集花朵的鲁棒性，实现了密集环境下的荔枝花朵识别。针对其他果园花期信息采集需求，Ambrozio等[9]和Sun等[10]为了检测自然环境下落叶果树的花朵，分别应用语义分割方法，提出了端到端的残留卷积神经网络和微调后）的DeepLab-ResNet网络，实现了面向苹果、梨和桃等多场景花朵的自动检测。Wu等[11]结合通道剪枝方法提出改进YOLOv4模型，并将其应用于自然环境下不同果树品种和光照方向的苹果花检测。Dorj等[12]和Lyu等[13]分别应用颜色检测算法和级联融合的目标检测方法，设计了能够在自然环境下自动检测柑橘花的嵌入式系统。\n当前的相关研究验证了自然环境下应用机器视觉技术采集荔枝花朵、果实及病虫害等信息的可行性[14-16]。然而, 荔枝花期信息统计工作存在一定困难。一方面，荔枝花量多，单支花穗的花朵数量可达数千朵，花朵目标小且相互遮挡[17-18]；另一方面，受品种、树龄、气候等条件影响，不同荔枝果园的花穗花量存在显著差异，并且荔枝花期具有多批次开花的特点 [19-20]。因此，仅对荔枝花期内单一时刻的花穗花量进行检测缺少统计学意义。一般地，园艺专家会选取若干典型花穗，并使用高密度尼龙网进行套袋，待花朵全部自然脱落后，再对荔枝干花进行人工统计。另外, 为提升统计效率，收集到的荔枝花通常先人工区分为雌、雄集合，再采用称重的方式估算花量和雌雄比例，但这不可避免将导致统计数据误差。因此，研究如何实现荔枝花快速检测与精准统计更加符合荔枝果园花期信息采集的实际应用需求。",
    "reference_list": "考点1：“花穗” 推荐译为 panicle（植物学术语，荔枝花为圆锥花序），避免使用不准确的 “flower spike”。\n考点2：“移植部署” 必须译为 port and deploy（在技术语境中同时指代码/模型移植并部署运行）。\n考点3：“人工统计误差” 必须译为 manual counting error(s)，在涉及手工计数场景时优先用 counting，避免笼统用 statistical。\n考点4：“模型量化” 推荐译为 model quantization（名词）或 quantize the model（动词），根据句式选择。\n考点5：“病虫害” 必须译为 diseases and pests，避免遗漏“diseases”或误译为“insects”。\n考点6：“合理调控” 必须译为 proper regulation 或 effective regulation，避免直译为 “reasonable regulation”。\n考点7：“合理施用” 必须译为 proper application 或 appropriate application，避免直译为 “reasonable application”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "117"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\n1.5.1 Boeing 787 Dreamliner\nThe Boeing 787 Dreamliner (Fig. 1.5A) is a family of long-range, midsize wide-body, twin-engine jet airliners that can seat 242–335 passengers in a typical three-class seating configuration. This aircraft, the world’s first major commercial airliner to use composite materials as the primary material in its airframe, is Boeing’s most fuel-efficient airliner [11]. The Boeing 787 maiden flight took place on December 15, 2009 and completed flight testing in mid-2011. Final Federal Aviation Administration (FAA) and European Aviation Safety Agency (EASA) type certification was received in August 2011 and the first 787-8 model was delivered to All Nippon Airways in September 2011.\n\nThe Boeing 787 aircraft is 80% composite by volume. By weight, the material contents is 50% composite, 20% aluminum, 15% titanium, 10% steel, and 5% other [11]. Aluminum is used for the wing and tail leading edges; titanium is used mainly on engines and fasteners, with steel used in various areas.\n\nEach Boeing 787 aircraft contains approximately 32,000 kg of CFRP composites, made with 23 t of carbon fiber [11]. Composites are used on fuselage, wings, tail, doors, and interior. Boeing 787 fuselage sections are laid up on huge rotating mandrels (Fig. 1.6A). AFP and ATL robotic heads robotically layers of carbon-fiber epoxy resin prepreg to contoured surfaces. Reinforcing fibers are oriented in specific directions to deliver maximum strength along maximum load paths. The fuselage sections are cured in huge autoclaves. The resulting monocoque shell has internal longitudinal stiffeners already built in (Fig. 1.6B and C). This highly integrated structure requires orders of magnitude less fasteners than the conventional built-up airframes. Similar composite manufacturing techniques are applied to the wings.\n\n5.5.3 Technical contribution to performance\nAir-vehicle performance is technology-based, and as technology evolves so performance is improved. This links to a gradual change in airliner design criteria, and while aircraft configuration has been relatively static, the shape of airliners has changed subtly in recent decades. It could change remarkably over coming years as new performance demands are made by customers.\n\nA new structural material having the most influence is carbon-fibre reinforced plastic (CFRP). The Airbus A380 uses some all-CFRP components and has a large proportion of the fuselage manufactured using a unique aluminium/reinforced-plastic sandwich (trade name ‘Glare’), while the newer Boeing 787 Dreamliner and its even newer Airbus equivalent aircraft, the A350, will use carbon-fibre extensively. The Boeing design is in a more advanced state of development and is anticipated to have an almost all-CFRP fuselage shell and CFRP wings. Airbus A350 plans are based on a similar technological basis.\n\nCFRP offers durability and is relatively light. The designers have to exploit the potential weight saving with care. For the 787 Dreamliner Boeing has allied airline requests for fuel efficiency improvements with a desire stemming from other areas of concern in the airports and airspace environments to offer more flexibility in operations. This is an early indication of the needs of the air transport system as a whole taking a part in the debates that range outside their direct area of interest. Boeing believe that the 787 will offer better fuel efficiency over a wide combination of payload and range values, and they also believe that being a smaller aircraft than most current long-haul types it will offer the opportunity for more point-to-point operations. The analysis of route networks in Chapter 1 has shown that airline hubbing is often the reason that some airports become congested, while others see their direct-route possibilities diminished. The 787 is being marketed as an aircraft capable of making hubs a thing of the past and opening more direct routes. The converse solution is to offer more capacity per movement at hubs, which is where the 600-800-seat A380 will be exploited. The reality will be, surely, that both types will make their mark.\n\nWhere the 787 is particularly significant is that the design is using the new technology adroitly. The aircraft wing is very flexible and in its detail it is indicative of a push to achieve a higher aerodynamic efficiency (a higher lift- to-drag ratio). This will reduce fuel-burn, and will be improved by using engines that are achieving better fuel-burn performance than earlier generation engines. The combination of aerodynamic and propulsion system improvements should set a new benchmark, and on preliminary performance data released by Boeing (at September 2005), the fuel efficiency at the maximum payload-range point was shown to be 33% improved on the 777-200LR. There is probably some optimism in this figure.\n\nThis has been achieved in one generation (there was an interval of about 15 years between the launch of 777 and 787 as projects), and exemplifies not just commitment by the manufacturers and their major suppliers to achieving significant environmental improvement but also in exploiting technology. In so doing, they do not minimise the cash-flow on their programmes and the risks they take are considerable. Most major companies involved in airliner design and suppliers such as aeroengine companies all delicately tread the lines that delineate technical and financial risk.\n\nAircraft efficiency is measurable in many ways. Some tabulated data regarding leading features of some significant aircraft types that have been introduced over the last 40 years are presented in Table 5.5 to exemplify briefly how some intuitive, and sometimes counter-intuitive, developments have taken place. Behind each of the strides that has been made in the evolutionary tale there is always also a tale of risk management on a grand scale.\n\nFuel fraction is a measure of the maximum fuel load as a proportion of the maximum take-off weight and is often quoted as a measure of technical efficiency. In the course of their life, short-medium-haul aircraft tend to complete more flights than long-haul aircraft and are more robust in terms of their construction. The consequence is that the fuel fraction is always lower than that of long-haul aircraft. (The differentiation is not so clear-cut, and the Boeing 757–200 and 767–400 are aircraft capable of trans- Atlantic operations and their fuel fraction is noticeably higher than other aircraft in their category.)\n\nListing the selected types in date order emphasises the fact that fuel fraction is not tending to rise, although it was expected that it would as lighter-weight structural materials became available. The observation is that as more fuel-efficient engines have been developed, the necessary range performance has been attained with smaller and less heavy aircraft.\n\nThe tendency for the key aerodynamic efficiency indicator, the wing aspect ratio, to rise with time is evident, albeit the rate of increase is slow. There are always exceptions to the rule. The A380 has a relatively low aspect ratio, which is attributable to the need to provide a given wing area but to fit into an apron stand ‘footprint’ that is 80 metres square. Hence aerodynamic efficiency has been compromised in order to make the aircraft compatible with modern airports.",
    "ori_text": "1.5.1 Boeing 787 Dreamliner\nThe Boeing 787 Dreamliner (Fig. 1.5A) is a family of long-range, midsize wide-body, twin-engine jet airliners that can seat 242–335 passengers in a typical three-class seating configuration. This aircraft, the world’s first major commercial airliner to use composite materials as the primary material in its airframe, is Boeing’s most fuel-efficient airliner [11]. The Boeing 787 maiden flight took place on December 15, 2009 and completed flight testing in mid-2011. Final Federal Aviation Administration (FAA) and European Aviation Safety Agency (EASA) type certification was received in August 2011 and the first 787-8 model was delivered to All Nippon Airways in September 2011.\n\nThe Boeing 787 aircraft is 80% composite by volume. By weight, the material contents is 50% composite, 20% aluminum, 15% titanium, 10% steel, and 5% other [11]. Aluminum is used for the wing and tail leading edges; titanium is used mainly on engines and fasteners, with steel used in various areas.\n\nEach Boeing 787 aircraft contains approximately 32,000 kg of CFRP composites, made with 23 t of carbon fiber [11]. Composites are used on fuselage, wings, tail, doors, and interior. Boeing 787 fuselage sections are laid up on huge rotating mandrels (Fig. 1.6A). AFP and ATL robotic heads robotically layers of carbon-fiber epoxy resin prepreg to contoured surfaces. Reinforcing fibers are oriented in specific directions to deliver maximum strength along maximum load paths. The fuselage sections are cured in huge autoclaves. The resulting monocoque shell has internal longitudinal stiffeners already built in (Fig. 1.6B and C). This highly integrated structure requires orders of magnitude less fasteners than the conventional built-up airframes. Similar composite manufacturing techniques are applied to the wings.\n\n5.5.3 Technical contribution to performance\nAir-vehicle performance is technology-based, and as technology evolves so performance is improved. This links to a gradual change in airliner design criteria, and while aircraft configuration has been relatively static, the shape of airliners has changed subtly in recent decades. It could change remarkably over coming years as new performance demands are made by customers.\n\nA new structural material having the most influence is carbon-fibre reinforced plastic (CFRP). The Airbus A380 uses some all-CFRP components and has a large proportion of the fuselage manufactured using a unique aluminium/reinforced-plastic sandwich (trade name ‘Glare’), while the newer Boeing 787 Dreamliner and its even newer Airbus equivalent aircraft, the A350, will use carbon-fibre extensively. The Boeing design is in a more advanced state of development and is anticipated to have an almost all-CFRP fuselage shell and CFRP wings. Airbus A350 plans are based on a similar technological basis.\n\nCFRP offers durability and is relatively light. The designers have to exploit the potential weight saving with care. For the 787 Dreamliner Boeing has allied airline requests for fuel efficiency improvements with a desire stemming from other areas of concern in the airports and airspace environments to offer more flexibility in operations. This is an early indication of the needs of the air transport system as a whole taking a part in the debates that range outside their direct area of interest. Boeing believe that the 787 will offer better fuel efficiency over a wide combination of payload and range values, and they also believe that being a smaller aircraft than most current long-haul types it will offer the opportunity for more point-to-point operations. The analysis of route networks in Chapter 1 has shown that airline hubbing is often the reason that some airports become congested, while others see their direct-route possibilities diminished. The 787 is being marketed as an aircraft capable of making hubs a thing of the past and opening more direct routes. The converse solution is to offer more capacity per movement at hubs, which is where the 600-800-seat A380 will be exploited. The reality will be, surely, that both types will make their mark.\n\nWhere the 787 is particularly significant is that the design is using the new technology adroitly. The aircraft wing is very flexible and in its detail it is indicative of a push to achieve a higher aerodynamic efficiency (a higher lift- to-drag ratio). This will reduce fuel-burn, and will be improved by using engines that are achieving better fuel-burn performance than earlier generation engines. The combination of aerodynamic and propulsion system improvements should set a new benchmark, and on preliminary performance data released by Boeing (at September 2005), the fuel efficiency at the maximum payload-range point was shown to be 33% improved on the 777-200LR. There is probably some optimism in this figure.\n\nThis has been achieved in one generation (there was an interval of about 15 years between the launch of 777 and 787 as projects), and exemplifies not just commitment by the manufacturers and their major suppliers to achieving significant environmental improvement but also in exploiting technology. In so doing, they do not minimise the cash-flow on their programmes and the risks they take are considerable. Most major companies involved in airliner design and suppliers such as aeroengine companies all delicately tread the lines that delineate technical and financial risk.\n\nAircraft efficiency is measurable in many ways. Some tabulated data regarding leading features of some significant aircraft types that have been introduced over the last 40 years are presented in Table 5.5 to exemplify briefly how some intuitive, and sometimes counter-intuitive, developments have taken place. Behind each of the strides that has been made in the evolutionary tale there is always also a tale of risk management on a grand scale.\n\nFuel fraction is a measure of the maximum fuel load as a proportion of the maximum take-off weight and is often quoted as a measure of technical efficiency. In the course of their life, short-medium-haul aircraft tend to complete more flights than long-haul aircraft and are more robust in terms of their construction. The consequence is that the fuel fraction is always lower than that of long-haul aircraft. (The differentiation is not so clear-cut, and the Boeing 757–200 and 767–400 are aircraft capable of trans- Atlantic operations and their fuel fraction is noticeably higher than other aircraft in their category.)\n\nListing the selected types in date order emphasises the fact that fuel fraction is not tending to rise, although it was expected that it would as lighter-weight structural materials became available. The observation is that as more fuel-efficient engines have been developed, the necessary range performance has been attained with smaller and less heavy aircraft.\n\nThe tendency for the key aerodynamic efficiency indicator, the wing aspect ratio, to rise with time is evident, albeit the rate of increase is slow. There are always exceptions to the rule. The A380 has a relatively low aspect ratio, which is attributable to the need to provide a given wing area but to fit into an apron stand ‘footprint’ that is 80 metres square. Hence aerodynamic efficiency has been compromised in order to make the aircraft compatible with modern airports.",
    "reference_list": "考点1：“All Nippon Airways”需译为“全日空航空”，译为“全日本航空”算错误\n考点2：“titanium”推荐译为“钛”\n考点3：“robotically”推荐译为“自动”\n考点4：“longitudinal stiffeners”推荐译为“纵向加劲肋”\n考点5：“The designers have to exploit the potential weight saving with care”推荐译为“设计师在挖掘其减重潜力时，必须十分谨慎。”\n考点6：“payload”推荐译为“有效载荷”\n考点7：“making hubs a thing of the past”推荐译为“打破枢纽束缚”\n考点8：“flexible”推荐译为“柔韧”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "9"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n　The city of Rome had sustained little diminution in her architectural splendour, when the setting sun shed his parting beams, as if with prophetic significance, upon the gilded roof of the venerable capitol, on the evening of the 24th of August, A.D. 410. The temple of Jupiter, though shorn of some of the dazzling ornaments with which the emperor Domitian had adorned its portals and pediments, still remained an imposing monument of the ancient paganism of the Imperial City. Other costly temples and public buildings, clustered around that seat of Roman pride and greatness, and met and charmed the eye of the citizen, as he ascended the slope of the Capitoline Hill. With a lordly air, these noble structures threw their long shadows over the spacious forum, where, of old, the sons of the republic had been accustomed to gather in crowds around the rostrum, to listen to the speeches of their orators; and where still the degenerate Roman was reminded of the deeds of his fathers, by the monuments of patriotism and victory which were strewn around him. On that evening, might be seen many a citizen and foreigner passing to and fro, along its stately colonnades, or reclining at his ease upon the marble seats; and in whatever direction he went, on leaving that far-famed spot, he passed through squares and streets which were adorned with temples, palaces, and baths, such as could have been erected in no city but one that had enriched itself with the spoils of the whole world. In short, Rome had undergone but little alteration since the eastern emperor Constantius, fifty years before, on visiting the city of his fathers, had been overwhelmed with astonishment at its surpassing magnificence. An historian of that period,[1] describing the visit in that inflated style which is so characteristic of the age, observes; \"As Constantius viewed the seven-hilled city, with its valleys and suburban districts, every object around him seemed to shine with transcendent splendour:—the temple of Tarpeian Jove exceeding everything he had beheld, as much as a Divine production could exceed the works of man; the spacious baths spreading around like provinces; the Amphitheatre with its solid walls of Tiburtine marble, and so lofty, that the eye is fatigued in looking upward to its summit; the Pantheon with its vast circular space, arched over by a magnificent dome; and its lofty pediments rising one above another, and crowned with statues of Roman heroes; the Forum and Temple of Peace; the Theatre of Pompey; the Musical Hall; the Stadia, and other imposing objects in the Eternal City. But when he came to the Forum of Trajan—the most astonishing structure under the face of heaven, and, as I conceive, wonderful in the estimation of the deities themselves—he was struck with astonishment, while considering its gigantic buildings, which are not to be described in language, or again to be equalled by mortal skill. Discarding the idea of erecting another forum like that, he thought that he might rear an equestrian statue, which should resemble the colossal horse of Trajan; but this design he also abandoned, upon hearing it remarked by the prince, Hormisdas, 'If you would succeed in having a similar horse, you must first provide a similar stable,'\" Such was the grandeur of ancient Rome; and it was probably with feelings of admiration like those of the emperor and his historian, that many a citizen returned from the baths and the forums to his own dwelling on the eventful evening in question. Gradually the sounds of business, and the murmur of voices in the streets died away: and as the stars shone forth in the face of heaven, the mighty city slept in silence. But it was a silence soon to be disturbed.\nAt the midnight hour, a blast of trumpets like the roar of thunder reverberated from hill to hill, and woke up myriads of the inhabitants from their deep slumbers—it was the signal that Alaric the Goth, with his mighty army, had entered Rome.\nTwo years before the barbarian general had besieged the city. Swayed by what he conceived a supernatural impulse, he led his victorious troops down the passes of the Apennines, upon the rich plains of Italy. A pious monk, it is said, met the warrior on his way, and exhorted him to refrain from his expedition; but he replied, \"I am urged on in spite of myself, by an irresistible impulse which is continually saving to me, 'March to Rome, and desolate the city.'\"[2] Thus, prompted by his ambition, he fulfilled his destiny, and wreaked a fearful amount of vengeance on the heads of the Romans, for the wrongs which they had inflicted upon others. Twice did he blockade the gates of Rome, and subdue the proud masters of the world. During the first siege, the terrors of famine and pestilence reduced the senate to submission, and the conqueror agreed to raise the siege, only upon the condition of his being paid a very large ransom. Negotiations for peace with the emperor Honorius, who was then at Ravenna, having failed, Alaric returned to Rome, and again pitched his camp before the walls. The remembrance of their calamities, during the former siege, constrained the people once more to yield; when the Gothic warrior insisted upon their renouncing allegiance to Honorius, and imposed upon them a new emperor in the person of Attalus, the prefect of the city. But it was not long before the latter forfeited the confidence of his master, and Alaric immediately proceeded publicly to strip him of the imperial purple. The Goth, after this circumstance, renewed his negotiations with the court of Ravenna; but being insulted by the heralds, and attacked by the troops of Honorius, he turned his army a third time towards the gates of Rome.[3]\nHistorians inform us, that it was by an act of treachery, that Alaric was now admitted into the city; but no satisfactory information can be obtained respecting the particulars of the important transaction. The Gothic trumpet, however, at the Salarian gate, the march of the enemy along the great highway, and the flames issuing from the palace of Sallust—which was fired by the troops, as soon as they entered within the walls—proclaimed that Rome, the Queen of Cities, after the lapse of nearly eight hundred years from her invasion by the Gauls, was once more in the hands of a barbarian foe. Although the Romans had been aware of the vicinity of Alaric, yet, lulled into a state of false security, they did not anticipate any assault, and the senators were quietly slumbering in their beds when the enemy entered the city. Fearful were the scenes enacted; and well might Jerome apply to it the lines of Virgil, in reference to the sack of Troy:\n\"What tongue can tell the slaughter of that night?\nWhat eyes can weep the sorrow and affright?\nAn ancient and imperial city falls—\nThe streets are fill'd with frequent funerals;\nHouses and holy temples float in blood,\nAnd hostile nations made a common flood;\nAll parts resound with tumults, plaints, and fears,\nAna grisly death in sundry shapes appears.\"\n \nThe cruel and licentious soldiery made a dreadful slaughter of the Roman people, and violated many a matron and virgin. The horrors of the invasion were further heightened by the excesses which were practised by forty thousand slaves, who now broke loose from the authority of their masters, and retaliated, on them and their families, the wrongs which themselves and their predecessors had endured through ages of oppression. But it is acknowledged by all writers, that Alaric—who was himself an Arian—showed some considerable regard for the Christians of the city, and spared the churches where they met for worship. Indeed he appointed the edifices, which had been dedicated to the apostles Peter and Paul, as places of refuge for the terrified Christian inhabitants, and gave strict orders that those who fled there for sanctuary, should be protected from injury. Instances illustrative of the forbearance of the soldiers, and of their respect not only for the persons of the Christians but for the consecrated vessels which they employed in their worship, are afforded us by the historians of those times. Orosius gives us a graphic description of a long train of Christians, carrying on their heads the communion-plate of gold and silver, and singing their sacred hymns, who were escorted in safety, by the Gothic soldiers, through the streets of the ravaged city, to the church of St. Peter. He speaks also of many of the barbarians, and the pagan Romans, uniting in these songs, and joining in the solemn procession; and represents the latter as saving themselves from vengeance, by taking shelter beneath the wing of the Christian faith.",
    "ori_text": "　The city of Rome had sustained little diminution in her architectural splendour, when the setting sun shed his parting beams, as if with prophetic significance, upon the gilded roof of the venerable capitol, on the evening of the 24th of August, A.D. 410. The temple of Jupiter, though shorn of some of the dazzling ornaments with which the emperor Domitian had adorned its portals and pediments, still remained an imposing monument of the ancient paganism of the Imperial City. Other costly temples and public buildings, clustered around that seat of Roman pride and greatness, and met and charmed the eye of the citizen, as he ascended the slope of the Capitoline Hill. With a lordly air, these noble structures threw their long shadows over the spacious forum, where, of old, the sons of the republic had been accustomed to gather in crowds around the rostrum, to listen to the speeches of their orators; and where still the degenerate Roman was reminded of the deeds of his fathers, by the monuments of patriotism and victory which were strewn around him. On that evening, might be seen many a citizen and foreigner passing to and fro, along its stately colonnades, or reclining at his ease upon the marble seats; and in whatever direction he went, on leaving that far-famed spot, he passed through squares and streets which were adorned with temples, palaces, and baths, such as could have been erected in no city but one that had enriched itself with the spoils of the whole world. In short, Rome had undergone but little alteration since the eastern emperor Constantius, fifty years before, on visiting the city of his fathers, had been overwhelmed with astonishment at its surpassing magnificence. An historian of that period,[1] describing the visit in that inflated style which is so characteristic of the age, observes; \"As Constantius viewed the seven-hilled city, with its valleys and suburban districts, every object around him seemed to shine with transcendent splendour:—the temple of Tarpeian Jove exceeding everything he had beheld, as much as a Divine production could exceed the works of man; the spacious baths spreading around like provinces; the Amphitheatre with its solid walls of Tiburtine marble, and so lofty, that the eye is fatigued in looking upward to its summit; the Pantheon with its vast circular space, arched over by a magnificent dome; and its lofty pediments rising one above another, and crowned with statues of Roman heroes; the Forum and Temple of Peace; the Theatre of Pompey; the Musical Hall; the Stadia, and other imposing objects in the Eternal City. But when he came to the Forum of Trajan—the most astonishing structure under the face of heaven, and, as I conceive, wonderful in the estimation of the deities themselves—he was struck with astonishment, while considering its gigantic buildings, which are not to be described in language, or again to be equalled by mortal skill. Discarding the idea of erecting another forum like that, he thought that he might rear an equestrian statue, which should resemble the colossal horse of Trajan; but this design he also abandoned, upon hearing it remarked by the prince, Hormisdas, 'If you would succeed in having a similar horse, you must first provide a similar stable,'\" Such was the grandeur of ancient Rome; and it was probably with feelings of admiration like those of the emperor and his historian, that many a citizen returned from the baths and the forums to his own dwelling on the eventful evening in question. Gradually the sounds of business, and the murmur of voices in the streets died away: and as the stars shone forth in the face of heaven, the mighty city slept in silence. But it was a silence soon to be disturbed.\nAt the midnight hour, a blast of trumpets like the roar of thunder reverberated from hill to hill, and woke up myriads of the inhabitants from their deep slumbers—it was the signal that Alaric the Goth, with his mighty army, had entered Rome.\nTwo years before the barbarian general had besieged the city. Swayed by what he conceived a supernatural impulse, he led his victorious troops down the passes of the Apennines, upon the rich plains of Italy. A pious monk, it is said, met the warrior on his way, and exhorted him to refrain from his expedition; but he replied, \"I am urged on in spite of myself, by an irresistible impulse which is continually saving to me, 'March to Rome, and desolate the city.'\"[2] Thus, prompted by his ambition, he fulfilled his destiny, and wreaked a fearful amount of vengeance on the heads of the Romans, for the wrongs which they had inflicted upon others. Twice did he blockade the gates of Rome, and subdue the proud masters of the world. During the first siege, the terrors of famine and pestilence reduced the senate to submission, and the conqueror agreed to raise the siege, only upon the condition of his being paid a very large ransom. Negotiations for peace with the emperor Honorius, who was then at Ravenna, having failed, Alaric returned to Rome, and again pitched his camp before the walls. The remembrance of their calamities, during the former siege, constrained the people once more to yield; when the Gothic warrior insisted upon their renouncing allegiance to Honorius, and imposed upon them a new emperor in the person of Attalus, the prefect of the city. But it was not long before the latter forfeited the confidence of his master, and Alaric immediately proceeded publicly to strip him of the imperial purple. The Goth, after this circumstance, renewed his negotiations with the court of Ravenna; but being insulted by the heralds, and attacked by the troops of Honorius, he turned his army a third time towards the gates of Rome.[3]\nHistorians inform us, that it was by an act of treachery, that Alaric was now admitted into the city; but no satisfactory information can be obtained respecting the particulars of the important transaction. The Gothic trumpet, however, at the Salarian gate, the march of the enemy along the great highway, and the flames issuing from the palace of Sallust—which was fired by the troops, as soon as they entered within the walls—proclaimed that Rome, the Queen of Cities, after the lapse of nearly eight hundred years from her invasion by the Gauls, was once more in the hands of a barbarian foe. Although the Romans had been aware of the vicinity of Alaric, yet, lulled into a state of false security, they did not anticipate any assault, and the senators were quietly slumbering in their beds when the enemy entered the city. Fearful were the scenes enacted; and well might Jerome apply to it the lines of Virgil, in reference to the sack of Troy:\n\"What tongue can tell the slaughter of that night?\nWhat eyes can weep the sorrow and affright?\nAn ancient and imperial city falls—\nThe streets are fill'd with frequent funerals;\nHouses and holy temples float in blood,\nAnd hostile nations made a common flood;\nAll parts resound with tumults, plaints, and fears,\nAna grisly death in sundry shapes appears.\"\n \nThe cruel and licentious soldiery made a dreadful slaughter of the Roman people, and violated many a matron and virgin. The horrors of the invasion were further heightened by the excesses which were practised by forty thousand slaves, who now broke loose from the authority of their masters, and retaliated, on them and their families, the wrongs which themselves and their predecessors had endured through ages of oppression. But it is acknowledged by all writers, that Alaric—who was himself an Arian—showed some considerable regard for the Christians of the city, and spared the churches where they met for worship. Indeed he appointed the edifices, which had been dedicated to the apostles Peter and Paul, as places of refuge for the terrified Christian inhabitants, and gave strict orders that those who fled there for sanctuary, should be protected from injury. Instances illustrative of the forbearance of the soldiers, and of their respect not only for the persons of the Christians but for the consecrated vessels which they employed in their worship, are afforded us by the historians of those times. Orosius gives us a graphic description of a long train of Christians, carrying on their heads the communion-plate of gold and silver, and singing their sacred hymns, who were escorted in safety, by the Gothic soldiers, through the streets of the ravaged city, to the church of St. Peter. He speaks also of many of the barbarians, and the pagan Romans, uniting in these songs, and joining in the solemn procession; and represents the latter as saving themselves from vengeance, by taking shelter beneath the wing of the Christian faith.",
    "reference_list": "考点1：【capitol】应译为 “卡比托利欧山/卡比托利欧”\n考点2：【Constantius】 应译为 “君士坦提乌斯”\n考点3：【portals and pediments】 应译为 “门廊与山花”\n考点4：【sons of the republic】 应译为 “共和国的子民”\n考点5：【eastern emperor】 应译为 “东罗马皇帝”",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "小说",
    "prompt_id": "78"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nAbstract:\n     America’s history of literature began with the swarming in of immigrants with different background and cultures. After that, American literature had been greatly influenced by the European culture for a long period. It was not until America’s independence, did Americans realized that they need national literature strongly, and American literature began to developed. The Civil War was a watershed in the history, after which American literature entered a period of full blooming. Romantics, which emphasized individualism and intuition and Tnscendentalism represented by Emerson came out into being. This was an exciting period in the history of American literature. Like the flowers of spring, there were suddenly many different kinds of writing at the same time. They have given depth and strength to American literature, and accelerated the forming of High Romantics. But due to the influence of Civil War, the American society was in a turbulent situation. The writings about local life, critical realism and unveiling the dark side of the society were increased. After The First World War, Americans were at a loss postwar, and the Modern American literature began.\nMy piece of paper is written in chronological order as these periods developed in order to have a clear outline of its progress.\n\nAmerican is a multi-national country. Just like a big container, which put in various kinds of elements. Different cultures, that can not only be co-existed but also form a sharp contrast, mixed together, It makes American literature style has a flavor of distinct and various aesthetic feeling. Many writers come from lower level, which makes American literature has the rich flavor of life and local color. Furthermore, many new styles of literature in the world are oriented in America since 20th century.\n\nThe process of American literature can be divided into following main periods: Colony and Puritan literature; early national literature; latter national literature and Modern literature.\n \n1. Colonial and early American literature\n(1). Travelers and Explorers\nWhen the European explorers first came to this new continent, the native Indians who probably got here from Asia about fifteen thousand years ago were still in origin, and they even had no written language, “The traditional literature was originally transmitted almost entirely by word of mouth, and therefore belongs to the category of oral literature,” (Wu Dingbo, 1) As time past, more and more travelers and explorers swarmed in. They wrote a lot of diaries、letters, and travel accounts to describe the new land as second Eden. No wander somebody said that the earliest American literature were the travel accounts written by European adventurers. Among the most remained were Captain John Smith’s True Relation of Virginia (1608), and Description of New England (1616).\nAlthough most of the Indian history was preserved in tales and songs, they had thoughts about life and nature. They loved the natural world around them deeply, and they believed that when a person was dead, he would give back what had borrowed while he was alive to nature. This kind of philosophy had influenced later or even modern American writers. It’s interesting that when we look at the literature of the Puritans, the Transcendentalists, the Naturalists, and even the Moderns, when we read Anne Bradstreet, Emily Dickinson, Stephen Crane, and Ernest Hemingway, we can find similar themes.\n\n(2) Pilgrim settlements\nSeveral years later, another group of settlers also arrived in the New World. This group was looking for the Jamestown settlement. However, because of bad navigation, they landed in Massachusetts. They were also coming to the New World with dreams of success, but their goal was different from the Jamestown settlement. They wanted to start a new world governed by the Bible. They were called Puritans because they wanted to live a better life by making themselves pure. They first arrived on the Mayflower and settled in Plymouth. This is the group we are usually thinking about when we talk about the \"first Americans.\"\n\nThe clearest history of their journey to the New World can be found in History of Plymouth Plantation (1608) written by William Bradford, who was also one of the Mayflower passengers. The History of Plymouth Plantation is a Puritan book in the best sense. “It’s loosely annalistic, but a direct and simple style gives charm, as a sincere faith in Puritanism gives purity, to the entire book.” (W. P. Trent, 1997)\n\nThe Puritans had several kinds of literature. By far the most common form is the writing related to Biblical teachings, or sermons, that the church leaders wrote. The Puritans believed that they were in the New World because God had brought them there for a special purpose. They thought that by studying the Bible they could learn more about this way of life. So they were very strict to their life, and they didn’t allow any kind of entertainment even in literature. That’s way Wu Dingbo said in his book “Literature of the New England Settlement is mainly a literary expression of the Puritan idealism” and “The literature of the colonial settlement served either God or colonial expansion or both.” (Wu Dingbo, 4)\n\nAnother important form of writing from this period is the histories. These books, like Bradford's History of Plymouth Plantation, are important because they tell us about life at the time of the Puritans.\n\nPeople also wrote many poems. But a lot of works were hidden and lost because people often considered poetry to be an inferior form of writing and not totally acceptable to Puritan thinking.\n\nOne of the most significant poets from this period was Anne Bradstreet (1612-1672). Her poems in Tenth Muse Lately Sprung Up In America (1650) reflected the con concerns of women who came to settle in the colonies, and in all her poems, however, she shows her strong belief in God.\n\n2. 18th century—the Age of reason\n(1) The Age of reason\nIn the 18th century, people believed in man’s own nature and the power of human reason. With Franklin as its spokesman, the 18th century America experienced an age of reason.Words had never been so useful and so important in human history. People wrote a lot of political writings. ",
    "ori_text": "Abstract:\n     America’s history of literature began with the swarming in of immigrants with different background and cultures. After that, American literature had been greatly influenced by the European culture for a long period. It was not until America’s independence, did Americans realized that they need national literature strongly, and American literature began to developed. The Civil War was a watershed in the history, after which American literature entered a period of full blooming. Romantics, which emphasized individualism and intuition and Tnscendentalism represented by Emerson came out into being. This was an exciting period in the history of American literature. Like the flowers of spring, there were suddenly many different kinds of writing at the same time. They have given depth and strength to American literature, and accelerated the forming of High Romantics. But due to the influence of Civil War, the American society was in a turbulent situation. The writings about local life, critical realism and unveiling the dark side of the society were increased. After The First World War, Americans were at a loss postwar, and the Modern American literature began.\nMy piece of paper is written in chronological order as these periods developed in order to have a clear outline of its progress.\n\nAmerican is a multi-national country. Just like a big container, which put in various kinds of elements. Different cultures, that can not only be co-existed but also form a sharp contrast, mixed together, It makes American literature style has a flavor of distinct and various aesthetic feeling. Many writers come from lower level, which makes American literature has the rich flavor of life and local color. Furthermore, many new styles of literature in the world are oriented in America since 20th century.\n\nThe process of American literature can be divided into following main periods: Colony and Puritan literature; early national literature; latter national literature and Modern literature.\n \n1. Colonial and early American literature\n(1). Travelers and Explorers\nWhen the European explorers first came to this new continent, the native Indians who probably got here from Asia about fifteen thousand years ago were still in origin, and they even had no written language, “The traditional literature was originally transmitted almost entirely by word of mouth, and therefore belongs to the category of oral literature,” (Wu Dingbo, 1) As time past, more and more travelers and explorers swarmed in. They wrote a lot of diaries、letters, and travel accounts to describe the new land as second Eden. No wander somebody said that the earliest American literature were the travel accounts written by European adventurers. Among the most remained were Captain John Smith’s True Relation of Virginia (1608), and Description of New England (1616).\nAlthough most of the Indian history was preserved in tales and songs, they had thoughts about life and nature. They loved the natural world around them deeply, and they believed that when a person was dead, he would give back what had borrowed while he was alive to nature. This kind of philosophy had influenced later or even modern American writers. It’s interesting that when we look at the literature of the Puritans, the Transcendentalists, the Naturalists, and even the Moderns, when we read Anne Bradstreet, Emily Dickinson, Stephen Crane, and Ernest Hemingway, we can find similar themes.\n\n(2) Pilgrim settlements\nSeveral years later, another group of settlers also arrived in the New World. This group was looking for the Jamestown settlement. However, because of bad navigation, they landed in Massachusetts. They were also coming to the New World with dreams of success, but their goal was different from the Jamestown settlement. They wanted to start a new world governed by the Bible. They were called Puritans because they wanted to live a better life by making themselves pure. They first arrived on the Mayflower and settled in Plymouth. This is the group we are usually thinking about when we talk about the \"first Americans.\"\n\nThe clearest history of their journey to the New World can be found in History of Plymouth Plantation (1608) written by William Bradford, who was also one of the Mayflower passengers. The History of Plymouth Plantation is a Puritan book in the best sense. “It’s loosely annalistic, but a direct and simple style gives charm, as a sincere faith in Puritanism gives purity, to the entire book.” (W. P. Trent, 1997)\n\nThe Puritans had several kinds of literature. By far the most common form is the writing related to Biblical teachings, or sermons, that the church leaders wrote. The Puritans believed that they were in the New World because God had brought them there for a special purpose. They thought that by studying the Bible they could learn more about this way of life. So they were very strict to their life, and they didn’t allow any kind of entertainment even in literature. That’s way Wu Dingbo said in his book “Literature of the New England Settlement is mainly a literary expression of the Puritan idealism” and “The literature of the colonial settlement served either God or colonial expansion or both.” (Wu Dingbo, 4)\n\nAnother important form of writing from this period is the histories. These books, like Bradford's History of Plymouth Plantation, are important because they tell us about life at the time of the Puritans.\n\nPeople also wrote many poems. But a lot of works were hidden and lost because people often considered poetry to be an inferior form of writing and not totally acceptable to Puritan thinking.\n\nOne of the most significant poets from this period was Anne Bradstreet (1612-1672). Her poems in Tenth Muse Lately Sprung Up In America (1650) reflected the con concerns of women who came to settle in the colonies, and in all her poems, however, she shows her strong belief in God.\n\n2. 18th century—the Age of reason\n(1) The Age of reason\nIn the 18th century, people believed in man’s own nature and the power of human reason. With Franklin as its spokesman, the 18th century America experienced an age of reason.Words had never been so useful and so important in human history. People wrote a lot of political writings. ",
    "reference_list": "考点1：\"Tenth Muse Lately Sprung Up In America\"应译为《在美洲新近出现的第十位缪斯》。\n考点2：\"the Age of reason''应该翻译为“理性主义时代”\n考点3：\"swarming in\"推荐译为“蜂拥而至”。\n考点4：\"Transcendentalism\"推荐译为“超验主义”，是美国文学和哲学史上的一个专有名词。这里应该翻译为“超验主义者”\n考点5： \"second Eden'应译为“第二个伊甸园”。\n考点6：\"High Romantics\"应译为“浪漫主义高潮”。\n考点7：\"Pilgrim settlements\"应译为“清教徒定居点”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "42"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n科技日报记者 薛岩\n记者从中国科协获悉，中国科协生命科学学会联合体开展的年度“中国生命科学十大进展”评选结果揭晓，7个知识创新类和3个技术创新类成果脱颖而出。\n本次入选的研究项目均面向生命科学前沿，面向人民生命健康，聚焦解决热点问题，具有原创性突出、社会意义重大的特点。十大成果分别是：\n一、衰老的时空编程及干预\n衰老是复杂的生物学过程，具有显著时空异质性。在复杂时空背景下，揭示衰老的关键驱动因素和开发安全有效的干预措施，是衰老科学研究面临的重大挑战。中国科学院动物研究所刘光慧、分子细胞科学卓越创新中心周斌、北京基因组研究所张维绮、动物研究所曲静等团队，为衰老研究提供新范式，也为衰老及其相关疾病的临床干预奠定基础，受到国际专业期刊的亮点评价。\n二、新型肠道菌源酶跨界调控代谢性疾病的作用机制与防治新策略\n肠道菌群与疾病发生发展密切相关，但目前靶向菌群多为整体性干预措施，缺乏特异性治疗策略，如何精准调控肠道菌群是国际生命科学研究的前沿问题。北京大学姜长涛、乔杰及山东大学刘双江团队等合作，提出“肠道菌源酶跨界调控宿主稳态”新理论，开发点击代谢组学技术等。团队进一步围绕BAS-suc开展了工程菌构建、激动剂开发等系列临床转化研究，开辟了代谢性疾病干预新路径。\n三、通用型CAR-T细胞治疗复发难治性自身免疫性疾病\n长期以来，彻底治愈红斑狼疮、硬皮病、多发性硬化症等自身免疫性疾病，是全球共同面临的医学难题。现有免疫抑制药物虽然可在一定程度上缓解病情，却不能完全阻止疾病的进展，反而可能带来使人虚弱的副作用。由中国人民解放军海军军医大学长征医院徐沪济领衔、联合华东师范大学杜冰、刘明耀团队以及上海邦耀生物科技有限公司，采用我国自主研发的异体CAR-T细胞开展临床研究，在全球首次成功治愈了严重自身免疫性疾病。\n四、异染色质形成机制\n旁着丝粒区域由快速演化且高度重复的卫星序列组成，该区域在不同物种间均以异染色质状态存在。然而，两个长期的未解之谜是“旁着丝粒区是怎样被识别并起始异染色质形成的”以及“不同物种间不保守的卫星序列是如何被保守的分子机器所识别的”。中国科学院生物物理研究所朱冰团队发现，保守的锌指蛋白ZNF512利用其非连续排布的锌指结构域识别富集于旁着丝粒区内的保守的不连续的TTC序列元件，并直接招募SUV39H家族蛋白，从而起始异染色质形成。在回答了近百年的科学困惑的同时，本发现也为TTC元件异常扩增导致FXN基因异染色质化并诱发共济失调症提供了机制性解释。\n五、紫杉醇生物合成\n紫杉醇是全球销量第一的植物天然广谱抗癌药物。然而，紫杉醇生产高度依赖红豆杉资源和化学合成，环境污染大，生产成本高。中国农业科学院农业基因组研究所闫建斌团队联合北京大学雷晓光等团队，发现了紫杉醇生物合成途径中的关键酶，阐明了颠覆传统认知的紫杉醇关键药效基团的形成机制。该成果被认为是开启紫杉醇生物制造领域大门的重要里程碑，标志着“中国在紫杉醇生物合成理论和技术上处于世界领先地位”。\n六、实现一年生与多年生植物的自由转换\n培育和推广多年生作物对于推动农业可持续性发展和应对未来气候变化具有重要意义。然而，由于缺乏研究模式，实验周期长，“多年生特性是由什么基因来决定的”一直是一个难以破解的“黑匣子”。中国科学院分子植物科学卓越中心王佳伟研究组通过构建跨物种遗传群体和正向遗传学手段，成功定位了控制植物多年生生活习性的三个关键MADS-box基因。该研究首次克隆了决定植物寿命长短的关键基因，并实现了一年生与多年生植物的自由转换，相关成果为设计与培育多年生作物奠定了理论基础，并入选相关国际专业期刊2024年度最佳论文之一。",
    "ori_text": "科技日报记者 薛岩\n记者从中国科协获悉，中国科协生命科学学会联合体开展的年度“中国生命科学十大进展”评选结果揭晓，7个知识创新类和3个技术创新类成果脱颖而出。\n本次入选的研究项目均面向生命科学前沿，面向人民生命健康，聚焦解决热点问题，具有原创性突出、社会意义重大的特点。十大成果分别是：\n一、衰老的时空编程及干预\n衰老是复杂的生物学过程，具有显著时空异质性。在复杂时空背景下，揭示衰老的关键驱动因素和开发安全有效的干预措施，是衰老科学研究面临的重大挑战。中国科学院动物研究所刘光慧、分子细胞科学卓越创新中心周斌、北京基因组研究所张维绮、动物研究所曲静等团队，为衰老研究提供新范式，也为衰老及其相关疾病的临床干预奠定基础，受到国际专业期刊的亮点评价。\n二、新型肠道菌源酶跨界调控代谢性疾病的作用机制与防治新策略\n肠道菌群与疾病发生发展密切相关，但目前靶向菌群多为整体性干预措施，缺乏特异性治疗策略，如何精准调控肠道菌群是国际生命科学研究的前沿问题。北京大学姜长涛、乔杰及山东大学刘双江团队等合作，提出“肠道菌源酶跨界调控宿主稳态”新理论，开发点击代谢组学技术等。团队进一步围绕BAS-suc开展了工程菌构建、激动剂开发等系列临床转化研究，开辟了代谢性疾病干预新路径。\n三、通用型CAR-T细胞治疗复发难治性自身免疫性疾病\n长期以来，彻底治愈红斑狼疮、硬皮病、多发性硬化症等自身免疫性疾病，是全球共同面临的医学难题。现有免疫抑制药物虽然可在一定程度上缓解病情，却不能完全阻止疾病的进展，反而可能带来使人虚弱的副作用。由中国人民解放军海军军医大学长征医院徐沪济领衔、联合华东师范大学杜冰、刘明耀团队以及上海邦耀生物科技有限公司，采用我国自主研发的异体CAR-T细胞开展临床研究，在全球首次成功治愈了严重自身免疫性疾病。\n四、异染色质形成机制\n旁着丝粒区域由快速演化且高度重复的卫星序列组成，该区域在不同物种间均以异染色质状态存在。然而，两个长期的未解之谜是“旁着丝粒区是怎样被识别并起始异染色质形成的”以及“不同物种间不保守的卫星序列是如何被保守的分子机器所识别的”。中国科学院生物物理研究所朱冰团队发现，保守的锌指蛋白ZNF512利用其非连续排布的锌指结构域识别富集于旁着丝粒区内的保守的不连续的TTC序列元件，并直接招募SUV39H家族蛋白，从而起始异染色质形成。在回答了近百年的科学困惑的同时，本发现也为TTC元件异常扩增导致FXN基因异染色质化并诱发共济失调症提供了机制性解释。\n五、紫杉醇生物合成\n紫杉醇是全球销量第一的植物天然广谱抗癌药物。然而，紫杉醇生产高度依赖红豆杉资源和化学合成，环境污染大，生产成本高。中国农业科学院农业基因组研究所闫建斌团队联合北京大学雷晓光等团队，发现了紫杉醇生物合成途径中的关键酶，阐明了颠覆传统认知的紫杉醇关键药效基团的形成机制。该成果被认为是开启紫杉醇生物制造领域大门的重要里程碑，标志着“中国在紫杉醇生物合成理论和技术上处于世界领先地位”。\n六、实现一年生与多年生植物的自由转换\n培育和推广多年生作物对于推动农业可持续性发展和应对未来气候变化具有重要意义。然而，由于缺乏研究模式，实验周期长，“多年生特性是由什么基因来决定的”一直是一个难以破解的“黑匣子”。中国科学院分子植物科学卓越中心王佳伟研究组通过构建跨物种遗传群体和正向遗传学手段，成功定位了控制植物多年生生活习性的三个关键MADS-box基因。该研究首次克隆了决定植物寿命长短的关键基因，并实现了一年生与多年生植物的自由转换，相关成果为设计与培育多年生作物奠定了理论基础，并入选相关国际专业期刊2024年度最佳论文之一。",
    "reference_list": "考点1：中国科协生命科学学会联合体 应译为 China Association for Science and Technology Life Sciences Society Consortium\n考点2：中国生命科学十大进展 应译为 Top 10 Advances in Life Sciences in China\n考点3：衰老的时空编程及干预 应译为 Spatiotemporal Programming and Intervention of Aging\n考点4：衰老科学研究 应译为 aging science research\n考点5：新型肠道菌源酶跨界调控代谢性疾病的作用机制与防治新策略 应译为 Mechanism and New Strategies of Cross-Regulation of Metabolic Diseases by Novel Gut-Derived Enzymes\n考点6：肠道菌群 应译为 gut microbiota\n考点7：宿主稳态 应译为 host homeostasis\n考点8：点击代谢组学 应译为 click metabolomics\n考点9：通用型CAR-T细胞治疗复发难治性自身免疫性疾病 应译为 Universal CAR-T Cell Therapy for Refractory and Relapsing Autoimmune Diseases\n考点10：红斑狼疮 应译为 systemic lupus erythematosus\n考点11：硬皮病 应译为 scleroderma\n考点12：多发性硬化症 应译为 multiple sclerosis\n考点13：异染色质形成机制 应译为 Mechanism of Heterochromatin Formation\n考点14：旁着丝粒区域 应译为 pericentromeric region\n考点15：卫星序列 应译为 satellite sequences\n考点16：锌指蛋白ZNF512 应译为 zinc finger protein ZNF512\n考点17：SUV39H家族蛋白 应译为 SUV39H family proteins\n考点18：FXN基因 应译为 FXN gene\n考点19：共济失调症 应译为 ataxia\n考点20：紫杉醇生物合成 应译为 Paclitaxel Biosynthesis\n考点21：紫杉醇关键药效基团 应译为 key pharmacophore of paclitaxel\n考点22：紫杉醇生物制造 应译为 paclitaxel biomanufacturing\n考点23：多年生作物 应译为 perennial crops\n考点24：MADS-box基因 应译为 MADS-box genes\n考点25：植物寿命长短的关键基因 应译为 key genes determining plant lifespan",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "80"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n我国一直坚持对代孕完全禁止的立法态度，但是在2015年下半年所通过的《人口与计划生育法修正案》中，立法人员出于对不孕不育家庭生育孩子权力的人道主义考虑，把此前关于禁止以任何形式实施代孕的法律条款进行了删除，这就让代孕在法律层面有了一定的管理空白。并且在社会中，我国当前广泛存在着不孕不育家庭，这些家庭在当前科学技术的辅助下完全可以实现拥有自己孩子的梦想，还有失独家庭对孩子的需要使得代孕看似可以推行。但在社会实际中，代孕弃养、物化女性，或者公众人物单纯为了自身的利益为目的违反公序良俗选择代孕等等不良现象层出不穷，这不得不需要社会进行深刻地反思，从伦理道德出发分析代孕合法性的对与错，为以后我国代孕合法性的未来走向总结推引出合理的建议，也为这一社会问题的解决而助力。\n\n一、代孕合法性争议下的道德相对论 　　\n（一）支持说\n首先从法律的角度来看，代孕合法化是对生育权的一种法律保护，更是对基本人权的一种保障，在我国的《妇女权益保障法》中明确确定了生育权这个概念，生育权是人权的一种，是每个家庭，每对父母所享有的基本权利，此外《婚姻法》《人口与计划生育法》都对生育权进行了相关的规定，每对夫妻享有是否生育孩子或者以何种方式生育孩子的权利，只要不违背社会公序良俗、伦理道德，皆可以为之。其次从法理学角度中来分析，可以把代孕合法性问题推引到道德与法律之间的关系上，本着维护正义的法律精神，代孕是对社会弱势群体的一种保护，不孕家庭、失独家庭因为缺少孩子而造成的心理负担以及现实矛盾让他们在社会大家庭中处于弱势的地位，为了帮助这类家庭走出困境，代孕是一种有效的方式，基于正义的法律精神，法律应该在这方面给以让步，并通过法律来保护这一行为，这是国家通过法律保护社会弱势群体的正义表现。最后再从为了社会和谐发展的目标来看代孕，太多的家庭因为年龄、疾病或者其他身体缺陷造成了家庭缺少孩子的情况，无法生育家庭或者失独家庭的需要使得代孕在我国民间广泛存在着，代孕若是被法律完全禁止，那么这些家庭的幸福如何被保障，因此出于对此类家庭的社会关怀以及本着社会和谐发展的目标，应该坚持实事求是的原则正视代孕的合理性存在，推广代孕合法化发展。\n（二）反对说 　　\n首先代孕不符合中国的传统伦理道德观念，因为中国传统文化具有相对保守的特点，代孕并不被广大的社会群体所普遍接受，代孕行为容易受到社会歧视与冷漠。并且代孕是由多方当事人所共同完成的，之间的伦理关系，财产继承以及情感处理等诸多问题容易造成当事人之间的人伦关系扭曲，最终造成社会秩序紊乱，形成不好的影响。所以这种由多方当事人所共同完成的生育方式是对生命伦理关系的破坏，不应予以支持。其次从法律层面来看，首先从民事角度，代孕行为本身有违背社会的公序良俗，在合同法中基于这条原则代孕合同是根本站不住脚的，是无效合同。再从行政角度来看，关于代孕行为我国法律没有条文给予行政支持，就是任何医疗机构没有资质独立随意进行代孕手术或辅助，另外关于代孕子女也没有相应的户口、医疗管理规定。此外代孕行为也是对代孕妇女基本人权的侵害，是对其人格权的侮辱。还有代孕所生的子女在以后的成长道路中，也很容易受人诋毁，人格权遭到侵害，不利于其身心健康地成长。最后再从社会发展角度来看，代孕行为很容易造成社会纠纷，并且此类纠纷很难公平、公正有效的得以解决，遗留的问题更是长期影响着代孕家庭及代孕母亲，另外代孕行为的利益驱使还对社会的正确价值观念带来冲击，使得功利主义观在社会中暴涨，故此为了杜绝这些不良社会影响的出现，代孕行为应该被禁止。",
    "ori_text": "我国一直坚持对代孕完全禁止的立法态度，但是在2015年下半年所通过的《人口与计划生育法修正案》中，立法人员出于对不孕不育家庭生育孩子权力的人道主义考虑，把此前关于禁止以任何形式实施代孕的法律条款进行了删除，这就让代孕在法律层面有了一定的管理空白。并且在社会中，我国当前广泛存在着不孕不育家庭，这些家庭在当前科学技术的辅助下完全可以实现拥有自己孩子的梦想，还有失独家庭对孩子的需要使得代孕看似可以推行。但在社会实际中，代孕弃养、物化女性，或者公众人物单纯为了自身的利益为目的违反公序良俗选择代孕等等不良现象层出不穷，这不得不需要社会进行深刻地反思，从伦理道德出发分析代孕合法性的对与错，为以后我国代孕合法性的未来走向总结推引出合理的建议，也为这一社会问题的解决而助力。\n\n一、代孕合法性争议下的道德相对论 　　\n（一）支持说\n首先从法律的角度来看，代孕合法化是对生育权的一种法律保护，更是对基本人权的一种保障，在我国的《妇女权益保障法》中明确确定了生育权这个概念，生育权是人权的一种，是每个家庭，每对父母所享有的基本权利，此外《婚姻法》《人口与计划生育法》都对生育权进行了相关的规定，每对夫妻享有是否生育孩子或者以何种方式生育孩子的权利，只要不违背社会公序良俗、伦理道德，皆可以为之。其次从法理学角度中来分析，可以把代孕合法性问题推引到道德与法律之间的关系上，本着维护正义的法律精神，代孕是对社会弱势群体的一种保护，不孕家庭、失独家庭因为缺少孩子而造成的心理负担以及现实矛盾让他们在社会大家庭中处于弱势的地位，为了帮助这类家庭走出困境，代孕是一种有效的方式，基于正义的法律精神，法律应该在这方面给以让步，并通过法律来保护这一行为，这是国家通过法律保护社会弱势群体的正义表现。最后再从为了社会和谐发展的目标来看代孕，太多的家庭因为年龄、疾病或者其他身体缺陷造成了家庭缺少孩子的情况，无法生育家庭或者失独家庭的需要使得代孕在我国民间广泛存在着，代孕若是被法律完全禁止，那么这些家庭的幸福如何被保障，因此出于对此类家庭的社会关怀以及本着社会和谐发展的目标，应该坚持实事求是的原则正视代孕的合理性存在，推广代孕合法化发展。\n（二）反对说 　　\n首先代孕不符合中国的传统伦理道德观念，因为中国传统文化具有相对保守的特点，代孕并不被广大的社会群体所普遍接受，代孕行为容易受到社会歧视与冷漠。并且代孕是由多方当事人所共同完成的，之间的伦理关系，财产继承以及情感处理等诸多问题容易造成当事人之间的人伦关系扭曲，最终造成社会秩序紊乱，形成不好的影响。所以这种由多方当事人所共同完成的生育方式是对生命伦理关系的破坏，不应予以支持。其次从法律层面来看，首先从民事角度，代孕行为本身有违背社会的公序良俗，在合同法中基于这条原则代孕合同是根本站不住脚的，是无效合同。再从行政角度来看，关于代孕行为我国法律没有条文给予行政支持，就是任何医疗机构没有资质独立随意进行代孕手术或辅助，另外关于代孕子女也没有相应的户口、医疗管理规定。此外代孕行为也是对代孕妇女基本人权的侵害，是对其人格权的侮辱。还有代孕所生的子女在以后的成长道路中，也很容易受人诋毁，人格权遭到侵害，不利于其身心健康地成长。最后再从社会发展角度来看，代孕行为很容易造成社会纠纷，并且此类纠纷很难公平、公正有效的得以解决，遗留的问题更是长期影响着代孕家庭及代孕母亲，另外代孕行为的利益驱使还对社会的正确价值观念带来冲击，使得功利主义观在社会中暴涨，故此为了杜绝这些不良社会影响的出现，代孕行为应该被禁止。",
    "reference_list": "考点1：“立法态度”推荐译为“ legislative stance; legislative attitude”\n考点2：“ 管理空白”推荐译为“ regulatory vacuum;”\n考点3：“ 失独家庭”推荐译为“ families who have lost their only child”\n考点4：“代孕弃养”推荐译为“abandonment of children born through surrogacy”\n考点5：“物化女性”推荐译为“the objectification of women; to commodify women”\n考点6：“公序良俗”推荐译为“public order and good morals; public order and good customs”\n考点7：“ 生育权 ”推荐译为“reproductive rights”\n考点8：“法理学”推荐译为“ jurisprudence”\n考点9：“社会弱势群体”推荐译为“socially vulnerable groups”\n考点10：“人伦关系”推荐译为“ethical human relationships; familial and social ethics; kinship and ethical bonds”\n考点11：“无效合同”推荐译为“Void contract”\n考点12：“功利主义”推荐译为“profit-seeking mentality; materialism”，注意语境下的贬义表达\n考点13：“我国”应译为“China”，而不是“our country”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "12"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n       Protein Language Models have become important tools in computational biology for tasks such as protein structure prediction, functional annotation, and sequence design. These models draw on recent advances in Natural Language Processing , which uses Deep Learning techniques to capture complex relationships within protein sequences. However, optimizing Protein Language Models for specific biological tasks is still a huge challenge due to the large volume of protein sequence space and the complexity of folding and interaction. To transform general yet unfocused protein Large Language Models into expert tools capable of solving specific biological challenges, an optimized strategy that combines Fine-Tuning and Prompt Engineering has emerged. The essence of this approach lies in a two-pronged process: on one hand, Parameter-Efficient Fine-Tuning uses specialized datasets related to specific tasks to further train the model, much like providing specialized training to equip the model with deep, domain-specific knowledge and fundamentally enhance its performance in targeted applications. On the other hand, advanced Prompt Engineering serves as a “precise remote control,” enabling researchers to deliver complex design objectives and constraints to the model in real time and at a fine-grained level through well-structured and information-rich instructions, thereby precisely steering its generation process. These two techniques complement each other—Fine-Tuning endows the model with robust internal expertise, while Prompt Engineering provides the means to harness and direct this expertise. The synergy between them ultimately gives rise to the next generation of protein design tools, which are both deeply specialized and highly controllable, dramatically accelerating innovation in fields such as drug discovery and synthetic biology. Protein science, the study of protein structure, function, and interactions in living organisms, has entered a new era with the emergence of Large Language Models. This convergence leverages various Deep Learning models, particularly the Transformer, to analyze and predict protein sequences, structures, and functions, accelerating biomedical research and drug development. For example,  ProteinBERT demonstrated the effectiveness for protein sequence analysis, while xTrimoPGLM, with its 100 billion parameters, established new capabilities in both protein understanding and generation. ProteinLMBench is a comprehensive, manually annotated benchmark for a comprehensive assessment of under- standing and representation of protein knowledge.TourSynbio-7B is a multi-modal large model designed for protein engineering and it does not require an external protein encoder.\nAutoPE mainly introduces a proxy framework called AutoProteinEngine, which utilizes Large Language Models to implement multimodal automated machine learning in protein engineering. However, the reason why general Large Language Models perform poorly on scientific tasks fundamentally lies in the inherent flaws of the datasets used to train them. Simply expanding the size of general web-text corpora is far from sufficient, as these datasets cannot meet the rigorous requirements of scientific research in terms of quality, structure, and content. The specific limitations are as follows:\n       Contamination and low signal-to-noise ratio in general corpora: Models trained on such \"polluted\" data tend to develop \"world knowledge\" that is biased toward common sense rather than rigorous scientific facts. This leads to a propensity for hallucinations, namely, generating statements that sound plausible but are entirely incorrect, and makes it difficult to distinguish between peer-reviewed knowledge and arbitrary claims found on the internet. Neglect of the multimodality of scientific knowledge: During the processing of traditional text datasets, structured information is often flattened or discarded, causing the model to lose the essence of the \"language\" of science. A model exposed only to plain text cannot truly understand or manipulate a chemical reaction equation, nor can it correctly generate or interpret a complex mathematical derivation. Insufficient coverage of \"long-tail\" scientific knowledge: As a result, the model exhibits breadth but lacks depth in knowledge. It may be able to discuss basic physics fluently but remains completely ignorant of a particular branch of condensed matter physics or the latest algorithms in bioinformatics. This imbalance in knowledge coverage severely limits its usefulness as a professional research assistant. Lack of knowledge provenance and citation information: The model cannot provide citations or sources for its generated content, which is fatal in scientific applications. It cannot distinguish between widely accepted theories and controversial hypotheses, nor can it help researchers trace the original source of information, greatly undermining its reliability. Static and outdated information: The knowledge acquired by the model will inevitably become outdated. For rapidly fields such as Artificial Intelligence or gene editing, a model trained on data from several years ago may provide information that is incorrect or no longer applicable. Protein structure prediction and functional analysis are of great significance in the field of bioinformatics. In recent years, the application of protein large language model has greatly improved the accuracy of protein sequence analysis. However, how to efficiently Fine-Tuning the parameters of large language models for optimal performance remains a challenge Overwhelming hardware barriers, especially the “VRAM wall.” This is the most immediate and fundamental limitation. Full parameter Fine-Tuning requires loading all model parameters, gradients, and optimizer states into GPU VRAM during training. Overall, fully Fine-Tuning a 7B-parameter model may require close to 100GB of VRAM. This far exceeds the capacity of most consumer GPUs (such as the RTX 4090, with 24GB) and even many professional-grade GPUs, creating a “VRAM wall” that ordinary\nusers cannot overcome. Inefficiency in deployment and storage. Full parameter Fine-Tuning generates a complete and independent model copy for each specific downstream task. This leads to the problem of “model copy proliferation.” For organizations with limited resources, simply storing these massive model files is already overwhelming, let alone configuring a separate and expensive inference service for each model in production environments. This results in extremely high costs for model scaling and maintenance. Instability during training and “catastrophic forgetting.” On limited hardware, researchers may be forced to use extremely small batch sizes just to make training feasible. Too small a batch size causes gradients to be noisy, making the training process highly unstable and difficult to converge. Improvements in task-specific performance may come at the cost of degrading general capabilities, which is unacceptable in many application scenarios. At the same time, unstable training also increases the difficulty and time cost of hyperparameter tuning. Extremely low iteration efficiency and high trial-and-error costs. Each training cycle of full parameter Fine-Tuning is extremely time-consuming. With limited computational resources, completing a single Fine-Tuning experiment may take days or even weeks. This greatly slows the pace of research and innovation. Researchers are unable to quickly conduct experiments, test ideas, or adjust hyperparameters. The high time and energy costs make exploratory research a luxury, hindering the popularization and democratization of the technology. At present, the commonly used evaluation indicators for protein language models are limited, mainly focusing on sequence prediction, structure prediction, etc., lacking rich downstream functional or interactive evaluations. The evaluation system for Large Language Models in biomedicine is still not perfect, especially in downstream tasks such as interactive question answering and reasoning, where the problem of single evaluation indicators is more prominent. The evaluation of Protein Language Models mainly relies on a limited number of benchmarks, with insufficient consideration of diverse tasks and actual dialogue task. The dataset of Protein Language Models has problems such as insufficient coverage of professional domain knowledge, untimely data updates, severe data pollution, and difficulty in ensuring scientificity . The Fine-Tuning of Protein Language Models faces significant limitations: Firstly, full-parameter Fine-Tuning has extremely high requirements for video memory and hardware, which are unaffordable for ordinary researchers; Secondly, different tasks require the separate saving and deployment of complete models, which\nleads to a significant increase in storage and operation and maintenance costs. Secondly, due to the limitations of hardware resources, unstable gradients and catastrophic forgetting are prone to occur during the training process, making it difficult to guarantee the model’s performance. Finally, the long training time and the low efficiency of experiments and parameter adjustment have greatly affected the promotion of research and application. At present, the evaluation methods for protein language models are relatively limited, mainly focusing on sequence and structure prediction, and lacking comprehensive assessment of downstream functionality and interactive capabilities. The evaluation system for large biomedical models is also not fully developed; in practical scenarios such as question answering and reasoning, the evaluation metrics are rather single-dimensional, making it difficult to fully demonstrate the overall application level of the models. \n     Based on the above content, the research questions are as follows. Firstly, this study optimized the application of Protein Language Models in the field of bioinformatics. By combining Fine-Tuning techniques and Prompt Engineering methods, it effectively enhanced the model’s capabilities in tasks such as protein sequence understanding, functional prediction, and structural inference. Secondly, this method can achieve efficient adaptation to specific downstream tasks without significantly increasing the consumption of computing resources, thereby promoting the automation and intelligence of protein science research. Finally, this research provides new ideas for the customized application of cross-domain large models, opens up broader prospects for the integration of life sciences and Artificial Intelligence, and helps accelerate the progress of practical applications such as drug design and disease mechanism analysis.\n",
    "ori_text": "\n\n       Protein Language Models have become important tools in computational biology for tasks such as protein structure prediction, functional annotation, and sequence design. These models draw on recent advances in Natural Language Processing , which uses Deep Learning techniques to capture complex relationships within protein sequences. However, optimizing Protein Language Models for specific biological tasks is still a huge challenge due to the large volume of protein sequence space and the complexity of folding and interaction. To transform general yet unfocused protein Large Language Models into expert tools capable of solving specific biological challenges, an optimized strategy that combines Fine-Tuning and Prompt Engineering has emerged. The essence of this approach lies in a two-pronged process: on one hand, Parameter-Efficient Fine-Tuning uses specialized datasets related to specific tasks to further train the model, much like providing specialized training to equip the model with deep, domain-specific knowledge and fundamentally enhance its performance in targeted applications. On the other hand, advanced Prompt Engineering serves as a “precise remote control,” enabling researchers to deliver complex design objectives and constraints to the model in real time and at a fine-grained level through well-structured and information-rich instructions, thereby precisely steering its generation process. These two techniques complement each other—Fine-Tuning endows the model with robust internal expertise, while Prompt Engineering provides the means to harness and direct this expertise. The synergy between them ultimately gives rise to the next generation of protein design tools, which are both deeply specialized and highly controllable, dramatically accelerating innovation in fields such as drug discovery and synthetic biology. Protein science, the study of protein structure, function, and interactions in living organisms, has entered a new era with the emergence of Large Language Models. This convergence leverages various Deep Learning models, particularly the Transformer, to analyze and predict protein sequences, structures, and functions, accelerating biomedical research and drug development. For example,  ProteinBERT demonstrated the effectiveness for protein sequence analysis, while xTrimoPGLM, with its 100 billion parameters, established new capabilities in both protein understanding and generation. ProteinLMBench is a comprehensive, manually annotated benchmark for a comprehensive assessment of under- standing and representation of protein knowledge.TourSynbio-7B is a multi-modal large model designed for protein engineering and it does not require an external protein encoder.\nAutoPE mainly introduces a proxy framework called AutoProteinEngine, which utilizes Large Language Models to implement multimodal automated machine learning in protein engineering. However, the reason why general Large Language Models perform poorly on scientific tasks fundamentally lies in the inherent flaws of the datasets used to train them. Simply expanding the size of general web-text corpora is far from sufficient, as these datasets cannot meet the rigorous requirements of scientific research in terms of quality, structure, and content. The specific limitations are as follows:\n       Contamination and low signal-to-noise ratio in general corpora: Models trained on such \"polluted\" data tend to develop \"world knowledge\" that is biased toward common sense rather than rigorous scientific facts. This leads to a propensity for hallucinations, namely, generating statements that sound plausible but are entirely incorrect, and makes it difficult to distinguish between peer-reviewed knowledge and arbitrary claims found on the internet. Neglect of the multimodality of scientific knowledge: During the processing of traditional text datasets, structured information is often flattened or discarded, causing the model to lose the essence of the \"language\" of science. A model exposed only to plain text cannot truly understand or manipulate a chemical reaction equation, nor can it correctly generate or interpret a complex mathematical derivation. Insufficient coverage of \"long-tail\" scientific knowledge: As a result, the model exhibits breadth but lacks depth in knowledge. It may be able to discuss basic physics fluently but remains completely ignorant of a particular branch of condensed matter physics or the latest algorithms in bioinformatics. This imbalance in knowledge coverage severely limits its usefulness as a professional research assistant. Lack of knowledge provenance and citation information: The model cannot provide citations or sources for its generated content, which is fatal in scientific applications. It cannot distinguish between widely accepted theories and controversial hypotheses, nor can it help researchers trace the original source of information, greatly undermining its reliability. Static and outdated information: The knowledge acquired by the model will inevitably become outdated. For rapidly fields such as Artificial Intelligence or gene editing, a model trained on data from several years ago may provide information that is incorrect or no longer applicable. Protein structure prediction and functional analysis are of great significance in the field of bioinformatics. In recent years, the application of protein large language model has greatly improved the accuracy of protein sequence analysis. However, how to efficiently Fine-Tuning the parameters of large language models for optimal performance remains a challenge Overwhelming hardware barriers, especially the “VRAM wall.” This is the most immediate and fundamental limitation. Full parameter Fine-Tuning requires loading all model parameters, gradients, and optimizer states into GPU VRAM during training. Overall, fully Fine-Tuning a 7B-parameter model may require close to 100GB of VRAM. This far exceeds the capacity of most consumer GPUs (such as the RTX 4090, with 24GB) and even many professional-grade GPUs, creating a “VRAM wall” that ordinary\nusers cannot overcome. Inefficiency in deployment and storage. Full parameter Fine-Tuning generates a complete and independent model copy for each specific downstream task. This leads to the problem of “model copy proliferation.” For organizations with limited resources, simply storing these massive model files is already overwhelming, let alone configuring a separate and expensive inference service for each model in production environments. This results in extremely high costs for model scaling and maintenance. Instability during training and “catastrophic forgetting.” On limited hardware, researchers may be forced to use extremely small batch sizes just to make training feasible. Too small a batch size causes gradients to be noisy, making the training process highly unstable and difficult to converge. Improvements in task-specific performance may come at the cost of degrading general capabilities, which is unacceptable in many application scenarios. At the same time, unstable training also increases the difficulty and time cost of hyperparameter tuning. Extremely low iteration efficiency and high trial-and-error costs. Each training cycle of full parameter Fine-Tuning is extremely time-consuming. With limited computational resources, completing a single Fine-Tuning experiment may take days or even weeks. This greatly slows the pace of research and innovation. Researchers are unable to quickly conduct experiments, test ideas, or adjust hyperparameters. The high time and energy costs make exploratory research a luxury, hindering the popularization and democratization of the technology. At present, the commonly used evaluation indicators for protein language models are limited, mainly focusing on sequence prediction, structure prediction, etc., lacking rich downstream functional or interactive evaluations. The evaluation system for Large Language Models in biomedicine is still not perfect, especially in downstream tasks such as interactive question answering and reasoning, where the problem of single evaluation indicators is more prominent. The evaluation of Protein Language Models mainly relies on a limited number of benchmarks, with insufficient consideration of diverse tasks and actual dialogue task. The dataset of Protein Language Models has problems such as insufficient coverage of professional domain knowledge, untimely data updates, severe data pollution, and difficulty in ensuring scientificity . The Fine-Tuning of Protein Language Models faces significant limitations: Firstly, full-parameter Fine-Tuning has extremely high requirements for video memory and hardware, which are unaffordable for ordinary researchers; Secondly, different tasks require the separate saving and deployment of complete models, which\nleads to a significant increase in storage and operation and maintenance costs. Secondly, due to the limitations of hardware resources, unstable gradients and catastrophic forgetting are prone to occur during the training process, making it difficult to guarantee the model’s performance. Finally, the long training time and the low efficiency of experiments and parameter adjustment have greatly affected the promotion of research and application. At present, the evaluation methods for protein language models are relatively limited, mainly focusing on sequence and structure prediction, and lacking comprehensive assessment of downstream functionality and interactive capabilities. The evaluation system for large biomedical models is also not fully developed; in practical scenarios such as question answering and reasoning, the evaluation metrics are rather single-dimensional, making it difficult to fully demonstrate the overall application level of the models. \n     Based on the above content, the research questions are as follows. Firstly, this study optimized the application of Protein Language Models in the field of bioinformatics. By combining Fine-Tuning techniques and Prompt Engineering methods, it effectively enhanced the model’s capabilities in tasks such as protein sequence understanding, functional prediction, and structural inference. Secondly, this method can achieve efficient adaptation to specific downstream tasks without significantly increasing the consumption of computing resources, thereby promoting the automation and intelligence of protein science research. Finally, this research provides new ideas for the customized application of cross-domain large models, opens up broader prospects for the integration of life sciences and Artificial Intelligence, and helps accelerate the progress of practical applications such as drug design and disease mechanism analysis.\n",
    "reference_list": "考点1： \"Large Language Models\" 应译为\"大语言模型\"\n考点2:   \"multi-modal large model\"应译为\"多模态大模型\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "172"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nObstetric anesthesia has evolved significantly over the past decade, driven by technological innovations, refined pharmacological strategies, and a deeper understanding of maternal-fetal physiology. These advancements have improved maternal and neonatal outcomes, addressing challenges in labor analgesia, cesarean delivery anesthesia, management of obstetric complications, and critical care in high-risk pregnancies. The field emphasizes patient-centered care, safety, and multidisciplinary collaboration, integrating anesthesiologists, obstetricians, neonatologists, and critical care specialists to optimize outcomes. This text explores these developments in detail, highlighting evidence-based practices, emerging technologies, and ongoing challenges.\n \n**Labor Analgesia**: Effective labor analgesia balances pain relief with minimal maternal and fetal side effects. Low-dose local anesthetics (LAs), such as bupivacaine (0.0625–0.125%) or ropivacaine (0.1–0.2%), are combined with adjuvants like fentanyl (2–5 μg/mL), sufentanil (0.5–1 μg/mL), or dexamethasone (4–8 mg) to enhance epidural analgesia while reducing motor blockade. Programmed Intermittent Epidural Bolus (PIEB) has emerged as a superior technique compared to continuous epidural infusion (CEI). PIEB delivers boluses (e.g., 8–10 mL every 45–60 minutes) via automated pumps, reducing total LA consumption by 20–30%, breakthrough pain by 15%, and motor blockade incidence. Studies, such as those published in *Anesthesiology* (2021), demonstrate PIEB’s ability to improve maternal satisfaction and reduce anesthesiologist interventions. Dural Puncture Epidural (DPE) techniques, involving intentional dural puncture with a 25–27G spinal needle before epidural catheter placement, accelerate analgesia onset (by 5–10 minutes) and improve sacral spread, though randomized trials show inconsistent benefits over standard epidurals. Ultrasound-guided neuraxial techniques have revolutionized care for challenging patients, such as those with obesity (BMI >35 kg/m²), scoliosis, or prior spinal surgery. Automated vertebral level identification systems, using real-time ultrasound imaging, achieve 95% accuracy in landmark identification, reducing failed epidural placements by 50%. Non-neuraxial options, like remifentanil patient-controlled intravenous analgesia (PCA) (0.1–0.5 μg/kg bolus, 8–10 min lockout), provide rapid pain relief but pose risks, including a 24.7% incidence of maternal oxygen desaturation and a 5% need for neonatal oxygen supplementation. Concerns about remifentanil’s safety have limited its use, particularly as it lacks FDA approval for pregnancy. Immersive virtual reality (VR) is a novel non-pharmacological adjunct, effective in early labor (pain scores <8), reducing anxiety and pain perception by 30–40% in daytime settings, per a 2022 *BJOG* study. VR’s efficacy diminishes in advanced labor, and patient preference for its use varies.\n \n**Cesarean Delivery Anesthesia**: Spinal anesthesia remains the preferred method for elective cesarean sections, offering rapid onset and reliable sensory blockade. Typical regimens include hyperbaric bupivacaine (10–12 mg) with fentanyl (10–25 μg) or morphine (100–200 μg) to prolong postoperative analgesia. Ultrasound-guided spinal anesthesia enhances first-attempt success rates (85–90%) and reduces complications like post-dural puncture headache (PDPH), which occurs in 1–3% of cases. PDPH is managed conservatively with hydration and caffeine, but severe cases require an epidural blood patch (EBP) with 15–20 mL autologous blood, achieving a 50–80% resolution rate. Post-spinal hypotension, affecting 50–70% of patients, is mitigated with prophylactic vasopressors, such as phenylephrine (25–50 μg/min infusion) or norepinephrine (6–8 μg bolus), targeting systolic blood pressure ≥90% of baseline or ≥100 mm Hg. The 2021 NICE guidelines emphasize individualized vasopressor dosing to prevent maternal nausea and fetal acidosis. Novel regional blocks, including quadratus lumborum block (QLB) and transversus abdominis plane (TAP) block, combined with wound infiltration (e.g., 0.25% bupivacaine), form the cornerstone of multimodal analgesia, reducing postoperative opioid consumption by 40%. For urgent cesarean deliveries (category 1, decision-to-delivery within 30 minutes), general anesthesia is required in 5–10% of cases. Videolaryngoscopy (e.g., Glidescope, C-MAC) improves intubation success rates (98% first-pass success), while high-flow nasal oxygen and second-generation supraglottic airway devices (e.g., Proseal LMA) minimize hypoxia risks. Preoperative neck and gastric ultrasound reduce aspiration risk by identifying full stomach conditions in 20% of urgent cases. Enhanced Recovery After Cesarean (ERAC) protocols promote early oral intake (within 2 hours), ambulation (within 6–8 hours), and catheter removal, reducing hospital stays by 12–24 hours and opioid use by 30%. However, ERAC implementation faces barriers in low-literacy populations, rural settings, and areas with limited staff training, as noted in a 2023 *Obstetric Anesthesia Digest* report.\n \n**Obstetric Complication Management**: Major obstetric hemorrhage, a leading cause of maternal mortality (1–2% of deliveries), requires rapid intervention. Carbetocin (100 μg IV), a long-acting oxytocin analog, outperforms oxytocin in preventing postpartum hemorrhage, reducing blood loss by 100–200 mL, per a 2020 *Cochrane Database* review. Tranexamic acid (1 g IV within 3 hours) is standard for bleeding control, supported by the WOMAN trial, which reported a 19% reduction in mortality. Rotational thromboelastometry (ROTEM) guides transfusion, targeting hemoglobin >7 g/dL, platelets >75,000/μL, fibrinogen >2 g/L, and INR <1.5, minimizing unnecessary blood product use by 25%. Hypertensive disorders, such as preeclampsia and eclampsia, affect 5–10% of pregnancies and require blood pressure control (<140/90 mm Hg) with labetalol (20–80 mg IV) or hydralazine (5–10 mg IV). Continuous wave Doppler ultrasound assesses maternal hemodynamics, aiding early preeclampsia diagnosis with 80% sensitivity. Cardiac risk stratification, using tools like the CARPREG II score or modified WHO (mWHO) classification, identifies high-risk patients, with registries like Tamil Nadu’s Pregnancy and Heart Disease Registry improving maternal survival by 15%. Venous thromboembolism (VTE), a leading cause of maternal morbidity, is assessed using NICE/RCOG guidelines, with low-molecular-weight heparin (e.g., enoxaparin 40 mg daily) as the cornerstone of prophylaxis. However, optimal dosing and timing remain understudied, particularly in obese patients. Anesthetic management of high-risk cases requires tailored approaches, such as combined spinal-epidural (CSE) techniques for patients with coagulopathy, ensuring safe neuraxial anesthesia while minimizing bleeding risks.\n \n**Critical Care in Obstetrics**: Approximately 3–8% of pregnant women require admission to an obstetric intensive care unit (OICU), driven by conditions like postpartum hemorrhage, sepsis, or cardiomyopathy. Modified Early Obstetric Warning Scores (MEOWS) and the Obstetric Comorbidity Index (OB-CMI) identify at-risk patients with 90% sensitivity, enabling early intervention. Point-of-care ultrasound (POCUS), including lung ultrasound and the BLUE protocol, diagnoses pulmonary edema and pleural effusion with 95% accuracy, surpassing chest X-rays. ROTEM-guided transfusion in postpartum hemorrhage reduces blood product use by 20–30%, improving outcomes. Maternal sepsis, affecting 0.1–0.3% of pregnancies, is managed with the obstetric-modified qSOFA score (lactate >2 mmol/L, altered mentation, or hypotension), triggering a “sepsis bundle” (early antibiotics, fluids, and source control within 12 hours). A 2022 *Critical Care Medicine* study reported a 25% reduction in mortality with bundle compliance. Extracorporeal membrane oxygenation (ECMO) is increasingly used for peripartum respiratory failure, with a 70% survival rate in case series. Perimortem cesarean delivery, recommended within 5 minutes of cardiac arrest without return of spontaneous circulation, improves maternal survival by 30% and fetal survival by 80%. Challenges in critical care include resource disparities, with low-income settings facing shortages of trained personnel and equipment, limiting ECMO and POCUS access.\n \n**Emerging Challenges and Future Directions**: Despite progress, obstetric anesthesia faces barriers to equitable care. Low-literacy populations and rural settings struggle with ERAC adoption due to inadequate patient education and infrastructure. The use of unapproved agents like dextromethorphan in pregnancy remains controversial, with insufficient safety data. Precision medicine, leveraging genetic profiling (e.g., CYP2D6 polymorphisms for opioid metabolism), holds promise for tailoring analgesia but is limited by cost and biomarker availability. Artificial intelligence (AI)-assisted ultrasound and predictive analytics for hemorrhage risk are under investigation, with pilot studies showing 85% accuracy in predicting severe outcomes. Training programs for anesthesiologists in low-resource settings are critical to bridge gaps, as emphasized by the World Federation of Societies of Anaesthesiologists (WFSA). Multidisciplinary protocols, standardized across regions, are needed to ensure consistent care, particularly for high-risk conditions like preeclampsia and VTE.\n \nThese advancements underscore the dynamic nature of obstetric anesthesia, requiring ongoing research, training, and policy support to address global disparities and optimize maternal-fetal outcomes.\n",
    "ori_text": "\n\nObstetric anesthesia has evolved significantly over the past decade, driven by technological innovations, refined pharmacological strategies, and a deeper understanding of maternal-fetal physiology. These advancements have improved maternal and neonatal outcomes, addressing challenges in labor analgesia, cesarean delivery anesthesia, management of obstetric complications, and critical care in high-risk pregnancies. The field emphasizes patient-centered care, safety, and multidisciplinary collaboration, integrating anesthesiologists, obstetricians, neonatologists, and critical care specialists to optimize outcomes. This text explores these developments in detail, highlighting evidence-based practices, emerging technologies, and ongoing challenges.\n \n**Labor Analgesia**: Effective labor analgesia balances pain relief with minimal maternal and fetal side effects. Low-dose local anesthetics (LAs), such as bupivacaine (0.0625–0.125%) or ropivacaine (0.1–0.2%), are combined with adjuvants like fentanyl (2–5 μg/mL), sufentanil (0.5–1 μg/mL), or dexamethasone (4–8 mg) to enhance epidural analgesia while reducing motor blockade. Programmed Intermittent Epidural Bolus (PIEB) has emerged as a superior technique compared to continuous epidural infusion (CEI). PIEB delivers boluses (e.g., 8–10 mL every 45–60 minutes) via automated pumps, reducing total LA consumption by 20–30%, breakthrough pain by 15%, and motor blockade incidence. Studies, such as those published in *Anesthesiology* (2021), demonstrate PIEB’s ability to improve maternal satisfaction and reduce anesthesiologist interventions. Dural Puncture Epidural (DPE) techniques, involving intentional dural puncture with a 25–27G spinal needle before epidural catheter placement, accelerate analgesia onset (by 5–10 minutes) and improve sacral spread, though randomized trials show inconsistent benefits over standard epidurals. Ultrasound-guided neuraxial techniques have revolutionized care for challenging patients, such as those with obesity (BMI >35 kg/m²), scoliosis, or prior spinal surgery. Automated vertebral level identification systems, using real-time ultrasound imaging, achieve 95% accuracy in landmark identification, reducing failed epidural placements by 50%. Non-neuraxial options, like remifentanil patient-controlled intravenous analgesia (PCA) (0.1–0.5 μg/kg bolus, 8–10 min lockout), provide rapid pain relief but pose risks, including a 24.7% incidence of maternal oxygen desaturation and a 5% need for neonatal oxygen supplementation. Concerns about remifentanil’s safety have limited its use, particularly as it lacks FDA approval for pregnancy. Immersive virtual reality (VR) is a novel non-pharmacological adjunct, effective in early labor (pain scores <8), reducing anxiety and pain perception by 30–40% in daytime settings, per a 2022 *BJOG* study. VR’s efficacy diminishes in advanced labor, and patient preference for its use varies.\n \n**Cesarean Delivery Anesthesia**: Spinal anesthesia remains the preferred method for elective cesarean sections, offering rapid onset and reliable sensory blockade. Typical regimens include hyperbaric bupivacaine (10–12 mg) with fentanyl (10–25 μg) or morphine (100–200 μg) to prolong postoperative analgesia. Ultrasound-guided spinal anesthesia enhances first-attempt success rates (85–90%) and reduces complications like post-dural puncture headache (PDPH), which occurs in 1–3% of cases. PDPH is managed conservatively with hydration and caffeine, but severe cases require an epidural blood patch (EBP) with 15–20 mL autologous blood, achieving a 50–80% resolution rate. Post-spinal hypotension, affecting 50–70% of patients, is mitigated with prophylactic vasopressors, such as phenylephrine (25–50 μg/min infusion) or norepinephrine (6–8 μg bolus), targeting systolic blood pressure ≥90% of baseline or ≥100 mm Hg. The 2021 NICE guidelines emphasize individualized vasopressor dosing to prevent maternal nausea and fetal acidosis. Novel regional blocks, including quadratus lumborum block (QLB) and transversus abdominis plane (TAP) block, combined with wound infiltration (e.g., 0.25% bupivacaine), form the cornerstone of multimodal analgesia, reducing postoperative opioid consumption by 40%. For urgent cesarean deliveries (category 1, decision-to-delivery within 30 minutes), general anesthesia is required in 5–10% of cases. Videolaryngoscopy (e.g., Glidescope, C-MAC) improves intubation success rates (98% first-pass success), while high-flow nasal oxygen and second-generation supraglottic airway devices (e.g., Proseal LMA) minimize hypoxia risks. Preoperative neck and gastric ultrasound reduce aspiration risk by identifying full stomach conditions in 20% of urgent cases. Enhanced Recovery After Cesarean (ERAC) protocols promote early oral intake (within 2 hours), ambulation (within 6–8 hours), and catheter removal, reducing hospital stays by 12–24 hours and opioid use by 30%. However, ERAC implementation faces barriers in low-literacy populations, rural settings, and areas with limited staff training, as noted in a 2023 *Obstetric Anesthesia Digest* report.\n \n**Obstetric Complication Management**: Major obstetric hemorrhage, a leading cause of maternal mortality (1–2% of deliveries), requires rapid intervention. Carbetocin (100 μg IV), a long-acting oxytocin analog, outperforms oxytocin in preventing postpartum hemorrhage, reducing blood loss by 100–200 mL, per a 2020 *Cochrane Database* review. Tranexamic acid (1 g IV within 3 hours) is standard for bleeding control, supported by the WOMAN trial, which reported a 19% reduction in mortality. Rotational thromboelastometry (ROTEM) guides transfusion, targeting hemoglobin >7 g/dL, platelets >75,000/μL, fibrinogen >2 g/L, and INR <1.5, minimizing unnecessary blood product use by 25%. Hypertensive disorders, such as preeclampsia and eclampsia, affect 5–10% of pregnancies and require blood pressure control (<140/90 mm Hg) with labetalol (20–80 mg IV) or hydralazine (5–10 mg IV). Continuous wave Doppler ultrasound assesses maternal hemodynamics, aiding early preeclampsia diagnosis with 80% sensitivity. Cardiac risk stratification, using tools like the CARPREG II score or modified WHO (mWHO) classification, identifies high-risk patients, with registries like Tamil Nadu’s Pregnancy and Heart Disease Registry improving maternal survival by 15%. Venous thromboembolism (VTE), a leading cause of maternal morbidity, is assessed using NICE/RCOG guidelines, with low-molecular-weight heparin (e.g., enoxaparin 40 mg daily) as the cornerstone of prophylaxis. However, optimal dosing and timing remain understudied, particularly in obese patients. Anesthetic management of high-risk cases requires tailored approaches, such as combined spinal-epidural (CSE) techniques for patients with coagulopathy, ensuring safe neuraxial anesthesia while minimizing bleeding risks.\n \n**Critical Care in Obstetrics**: Approximately 3–8% of pregnant women require admission to an obstetric intensive care unit (OICU), driven by conditions like postpartum hemorrhage, sepsis, or cardiomyopathy. Modified Early Obstetric Warning Scores (MEOWS) and the Obstetric Comorbidity Index (OB-CMI) identify at-risk patients with 90% sensitivity, enabling early intervention. Point-of-care ultrasound (POCUS), including lung ultrasound and the BLUE protocol, diagnoses pulmonary edema and pleural effusion with 95% accuracy, surpassing chest X-rays. ROTEM-guided transfusion in postpartum hemorrhage reduces blood product use by 20–30%, improving outcomes. Maternal sepsis, affecting 0.1–0.3% of pregnancies, is managed with the obstetric-modified qSOFA score (lactate >2 mmol/L, altered mentation, or hypotension), triggering a “sepsis bundle” (early antibiotics, fluids, and source control within 12 hours). A 2022 *Critical Care Medicine* study reported a 25% reduction in mortality with bundle compliance. Extracorporeal membrane oxygenation (ECMO) is increasingly used for peripartum respiratory failure, with a 70% survival rate in case series. Perimortem cesarean delivery, recommended within 5 minutes of cardiac arrest without return of spontaneous circulation, improves maternal survival by 30% and fetal survival by 80%. Challenges in critical care include resource disparities, with low-income settings facing shortages of trained personnel and equipment, limiting ECMO and POCUS access.\n \n**Emerging Challenges and Future Directions**: Despite progress, obstetric anesthesia faces barriers to equitable care. Low-literacy populations and rural settings struggle with ERAC adoption due to inadequate patient education and infrastructure. The use of unapproved agents like dextromethorphan in pregnancy remains controversial, with insufficient safety data. Precision medicine, leveraging genetic profiling (e.g., CYP2D6 polymorphisms for opioid metabolism), holds promise for tailoring analgesia but is limited by cost and biomarker availability. Artificial intelligence (AI)-assisted ultrasound and predictive analytics for hemorrhage risk are under investigation, with pilot studies showing 85% accuracy in predicting severe outcomes. Training programs for anesthesiologists in low-resource settings are critical to bridge gaps, as emphasized by the World Federation of Societies of Anaesthesiologists (WFSA). Multidisciplinary protocols, standardized across regions, are needed to ensure consistent care, particularly for high-risk conditions like preeclampsia and VTE.\n \nThese advancements underscore the dynamic nature of obstetric anesthesia, requiring ongoing research, training, and policy support to address global disparities and optimize maternal-fetal outcomes.\n",
    "reference_list": "考点1：\"Ultrasound-guided neuraxial techniques\" 推荐译为 “超声引导的椎管内穿刺技术”\n考点2：\"epidural blood patch\" 必须译为 “硬膜外血补丁”\n考点3：\"maternal sepsis\" 推荐译为 “产妇脓毒症”\n考点4：\"combined spinal-epidural (CSE)\" 推荐译为 “腰麻 - 硬膜外联合（CSE）”\n考点5：\"Non-neuraxial options\" 推荐译为 “非椎管内麻醉”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "152"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n生物学：生命系统的认知与探索‌\n‌一、生命演化历程与生物多样性‌\n‌1. 地球生命的起源与阶段演化‌\n现存生物经历了约35亿年的渐进演化。最早的原核生物（细菌、蓝藻）出现于35-33亿年前，开启“菌藻植物时代”。至4亿年前志留纪晚期，绿藻演化出原始陆生维管植物——裸蕨，标志着陆地生态系统的初步形成。泥盆纪末期，裸蕨被蕨类植物取代，进入“蕨类植物时代”，巨型乔木状蕨类（如鳞木、芦木）成为陆地主导。二叠纪至白垩纪早期，裸子植物兴起（“裸子植物时代”），中生代达到繁盛顶峰。白垩纪至今为“被子植物时代”，其种类多样性、环境适应性使其成为现代优势类群。\n2. ‌演化规律与驱动力‌\n生命演化遵循“从低级到高级、简单到复杂、水生到陆生”的路径，核心驱动力包括遗传变异、自然选择及环境适应性分化。苔藓植物虽在泥盆纪出现，但因适应性局限未能成为主流，印证了演化中的“侧支淘汰”现象。\n‌二、现代生物学的研究维度与应用‌\n‌1. 微观机制解析‌\n‌- 基因工程‌：通过重组DNA技术定向改造生物遗传物质。例如，将外源基因导入受体细胞，实现跨物种性状传递，为农业育种（抗虫作物）及医学（胰岛素合成）提供核心技术支持。\n‌- 细胞抗逆机制‌：研究揭示植物抵抗重金属胁迫的策略。以大白菜为例，耐镉品种通过将镉固定在根细胞壁（占比70%以上），并提升非蛋白硫醇（如植物螯合肽）和柠檬酸浓度，显著降低镉向地上部分的转运。\n2. ‌生态保护与可持续发展‌\n- ‌生物多样性保护‌：成都大熊猫基地通过种群复壮技术及公众科普，近三年开展576场活动，推动公众认知物种保护的紧迫性。\n‌- 低碳实践‌：推广节能灯（耗电仅为白炽灯的1/5）、自行车通勤（强化心肺功能并减少碳排放）等行为，将生物学原理转化为公民环保行动。\n‌三、生物学教育的核心理念革新‌\n‌1. 生命教育渗透‌\n中小学课堂强化“认识生命-珍爱生命-敬畏生命”的逻辑主线。例如：\n- 高中课程关联细胞构成（C、H、O、N等元素化合物）与个体发育（受精卵分化），引导学生理解生命诞生的系统性；\n- 初中采用“情境驱动”教学，如通过食物霉变案例导入《细菌和真菌的分布》课程，激发探究兴趣。\n‌2. 跨学科能力整合‌\n‌- 实验技能‌：初中生需掌握显微观察、标本制作等基础技术；高中进阶至DNA提取、PCR扩增等分子操作。\n‌- 学科融合‌：如生物-化学交叉（“生化不分家”），学习有机化学（《有机化学基础》）是理解蛋白质结构、代谢途径的前提。\n‌四、前沿领域与未来挑战‌\n‌1. 生命节律与健康干预‌\n2024年世界生命科学大会聚焦“昼夜节律”对代谢、免疫的调控机制。研究发现，广西长寿人群肠道菌群结构与青年人类似，提示微生物组“年轻化”可能是抗衰老的关键靶点。\n‌2. 合成生物学突破‌\n基于基因编辑技术（如CRISPR），科学家尝试设计人工生命系统。例如重构微生物代谢通路生产生物燃料，或合成新型药物前体，推动“定制化生物制造”进程。\n‌3. 全球科研竞争力‌\n据2023自然指数排名，中国在生命科学领域以21,300.75分位列全球第一，美国（20,255.78分）、德国（4,354.03分）紧随其后，亚洲国家中韩国（1,624.03分）、印度（1,323.46分）加速追赶。\n‌结语：生物学的使命与担当‌\n生物学始终肩负解析生命本质、协调人地关系的双重使命。从三十亿年演化史的追溯，到基因编辑技术的伦理边界探讨，学科发展需坚持‌科技创新‌（如合成生物学）与‌科学普及‌（如大熊猫保护宣传）并重，最终实现“人与自然和谐共生”的终极目标。",
    "ori_text": "生物学：生命系统的认知与探索‌\n‌一、生命演化历程与生物多样性‌\n‌1. 地球生命的起源与阶段演化‌\n现存生物经历了约35亿年的渐进演化。最早的原核生物（细菌、蓝藻）出现于35-33亿年前，开启“菌藻植物时代”。至4亿年前志留纪晚期，绿藻演化出原始陆生维管植物——裸蕨，标志着陆地生态系统的初步形成。泥盆纪末期，裸蕨被蕨类植物取代，进入“蕨类植物时代”，巨型乔木状蕨类（如鳞木、芦木）成为陆地主导。二叠纪至白垩纪早期，裸子植物兴起（“裸子植物时代”），中生代达到繁盛顶峰。白垩纪至今为“被子植物时代”，其种类多样性、环境适应性使其成为现代优势类群。\n2. ‌演化规律与驱动力‌\n生命演化遵循“从低级到高级、简单到复杂、水生到陆生”的路径，核心驱动力包括遗传变异、自然选择及环境适应性分化。苔藓植物虽在泥盆纪出现，但因适应性局限未能成为主流，印证了演化中的“侧支淘汰”现象。\n‌二、现代生物学的研究维度与应用‌\n‌1. 微观机制解析‌\n‌- 基因工程‌：通过重组DNA技术定向改造生物遗传物质。例如，将外源基因导入受体细胞，实现跨物种性状传递，为农业育种（抗虫作物）及医学（胰岛素合成）提供核心技术支持。\n‌- 细胞抗逆机制‌：研究揭示植物抵抗重金属胁迫的策略。以大白菜为例，耐镉品种通过将镉固定在根细胞壁（占比70%以上），并提升非蛋白硫醇（如植物螯合肽）和柠檬酸浓度，显著降低镉向地上部分的转运。\n2. ‌生态保护与可持续发展‌\n- ‌生物多样性保护‌：成都大熊猫基地通过种群复壮技术及公众科普，近三年开展576场活动，推动公众认知物种保护的紧迫性。\n‌- 低碳实践‌：推广节能灯（耗电仅为白炽灯的1/5）、自行车通勤（强化心肺功能并减少碳排放）等行为，将生物学原理转化为公民环保行动。\n‌三、生物学教育的核心理念革新‌\n‌1. 生命教育渗透‌\n中小学课堂强化“认识生命-珍爱生命-敬畏生命”的逻辑主线。例如：\n- 高中课程关联细胞构成（C、H、O、N等元素化合物）与个体发育（受精卵分化），引导学生理解生命诞生的系统性；\n- 初中采用“情境驱动”教学，如通过食物霉变案例导入《细菌和真菌的分布》课程，激发探究兴趣。\n‌2. 跨学科能力整合‌\n‌- 实验技能‌：初中生需掌握显微观察、标本制作等基础技术；高中进阶至DNA提取、PCR扩增等分子操作。\n‌- 学科融合‌：如生物-化学交叉（“生化不分家”），学习有机化学（《有机化学基础》）是理解蛋白质结构、代谢途径的前提。\n‌四、前沿领域与未来挑战‌\n‌1. 生命节律与健康干预‌\n2024年世界生命科学大会聚焦“昼夜节律”对代谢、免疫的调控机制。研究发现，广西长寿人群肠道菌群结构与青年人类似，提示微生物组“年轻化”可能是抗衰老的关键靶点。\n‌2. 合成生物学突破‌\n基于基因编辑技术（如CRISPR），科学家尝试设计人工生命系统。例如重构微生物代谢通路生产生物燃料，或合成新型药物前体，推动“定制化生物制造”进程。\n‌3. 全球科研竞争力‌\n据2023自然指数排名，中国在生命科学领域以21,300.75分位列全球第一，美国（20,255.78分）、德国（4,354.03分）紧随其后，亚洲国家中韩国（1,624.03分）、印度（1,323.46分）加速追赶。\n‌结语：生物学的使命与担当‌\n生物学始终肩负解析生命本质、协调人地关系的双重使命。从三十亿年演化史的追溯，到基因编辑技术的伦理边界探讨，学科发展需坚持‌科技创新‌（如合成生物学）与‌科学普及‌（如大熊猫保护宣传）并重，最终实现“人与自然和谐共生”的终极目标。",
    "reference_list": "考点1：“演变规律”应翻译为“evolution law”\n考点2：《有机化学基础》应翻译为“Fundamentals of Organic Cheministry”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "39"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nWe start by exploring the notion of a moral principle. If particularism is to hang its hat on rejecting “moral principles,” we had better know what sort of creatures they would be.\n The term “moral principle” is bandied about loosely: It can sound as though any list of broad moral injunctions count, which makes it difficult to isolate particularism’s target. That difficulty is probably reinforced by the doctrine’s name (not to mention the rhetorical flourishes its proponents sometimes favor); “particularism,” after all, sounds as though it must stand in opposition to “generalism”—a position, presumably, that attests to the existence or usefulness of generality in morality. But there are some forms of generality—for example, subsumption under concepts, or, again, everyday generalizations about, say, the frequency of unfair elections—that no one would eschew. In fact, though, the conception of moral principle that forms particularism’s target is meant to be something quite specific. Let’s take a look.\n We can begin by distinguishing two different tasks that purported principles have been asked to play in morality. Broadly put, normative principles purport to articulate which considerations count as good- or bad-making, right- or wrong-making. In contrast to ontological claims about what, as it were, make good making features good-making—a divine commandment, a Platonic Reality, the output of some idealized contract—normative principles aim to set forth those that do so count. A deontologist’s list of duties, the utilitarian’s injunction to maximize net aggregate utility, the Ten Commandments would all qualify—together with theoretical generalizations that try to elucidate the concepts therein (understanding, say, what makes an act count as consent, a gesture as generous).  \nDeliberative principles are generalizations that purport to give us advice on what procedures mere mortals should follow in order to arrive at good moral verdicts. These principles lay out directions to agents about what to do with a given set of inputs in order to move from uncertainty to clarity, disagreement to resolution. For many, of course, the correct deliberative principles piggyback fairly straightforwardly on the correct normative principles: The best procedure is to apply one’s understanding of the normative principles to the inputs at hand. The two sorts of principles needn’t go hand in hand, though. After all, one might think the moral landscape susceptible to all manner of interesting methods of divination—kicking the Blarney stone three times, following instructions to achieve the requisite meditative epiphany, doing whatever one’s wise friend Fred does. Less fancifully, many utilitarians famously distinguish their normative and deliberative principles: The utilitarian calculus determines what actions are in fact good or bad, but it isn’t as if one is meant to engage in expected utility calculations when deciding how to react to an abusive boyfriend. Here local rules of thumb are advised, precisely because employing them has higher utility than attempting a utility calculation.\n Kant’s moral philosophy was complex in part because he provided both sorts of principles. Part of his task was to outline a principle that marks a deliberative procedure for deciding what is permissible—namely, identify one’s maxim, see if it could be a natural law, and then see if it could be willed as such. This is a principle that doesn’t itself state contentful moral injunctives. But he also, familiarly, pulled back from that first-personal test to defend a set of normative in junctions, including directives not to lie, not to treat others as mere means (or wear wigs).\n We have, then, two agendas that are at least conceptually separable: sorting out the nature of moral reality and figuring out procedures to make our moral way.\n Now obviously, a great many people, from Ann Landers to Aristotle, think there’s something to be said by way of filling in our understanding of the normative terrain and of giving suggestions for helpful procedures. At the core of an enormously wide range of Western ethical theory, though, is a certain conception of the sort of generalization we can—and should—find in answer to these questions. The conception is sufficiently dominant, indeed, that it might fairly be called the classical conception of moral Principles (hence hereafter awarded capitalization). It is this sort of Principle that forms the target of particularism.\n A classical Principle is marked by the following three features.\n 1. Classical Principles are universal, exceptionless, law-like moral generalizations that mark the moral import of considerations. Normative such Principles purport to illuminate something’s moral status, or again to set forth the conditions for understanding its moral status, by making explicit a necessary and nontrivial connection. Deliberative such Principles, where distinct from invocations to use the former, purport to set forth procedures that, if ideally executed, guarantee hitting their mark, by capturing something essential about the nature of good deliberation (think of Kant’s Categorical Imperative test rather than the utilitarian’s locally useful rules of thumb). This implies that while such Principles can be rendered as universal conditionals of the form\n(∀x)(Fx → Gx)；or perhaps □(∀x)(Fx → Gx)\nwhere G picks out some recognizable moral property, the conditional must assert some sort of a substantive and law-like connection between F and G. The → is not, that is, the ⊃ of material implication: Surface grammar does not a Principle make.\n 2. The conditionals implicit in classical Principles serve genuine inferential roles in determining, criticizing, or justifying particular moral claims. They are supposed to name a genuinely possible move from noting that something is F to concluding it is G: They concern the import, that is, of features whose moral import—for instance, whether it counts as a reason for or against the action—is in principle questionable. Crucially, then, agreement on a given Principle can serve as epistemic leverage on beliefs, hunches, or conjectures about individual cases. Hence, → is also not expressing merely the sort of self-evident entailment of obvious analyticity that, however helpful it might be for housekeeping and regimenting our language, is without possibility of substantive controversy.\n 3. Classical Principles are members of theoretical systems. A system, as the name implies, is meant to be more than simply an aggregate—or “unconnected heap,” as David McNaughton (1996) nicely puts it—of true generalizations. A system is a set of interanimating propositions whose cross-connections themselves serve to illuminate the subject matter. Crucially, then, commitment to one Principle can serve as leverage when discussing, deliberating, or disputing commitment to another such generalization. Such inter-Principle leverage can be achieved either through simplification—as when we corral otherwise disparate phenomena under a few common and elegantly interrelated categories, or by articulating a complex web whose multiplicity of inferential connections between Principles helps to tighten our understanding of each. Whatever account one prefers, something isn’t a classical Principle unless it fits into a structure of other Principles that purport to systematic illumination.\n Classical Principles, then, are exceptionless, explanatory, interrelated moral generalizations that are capable of serving key epistemic functions.\n Highlighting these various features begins to show why there is something substantive in contention with their denial. It’s sometimes argued that particularism’s objection to Principles, far from being radical, is more a tempest in a teapot. Everyone, surely, is a generalist, once we go sufficiently far up in abstraction or far down in detail. After all, even particularists agree that the moral supervenes on the natural—two situations cannot be alike in every natural respect and differ  in their moral features. This means that there must be some exceptionless generalizations that express the moral as a function of the natural. Such “supervenience functions,” as we might call them, may of course be enormously complex; but that’s just a difference in degree, not kind. Moving to the other end of the spectrum, even the most committed particularist, it’s said, will admit that there is some level of abstraction where moral generalizations are safe from exception, if only principles such as ‘pursue the good’ or ‘do the right thing’. This means, though, that they are not rejecting principles, just squabbling over their concreteness. Particularists, in short, don’t reject moral principles; they just relocate them.\n But admitting the existence of exceptionless moral generalizations is not equivalent to admitting to the existence of Principles. As the foregoing criteria make clear, the latter must be explanatory, ensconced in a surrounding theory, and epistemically useful. This means, for one, that acknowledgement of mere supervenience functions does not go far toward acknowledgement of a Principle.\n As John McDowell (1979) points out, supervenience can be admitted so readily because doing so admits to so little: it doesn’t mean that there are any useful patterns to the way in which the dependencies line up (see also Little, 2000, sec. 3; Jackson, Pettit, and Smith, 2000). While situations can’t differ in their moral properties without also differing in their natural properties, that is, this does not imply that a given moral difference (say, the difference between being just and unjust) need always be found in the same natural differences. Instead, stringing together the situations in which an action is cruel rather than kind, for example, may yield groupings that would simply look gerrymandered to anyone who does not have an independent competency with the moral concepts. On such a picture, the complicated sets of properties mentioned in supervenience functions will not constitute anything recognizably explanatory; they are too disjointed—“too indiscriminate,” as Jonathan Dancy (1999, p. 26) puts it—to serve. \nSimilarly for abstraction. It’s certainly true that no one will abjure the existence of exceptionless heady abstractions in morality—at the limit, we can invent a predicate whose application entails invariant moral import (we could dub ‘lighing’, say, as the term to pick out those cases of lying that are wrong-making). But this doesn’t yet mean we have on hand anything explanatory or procedurally useful. If classification as such simply reflects judgment of its objectionable nature definitionally, no substantive explanatory work will be done by the generalization that lighings are wrong. The predicate may still be useful—say, in marking off moral from pragmatic or again legal reasons; but expression of the generalization won’t serve as check on one’s specific intuitions. Similarly for deliberative principles. “Choose well, grasshopper,” may be a pragmatically helpful inspiration, but it hardly offers substantive guidance.\n Finally, since classical Principles are meant to be pieces of theory, one cannot determine the status of a given generalization as such in isolation from its relation to other theoretical generalizations. This excludes one otherwise innocuous use of the “principlist” label as off topic here. Someone who avows a particular list of injunctions as “principles to live by” may count in one sense as strongly principlist; if those principles, though, are a disconnected list, or involve concepts, such as Justice Stewart’s conception of ‘obscenity’, about which no further theorizing can be done, one does not thereby count as advocating a set of Principles of the sort particularists want to reject.",
    "ori_text": "\n\nWe start by exploring the notion of a moral principle. If particularism is to hang its hat on rejecting “moral principles,” we had better know what sort of creatures they would be.\n The term “moral principle” is bandied about loosely: It can sound as though any list of broad moral injunctions count, which makes it difficult to isolate particularism’s target. That difficulty is probably reinforced by the doctrine’s name (not to mention the rhetorical flourishes its proponents sometimes favor); “particularism,” after all, sounds as though it must stand in opposition to “generalism”—a position, presumably, that attests to the existence or usefulness of generality in morality. But there are some forms of generality—for example, subsumption under concepts, or, again, everyday generalizations about, say, the frequency of unfair elections—that no one would eschew. In fact, though, the conception of moral principle that forms particularism’s target is meant to be something quite specific. Let’s take a look.\n We can begin by distinguishing two different tasks that purported principles have been asked to play in morality. Broadly put, normative principles purport to articulate which considerations count as good- or bad-making, right- or wrong-making. In contrast to ontological claims about what, as it were, make good making features good-making—a divine commandment, a Platonic Reality, the output of some idealized contract—normative principles aim to set forth those that do so count. A deontologist’s list of duties, the utilitarian’s injunction to maximize net aggregate utility, the Ten Commandments would all qualify—together with theoretical generalizations that try to elucidate the concepts therein (understanding, say, what makes an act count as consent, a gesture as generous).  \nDeliberative principles are generalizations that purport to give us advice on what procedures mere mortals should follow in order to arrive at good moral verdicts. These principles lay out directions to agents about what to do with a given set of inputs in order to move from uncertainty to clarity, disagreement to resolution. For many, of course, the correct deliberative principles piggyback fairly straightforwardly on the correct normative principles: The best procedure is to apply one’s understanding of the normative principles to the inputs at hand. The two sorts of principles needn’t go hand in hand, though. After all, one might think the moral landscape susceptible to all manner of interesting methods of divination—kicking the Blarney stone three times, following instructions to achieve the requisite meditative epiphany, doing whatever one’s wise friend Fred does. Less fancifully, many utilitarians famously distinguish their normative and deliberative principles: The utilitarian calculus determines what actions are in fact good or bad, but it isn’t as if one is meant to engage in expected utility calculations when deciding how to react to an abusive boyfriend. Here local rules of thumb are advised, precisely because employing them has higher utility than attempting a utility calculation.\n Kant’s moral philosophy was complex in part because he provided both sorts of principles. Part of his task was to outline a principle that marks a deliberative procedure for deciding what is permissible—namely, identify one’s maxim, see if it could be a natural law, and then see if it could be willed as such. This is a principle that doesn’t itself state contentful moral injunctives. But he also, familiarly, pulled back from that first-personal test to defend a set of normative in junctions, including directives not to lie, not to treat others as mere means (or wear wigs).\n We have, then, two agendas that are at least conceptually separable: sorting out the nature of moral reality and figuring out procedures to make our moral way.\n Now obviously, a great many people, from Ann Landers to Aristotle, think there’s something to be said by way of filling in our understanding of the normative terrain and of giving suggestions for helpful procedures. At the core of an enormously wide range of Western ethical theory, though, is a certain conception of the sort of generalization we can—and should—find in answer to these questions. The conception is sufficiently dominant, indeed, that it might fairly be called the classical conception of moral Principles (hence hereafter awarded capitalization). It is this sort of Principle that forms the target of particularism.\n A classical Principle is marked by the following three features.\n 1. Classical Principles are universal, exceptionless, law-like moral generalizations that mark the moral import of considerations. Normative such Principles purport to illuminate something’s moral status, or again to set forth the conditions for understanding its moral status, by making explicit a necessary and nontrivial connection. Deliberative such Principles, where distinct from invocations to use the former, purport to set forth procedures that, if ideally executed, guarantee hitting their mark, by capturing something essential about the nature of good deliberation (think of Kant’s Categorical Imperative test rather than the utilitarian’s locally useful rules of thumb). This implies that while such Principles can be rendered as universal conditionals of the form\n(∀x)(Fx → Gx)；or perhaps □(∀x)(Fx → Gx)\nwhere G picks out some recognizable moral property, the conditional must assert some sort of a substantive and law-like connection between F and G. The → is not, that is, the ⊃ of material implication: Surface grammar does not a Principle make.\n 2. The conditionals implicit in classical Principles serve genuine inferential roles in determining, criticizing, or justifying particular moral claims. They are supposed to name a genuinely possible move from noting that something is F to concluding it is G: They concern the import, that is, of features whose moral import—for instance, whether it counts as a reason for or against the action—is in principle questionable. Crucially, then, agreement on a given Principle can serve as epistemic leverage on beliefs, hunches, or conjectures about individual cases. Hence, → is also not expressing merely the sort of self-evident entailment of obvious analyticity that, however helpful it might be for housekeeping and regimenting our language, is without possibility of substantive controversy.\n 3. Classical Principles are members of theoretical systems. A system, as the name implies, is meant to be more than simply an aggregate—or “unconnected heap,” as David McNaughton (1996) nicely puts it—of true generalizations. A system is a set of interanimating propositions whose cross-connections themselves serve to illuminate the subject matter. Crucially, then, commitment to one Principle can serve as leverage when discussing, deliberating, or disputing commitment to another such generalization. Such inter-Principle leverage can be achieved either through simplification—as when we corral otherwise disparate phenomena under a few common and elegantly interrelated categories, or by articulating a complex web whose multiplicity of inferential connections between Principles helps to tighten our understanding of each. Whatever account one prefers, something isn’t a classical Principle unless it fits into a structure of other Principles that purport to systematic illumination.\n Classical Principles, then, are exceptionless, explanatory, interrelated moral generalizations that are capable of serving key epistemic functions.\n Highlighting these various features begins to show why there is something substantive in contention with their denial. It’s sometimes argued that particularism’s objection to Principles, far from being radical, is more a tempest in a teapot. Everyone, surely, is a generalist, once we go sufficiently far up in abstraction or far down in detail. After all, even particularists agree that the moral supervenes on the natural—two situations cannot be alike in every natural respect and differ  in their moral features. This means that there must be some exceptionless generalizations that express the moral as a function of the natural. Such “supervenience functions,” as we might call them, may of course be enormously complex; but that’s just a difference in degree, not kind. Moving to the other end of the spectrum, even the most committed particularist, it’s said, will admit that there is some level of abstraction where moral generalizations are safe from exception, if only principles such as ‘pursue the good’ or ‘do the right thing’. This means, though, that they are not rejecting principles, just squabbling over their concreteness. Particularists, in short, don’t reject moral principles; they just relocate them.\n But admitting the existence of exceptionless moral generalizations is not equivalent to admitting to the existence of Principles. As the foregoing criteria make clear, the latter must be explanatory, ensconced in a surrounding theory, and epistemically useful. This means, for one, that acknowledgement of mere supervenience functions does not go far toward acknowledgement of a Principle.\n As John McDowell (1979) points out, supervenience can be admitted so readily because doing so admits to so little: it doesn’t mean that there are any useful patterns to the way in which the dependencies line up (see also Little, 2000, sec. 3; Jackson, Pettit, and Smith, 2000). While situations can’t differ in their moral properties without also differing in their natural properties, that is, this does not imply that a given moral difference (say, the difference between being just and unjust) need always be found in the same natural differences. Instead, stringing together the situations in which an action is cruel rather than kind, for example, may yield groupings that would simply look gerrymandered to anyone who does not have an independent competency with the moral concepts. On such a picture, the complicated sets of properties mentioned in supervenience functions will not constitute anything recognizably explanatory; they are too disjointed—“too indiscriminate,” as Jonathan Dancy (1999, p. 26) puts it—to serve. \nSimilarly for abstraction. It’s certainly true that no one will abjure the existence of exceptionless heady abstractions in morality—at the limit, we can invent a predicate whose application entails invariant moral import (we could dub ‘lighing’, say, as the term to pick out those cases of lying that are wrong-making). But this doesn’t yet mean we have on hand anything explanatory or procedurally useful. If classification as such simply reflects judgment of its objectionable nature definitionally, no substantive explanatory work will be done by the generalization that lighings are wrong. The predicate may still be useful—say, in marking off moral from pragmatic or again legal reasons; but expression of the generalization won’t serve as check on one’s specific intuitions. Similarly for deliberative principles. “Choose well, grasshopper,” may be a pragmatically helpful inspiration, but it hardly offers substantive guidance.\n Finally, since classical Principles are meant to be pieces of theory, one cannot determine the status of a given generalization as such in isolation from its relation to other theoretical generalizations. This excludes one otherwise innocuous use of the “principlist” label as off topic here. Someone who avows a particular list of injunctions as “principles to live by” may count in one sense as strongly principlist; if those principles, though, are a disconnected list, or involve concepts, such as Justice Stewart’s conception of ‘obscenity’, about which no further theorizing can be done, one does not thereby count as advocating a set of Principles of the sort particularists want to reject.",
    "reference_list": "考点1：“deliberative principles”译为“慎思性原则”\n考点2：“kicking the Blarney stone three times”译为“踢巧言石三次\n考点3：“a tempest in a teapot”译为“小题大做”，英语经典俚语\n考点4：“Choose well, grasshopper”译为“好好选择吧，年轻人/新人”， \n考点5：\"invocations\" 推荐译为“援引”或“诉诸”，不可译为“召唤”\n考点6：“abusive boyfriend”不可译为“虐待性男友”，应译为更中性的“一个施暴的伴侣”\n考点7：“interanimating”推荐译为“相互赋予生命、相互激发”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "184"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n1. Introduction\nPost-quantum cryptography (PQC) has been actively studied in recent years. To construct PQC, a public key encryption scheme (PKE) with chosen-plaintext attack (CPA) security is first developed, and then a key encapsulation mechanism (KEM) with chosen-ciphertext attack (CCA) security is obtained by combining the PKE with either the Fujisaki–Okamoto (FO) transform [FO99] or its variants. Thus, the re-encryption of the FO(-like) transform plays an essential role in the decapsulation of PQC.\nIn practical uses of PQC, security evaluation against implementation attacks, such as side-channel attacks, in addition to mathematical cryptanalysis attacks is inevitable. Side-channel attacks on PQC have been first studied on the PKE decryption part that exploits the secret key directly, similar to those on the modular exponentiation/scalar multiplication in RSA/elliptic curve cryptography (ECC). In recent years, another attack aspect has been studied [GTN20,RRCB20,UXT+21], in which the attacker focuses on the leakage of re-encryption to implement a decryption oracle, which enables one to mount a chosen-ciphertext attack (CCA) on the underlying CPA-secure PKE. Note that the decryption oracle is not necessarily a full decryption oracle but it can be, for example, plaintext-checking (PC) and decryption-failure (DF) oracles. These attacks suggest that we should protect not only the PKE decryption but also the whole KEM decapsulation, including re-encryption and the equality/validity checks of the re-encrypted ciphertext, against side-channel attacks. Ueno et al. [UXT+21] showed that such an attack was generally applicable to many post-quantum KEMs equipped with an FO-like transforms, and demonstrated that their attack could recover eight of the nine KEM candidates in the third round of the NIST PQC standardization.\nThese studies suggest that the potential and limitation of such attacks (i.e., the least number of side-channel traces for a successful key recovery) should be investigated to develop secure KEM implementations, including the design of countermeasures and/or cryptographic protocols. The number of side-channel traces required for a successful attack is commonly determined by two factors: (1) the number of decryption oracle accesses required for key recovery and (2) the number of traces required to realize the reliable decryption oracle. Therefore, a tight evaluation of the factors, that is, an efficient keyrecovery algorithm with a decryption oracle that can be realized from side-channel traces, would contribute to understanding the least number of traces (i.e., the optimal attack cost) for a successful key recovery.\n2.Related works\nA KEM is a public-key cryptographic primitive used to transmit a secret key securely. A KEM consists of three probabilistic polynomial-time algorithms: key generation (KeyGen), encapsulation (Encaps), and decapsulation (Decaps). Most post-quantum KEMs are proven to be CCA secure since they adopt an FO-like transform. Here, we refer to FO transforms and their variants [HHK17, SXY18, BHH+19] as FO-like transforms. Algorithm 1 illustrates a typical post-quantum KEM equipped with an underlying PKE scheme and an FO-like transform, assuming that the PKE is CPA secure and is given as three probabilistic polynomial-time algorithms: key generation Gen, encryption Enc and decryption Dec. Such KEMs employ random oracles (ROs) denoted by G, H, and Hprf in Algorithm 1, which are frequently realized using a cryptographic hash function (or other symmetric primitive), and are frequently instantiated with SHA-3 or SHAKE. The attacks considered herein focus on the decapsulation KEM.Decaps, which computes the shared secret as a result of H at Line 6 from an input ciphertext c, a private key sk and a public key pk (if the input ciphertext is valid). KEM.Decaps first applies the PKE decryption PKE.Dec to compute the corresponding plaintext m′ from the ciphertext and then performs a re-encryption to validate the computed m′, that is, computes PKE.Enc in the same manner as KEM.Encaps to check whether the re-encrypted ciphertext c′ equals to the input ciphertext c. If c = c′, the input ciphertext is considered valid, and the shared secret H(m′, c) is then calculated and output. Otherwise (i.e., c ̸= c′), the ciphertext is invalid, and a pseudorandom value computed using Hprf (or a rejection symbol) is output at Line 8. The FO-like transform performs the ciphertext verification to detect any invalid ciphertexts and prevent any CCA that queries invalid ciphertexts and exploits their decryption results.\nSide-channel attacks on the FO-like transforms were initially presented in the pioneering works by Guo et al. [GTN20] and Ravi et al. [RRCB20]. Guo et al. presented a timing attack exploiting the equality check (as at Line 5 in Algorithm 1). Ciphertexts of postquantum KEMs are treated as a long vector in CPUs/microcontrollers. A comparison using an usual operation (e.g., memcmp) takes a (relatively) long time if two ciphertexts are very similar to each other; otherwise, the comparison terminates shortly. They exploited this timing difference to implement a PC oracle for lattice- and code-based KEMs, and presented key-recovery attacks for lattice-based and code-based KEMs where the equality check was not implemented in constant time. Ravi et al. reported the first power/EM attack on an FO-like transform. The attack implemented a PC oracle or decryption failure oracle by exploiting the side-channel leakage during computation of RO (i.e., hash function) in re-encryption with a t-test-based template. Their attack achieved key recovery of six lattice-based KEMs: Kyber, Saber, FrodoKEM, Round5, NewHope and LAC.  Bhasin et al. [BDH+21] presented an attack on masked polynomial comparison schemes for Kyber, Saber, and FrodoKEM [OSPG18, BPO+20] by exploiting ciphertext equality checks in lattice-based KEMs and demonstrated its application to Kyber. They implemented a PC oracle using a distinguisher based on the t-test. More recently, Ueno et al. demonstrated a generalization of power/EM attacks on FO-like transforms [UXT+21]. They illustrated that the side-channel leakage during re-encryption can be generally exploited if a KR-PCA on the underlying PKE is known. They demonstrated that their attack could achieve key recovery of eight out of nine KEMs of NIST PQC third-round candidates. One major research direction of attacks of this kind is to improve the attack efficiency (i.e., reduce the number of required traces) for a precise evaluation of the cost of an optimal attack. Other side-channel-assisted CCAs have also been extensively studied in this way [XPR+22, RBRC22, SKL+20, REB+21, NDGJ21], especially for lattice-based KEMs. More recently, in [QCZ+21], Qin et al. showed an improvement of CCAs on lattice-based KEMs using a binary key-mismatch oracle with adaptive queries, which reduced the number of oracle accesses/queries compared to that of the CCA used in [UXT+21]. In [SCZ+23], Shen et al. presented a side-channel-assisted CCA using a binary PC oracle with an error correction of the PC oracle outputs, implemented by side-channel information. They showed that the error tolerance reduced the number of traces required to implement a PC oracle, which reduced the total number of traces required for key recovery. They also applied their attack to Kyber, and achieved up to 55.4% reduction of the total number of traces required for key recovery compared to that in [UXT+21].\n3.Proposed Attack\nThe major drawback of CCAs with the PC oracle outlined in Section 2.3 is that the attacker obtains no more than one-bit information per oracle access4, which results in a large number of traces being required for key recovery. In this study, we propose an oracle named the multiple-valued plaintext-checking (MV-PC) oracle to extract more bits of information per oracle access. Let μ be a positive integer. Consider an attacker who knows that a ciphertext c ̃ is necessarily decrypted to either of the μ plaintexts m0, m1, . . . , mμ−1. The attacker can recover the secret key of the KEM with repeated and adaptive queries if the attacker knows to which plaintext c ̃ is decrypted. Such an oracle is a generalization of the (binary) PC oracle with μ = 2. Note that, without side-channels, the FO-like transform theoretically does not provide any information about which plaintext c ̃ corresponds to (although the attacker knows the reference plaintext for valid ciphertext). We name this oracle the MV-PC oracle, and formally define it as  Oμ(c ̃; m0, m1, . . . , mμ−1) = v s.t. PKE.Decsk(c ̃) = mv.  Intuitively, the MV-PC oracle for μ values (called μV-PC) provides up-to log2 μ information to the attacker; therefore, a CCA using the MV-PC oracle would achieve key recovery with fewer oracle accesses roughly by a factor of 1/ log2 μ than that of the conventional KR-PCA with the binary PC oracle.\n3.2 General attack description\nThe proposed attack exploits an MV-PC oracle through a side-channel leakage and recovers the secret key by side-channel-assisted CCA on the underlying CPA-secure PKE. As well as the previous attack in [UXT+21], the proposed attack focuses on the side-channel leakage during the RO evaluation (i.e., computation of symmetric primitive like hash function) of re-encryption in PKE.Decaps. Using the side-channel leakage, the attacker accesses to an MV-PC oracle; that is, estimates which an invalid ciphertext c ̃ is decrypted to plaintext m0, m1, . . . , mμ−1 by PKE.Dec. If the attacker can correctly estimate the plaintext from the side-channel leakage, the attacker can perform a key recovery CCA. The proposed attack achieves a key recovery with fewer side-channel traces, if the MV-PC oracle is efficiently implemented. As in [UXT+21], the proposed SCA consists of profiling and attack phases. In the profiling phase, the attacker trains a μ-classification NN to estimate the plaintext (i.e., implement an μV-PC oracle) from side-channel traces during the RO evaluation. In the attack phase, the attacker queries invalid ciphertexts and performs a CCA using the μVPC oracle implemented by the trained NN. Although the attack requires a profiling, we do not require any profiling device which the attacker can know/control the secret key, in contrast to major DL-based side-channel attacks on symmetric primitive. This is because the profiling can be carried out without secret key, as in previous SCAs on latticebased KEMs [RRCB20, XPR+22, RBRC20, SKL+20, NDGJ21, UXT+21]. The usage of NN makes the proposed attack general and efficient, because it has been shown that\nDL-based side-channel attacks are applicable to various implementations (including ones with countermeasures such as masking and random delay) without detailed knowledge of implementation nor a specific condition/assumption about leakage. Moreover, the proposed attack can be carried out by the neural distinguisher from side-channel leakage during the RO evaluation, and the key recovery capability depends solely on the quality of the neural distinguisher.\n",
    "ori_text": "\n\n1. Introduction\nPost-quantum cryptography (PQC) has been actively studied in recent years. To construct PQC, a public key encryption scheme (PKE) with chosen-plaintext attack (CPA) security is first developed, and then a key encapsulation mechanism (KEM) with chosen-ciphertext attack (CCA) security is obtained by combining the PKE with either the Fujisaki–Okamoto (FO) transform [FO99] or its variants. Thus, the re-encryption of the FO(-like) transform plays an essential role in the decapsulation of PQC.\nIn practical uses of PQC, security evaluation against implementation attacks, such as side-channel attacks, in addition to mathematical cryptanalysis attacks is inevitable. Side-channel attacks on PQC have been first studied on the PKE decryption part that exploits the secret key directly, similar to those on the modular exponentiation/scalar multiplication in RSA/elliptic curve cryptography (ECC). In recent years, another attack aspect has been studied [GTN20,RRCB20,UXT+21], in which the attacker focuses on the leakage of re-encryption to implement a decryption oracle, which enables one to mount a chosen-ciphertext attack (CCA) on the underlying CPA-secure PKE. Note that the decryption oracle is not necessarily a full decryption oracle but it can be, for example, plaintext-checking (PC) and decryption-failure (DF) oracles. These attacks suggest that we should protect not only the PKE decryption but also the whole KEM decapsulation, including re-encryption and the equality/validity checks of the re-encrypted ciphertext, against side-channel attacks. Ueno et al. [UXT+21] showed that such an attack was generally applicable to many post-quantum KEMs equipped with an FO-like transforms, and demonstrated that their attack could recover eight of the nine KEM candidates in the third round of the NIST PQC standardization.\nThese studies suggest that the potential and limitation of such attacks (i.e., the least number of side-channel traces for a successful key recovery) should be investigated to develop secure KEM implementations, including the design of countermeasures and/or cryptographic protocols. The number of side-channel traces required for a successful attack is commonly determined by two factors: (1) the number of decryption oracle accesses required for key recovery and (2) the number of traces required to realize the reliable decryption oracle. Therefore, a tight evaluation of the factors, that is, an efficient keyrecovery algorithm with a decryption oracle that can be realized from side-channel traces, would contribute to understanding the least number of traces (i.e., the optimal attack cost) for a successful key recovery.\n2.Related works\nA KEM is a public-key cryptographic primitive used to transmit a secret key securely. A KEM consists of three probabilistic polynomial-time algorithms: key generation (KeyGen), encapsulation (Encaps), and decapsulation (Decaps). Most post-quantum KEMs are proven to be CCA secure since they adopt an FO-like transform. Here, we refer to FO transforms and their variants [HHK17, SXY18, BHH+19] as FO-like transforms. Algorithm 1 illustrates a typical post-quantum KEM equipped with an underlying PKE scheme and an FO-like transform, assuming that the PKE is CPA secure and is given as three probabilistic polynomial-time algorithms: key generation Gen, encryption Enc and decryption Dec. Such KEMs employ random oracles (ROs) denoted by G, H, and Hprf in Algorithm 1, which are frequently realized using a cryptographic hash function (or other symmetric primitive), and are frequently instantiated with SHA-3 or SHAKE. The attacks considered herein focus on the decapsulation KEM.Decaps, which computes the shared secret as a result of H at Line 6 from an input ciphertext c, a private key sk and a public key pk (if the input ciphertext is valid). KEM.Decaps first applies the PKE decryption PKE.Dec to compute the corresponding plaintext m′ from the ciphertext and then performs a re-encryption to validate the computed m′, that is, computes PKE.Enc in the same manner as KEM.Encaps to check whether the re-encrypted ciphertext c′ equals to the input ciphertext c. If c = c′, the input ciphertext is considered valid, and the shared secret H(m′, c) is then calculated and output. Otherwise (i.e., c ̸= c′), the ciphertext is invalid, and a pseudorandom value computed using Hprf (or a rejection symbol) is output at Line 8. The FO-like transform performs the ciphertext verification to detect any invalid ciphertexts and prevent any CCA that queries invalid ciphertexts and exploits their decryption results.\nSide-channel attacks on the FO-like transforms were initially presented in the pioneering works by Guo et al. [GTN20] and Ravi et al. [RRCB20]. Guo et al. presented a timing attack exploiting the equality check (as at Line 5 in Algorithm 1). Ciphertexts of postquantum KEMs are treated as a long vector in CPUs/microcontrollers. A comparison using an usual operation (e.g., memcmp) takes a (relatively) long time if two ciphertexts are very similar to each other; otherwise, the comparison terminates shortly. They exploited this timing difference to implement a PC oracle for lattice- and code-based KEMs, and presented key-recovery attacks for lattice-based and code-based KEMs where the equality check was not implemented in constant time. Ravi et al. reported the first power/EM attack on an FO-like transform. The attack implemented a PC oracle or decryption failure oracle by exploiting the side-channel leakage during computation of RO (i.e., hash function) in re-encryption with a t-test-based template. Their attack achieved key recovery of six lattice-based KEMs: Kyber, Saber, FrodoKEM, Round5, NewHope and LAC.  Bhasin et al. [BDH+21] presented an attack on masked polynomial comparison schemes for Kyber, Saber, and FrodoKEM [OSPG18, BPO+20] by exploiting ciphertext equality checks in lattice-based KEMs and demonstrated its application to Kyber. They implemented a PC oracle using a distinguisher based on the t-test. More recently, Ueno et al. demonstrated a generalization of power/EM attacks on FO-like transforms [UXT+21]. They illustrated that the side-channel leakage during re-encryption can be generally exploited if a KR-PCA on the underlying PKE is known. They demonstrated that their attack could achieve key recovery of eight out of nine KEMs of NIST PQC third-round candidates. One major research direction of attacks of this kind is to improve the attack efficiency (i.e., reduce the number of required traces) for a precise evaluation of the cost of an optimal attack. Other side-channel-assisted CCAs have also been extensively studied in this way [XPR+22, RBRC22, SKL+20, REB+21, NDGJ21], especially for lattice-based KEMs. More recently, in [QCZ+21], Qin et al. showed an improvement of CCAs on lattice-based KEMs using a binary key-mismatch oracle with adaptive queries, which reduced the number of oracle accesses/queries compared to that of the CCA used in [UXT+21]. In [SCZ+23], Shen et al. presented a side-channel-assisted CCA using a binary PC oracle with an error correction of the PC oracle outputs, implemented by side-channel information. They showed that the error tolerance reduced the number of traces required to implement a PC oracle, which reduced the total number of traces required for key recovery. They also applied their attack to Kyber, and achieved up to 55.4% reduction of the total number of traces required for key recovery compared to that in [UXT+21].\n3.Proposed Attack\nThe major drawback of CCAs with the PC oracle outlined in Section 2.3 is that the attacker obtains no more than one-bit information per oracle access4, which results in a large number of traces being required for key recovery. In this study, we propose an oracle named the multiple-valued plaintext-checking (MV-PC) oracle to extract more bits of information per oracle access. Let μ be a positive integer. Consider an attacker who knows that a ciphertext c ̃ is necessarily decrypted to either of the μ plaintexts m0, m1, . . . , mμ−1. The attacker can recover the secret key of the KEM with repeated and adaptive queries if the attacker knows to which plaintext c ̃ is decrypted. Such an oracle is a generalization of the (binary) PC oracle with μ = 2. Note that, without side-channels, the FO-like transform theoretically does not provide any information about which plaintext c ̃ corresponds to (although the attacker knows the reference plaintext for valid ciphertext). We name this oracle the MV-PC oracle, and formally define it as  Oμ(c ̃; m0, m1, . . . , mμ−1) = v s.t. PKE.Decsk(c ̃) = mv.  Intuitively, the MV-PC oracle for μ values (called μV-PC) provides up-to log2 μ information to the attacker; therefore, a CCA using the MV-PC oracle would achieve key recovery with fewer oracle accesses roughly by a factor of 1/ log2 μ than that of the conventional KR-PCA with the binary PC oracle.\n3.2 General attack description\nThe proposed attack exploits an MV-PC oracle through a side-channel leakage and recovers the secret key by side-channel-assisted CCA on the underlying CPA-secure PKE. As well as the previous attack in [UXT+21], the proposed attack focuses on the side-channel leakage during the RO evaluation (i.e., computation of symmetric primitive like hash function) of re-encryption in PKE.Decaps. Using the side-channel leakage, the attacker accesses to an MV-PC oracle; that is, estimates which an invalid ciphertext c ̃ is decrypted to plaintext m0, m1, . . . , mμ−1 by PKE.Dec. If the attacker can correctly estimate the plaintext from the side-channel leakage, the attacker can perform a key recovery CCA. The proposed attack achieves a key recovery with fewer side-channel traces, if the MV-PC oracle is efficiently implemented. As in [UXT+21], the proposed SCA consists of profiling and attack phases. In the profiling phase, the attacker trains a μ-classification NN to estimate the plaintext (i.e., implement an μV-PC oracle) from side-channel traces during the RO evaluation. In the attack phase, the attacker queries invalid ciphertexts and performs a CCA using the μVPC oracle implemented by the trained NN. Although the attack requires a profiling, we do not require any profiling device which the attacker can know/control the secret key, in contrast to major DL-based side-channel attacks on symmetric primitive. This is because the profiling can be carried out without secret key, as in previous SCAs on latticebased KEMs [RRCB20, XPR+22, RBRC20, SKL+20, NDGJ21, UXT+21]. The usage of NN makes the proposed attack general and efficient, because it has been shown that\nDL-based side-channel attacks are applicable to various implementations (including ones with countermeasures such as masking and random delay) without detailed knowledge of implementation nor a specific condition/assumption about leakage. Moreover, the proposed attack can be carried out by the neural distinguisher from side-channel leakage during the RO evaluation, and the key recovery capability depends solely on the quality of the neural distinguisher.\n",
    "reference_list": "考点1：“plaintext-checking oracle” 推荐翻译为 明文检查谕言机 或 明文检查预言机\n考点2：“full decryptyion oracle” 推荐翻译为 全解密谕言机 或 全解密预言机\n考点3： ”decryption failure oracle“ 推荐翻译为 解密失败谕言机 或 解密失败预言机\n考点4：“exploit\" 应跟据后接宾语调整翻译语义，如”exploit the secret key“推荐翻译为”非法获取私钥“，”exploit the decryption results“则推荐翻译为”利用解密后的结果“\n考点5：”invalid“ 在密码学选择密文攻击场景下推荐翻译为 ”非法的“\n考点6：”trace“ 在侧信道密码分析领域推荐翻译为 ”波形“\n考点7：”profiling phase“ 在侧信道密码分析领域推荐必须译为 ”建模阶段“\n考点8：”cryptographic primitive“ 推荐翻译为 ”密码学原语” 或 “密码学基础组件”\n考点9：“secret key” 在公钥密码学场景下必须译为 “私钥”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "139"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nPRIVATE EQUITY FUND SUBSCRIPTION AGREEMENT\nArticle 1: Fund Structure and Investment Objectives\nThis Subscription Agreement (\"Agreement\") is entered into between the General Partner, acting as the fund manager of ABC Private Equity Fund L.P. (\"Fund\"), and the undersigned Limited Partner (\"Investor\" or \"Subscriber\"). The Fund is structured as a limited partnership domiciled in Delaware, with the General Partner holding unlimited liability for fund operations and Limited Partners enjoying limited liability protection subject to their capital commitments.\nThe Fund's primary investment objective is to achieve superior risk-adjusted returns through acquiring controlling or significant minority stakes in middle-market companies across diversified sectors. The investment strategy focuses on value creation through operational improvements, strategic repositioning, and prudent use of leverage. The Fund operates under a closed-end structure with a predetermined investment period of five years, followed by a harvest period not exceeding three years.\nArticle 2: Capital Commitment and Drawdown Mechanisms\nThe Investor hereby commits to contribute the aggregate amount specified in Schedule A (\"Capital Commitment\") to the Fund. Such commitment represents the maximum amount that may be called by the General Partner during the commitment period. Capital contributions shall be made through a series of capital calls issued by the General Partner upon not less than ten (10) business days' prior written notice to all Limited Partners.\nEach capital call notice shall specify the purpose of the drawdown, the aggregate amount being called, each Limited Partner's pro rata share based on their respective capital commitments, and the deadline for funding. Failure to satisfy a capital call within the prescribed timeframe shall constitute a default event, subjecting the defaulting Limited Partner to remedial measures including, but not limited to, dilution of their partnership interest, forfeiture of previously contributed capital, and potential forced withdrawal from the Fund.\nThe General Partner reserves the right to implement a bridging facility to accommodate temporary funding needs, with any associated costs allocated proportionally among all Limited Partners. Interest expense and arrangement fees related to such facilities shall be treated as Fund expenses and allocated according to the waterfall distribution mechanism outlined herein.\nArticle 3: Management Fee Structure and Carried Interest\nThe Investor acknowledges and agrees to pay a management fee calculated as 2.0% per annum of the Investor's capital commitment during the commitment period, and 2.0% per annum of the Investor's contributed capital thereafter. Management fees are payable quarterly in advance and are subject to offset against future carried interest distributions to the General Partner.\nThe General Partner shall be entitled to carried interest equal to 20% of the Fund's net profits, subject to an 8% preferred return hurdle rate applied to Limited Partners' contributed capital. The carried interest calculation shall employ the European waterfall method, whereby carried interest is only distributed after all Limited Partners have received return of their contributed capital plus the specified preferred return on a cumulative basis.\nAny carried interest distributed to the General Partner shall be subject to clawback provisions in the event that subsequent portfolio company exits result in aggregate Fund performance falling below the hurdle rate threshold. The clawback mechanism ensures that Limited Partners receive their preferred return before any carried interest is definitively retained by the General Partner.\nArticle 4: Portfolio Company Governance and Reserved Rights\nThe General Partner shall maintain discretionary authority over all investment decisions, including but not limited to initial acquisitions, follow-on investments, portfolio company board representation, and exit strategies. However, certain material decisions require Limited Partner advisory committee approval or supermajority consent as specified in the Limited Partnership Agreement.\nReserved rights subject to Limited Partner approval include: (i) amendments to the investment strategy or geographic focus; (ii) co-investment opportunities exceeding 15% of total Fund commitments; (iii) related party transactions involving the General Partner or its affiliates; (iv) modifications to the fee structure or carried interest arrangement; and (v) early termination of the Fund or extension of the investment period beyond the initial five-year term.\nThe Limited Partner advisory committee shall comprise representatives elected by Limited Partners holding not less than 66% of total capital commitments. Advisory committee members serve two-year terms and are responsible for reviewing potential conflicts of interest, approving annual valuations of portfolio investments, and providing guidance on material Fund governance matters.\nArticle 5: Due Diligence and Disclosure Obligations\nThe Investor represents and warrants that they have conducted adequate due diligence regarding the Fund's investment strategy, risk profile, and operational framework. The Investor acknowledges receipt of the Fund's Private Placement Memorandum, Limited Partnership Agreement, and audited financial statements of the General Partner.\nThe General Partner shall provide quarterly reporting to all Limited Partners, including portfolio company valuations prepared in accordance with International Private Equity and Venture Capital Valuation Guidelines. Annual reports shall include audited financial statements prepared by an independent accounting firm of recognized international standing.\nThe General Partner maintains discretionary authority regarding the timing and method of portfolio company exits, including initial public offerings, strategic sales, management buyouts, and secondary market transactions. Limited Partners acknowledge that liquidity events are inherently unpredictable and may require extended holding periods to maximize value creation.\nArticle 6: Risk Factors and Regulatory Compliance\nInvestment in the Fund involves substantial risks, including but not limited to: (i) potential total loss of invested capital; (ii) illiquidity of partnership interests; (iii) concentration risk due to focused investment strategy; (iv) leverage-related risks at both Fund and portfolio company levels; (v) regulatory changes affecting target markets or investment structures; and (vi) key person dependency related to the General Partner's investment team.\nThe Fund is exempt from registration under the Investment Company Act of 1940 pursuant to Section 3(c)(1) thereof and relies on exemptions under the Securities Act of 1933 for private placement of partnership interests. The Investor must qualify as an accredited investor as defined under Regulation D and satisfy applicable suitability standards.\nCross-border investments may expose the Fund to foreign exchange risk, political risk, and varying regulatory environments. The General Partner maintains professional indemnity insurance and implements comprehensive compliance procedures to mitigate operational risks, but cannot guarantee protection against all potential liabilities.\nArticle 7: Transfer Restrictions and Secondary Market Transactions\nPartnership interests are subject to strict transfer restrictions and may not be sold, assigned, or transferred without prior written consent of the General Partner. Any proposed transfer must comply with applicable securities laws and maintain the Fund's exemption status under relevant investment company regulations.\nSecondary market transactions involving partnership interests require valuation opinions from qualified independent appraisers and may trigger right of first refusal provisions in favor of existing Limited Partners. Transfer procedures must allow adequate due diligence periods for prospective assignees and ensure compliance with know-your-customer and anti-money laundering requirements.\nThe General Partner reserves the right to implement mandatory redemption provisions in cases where Limited Partner transfers would compromise the Fund's regulatory status or operational efficiency. Redemption prices shall be determined based on independently appraised net asset values, subject to applicable discounts reflecting illiquidity and transfer costs.\nArticle 8: Tax Considerations and Regulatory Reporting\nThe Fund is structured as a pass-through entity for U.S. federal income tax purposes, with all income, gains, losses, and deductions allocated to Limited Partners according to their respective partnership interests. Limited Partners are responsible for their own tax liabilities arising from Fund operations and distributions.\nThe General Partner shall provide annual Schedule K-1 forms detailing each Limited Partner's allocable share of Fund income and expenses. International investors may be subject to withholding taxes on U.S.-source income and should consult independent tax advisors regarding treaty benefits and foreign tax credit opportunities.\nThe Fund maintains compliance with Foreign Account Tax Compliance Act (FATCA) requirements and Common Reporting Standard (CRS) obligations. Limited Partners acknowledge that confidential information may be disclosed to tax authorities pursuant to applicable reporting requirements and international tax treaties.\nArticle 9: Termination and Liquidation Procedures\nThe Fund shall terminate upon the earlier of: (i) expiration of the partnership term as specified in the Limited Partnership Agreement; (ii) completion of all portfolio exits and final distributions; (iii) dissolution by General Partner election; or (iv) removal of the General Partner by supermajority Limited Partner vote for cause.\nUpon termination, the General Partner shall liquidate remaining portfolio investments in an orderly manner designed to maximize recovery values for Limited Partners. Liquidation proceeds shall be distributed according to the waterfall mechanism, with Limited Partners receiving priority over carried interest distributions until full return of contributed capital plus preferred returns.\nFinal accounting and distribution statements shall be prepared by independent auditors and distributed to all Limited Partners within 90 days of final asset disposition. Any remaining liabilities or contingent obligations shall be reserved against final distributions until resolution or expiration of applicable statute of limitations periods.\nArticle 10: Dispute Resolution and Governing Law\nThis Agreement shall be governed by and construed in accordance with the laws of the State of Delaware, without regard to choice of law principles. Any disputes arising under this Agreement shall be resolved through binding arbitration administered by the American Arbitration Association under its Commercial Arbitration Rules.\nThe arbitration shall be conducted by a three-member panel, with each party selecting one arbitrator and the two party-appointed arbitrators selecting a neutral chairperson. Arbitration proceedings shall be confidential, and awards shall be final and binding upon all parties, subject only to limited judicial review as provided under the Federal Arbitration Act.\nThe prevailing party in any dispute resolution proceeding shall be entitled to recover reasonable attorneys' fees and costs from the non-prevailing party. All parties waive any right to jury trial and agree that arbitration is the exclusive method for resolving disputes related to this Agreement or the Fund's operations.",
    "ori_text": "\n\nPRIVATE EQUITY FUND SUBSCRIPTION AGREEMENT\nArticle 1: Fund Structure and Investment Objectives\nThis Subscription Agreement (\"Agreement\") is entered into between the General Partner, acting as the fund manager of ABC Private Equity Fund L.P. (\"Fund\"), and the undersigned Limited Partner (\"Investor\" or \"Subscriber\"). The Fund is structured as a limited partnership domiciled in Delaware, with the General Partner holding unlimited liability for fund operations and Limited Partners enjoying limited liability protection subject to their capital commitments.\nThe Fund's primary investment objective is to achieve superior risk-adjusted returns through acquiring controlling or significant minority stakes in middle-market companies across diversified sectors. The investment strategy focuses on value creation through operational improvements, strategic repositioning, and prudent use of leverage. The Fund operates under a closed-end structure with a predetermined investment period of five years, followed by a harvest period not exceeding three years.\nArticle 2: Capital Commitment and Drawdown Mechanisms\nThe Investor hereby commits to contribute the aggregate amount specified in Schedule A (\"Capital Commitment\") to the Fund. Such commitment represents the maximum amount that may be called by the General Partner during the commitment period. Capital contributions shall be made through a series of capital calls issued by the General Partner upon not less than ten (10) business days' prior written notice to all Limited Partners.\nEach capital call notice shall specify the purpose of the drawdown, the aggregate amount being called, each Limited Partner's pro rata share based on their respective capital commitments, and the deadline for funding. Failure to satisfy a capital call within the prescribed timeframe shall constitute a default event, subjecting the defaulting Limited Partner to remedial measures including, but not limited to, dilution of their partnership interest, forfeiture of previously contributed capital, and potential forced withdrawal from the Fund.\nThe General Partner reserves the right to implement a bridging facility to accommodate temporary funding needs, with any associated costs allocated proportionally among all Limited Partners. Interest expense and arrangement fees related to such facilities shall be treated as Fund expenses and allocated according to the waterfall distribution mechanism outlined herein.\nArticle 3: Management Fee Structure and Carried Interest\nThe Investor acknowledges and agrees to pay a management fee calculated as 2.0% per annum of the Investor's capital commitment during the commitment period, and 2.0% per annum of the Investor's contributed capital thereafter. Management fees are payable quarterly in advance and are subject to offset against future carried interest distributions to the General Partner.\nThe General Partner shall be entitled to carried interest equal to 20% of the Fund's net profits, subject to an 8% preferred return hurdle rate applied to Limited Partners' contributed capital. The carried interest calculation shall employ the European waterfall method, whereby carried interest is only distributed after all Limited Partners have received return of their contributed capital plus the specified preferred return on a cumulative basis.\nAny carried interest distributed to the General Partner shall be subject to clawback provisions in the event that subsequent portfolio company exits result in aggregate Fund performance falling below the hurdle rate threshold. The clawback mechanism ensures that Limited Partners receive their preferred return before any carried interest is definitively retained by the General Partner.\nArticle 4: Portfolio Company Governance and Reserved Rights\nThe General Partner shall maintain discretionary authority over all investment decisions, including but not limited to initial acquisitions, follow-on investments, portfolio company board representation, and exit strategies. However, certain material decisions require Limited Partner advisory committee approval or supermajority consent as specified in the Limited Partnership Agreement.\nReserved rights subject to Limited Partner approval include: (i) amendments to the investment strategy or geographic focus; (ii) co-investment opportunities exceeding 15% of total Fund commitments; (iii) related party transactions involving the General Partner or its affiliates; (iv) modifications to the fee structure or carried interest arrangement; and (v) early termination of the Fund or extension of the investment period beyond the initial five-year term.\nThe Limited Partner advisory committee shall comprise representatives elected by Limited Partners holding not less than 66% of total capital commitments. Advisory committee members serve two-year terms and are responsible for reviewing potential conflicts of interest, approving annual valuations of portfolio investments, and providing guidance on material Fund governance matters.\nArticle 5: Due Diligence and Disclosure Obligations\nThe Investor represents and warrants that they have conducted adequate due diligence regarding the Fund's investment strategy, risk profile, and operational framework. The Investor acknowledges receipt of the Fund's Private Placement Memorandum, Limited Partnership Agreement, and audited financial statements of the General Partner.\nThe General Partner shall provide quarterly reporting to all Limited Partners, including portfolio company valuations prepared in accordance with International Private Equity and Venture Capital Valuation Guidelines. Annual reports shall include audited financial statements prepared by an independent accounting firm of recognized international standing.\nThe General Partner maintains discretionary authority regarding the timing and method of portfolio company exits, including initial public offerings, strategic sales, management buyouts, and secondary market transactions. Limited Partners acknowledge that liquidity events are inherently unpredictable and may require extended holding periods to maximize value creation.\nArticle 6: Risk Factors and Regulatory Compliance\nInvestment in the Fund involves substantial risks, including but not limited to: (i) potential total loss of invested capital; (ii) illiquidity of partnership interests; (iii) concentration risk due to focused investment strategy; (iv) leverage-related risks at both Fund and portfolio company levels; (v) regulatory changes affecting target markets or investment structures; and (vi) key person dependency related to the General Partner's investment team.\nThe Fund is exempt from registration under the Investment Company Act of 1940 pursuant to Section 3(c)(1) thereof and relies on exemptions under the Securities Act of 1933 for private placement of partnership interests. The Investor must qualify as an accredited investor as defined under Regulation D and satisfy applicable suitability standards.\nCross-border investments may expose the Fund to foreign exchange risk, political risk, and varying regulatory environments. The General Partner maintains professional indemnity insurance and implements comprehensive compliance procedures to mitigate operational risks, but cannot guarantee protection against all potential liabilities.\nArticle 7: Transfer Restrictions and Secondary Market Transactions\nPartnership interests are subject to strict transfer restrictions and may not be sold, assigned, or transferred without prior written consent of the General Partner. Any proposed transfer must comply with applicable securities laws and maintain the Fund's exemption status under relevant investment company regulations.\nSecondary market transactions involving partnership interests require valuation opinions from qualified independent appraisers and may trigger right of first refusal provisions in favor of existing Limited Partners. Transfer procedures must allow adequate due diligence periods for prospective assignees and ensure compliance with know-your-customer and anti-money laundering requirements.\nThe General Partner reserves the right to implement mandatory redemption provisions in cases where Limited Partner transfers would compromise the Fund's regulatory status or operational efficiency. Redemption prices shall be determined based on independently appraised net asset values, subject to applicable discounts reflecting illiquidity and transfer costs.\nArticle 8: Tax Considerations and Regulatory Reporting\nThe Fund is structured as a pass-through entity for U.S. federal income tax purposes, with all income, gains, losses, and deductions allocated to Limited Partners according to their respective partnership interests. Limited Partners are responsible for their own tax liabilities arising from Fund operations and distributions.\nThe General Partner shall provide annual Schedule K-1 forms detailing each Limited Partner's allocable share of Fund income and expenses. International investors may be subject to withholding taxes on U.S.-source income and should consult independent tax advisors regarding treaty benefits and foreign tax credit opportunities.\nThe Fund maintains compliance with Foreign Account Tax Compliance Act (FATCA) requirements and Common Reporting Standard (CRS) obligations. Limited Partners acknowledge that confidential information may be disclosed to tax authorities pursuant to applicable reporting requirements and international tax treaties.\nArticle 9: Termination and Liquidation Procedures\nThe Fund shall terminate upon the earlier of: (i) expiration of the partnership term as specified in the Limited Partnership Agreement; (ii) completion of all portfolio exits and final distributions; (iii) dissolution by General Partner election; or (iv) removal of the General Partner by supermajority Limited Partner vote for cause.\nUpon termination, the General Partner shall liquidate remaining portfolio investments in an orderly manner designed to maximize recovery values for Limited Partners. Liquidation proceeds shall be distributed according to the waterfall mechanism, with Limited Partners receiving priority over carried interest distributions until full return of contributed capital plus preferred returns.\nFinal accounting and distribution statements shall be prepared by independent auditors and distributed to all Limited Partners within 90 days of final asset disposition. Any remaining liabilities or contingent obligations shall be reserved against final distributions until resolution or expiration of applicable statute of limitations periods.\nArticle 10: Dispute Resolution and Governing Law\nThis Agreement shall be governed by and construed in accordance with the laws of the State of Delaware, without regard to choice of law principles. Any disputes arising under this Agreement shall be resolved through binding arbitration administered by the American Arbitration Association under its Commercial Arbitration Rules.\nThe arbitration shall be conducted by a three-member panel, with each party selecting one arbitrator and the two party-appointed arbitrators selecting a neutral chairperson. Arbitration proceedings shall be confidential, and awards shall be final and binding upon all parties, subject only to limited judicial review as provided under the Federal Arbitration Act.\nThe prevailing party in any dispute resolution proceeding shall be entitled to recover reasonable attorneys' fees and costs from the non-prevailing party. All parties waive any right to jury trial and agree that arbitration is the exclusive method for resolving disputes related to this Agreement or the Fund's operations.",
    "reference_list": "考点1：Limited Partnership 推荐译为\"有限合伙企业\"\n考点2：Capital Commitment 推荐译为\"出资承诺\"\n考点3：Drawdown Mechanisms 推荐译为\"资金调用机制\"\"缴款机制\"\n考点4：Carried Interest 推荐译为\"附带权益\"\"业绩报酬\"\n考点5：Hurdle Rate 推荐译为\"门槛收益率\"\n考点6：European Waterfall Method 推荐译为\"欧式瀑布分配法\"\n考点7：Clawback Provisions 推荐译为\"回拨条款\"\n考点8：Pass-through Entity 推荐译为\"税收透明实体\"\n考点9：Schedule K-1 必须译为\"K-1税表/K-1表/K-1表格\"\n考点10：Binding Arbitration 推荐译为\"强制仲裁\"/“有拘束力的仲裁”\n考点11：Harvest Period 推荐译为\"退出期\"\n考点12：International Private Equity and Venture Capital Valuation Guidelines 推荐译为\"《国际私募股权和风险投资估值指引》/《IPEV估值指引》\"",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "124"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nDiet\n\nPeople’s diets vary from one country to another. Diets can also vary within a single country. Geographic differences explain part of this variation. For example, people who live near the ocean might eat greater amounts of fish than people who live farther inland. People living in cool regions with short growing seasons depend on crops that mature quickly, such as potatoes. In warm, wet lowlands where the soil retains water, rice is often a staple.\n\nGeographic factors are less important today than they were a century ago. Improved methods of agriculture and transportation, as well as increased trade and tourism, have made more types of food available to a wider variety of people.\n\nImproved methods of food processing, preservation, storage, and shipping allow many people to enjoy foods produced far from their homes. Spanish olive oil, French cheeses, and sardines from Norway, for example, are eaten as far away as Australia.\n\nLocal traditions and customs play a role in determining what foods people eat and how they are prepared. English tradition encourages roast beef and Yorkshire pudding, a type of bread, be eaten together. Many Asians serve rice with almost every meal.\n\nEconomic factors also affect what people eat. In the U.S. state of Maine, lobster is usually a relatively inexpensive food. The shellfish is native to the state’s coastal areas and has been a traditional food for hundreds of years. However, lobster is a luxury item in the Midwest, where it must be flown in. Lobster dishes served in Iowa may cost two to three times what they do in Maine.\n\nIn developed countries, many people have enough money to buy a variety of nutritious foods. Malnutrition is not a large problem, and people have a long lifespan. But even in these countries, there are many people who cannot buy these foods because resources are not evenly distributed throughout the population. In some places, healthy, nutritious food can be more expensive than so-called “junk food,” which has many calories but little nutritional benefit.\n\nEven those who can afford healthy food may eat poorly. The diets of many people in developed countries are too high in the fats, salt, and refined sugars found in junk food. These diets are too low in fruits, vegetables, and fiber.\n\nIn developing countries, malnutrition is more common. A poor harvest, flood, or drought may cause famine, because the community or nation is not economically able to import food.\n\nThe diets of the urban and rural populations of developing countries are often quite different. People in urban areas eat more processed foods, while people who live in rural areas may have access to fresh milk, fruits, and vegetables. However, people living in rural areas are the first to be affected by a poor harvest.\n\nFood and Culture\n\nPeople do not eat only to obtain nutrients and ward off hunger and starvation. People’s eating habits are strongly influenced by culture. Rituals around preparing, sharing, and consuming food serve social roles as well as biological ones.\n\nReligion sometimes plays a role in what, and when, people eat. Followers of the Jain religion, for example, strongly believe in nonviolence toward all living things. Strict Jains never eat meat. Many Jains also refrain from eating potatoes and other tubers because many small organisms are harmed as the tubers are pulled from the earth.\n\nJewish kashrut law and Muslim dhabihah law outline many rules for eating. Both include a ban on pork. Food that is prepared according to kashrut law is called kosher, while food that is prepared according to dhabihah law is called halal.\n\nDuring the month of Ramadan, Muslims fast, or avoid eating, during daylight hours. Typically, Muslims will eat one meal before dawn and one after sunset, but nothing at all while the sun is shining. Ramadan is considered a time for inner reflection, devotion to God, and self-control.\n\nFeasting is also an important ritual, both for religious and nonreligious reasons. Most religious fasting periods, such as Ramadan, are followed by holiday feasts. Eid al-Fitr is the Islamic holiday following Ramadan. One of the ways Muslims celebrate Eid is to donate food to the poor.\n\nNonreligious holidays often include feasts as well. In the United States, people gather to eat turkey, stuffing, cranberry sauce, and pumpkin pie on Thanksgiving. In China, families celebrate the Chinese New Year with foods that symbolize luck and prosperity, such as long noodles, chickens, fish, oysters, dumplings, tangerines, oranges, and sticky rice cakes.\n\nMany people make dietary choices based on ethics—beliefs about what is right and wrong. For instance, some people choose not to eat meat out of concern for the environment. Livestock is one of the leading contributors to carbon emissions, and some people reduce the amount of beef they eat to reduce their “carbon footprint.” Many people avoid eating meat out of concern for animal welfare.\n\nVegetarians avoid eating all meat and fish. Vegans avoid all animal products, including eggs, milk, cheese, and honey. Some people who are not vegetarians may raise or buy humanely produced animal products such as free-range chicken and grass-fed beef.\n\nOther ethics-based food practices include choosing organic or locally grown foods. People who choose organic foods may do so because of the reduced number of chemicals in the food. Organic food relies little on genetic modification or pesticides. Organic food also releases fewer chemicals into the environment in the form of runoff.\n\nThe “locavore” movement values the reduced environmental impact of local foods. There are fewer transportation costs, such as greenhouse gas emissions, with local foods.\n\nThe way we serve and eat food is as culturally important as what foods we consume. In East Asian countries, most people use chopsticks to pick up their food. In Europe and the Americas, a variety of utensils serve different purposes. A full, formal place setting can include a salad fork, dinner fork, dessert fork, teaspoon, soup spoon, butter knife, and dinner knife. In other countries, such as India and Ethiopia, many foods are picked up with pieces of flat bread rather than utensils.\n\nTable manners vary widely from culture to culture. Manners include rules about how and where people should sit, when to begin eating, which utensils to use in certain situations and with which hand, and what behaviors might be considered rude.\n\nIn East Asian countries, it is considered rude to point at people with your chopsticks, or to rest your chopsticks standing upright in your rice. In Malaysia, eating with your left hand is considered unclean. In Japan, it is acceptable and even encouraged to make slurping noises while eating hot noodles, but not while eating soup. In Russia, it is considered polite to leave a bit of food after eating, but in Brazil, people are expected to eat everything on their plates.\n\nCuisine\n\nFood and food preparation associated with a specific region are known as that region’s cuisine. Cuisine can be national, such as the fresh fish and noodles associated with Japanese food. Cuisine can also be regional or local. California cuisine, for instance, is known for mixing different types of national cuisines, such as French and Chinese.\n\nA food’s adaptability to a specific region can define that region. Maize, native to North and Central America, is considered one of Mexico’s greatest “national treasures.” An image of Xochipilli, the Aztec god of maize, appears on Mexico's 100-peso bill.\n\nMost cuisines feature staple foods of the region. In the Democratic Republic of Congo, boiled cassava root is a staple food. The large leaves of the cassava and a fiery pepper sauce called pili-pili are often part of a traditional Congolese meal. Fresh-picked bananas, papayas, and pineapples are frequently eaten. Animal proteins from poultry, fish, and crocodiles are also popular foods in the Democratic Republic of Congo.\n\nClimate can also impact the cuisine of a region. Much of Russia faces cold winters, so few crops grow there. Warm soups are a large part of Russian cuisine. Borscht, or beet soup, is probably the most familiar Russian soup. Beets are vegetables that are capable of growing in the cold, hard ground. Grains that grow well in cold climates are also popular in Russian cuisine. Kasha, for example, is cooked grains, such as buckwheat, barley, or semolina. Blini, or buckwheat pancakes, are served with caviar, smoked fish, butter, and sour cream. Pickles, cucumbers, and onions are widely eaten.\n\nSince Japan is surrounded by the ocean, fish is a mainstay of Japanese cuisine. It is prepared in a variety of ways. Sashimi, for example, is raw fish dipped in seasoned soy sauce. Tempura is prawns or slices of fish and vegetables dipped in batter and fried. Most sushi is made from flavored rice covered with slices of raw or cooked fish and vegetables.\n\nEven non-native foods can define a region. Potatoes were introduced to Ireland in the early 17th century, probably by the explorer Sir Walter Raleigh, who brought the tubers home with him after exploring the Americas. Potatoes, especially the “lumper” variety, grow well in cold climates and rocky soil. Within 200 years, the population of Ireland was dependent on lumpers for most of their carbohydrates. A potato disease, or blight, struck Ireland in the mid-19th century, causing the so-called Irish Potato Famine. More than a million Irish people died of malnutrition, and a million more were forced to immigrate.\n\nOften, cuisine reflects a country or region’s history. Pho, for instance, is a Vietnamese noodle soup made with large chunks of meat, vegetables, and spices, such as basil. Vietnam was a French colony from the 19th century to the middle of the 20th century. French colonists brought French cuisine with them, including the stew called pot au feu. Pho is an adaptation of pot au feu, with the most significant addition being rice noodles, which are native to Southeast Asia. “Pho” even sounds like “feu.”\n\nThe growing number of immigrants in many cities has broadened people’s tastes in food. Many foods associated with national cuisines are inventions of immigrants. Chicken tikka masala, for example, is one of the most popular “Indian” dishes in the world. Chicken tikka masala was invented by an immigrant Pakistani chef in Glasgow, Scotland.\n\nOften, immigrants will adapt their traditional diet with foods not available in their homeland. Chinese-American food, for instance, often features tomatoes and potatoes, foods that are not native to Asia.\n\nCuisine varies widely, even within a specific region and a specific food. In the Carolinas region of the United States, for example, there are more than a dozen types of traditional barbecue. In this region, pork is the most familiar barbecued meat, although chicken and beef are also barbecued. Some barbecues feature a mustard-based sauce, while others feature tomato, vinegar, or molasses. Still other traditional barbecues are “dry,” and feature spice-based rubs instead of sauce.",
    "ori_text": "Diet\n\nPeople’s diets vary from one country to another. Diets can also vary within a single country. Geographic differences explain part of this variation. For example, people who live near the ocean might eat greater amounts of fish than people who live farther inland. People living in cool regions with short growing seasons depend on crops that mature quickly, such as potatoes. In warm, wet lowlands where the soil retains water, rice is often a staple.\n\nGeographic factors are less important today than they were a century ago. Improved methods of agriculture and transportation, as well as increased trade and tourism, have made more types of food available to a wider variety of people.\n\nImproved methods of food processing, preservation, storage, and shipping allow many people to enjoy foods produced far from their homes. Spanish olive oil, French cheeses, and sardines from Norway, for example, are eaten as far away as Australia.\n\nLocal traditions and customs play a role in determining what foods people eat and how they are prepared. English tradition encourages roast beef and Yorkshire pudding, a type of bread, be eaten together. Many Asians serve rice with almost every meal.\n\nEconomic factors also affect what people eat. In the U.S. state of Maine, lobster is usually a relatively inexpensive food. The shellfish is native to the state’s coastal areas and has been a traditional food for hundreds of years. However, lobster is a luxury item in the Midwest, where it must be flown in. Lobster dishes served in Iowa may cost two to three times what they do in Maine.\n\nIn developed countries, many people have enough money to buy a variety of nutritious foods. Malnutrition is not a large problem, and people have a long lifespan. But even in these countries, there are many people who cannot buy these foods because resources are not evenly distributed throughout the population. In some places, healthy, nutritious food can be more expensive than so-called “junk food,” which has many calories but little nutritional benefit.\n\nEven those who can afford healthy food may eat poorly. The diets of many people in developed countries are too high in the fats, salt, and refined sugars found in junk food. These diets are too low in fruits, vegetables, and fiber.\n\nIn developing countries, malnutrition is more common. A poor harvest, flood, or drought may cause famine, because the community or nation is not economically able to import food.\n\nThe diets of the urban and rural populations of developing countries are often quite different. People in urban areas eat more processed foods, while people who live in rural areas may have access to fresh milk, fruits, and vegetables. However, people living in rural areas are the first to be affected by a poor harvest.\n\nFood and Culture\n\nPeople do not eat only to obtain nutrients and ward off hunger and starvation. People’s eating habits are strongly influenced by culture. Rituals around preparing, sharing, and consuming food serve social roles as well as biological ones.\n\nReligion sometimes plays a role in what, and when, people eat. Followers of the Jain religion, for example, strongly believe in nonviolence toward all living things. Strict Jains never eat meat. Many Jains also refrain from eating potatoes and other tubers because many small organisms are harmed as the tubers are pulled from the earth.\n\nJewish kashrut law and Muslim dhabihah law outline many rules for eating. Both include a ban on pork. Food that is prepared according to kashrut law is called kosher, while food that is prepared according to dhabihah law is called halal.\n\nDuring the month of Ramadan, Muslims fast, or avoid eating, during daylight hours. Typically, Muslims will eat one meal before dawn and one after sunset, but nothing at all while the sun is shining. Ramadan is considered a time for inner reflection, devotion to God, and self-control.\n\nFeasting is also an important ritual, both for religious and nonreligious reasons. Most religious fasting periods, such as Ramadan, are followed by holiday feasts. Eid al-Fitr is the Islamic holiday following Ramadan. One of the ways Muslims celebrate Eid is to donate food to the poor.\n\nNonreligious holidays often include feasts as well. In the United States, people gather to eat turkey, stuffing, cranberry sauce, and pumpkin pie on Thanksgiving. In China, families celebrate the Chinese New Year with foods that symbolize luck and prosperity, such as long noodles, chickens, fish, oysters, dumplings, tangerines, oranges, and sticky rice cakes.\n\nMany people make dietary choices based on ethics—beliefs about what is right and wrong. For instance, some people choose not to eat meat out of concern for the environment. Livestock is one of the leading contributors to carbon emissions, and some people reduce the amount of beef they eat to reduce their “carbon footprint.” Many people avoid eating meat out of concern for animal welfare.\n\nVegetarians avoid eating all meat and fish. Vegans avoid all animal products, including eggs, milk, cheese, and honey. Some people who are not vegetarians may raise or buy humanely produced animal products such as free-range chicken and grass-fed beef.\n\nOther ethics-based food practices include choosing organic or locally grown foods. People who choose organic foods may do so because of the reduced number of chemicals in the food. Organic food relies little on genetic modification or pesticides. Organic food also releases fewer chemicals into the environment in the form of runoff.\n\nThe “locavore” movement values the reduced environmental impact of local foods. There are fewer transportation costs, such as greenhouse gas emissions, with local foods.\n\nThe way we serve and eat food is as culturally important as what foods we consume. In East Asian countries, most people use chopsticks to pick up their food. In Europe and the Americas, a variety of utensils serve different purposes. A full, formal place setting can include a salad fork, dinner fork, dessert fork, teaspoon, soup spoon, butter knife, and dinner knife. In other countries, such as India and Ethiopia, many foods are picked up with pieces of flat bread rather than utensils.\n\nTable manners vary widely from culture to culture. Manners include rules about how and where people should sit, when to begin eating, which utensils to use in certain situations and with which hand, and what behaviors might be considered rude.\n\nIn East Asian countries, it is considered rude to point at people with your chopsticks, or to rest your chopsticks standing upright in your rice. In Malaysia, eating with your left hand is considered unclean. In Japan, it is acceptable and even encouraged to make slurping noises while eating hot noodles, but not while eating soup. In Russia, it is considered polite to leave a bit of food after eating, but in Brazil, people are expected to eat everything on their plates.\n\nCuisine\n\nFood and food preparation associated with a specific region are known as that region’s cuisine. Cuisine can be national, such as the fresh fish and noodles associated with Japanese food. Cuisine can also be regional or local. California cuisine, for instance, is known for mixing different types of national cuisines, such as French and Chinese.\n\nA food’s adaptability to a specific region can define that region. Maize, native to North and Central America, is considered one of Mexico’s greatest “national treasures.” An image of Xochipilli, the Aztec god of maize, appears on Mexico's 100-peso bill.\n\nMost cuisines feature staple foods of the region. In the Democratic Republic of Congo, boiled cassava root is a staple food. The large leaves of the cassava and a fiery pepper sauce called pili-pili are often part of a traditional Congolese meal. Fresh-picked bananas, papayas, and pineapples are frequently eaten. Animal proteins from poultry, fish, and crocodiles are also popular foods in the Democratic Republic of Congo.\n\nClimate can also impact the cuisine of a region. Much of Russia faces cold winters, so few crops grow there. Warm soups are a large part of Russian cuisine. Borscht, or beet soup, is probably the most familiar Russian soup. Beets are vegetables that are capable of growing in the cold, hard ground. Grains that grow well in cold climates are also popular in Russian cuisine. Kasha, for example, is cooked grains, such as buckwheat, barley, or semolina. Blini, or buckwheat pancakes, are served with caviar, smoked fish, butter, and sour cream. Pickles, cucumbers, and onions are widely eaten.\n\nSince Japan is surrounded by the ocean, fish is a mainstay of Japanese cuisine. It is prepared in a variety of ways. Sashimi, for example, is raw fish dipped in seasoned soy sauce. Tempura is prawns or slices of fish and vegetables dipped in batter and fried. Most sushi is made from flavored rice covered with slices of raw or cooked fish and vegetables.\n\nEven non-native foods can define a region. Potatoes were introduced to Ireland in the early 17th century, probably by the explorer Sir Walter Raleigh, who brought the tubers home with him after exploring the Americas. Potatoes, especially the “lumper” variety, grow well in cold climates and rocky soil. Within 200 years, the population of Ireland was dependent on lumpers for most of their carbohydrates. A potato disease, or blight, struck Ireland in the mid-19th century, causing the so-called Irish Potato Famine. More than a million Irish people died of malnutrition, and a million more were forced to immigrate.\n\nOften, cuisine reflects a country or region’s history. Pho, for instance, is a Vietnamese noodle soup made with large chunks of meat, vegetables, and spices, such as basil. Vietnam was a French colony from the 19th century to the middle of the 20th century. French colonists brought French cuisine with them, including the stew called pot au feu. Pho is an adaptation of pot au feu, with the most significant addition being rice noodles, which are native to Southeast Asia. “Pho” even sounds like “feu.”\n\nThe growing number of immigrants in many cities has broadened people’s tastes in food. Many foods associated with national cuisines are inventions of immigrants. Chicken tikka masala, for example, is one of the most popular “Indian” dishes in the world. Chicken tikka masala was invented by an immigrant Pakistani chef in Glasgow, Scotland.\n\nOften, immigrants will adapt their traditional diet with foods not available in their homeland. Chinese-American food, for instance, often features tomatoes and potatoes, foods that are not native to Asia.\n\nCuisine varies widely, even within a specific region and a specific food. In the Carolinas region of the United States, for example, there are more than a dozen types of traditional barbecue. In this region, pork is the most familiar barbecued meat, although chicken and beef are also barbecued. Some barbecues feature a mustard-based sauce, while others feature tomato, vinegar, or molasses. Still other traditional barbecues are “dry,” and feature spice-based rubs instead of sauce.",
    "reference_list": "考点1： “religious fasting periods”应译为“宗教禁食期”。\n考点2： “Jains“应译为“耆那教”。\n考点3： ”Kashrut“应译为“洁食律法。“\n考点4： “Dhabihah”应译为“清真动物屠宰法”。\n考点5：“halal”应译为“清真食品”。\n考点6：“Ramadanl”应译为“斋月”。\n考点7：“Eid al-Fitr”应译为“开斋节”。\n考点8：“Chicken Tikka Masala”应译为“香料烤鸡咖喱”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "53"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nFrom the Red Detachment to the Women: A Postscript\n\nLife and Dance\nMost Chinese urban independent theatre and performance makers have been connected in some way to the Beijing-based Caochangdi Workstation (Caochangdi Gongzuozhan1 ) and the Living Dance Studio  (Shenghuo Wudao Gongzuoshi). They attended the body workshops conducted by choreographer Wen Hui and borrowed the Workstation stage to rehearse their own projects. Some presented their earliest pieces at the festivals held at either the Workstation or the Young Choreographers’ Project. I was probably the last one to enjoy the opportunity to work as an artist at Caochangdi and did so mainly in the summer of 2014, right before its demolition.  That was also my first collaboration with Wen Hui. Without a lived experience of working with the Living Dance Studio, I could not understand this kind of creative process, which bears all the marks of inspiration, rapture, and everyday triviality.\n\nCaochangdi Workstation, a significant incubation site for innovations in unconventional theatre and performance in urban China, lives on in spirit. However, in the middle of our first round of rehearsals for RED (HONG), its physical body ceased to exist. When I returned to Beijing in summer 2015 for the second round of rehearsals, the cast had changed, and the rehearsal space was Wen Hui’s living room. New to the team were two women of the post-’80s generation: Jiang Fan and Li Xinmin.  Both have laughed and cried along with the ups and downs of China’s market-oriented, commercialized system. But they know little, if anything, of the Cultural Revolution that dominated the mid-1960s to mid-1970s.\n\nWen Hui suggested: “Let’s start all over again.” That remark sparked my epiphany. Our living condition, the moment we found ourselves in, would determine the direction of the dance.\n\nFrom the Red Detachment of Women\nThe inspiration to create RED came from three sources. The first was a trove of documentary materials related to The Red Detachment of Women (Hongse Niangzi Jun)—audiovisual clips, publications, memorabilia from the original revolutionary model ballet, interview footage. These were incorporated to evoke a special territory of memory and reactivate a living and lived archive within specific bodies: those of the performers and those of people who experienced the Cultural Revolution.\n\nThe second combined the desire to understand the complex feelings of people who experienced the politicized art and aestheticized politics that held sway during the Cultural Revolution, along with the desire to explore the in/congruity between the state’s discourse and the everyday cultural lives of the people.\n\nThe third was the idea to use the dancers’ bodies as a departure point. Varied connections with the original model ballet, in content and movement and staging, would allow RED to anatomize the original choreography and explore here-and-now experiences as dancers and survivors, together, revisit that turbulent decade. Tasks both new and stimulating befell me with the arrival of the two new members. With its all-women ensemble, RED could and should add another layer to the complexity of women’s reality in China today. It should function as a way to reflect on how the socialist imagination prescribed gender equality and women’s liberation, which were embedded in Maoist state feminism and disseminated through the revolutionary model opera . Accordingly, we played the collected documentary materials to the younger performers, pausing whenever they felt inclined to share their thoughts or express themselves through movement. I also created a tabular list of the known past experiences and current realities of the two generations of female performers, including each of their distinct experiences with and understandings of The Red Detachment of Women.\n\nThen we heard, quite by accident, that United Heart Home of Hope (Tongxin Xiwang Jiayuan), an NGO founded in 2003 with the goal of supporting women and children in the migrant communities on the outskirts of Beijing, was singing Marching Forward (Xiang Qianjin), the theme song from the 1961 film The Red Detachment of Women, at all of their meetings. 7 We immediately decided to interview Ma Xiaoduo, the organization’s founder. Ma freely admitted that she did not remember much of the model ballet from seeing it in elementary school. But she recounted being exceptionally moved by a single occurrence in the plot: The female protagonist’s change of fortune after she joined the Red Army-led women’s detachment. To Ma, The Red Detachment of Women is about how women should transform themselves to free themselves from oppression and misery. United Heart Home of Hope was formed with exactly the same vision of self-salvation.\n\nThe development of the script of RED in 2015 was strongly directed at and dedicated to women in general and the four female performers specifically. However, in addition to using the original model ballet to engage with the decade-long social and cultural chaos initiated by the Cultural Revolution and examining the cultural products praised by the revolutionary discourse of class struggle, I wonder how RED can reflect the ways that women in today’s China face ideological orientations that are official, if different, and engage in new forms of political, social, and gender-specific struggle.\n\nLooking Back\nAct Three, “Looking Back”, aims to both show the past generation’s reminiscences onscreen and to demonstrate, through four performers’ current stories, their vibrant and tenacious presence onstage. My deepest regret is that this part could not be developed as planned due to inadequate initiatives, opportunity, budget, and rehearsal time. Since “the author is dead” and the performance text refuses further development, can only replace some of these current stories from the original script into a postscript.\n\nLiu Zhuying could not care less if any connection exists between revolutionary model opera and guangchang wu (public square dancing). To her, the latter is neither a mobilization of mass culture in an era of depoliticization nor a cultural form of reconstruction of Maoist collectivism. She only complains that the middle-aged female dancers are not professional enough, in either spirit or technique. As a local official in charge of cultural activities, her main purpose in organizing large-scale public square-dancing activities is to maintain stability in sensitive times. This goal is best accomplished if public spaces are filled with energetic, if amateur, dancers.\n\nJiang Fan resigned her position as a choreographer and dancer at the Shanghai Opera House Dance Troupe in 2015 and moderately enjoys her freedom from the state-owned performing arts institutions and their suffocating leitmotif projects. She makes a living by choreographing musicals and has collaborated with Shanghai International Dance Center as an independent artist. During the creation of RED, she recognized the continuity between the revolutionary model opera of 50 years ago and today’s leitmotif works that eulogize the Party’s revolutionary history. The more artistically independent she becomes, the more she must think about how to balance the market, audience interests, and the degree to which the present can be transmitted through individualized artistic references.\n\nLike Wu Qinghua, the female protagonist in the model ballet, Li Xinmin desperately fled her hometown (Huamulin, in rural Yunnan Province) to Kunming and then to Beijing. Since the demise of Caochangdi Workstation, when she lost her dwelling in the city, she continued to make documentary films, worked in an NGO for migrant domestic workers, sold fruit with friends, and, with her longtime artistic partner, created an autobiographical documentary theatre piece, Timeline (Fanhui de Lu). However, unlike Wu Qinghua, she made peace with her past and decided to go back to Huamulin, where she is about to get married and is expecting her first child. She still thinks The Red Detachment of Women has little to do with her life and regrets spending so much energy on RED.\n\nWe see very little of Wen Hui’s personal memories and narratives in RED. She keeps creating new pieces and touring old ones around Europe, the site of her “independence,” and conducting workshops on the body as an archive in universities all over the world. In December 2018, she commemorated the twentieth anniversary of the independent theatre and performance movement in urban China with Paper Tiger Studio Beijing (Beijing Zhilaohu Xiju Gongzuoshi) and Niao Collective at the Beijing Inside-Out Art Museum. This work functions as a physical manifesto that echoes independent artists’ ongoing rewriting of theatre and performance history in modern China. Nonetheless, even as she works with all forms of activity around the phenomenon of memorization, she chooses not to mention in public two losses of her own: That of Caochangdi Workstation and that of Wu Wenguang, her artistic and life partner.\n\nA Nightmare\nWhen RED was staged at the Asia Society in New York in November 2018, I moderated a pre-performance dialogue. 10 Some interview footage that was not included in the final documentary performance was shown to the audience. From this footage, I selected Ma Xiaoduo’s recollection of her nightmare:\n\nFor years, I have had the same nightmare: I am in the middle of the bridge and cannot cross it. The bridge starts crumbling, and I have to hold tight. That kind of nightmare is a reflection of repression. Sometimes I feel like I am going to screw it. I need to bring it down. I want to be freed. I feel I am being repressed. It’s like when the red light is on, you are stopped there and cannot move. Just because you are a rural woman, just because you are a woman, everyone can keep walking, but not you. I was blocked all the time. Anyone could do things, but not you. So this is a kind of battle. Whenever I listen to Marching Forward, I feel the power.",
    "ori_text": "\n\nFrom the Red Detachment to the Women: A Postscript\n\nLife and Dance\nMost Chinese urban independent theatre and performance makers have been connected in some way to the Beijing-based Caochangdi Workstation (Caochangdi Gongzuozhan1 ) and the Living Dance Studio  (Shenghuo Wudao Gongzuoshi). They attended the body workshops conducted by choreographer Wen Hui and borrowed the Workstation stage to rehearse their own projects. Some presented their earliest pieces at the festivals held at either the Workstation or the Young Choreographers’ Project. I was probably the last one to enjoy the opportunity to work as an artist at Caochangdi and did so mainly in the summer of 2014, right before its demolition.  That was also my first collaboration with Wen Hui. Without a lived experience of working with the Living Dance Studio, I could not understand this kind of creative process, which bears all the marks of inspiration, rapture, and everyday triviality.\n\nCaochangdi Workstation, a significant incubation site for innovations in unconventional theatre and performance in urban China, lives on in spirit. However, in the middle of our first round of rehearsals for RED (HONG), its physical body ceased to exist. When I returned to Beijing in summer 2015 for the second round of rehearsals, the cast had changed, and the rehearsal space was Wen Hui’s living room. New to the team were two women of the post-’80s generation: Jiang Fan and Li Xinmin.  Both have laughed and cried along with the ups and downs of China’s market-oriented, commercialized system. But they know little, if anything, of the Cultural Revolution that dominated the mid-1960s to mid-1970s.\n\nWen Hui suggested: “Let’s start all over again.” That remark sparked my epiphany. Our living condition, the moment we found ourselves in, would determine the direction of the dance.\n\nFrom the Red Detachment of Women\nThe inspiration to create RED came from three sources. The first was a trove of documentary materials related to The Red Detachment of Women (Hongse Niangzi Jun)—audiovisual clips, publications, memorabilia from the original revolutionary model ballet, interview footage. These were incorporated to evoke a special territory of memory and reactivate a living and lived archive within specific bodies: those of the performers and those of people who experienced the Cultural Revolution.\n\nThe second combined the desire to understand the complex feelings of people who experienced the politicized art and aestheticized politics that held sway during the Cultural Revolution, along with the desire to explore the in/congruity between the state’s discourse and the everyday cultural lives of the people.\n\nThe third was the idea to use the dancers’ bodies as a departure point. Varied connections with the original model ballet, in content and movement and staging, would allow RED to anatomize the original choreography and explore here-and-now experiences as dancers and survivors, together, revisit that turbulent decade. Tasks both new and stimulating befell me with the arrival of the two new members. With its all-women ensemble, RED could and should add another layer to the complexity of women’s reality in China today. It should function as a way to reflect on how the socialist imagination prescribed gender equality and women’s liberation, which were embedded in Maoist state feminism and disseminated through the revolutionary model opera . Accordingly, we played the collected documentary materials to the younger performers, pausing whenever they felt inclined to share their thoughts or express themselves through movement. I also created a tabular list of the known past experiences and current realities of the two generations of female performers, including each of their distinct experiences with and understandings of The Red Detachment of Women.\n\nThen we heard, quite by accident, that United Heart Home of Hope (Tongxin Xiwang Jiayuan), an NGO founded in 2003 with the goal of supporting women and children in the migrant communities on the outskirts of Beijing, was singing Marching Forward (Xiang Qianjin), the theme song from the 1961 film The Red Detachment of Women, at all of their meetings. 7 We immediately decided to interview Ma Xiaoduo, the organization’s founder. Ma freely admitted that she did not remember much of the model ballet from seeing it in elementary school. But she recounted being exceptionally moved by a single occurrence in the plot: The female protagonist’s change of fortune after she joined the Red Army-led women’s detachment. To Ma, The Red Detachment of Women is about how women should transform themselves to free themselves from oppression and misery. United Heart Home of Hope was formed with exactly the same vision of self-salvation.\n\nThe development of the script of RED in 2015 was strongly directed at and dedicated to women in general and the four female performers specifically. However, in addition to using the original model ballet to engage with the decade-long social and cultural chaos initiated by the Cultural Revolution and examining the cultural products praised by the revolutionary discourse of class struggle, I wonder how RED can reflect the ways that women in today’s China face ideological orientations that are official, if different, and engage in new forms of political, social, and gender-specific struggle.\n\nLooking Back\nAct Three, “Looking Back”, aims to both show the past generation’s reminiscences onscreen and to demonstrate, through four performers’ current stories, their vibrant and tenacious presence onstage. My deepest regret is that this part could not be developed as planned due to inadequate initiatives, opportunity, budget, and rehearsal time. Since “the author is dead” and the performance text refuses further development, can only replace some of these current stories from the original script into a postscript.\n\nLiu Zhuying could not care less if any connection exists between revolutionary model opera and guangchang wu (public square dancing). To her, the latter is neither a mobilization of mass culture in an era of depoliticization nor a cultural form of reconstruction of Maoist collectivism. She only complains that the middle-aged female dancers are not professional enough, in either spirit or technique. As a local official in charge of cultural activities, her main purpose in organizing large-scale public square-dancing activities is to maintain stability in sensitive times. This goal is best accomplished if public spaces are filled with energetic, if amateur, dancers.\n\nJiang Fan resigned her position as a choreographer and dancer at the Shanghai Opera House Dance Troupe in 2015 and moderately enjoys her freedom from the state-owned performing arts institutions and their suffocating leitmotif projects. She makes a living by choreographing musicals and has collaborated with Shanghai International Dance Center as an independent artist. During the creation of RED, she recognized the continuity between the revolutionary model opera of 50 years ago and today’s leitmotif works that eulogize the Party’s revolutionary history. The more artistically independent she becomes, the more she must think about how to balance the market, audience interests, and the degree to which the present can be transmitted through individualized artistic references.\n\nLike Wu Qinghua, the female protagonist in the model ballet, Li Xinmin desperately fled her hometown (Huamulin, in rural Yunnan Province) to Kunming and then to Beijing. Since the demise of Caochangdi Workstation, when she lost her dwelling in the city, she continued to make documentary films, worked in an NGO for migrant domestic workers, sold fruit with friends, and, with her longtime artistic partner, created an autobiographical documentary theatre piece, Timeline (Fanhui de Lu). However, unlike Wu Qinghua, she made peace with her past and decided to go back to Huamulin, where she is about to get married and is expecting her first child. She still thinks The Red Detachment of Women has little to do with her life and regrets spending so much energy on RED.\n\nWe see very little of Wen Hui’s personal memories and narratives in RED. She keeps creating new pieces and touring old ones around Europe, the site of her “independence,” and conducting workshops on the body as an archive in universities all over the world. In December 2018, she commemorated the twentieth anniversary of the independent theatre and performance movement in urban China with Paper Tiger Studio Beijing (Beijing Zhilaohu Xiju Gongzuoshi) and Niao Collective at the Beijing Inside-Out Art Museum. This work functions as a physical manifesto that echoes independent artists’ ongoing rewriting of theatre and performance history in modern China. Nonetheless, even as she works with all forms of activity around the phenomenon of memorization, she chooses not to mention in public two losses of her own: That of Caochangdi Workstation and that of Wu Wenguang, her artistic and life partner.\n\nA Nightmare\nWhen RED was staged at the Asia Society in New York in November 2018, I moderated a pre-performance dialogue. 10 Some interview footage that was not included in the final documentary performance was shown to the audience. From this footage, I selected Ma Xiaoduo’s recollection of her nightmare:\n\nFor years, I have had the same nightmare: I am in the middle of the bridge and cannot cross it. The bridge starts crumbling, and I have to hold tight. That kind of nightmare is a reflection of repression. Sometimes I feel like I am going to screw it. I need to bring it down. I want to be freed. I feel I am being repressed. It’s like when the red light is on, you are stopped there and cannot move. Just because you are a rural woman, just because you are a woman, everyone can keep walking, but not you. I was blocked all the time. Anyone could do things, but not you. So this is a kind of battle. Whenever I listen to Marching Forward, I feel the power.",
    "reference_list": "考点1：the Red Detachment to the Women 推荐翻译为：《红色娘子军》\n考点2：Beijing Inside-Out Art Museum 必须翻译为：北京中间美术馆，不可错译为“北京798艺术空间”\n考点3：Marching Forward (Xiang Qianjin) 推荐翻译为：《向前进》\n考点4：Jiang Fan 推荐翻译为：江帆\n考点5：ceased to exist 推荐翻译为：实体已不存在 / 已被拆除，不要直译为“停止存在”\n考点6：archive 推荐翻译为：（身体性的）档案，在剧场语境中强调“身体作为档案”，不要机械译为“档案馆”或“资料”\n考点7：“a living and lived archive”不可直译为“一个鲜活的档案”，推荐译为“鲜活的、亲历的记忆档案”。\n考点8：“presence”不可直译为“存在”，过于抽象和字面化，可译为“形象”、“风采”或“坚韧鲜活的生命力”\n考点9：“...due to inadequate initiatives...”的“initiatives”推荐译为“（创作上的）新想法、动议”，不可译为“主动性”\n考点10：\"Screw it”推荐译为“去他的吧！”或“我受够了！”",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "传记",
    "prompt_id": "190"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nNatural resources, pollution, and other environmental considerations are absent from the Solow model. But at least since Malthus (1798) made his classic argument, many people have believed that these considerations are critical to the possibilities for long-run economic growth. For example, the amounts of oil and other natural resources on earth are fixed. This could mean that any attempt to embark on a path of perpetually rising output will eventually deplete those resources, and must therefore fail. Similarly, the fixed supply of land may become a binding constraint on our ability to produce. Or ever-increasing output may generate an ever-increasing stock of pollution that will bring growth to a halt.   \nThis section addresses the issue of how environmental limitations affect long-run growth. In thinking about this issue, it is important to distinguish between environmental factors for which there are well-defined property rights—notably natural resources and land—and those for which there are not—notably pollution-free air and water.   \nThe existence of property rights for an environmental good has two important implications. The first is that markets provide valuable signals concerning how the good should be used. Suppose, for example, that the best available evidence indicates that the limited supply of oil will be an important limitation on our ability to produce in the future. This means that oil will command a high price in the future. But this in turn implies that the owners of oil do not want to sell their oil cheaply today. Thus oil commands a high price today, and so current users have an incentive to conserve. In short, evidence that the fixed amount of oil is likely to limit our ability to produce in the future would not be grounds for government intervention. Such a situation, though unfortunate, would be addressed by the market.   \nThe second implication of the existence of property rights for an environmental good is that we can use the good’s price to obtain evidence about its importance in production. For example, since evidence that oil will be an important constraint on future production would cause it to have a high price today, economists can use the current price to infer what the best available evidence suggests about oil’s importance; they do not need to assess that evidence independently.   \nWith environmental goods for which there are no property rights, the use of a good has externalities. For example, firms can pollute without compensating the people they harm. Thus the case for government intervention is much stronger. And there is no market price to provide a handy summary of the evidence concerning the good’s importance. As a result, economists interested in environmental issues must attempt to assess that evidence themselves.  \nThe stock of land is fixed, and resource use must eventually fall. Thus even though technology has been able to keep ahead of resource and land limitations over the past few centuries, it may still appear that those limitations must eventually become a binding constraint on our ability to produce.   \nThe reason that this does not occur in our model is that production is Cobb–Douglas. With Cobb–Douglas production, a given percentage change in A always produces the same percentage change in output, regardless of how large A is relative to R and T. As a result, technological progress can always counterbalance declines in R/L and T/L.   \nThis is not a general property of production functions, however. With Cobb–Douglas production, the elasticity of substitution between inputs is 1. If this elasticity is less than 1, the share of income going to the inputs that are becoming scarcer rises over time. Intuitively, as the production function becomes more like the Leontief case, the inputs that are becoming scarcer become increasingly important. Conversely, if the elasticity of substitution is greater than 1, the share of income going to the inputs that are becoming scarcer is falling. This, too, is intuitive: as the production function becomes closer to linear, the abundant factors benefit.   In terms of our earlier analysis, what this means is that if we do not restrict our attention to Cobb–Douglas production, the shares in expression (1.51) for the growth drag are no longer constant, but are functions of factor proportions. And if the elasticity of substitution is less than 1, the share of income going to resources and land is rising over time—and thus the growth drag is as well. Indeed, in this case the share of income going to the slowestgrowing input—resources—approaches 1. Thus the growth drag approaches b + n. That is, asymptotically income per worker declines at rate b + n, the rate at which resource use per worker is falling. This case supports our apocalyptic intuition: in the long run, the fixed supply of resources leads to steadily declining incomes.   \nIn fact, however, recognizing that production may not be Cobb–Douglas should not raise our estimate of the importance of resource and land limitations, but reduce it. The reason is that the shares of income going to resources and land are falling rather than rising. We can write land’s shareas the real rental price of land multiplied by the ratio of land to output. The real rental price shows little trend, while the land-to-GDP ratio has been falling steadily. Thus land’s share has been declining. Similarly, real resource prices have had a moderate downward trend, and the ratio of resource use to GDP has also been falling. Thus resources’ share has also been declining. And declining resource and land shares imply a falling growth drag.   \nThe fact that land’s and resources’ shares have been declining despite the fact that these factors have been becoming relatively scarcer means that the elasticity of substitution between these inputs and the others must be greater than 1. At first glance, this may seem surprising. If we think in terms of narrowly defined goods—books, for example—possibilities for substitution among inputs may not seem particularly large. But if we recognize that what people value is not particular goods but the ultimate services they provide—information storage, for example—the idea that there are often large possibilities for substitution becomes more plausible. Information can be stored not only through books, but through oral tradition, stone tablets, microfilm, videotape, DVDs, hard drives, and more. These different means of storage use capital, resources, land, and labor in very different proportions. As a result, the economy can respond to the increasing scarcity of resources and land by moving to means of information storage that use those inputs less intensively.   \nDeclining quantities of resources and land per worker are not the only ways that environmental problems can limit growth. Production creates pollution. This pollution reduces properly measured output. That is, if our data on real output accounted for all the outputs of production at prices that reflect their impacts on utility, pollution would enter with a negative price. In addition, pollution could rise to the point where it reduces conventionally measured output. For example, global warming could reduce output through its impact on sea levels and weather patterns.   \nEconomic theory does not give us reason to be sanguine about pollution. Because those who pollute do not bear the costs of their pollution, an unregulated market leads to excessive pollution. Similarly, there is nothing to prevent an environmental catastrophe in an unregulated market. For example, suppose there is some critical level of pollution that would result in a sudden and drastic change in climate. Because pollution’s effects are external, there is no market mechanism to prevent pollution from rising to such a level, or even a market price of a pollution-free environment to warn us that well-informed individuals believe a catastrophe is imminent.   \nConceptually, the correct policy to deal with pollution is straightforward. We should estimate the dollar value of the negative externality and taxpollution by this amount. This would bring private and social costs in line, and thus would result in the socially optimal level of pollution.   \nAlthough describing the optimal policy is easy, it is still useful to know how severe the problems posed by pollution are. In terms of understanding economic growth, we would like to know by how much pollution is likely to retard growth if no corrective measures are taken. In terms of policy, we would like to know how large a pollution tax is appropriate. We would also like to know whether, if pollution taxes are politically infeasible, the benefits of cruder regulatory approaches are likely to outweigh their costs. Finally, in terms of our own behavior, we would like to know how much effort individuals who care about others’ well-being should make to curtail their activities that cause pollution.   \nSince there are no market prices to use as guides, economists interested in pollution must begin by looking at the scientific evidence. In the case of global warming, for example, a reasonable point estimate is that in the absence of major intervention, the average temperature will rise by 3 degrees centigrade over the next century, with various effects on climate (Nordhaus, 2008). Economists can help estimate the welfare consequences of these changes. To give just one example, experts on farming had estimated the likely impact of global warming on U.S. farmers’ ability to continue growing their current crops. These studies concluded that global warming would have a significant negative impact. Mendelsohn, Nordhaus, and Shaw (1994), however, note that farmers can respond to changing weather patterns by moving into different crops, or even switching their land use out of crops altogether. They find that once these possibilities for substitution are taken into account, the overall effect of global warming on U.S. farmers is small and may be positive (see also Deschenes and Greenstone, 2007).   \nAfter considering the various channels through which global warming is likely to affect welfare, Nordhaus (2008) concludes that a reasonable estimate is that the overall welfare effect as of 2100 is likely to be slightly negative—the equivalent of a reduction in GDP of 2 to 3 percent. This corresponds to a reduction in average annual growth of only about 0.03 percentage points. Not surprisingly, Nordhaus finds that drastic measures to combat climate change, such as policies that would largely halt further warming by cutting emissions of greenhouse gases to less than half their 1990 levels, would be much more harmful than simply doing nothing. Similarly, mainstream estimates of the social cost of carbon (that is, the size of the appropriate Pigovian tax to address the negative externalities from carbon emissions through their impact on climate), while not trivial, are only moderate. Both Greenstone, Kopits, and Wolverton (2013) and Nordhaus(2014) estimate the cost as about $20 per ton. One way of describing the size of such a tax is that it would add about $0.20 to the cost of a gallon of\ngasoline.\nOf course, it is possible that these attempts to interpret the scientific evidence and estimate the likely welfare effects are far from the mark. There appear to be two main considerations that could lend support to much stronger views of the costs of climate change and the value of measures to address it. The first is tail risks (or tipping points) that is, the perhaps small chance that outcomes will be vastly worse than the point estimates. Nordhaus (2013) tries to account for uncertainty and concludes that it does not greatly change his conclusions; one reason is simply that just as outcomes could be worse than his point estimates, they could also be better. Likewise, Greenstone, Kopits, and Wolverton (2013) find that there are alternative assumptions that lead to, say, a doubling of the estimated social cost of carbon, but that it is hard to make a case for estimates that are qualitatively different from their baseline. In contrast, Weitzman (2009) argues that tail risks fundamentally change the analysis of climate change and support much more dramatic policy changes.\nThe second important issue is the appropriate discount rate: even small changes in the discount rate have very large effects on analyses of policies that involve costs today in exchange for benefits extending decades into the future. And with a sufficiently low discount rate, impacts at horizons beyond the 50 to 100 years usually examined in analyses of climate change could have large effects on the conclusions. A good introduction to the question of how to discount the costs and benefits of actions to mitigate climate change is the debate between Nordhaus (2007) and Stern (2008). Despite these complications, the fact remains that most (though certainly not all) economists who have studied climate change seriously, even ones whose initial positions were very sympathetic with environmental concerns, have concluded that the impact of climate change on growth is likely to be no more than moderate.25\nFinally, it is important to remember that climate change is not the only type of pollution. Indeed, using an approach similar to his analysis of climate change, Nordhaus (1992) estimates that the welfare costs of the externalities from other types of pollution are probably slightly larger than those from climate change; his point estimate is that they are lowering appropriately measured annual growth by roughly 0.04 percentage points. Thus, policymakers and concerned citizens should not lose sight of more conventional types of pollution.\n",
    "ori_text": "\n\nNatural resources, pollution, and other environmental considerations are absent from the Solow model. But at least since Malthus (1798) made his classic argument, many people have believed that these considerations are critical to the possibilities for long-run economic growth. For example, the amounts of oil and other natural resources on earth are fixed. This could mean that any attempt to embark on a path of perpetually rising output will eventually deplete those resources, and must therefore fail. Similarly, the fixed supply of land may become a binding constraint on our ability to produce. Or ever-increasing output may generate an ever-increasing stock of pollution that will bring growth to a halt.   \nThis section addresses the issue of how environmental limitations affect long-run growth. In thinking about this issue, it is important to distinguish between environmental factors for which there are well-defined property rights—notably natural resources and land—and those for which there are not—notably pollution-free air and water.   \nThe existence of property rights for an environmental good has two important implications. The first is that markets provide valuable signals concerning how the good should be used. Suppose, for example, that the best available evidence indicates that the limited supply of oil will be an important limitation on our ability to produce in the future. This means that oil will command a high price in the future. But this in turn implies that the owners of oil do not want to sell their oil cheaply today. Thus oil commands a high price today, and so current users have an incentive to conserve. In short, evidence that the fixed amount of oil is likely to limit our ability to produce in the future would not be grounds for government intervention. Such a situation, though unfortunate, would be addressed by the market.   \nThe second implication of the existence of property rights for an environmental good is that we can use the good’s price to obtain evidence about its importance in production. For example, since evidence that oil will be an important constraint on future production would cause it to have a high price today, economists can use the current price to infer what the best available evidence suggests about oil’s importance; they do not need to assess that evidence independently.   \nWith environmental goods for which there are no property rights, the use of a good has externalities. For example, firms can pollute without compensating the people they harm. Thus the case for government intervention is much stronger. And there is no market price to provide a handy summary of the evidence concerning the good’s importance. As a result, economists interested in environmental issues must attempt to assess that evidence themselves.  \nThe stock of land is fixed, and resource use must eventually fall. Thus even though technology has been able to keep ahead of resource and land limitations over the past few centuries, it may still appear that those limitations must eventually become a binding constraint on our ability to produce.   \nThe reason that this does not occur in our model is that production is Cobb–Douglas. With Cobb–Douglas production, a given percentage change in A always produces the same percentage change in output, regardless of how large A is relative to R and T. As a result, technological progress can always counterbalance declines in R/L and T/L.   \nThis is not a general property of production functions, however. With Cobb–Douglas production, the elasticity of substitution between inputs is 1. If this elasticity is less than 1, the share of income going to the inputs that are becoming scarcer rises over time. Intuitively, as the production function becomes more like the Leontief case, the inputs that are becoming scarcer become increasingly important. Conversely, if the elasticity of substitution is greater than 1, the share of income going to the inputs that are becoming scarcer is falling. This, too, is intuitive: as the production function becomes closer to linear, the abundant factors benefit.   In terms of our earlier analysis, what this means is that if we do not restrict our attention to Cobb–Douglas production, the shares in expression (1.51) for the growth drag are no longer constant, but are functions of factor proportions. And if the elasticity of substitution is less than 1, the share of income going to resources and land is rising over time—and thus the growth drag is as well. Indeed, in this case the share of income going to the slowestgrowing input—resources—approaches 1. Thus the growth drag approaches b + n. That is, asymptotically income per worker declines at rate b + n, the rate at which resource use per worker is falling. This case supports our apocalyptic intuition: in the long run, the fixed supply of resources leads to steadily declining incomes.   \nIn fact, however, recognizing that production may not be Cobb–Douglas should not raise our estimate of the importance of resource and land limitations, but reduce it. The reason is that the shares of income going to resources and land are falling rather than rising. We can write land’s shareas the real rental price of land multiplied by the ratio of land to output. The real rental price shows little trend, while the land-to-GDP ratio has been falling steadily. Thus land’s share has been declining. Similarly, real resource prices have had a moderate downward trend, and the ratio of resource use to GDP has also been falling. Thus resources’ share has also been declining. And declining resource and land shares imply a falling growth drag.   \nThe fact that land’s and resources’ shares have been declining despite the fact that these factors have been becoming relatively scarcer means that the elasticity of substitution between these inputs and the others must be greater than 1. At first glance, this may seem surprising. If we think in terms of narrowly defined goods—books, for example—possibilities for substitution among inputs may not seem particularly large. But if we recognize that what people value is not particular goods but the ultimate services they provide—information storage, for example—the idea that there are often large possibilities for substitution becomes more plausible. Information can be stored not only through books, but through oral tradition, stone tablets, microfilm, videotape, DVDs, hard drives, and more. These different means of storage use capital, resources, land, and labor in very different proportions. As a result, the economy can respond to the increasing scarcity of resources and land by moving to means of information storage that use those inputs less intensively.   \nDeclining quantities of resources and land per worker are not the only ways that environmental problems can limit growth. Production creates pollution. This pollution reduces properly measured output. That is, if our data on real output accounted for all the outputs of production at prices that reflect their impacts on utility, pollution would enter with a negative price. In addition, pollution could rise to the point where it reduces conventionally measured output. For example, global warming could reduce output through its impact on sea levels and weather patterns.   \nEconomic theory does not give us reason to be sanguine about pollution. Because those who pollute do not bear the costs of their pollution, an unregulated market leads to excessive pollution. Similarly, there is nothing to prevent an environmental catastrophe in an unregulated market. For example, suppose there is some critical level of pollution that would result in a sudden and drastic change in climate. Because pollution’s effects are external, there is no market mechanism to prevent pollution from rising to such a level, or even a market price of a pollution-free environment to warn us that well-informed individuals believe a catastrophe is imminent.   \nConceptually, the correct policy to deal with pollution is straightforward. We should estimate the dollar value of the negative externality and taxpollution by this amount. This would bring private and social costs in line, and thus would result in the socially optimal level of pollution.   \nAlthough describing the optimal policy is easy, it is still useful to know how severe the problems posed by pollution are. In terms of understanding economic growth, we would like to know by how much pollution is likely to retard growth if no corrective measures are taken. In terms of policy, we would like to know how large a pollution tax is appropriate. We would also like to know whether, if pollution taxes are politically infeasible, the benefits of cruder regulatory approaches are likely to outweigh their costs. Finally, in terms of our own behavior, we would like to know how much effort individuals who care about others’ well-being should make to curtail their activities that cause pollution.   \nSince there are no market prices to use as guides, economists interested in pollution must begin by looking at the scientific evidence. In the case of global warming, for example, a reasonable point estimate is that in the absence of major intervention, the average temperature will rise by 3 degrees centigrade over the next century, with various effects on climate (Nordhaus, 2008). Economists can help estimate the welfare consequences of these changes. To give just one example, experts on farming had estimated the likely impact of global warming on U.S. farmers’ ability to continue growing their current crops. These studies concluded that global warming would have a significant negative impact. Mendelsohn, Nordhaus, and Shaw (1994), however, note that farmers can respond to changing weather patterns by moving into different crops, or even switching their land use out of crops altogether. They find that once these possibilities for substitution are taken into account, the overall effect of global warming on U.S. farmers is small and may be positive (see also Deschenes and Greenstone, 2007).   \nAfter considering the various channels through which global warming is likely to affect welfare, Nordhaus (2008) concludes that a reasonable estimate is that the overall welfare effect as of 2100 is likely to be slightly negative—the equivalent of a reduction in GDP of 2 to 3 percent. This corresponds to a reduction in average annual growth of only about 0.03 percentage points. Not surprisingly, Nordhaus finds that drastic measures to combat climate change, such as policies that would largely halt further warming by cutting emissions of greenhouse gases to less than half their 1990 levels, would be much more harmful than simply doing nothing. Similarly, mainstream estimates of the social cost of carbon (that is, the size of the appropriate Pigovian tax to address the negative externalities from carbon emissions through their impact on climate), while not trivial, are only moderate. Both Greenstone, Kopits, and Wolverton (2013) and Nordhaus(2014) estimate the cost as about $20 per ton. One way of describing the size of such a tax is that it would add about $0.20 to the cost of a gallon of\ngasoline.\nOf course, it is possible that these attempts to interpret the scientific evidence and estimate the likely welfare effects are far from the mark. There appear to be two main considerations that could lend support to much stronger views of the costs of climate change and the value of measures to address it. The first is tail risks (or tipping points) that is, the perhaps small chance that outcomes will be vastly worse than the point estimates. Nordhaus (2013) tries to account for uncertainty and concludes that it does not greatly change his conclusions; one reason is simply that just as outcomes could be worse than his point estimates, they could also be better. Likewise, Greenstone, Kopits, and Wolverton (2013) find that there are alternative assumptions that lead to, say, a doubling of the estimated social cost of carbon, but that it is hard to make a case for estimates that are qualitatively different from their baseline. In contrast, Weitzman (2009) argues that tail risks fundamentally change the analysis of climate change and support much more dramatic policy changes.\nThe second important issue is the appropriate discount rate: even small changes in the discount rate have very large effects on analyses of policies that involve costs today in exchange for benefits extending decades into the future. And with a sufficiently low discount rate, impacts at horizons beyond the 50 to 100 years usually examined in analyses of climate change could have large effects on the conclusions. A good introduction to the question of how to discount the costs and benefits of actions to mitigate climate change is the debate between Nordhaus (2007) and Stern (2008). Despite these complications, the fact remains that most (though certainly not all) economists who have studied climate change seriously, even ones whose initial positions were very sympathetic with environmental concerns, have concluded that the impact of climate change on growth is likely to be no more than moderate.25\nFinally, it is important to remember that climate change is not the only type of pollution. Indeed, using an approach similar to his analysis of climate change, Nordhaus (1992) estimates that the welfare costs of the externalities from other types of pollution are probably slightly larger than those from climate change; his point estimate is that they are lowering appropriately measured annual growth by roughly 0.04 percentage points. Thus, policymakers and concerned citizens should not lose sight of more conventional types of pollution.\n",
    "reference_list": "考点1：\"narrowly defined goods“推荐译为“狭义的产品“。\n考点2：“pollution’s effects are external”应译为“污染的影响是外生的”，”外生性“是经济学模型中常见概念，此处应准确翻译。\n考点3：“ tipping points”推荐译为“临界点理论“。\n考点4:  \"apocalyptic intuition\"推荐译为“末世直觉”\n考点5:  \"sympathetic with environmental concerns\"中的“sympathetic”不能译为“同情”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "165"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n5.2.4   Change control\nThe scope of change control is defined by each organization. It will typically include all IT infrastructure, applications, documentation, processes, supplier relationships, and anything else that might directly or indirectly impact a product or service.\nIt is important to distinguish change control from organizational change management. Organizational change management manages the people aspects of   changes to ensure that improvements and organizational transformation initiatives are implemented successfully. Change control is usually focused on changes in products and services.\nChange control must balance the need to make beneficial changes that will deliver additional value with the need to protect customers and users from the adverse effect of changes. All changes should be assessed by people who are able to understand the risks and the expected benefits; the changes must then be    authorized before they are deployed. This assessment, however, should not introduce unnecessary delay.\nThe person or group who authorizes a change is known as a change authority. It is essential that the correct change authority is assigned to each type of change to ensure that change control is both efficient and effective. In high-velocity organizations, it is a common practice to decentralize change approval, making the peer review a top predictor of high performance.\nThere are three types of change that are each managed in different ways:\n•Standard changes These are low-risk, pre-authorized changes that are well understood and fully documented, and can be implemented without needing additional authorization. They are often initiated as service requests, but may also be operational changes. When the procedure for a standard change is created or modified, there should be a full risk assessment and authorization as for any other change. This risk assessment does not need to be repeated each time the standard change is implemented; it only needs to be done if there is a  modification to the way it is carried out.\n•Normal changes These are changes that need to be scheduled, assessed, and authorized following a process. Change models based on the type of change determine the roles for assessment and authorization. Some normal changes are low risk, and the change authority for these is usually someone who can make rapid decisions, often using automation to speed up the change. Other normal changes are very major and the change authority could be as high as the management board (or equivalent). Initiation of a normal change is triggered by the creation of a change request. This may be created manually, but organizations that have an automated pipeline for continuous integration and continuous deployment often automate most steps of the change control process.\n•   Emergency changes These are changes that must be implemented as soon as possible; for example, to resolve an incident or implement a security patch.\nEmergency changes are not typically included in a change schedule, and the process for assessment and authorization is expedited to ensure they can be implemented quickly. As far as possible, emergency changes should be subject to the same testing, assessment, and authorization as normal changes, but it may be acceptable to defer some documentation until after the change has been implemented, and sometimes it will be necessary to implement the change with less testing due to time constraints. There may also be a separate change authority for emergency changes, typically including a small number of senior managers who understand the business risks involved.\nThe change schedule is used to help plan changes, assist in communication, avoid conflicts, and assign resources. It can also be used after changes have been deployed to provide information needed for incident management, problem management, and improvement planning. Regardless of who the change authority is, they may need to communicate widely across the organization. Risk assessment, for instance, may require them to gather input from many people with specialist knowledge. Additionally, there is usually a need to communicate information about the change to ensure people are fully prepared before the change is deployed.\nFigure 5.19 shows the contribution of change control to the service value chain, with the practice being involved in all value chain activities:\n•   Plan Changes to product and service portfolios, policies, and practices all require a certain level of control, and the change control practice is used to provide it.\n•   Improve Many improvements will require changes to be made, and these should be assessed and authorized in the same way as all other changes.\n•   Engage Customers and users may need to be consulted or informed about changes, depending on the nature of the change.\n•   Design and transition Many changes are initiated as a result of new or changed services. Change control activity is a major contributor to transition.\n•   Obtain/build Changes to components are subject to change control, whether they are built in house or obtained from suppliers.\n•   Deliver and support Changes may have an impact on delivery and support, and information about changes must be communicated to personnel who carry out this value chain activity. These people may also play a part in assessing and authorizing changes.\n \nFigure 5.19 Heat map of the contribution of change control to value chain activities\n\nThe IT IL story: Change control\nHenri: The car hire market is developingfaster than ever. To make sure that Axle meets customer demands and capitalizes on opportunities, we need to  have speed–to–market and to experiment with new ideas. Our new service\noferings will see a lot of change at Axle. Some teams will need to double, while others may reduce. We need to bring everyone at Axle on board.\nRadhika: The change control practice at Axle makes sure that our services achieve the right balance of flexibility and reliability.\nMarco: Some of our processes are highly automated and designedfor the fast deployment of changes. These are perfectfor changes to our booking app and some of our lT systems.\nSu: ln other cases, such as when we update our vehicles, we use a mix of\nmanual and automated testing. For example, the Axle Aware road monitoring  and safety system requires consultation and approval before we can update it.\nMarco: Systems such as Axle Aware can’t be altered like the booking app. The priorityfor those changes is that we act safely and comply with appropriate regulations. That’s more important than time to market.\n5.2.5 Incident management\nKey message\nThe purpose of the incident management practice is to minimize the negative impact of incidents by restoring normal service operation as quickly as possible.\nIncident management can have an enormous impact on customer and user satisfaction, and on how customers and users perceive the service provider. Every incident should be logged and managed to ensure that it is resolved in a time that meets the expectations of the customer and user. Target resolution times are agreed, documented, and communicated to ensure that expectations are realistic. Incidents are prioritized based on an agreed classification to ensure that incidents  with the highest business impact are resolved first.\nOrganizations should design their incident management practice to provide appropriate management and resource allocation to different types of incident.\nIncidents with a low impact must be managed efficiently to ensure that they do not consume too many resources. Incidents with a larger impact may require more resources and more complex management. There are usually separate processes for managing major incidents, and for managing information security incidents.\nInformation about incidents should be stored in incident records in a suitable tool. Ideally, this tool should also provide links to related CIs, changes, problems, known errors, and other knowledge to enable quick and efficient diagnosis and recovery. Modern IT service management tools can provide automated matching of incidents to other incidents, problems, or known errors, and can even provide intelligent analysis of incident data to generate recommendations for helping with future incidents.\nIt is important that people working on an incident provide good-quality updates in a  timely fashion. These updates should include information about symptoms, business impact, CIs affected, actions completed, and actions planned. Each of these should    have a timestamp and information about the people involved, so that the people involved or interested can be kept informed. There may also be a need for good collaboration tools so that people working on an incident can collaborate effectively.\nIncidents may be diagnosed and resolved by people in many different groups, depending on the complexity of the issue or the incident type. All of these groups need to understand the incident management process, and how their contribution to this helps to manage the value, outcomes, costs, and risks of t he services provided:\n•   Some incidents will be resolved by the users themselves, using self-help. Use of specific self-help records should be captured for use in measurement and improvement activities.\n•   Some incidents will be resolved by the service desk.\n•   More complex incidents will usually be escalated to a support team for resolution. Typically, the routing is based on the incident category, which should help to identify the correct team.\n•   Incidents can be escalated to suppliers or partners, who offer support for their products and services.\n•   The most complex incidents, and all major incidents, often require a temporary team to work together to identify the resolution. This team may include representatives of many stakeholders, including the service provider, suppliers, users, etc.\n•   In some extreme cases, disaster recovery plans may be invoked to resolve an  incident. Disaster recovery is described in the service continuity management practice (section 5.2.12).\nEffective incident management often requires a high level of collaboration within and between teams. These teams may include the service desk, technical support, application support, and vendors. Collaboration can facilitate information-sharing and learning, as well as helping to solve the incident more efficiently and effectively.\n\nThird-party products and services that are used as components of a service require support agreements which align the obligations of the supplier with the commitments made by the service provider to customers. Incident management may require frequent interaction with these suppliers, and routine management of this aspect of supplier contracts is often part of the incident management practice. A supplier can also act as a service desk, logging and managing all incidents and escalating them to subject matter experts or other parties as required.\nThere should be a formal process for logging and managing incidents. This process     does not usually include detailed procedures for how to diagnose, investigate, and    resolve incidents, but can provide techniques for making investigation and diagnosis more efficient. There may be scripts for collecting information from users during initial contact, and this may lead directly to diagnosis and resolution of simple incidents. Investigation of more complicated incidents often requires knowledge and expertise, rather than procedural steps.\nDealing with incidents is possible in every value chain activity, though t he most visible (due to effect on users) are incidents in an operational environment.\nFigure 5.20 shows the contribution of incident management to the service value chain, with the practice being applied mainly to the engage, and deliver and support value chain activities. Except for plan, other activities may use information about\nincidents to help set priorities:\n•   Improve Incident records are a key input to improvement activities, and are prioritized both in terms of incident frequency and severity.\n•   Engage Incidents are visible to users, and significant incidents are also visible to customers. Good incident management requires regular communication to understand the issues, set expectations, provide status updates, and agree that the issue has been resolved so the incident can be closed.\n•   Design and transition Incidents may occur in test environments, as well as during service release and deployment. The practice ensures these incidents are resolved in a timely and controlled manner.\n•   Obtain/build Incidents may occur in development environments. Incident management practice ensures these incidents are resolved in a timely and controlled manner.\n•   Deliver and support Incident management makes a significant contribution to support. This value chain activity includes resolving incidents and problems.\nFigure 5.20 Heat map of the contribution of incident management to value chain activities\nThe IT IL story: Axle’s incident management\nRadhika: Axle faces many potential IT and non-IT incidents. Cars can break down, road accidents might occur, or our customers mightface challenges with unfamiliar road rules.\nMarco: A car booking can be a fected by an error in our app, or by a user getting lost due to a navigation error with our software. When incidents occur, we have to be ready to restore normal services as soon as possible. We also have to make sure our team knows how and when to switchfrom pre-defined recovery procedures to swarming and collective analysis.\nRadhika: We also make sure that such cases are followed by investigation and improvements.\nHenri: Axle has developed clear processes for all types of incidents, with workarounds available for cases that happen frequently, such as a tyre puncture or loss of internet connectivity.\nRadhika: Our teams work together with our suppliers and partners to ensure fast and efective incident response. We develop and test recovery procedures together with the partners involved in any incidents we experience.",
    "ori_text": "5.2.4   Change control\nThe scope of change control is defined by each organization. It will typically include all IT infrastructure, applications, documentation, processes, supplier relationships, and anything else that might directly or indirectly impact a product or service.\nIt is important to distinguish change control from organizational change management. Organizational change management manages the people aspects of   changes to ensure that improvements and organizational transformation initiatives are implemented successfully. Change control is usually focused on changes in products and services.\nChange control must balance the need to make beneficial changes that will deliver additional value with the need to protect customers and users from the adverse effect of changes. All changes should be assessed by people who are able to understand the risks and the expected benefits; the changes must then be    authorized before they are deployed. This assessment, however, should not introduce unnecessary delay.\nThe person or group who authorizes a change is known as a change authority. It is essential that the correct change authority is assigned to each type of change to ensure that change control is both efficient and effective. In high-velocity organizations, it is a common practice to decentralize change approval, making the peer review a top predictor of high performance.\nThere are three types of change that are each managed in different ways:\n•Standard changes These are low-risk, pre-authorized changes that are well understood and fully documented, and can be implemented without needing additional authorization. They are often initiated as service requests, but may also be operational changes. When the procedure for a standard change is created or modified, there should be a full risk assessment and authorization as for any other change. This risk assessment does not need to be repeated each time the standard change is implemented; it only needs to be done if there is a  modification to the way it is carried out.\n•Normal changes These are changes that need to be scheduled, assessed, and authorized following a process. Change models based on the type of change determine the roles for assessment and authorization. Some normal changes are low risk, and the change authority for these is usually someone who can make rapid decisions, often using automation to speed up the change. Other normal changes are very major and the change authority could be as high as the management board (or equivalent). Initiation of a normal change is triggered by the creation of a change request. This may be created manually, but organizations that have an automated pipeline for continuous integration and continuous deployment often automate most steps of the change control process.\n•   Emergency changes These are changes that must be implemented as soon as possible; for example, to resolve an incident or implement a security patch.\nEmergency changes are not typically included in a change schedule, and the process for assessment and authorization is expedited to ensure they can be implemented quickly. As far as possible, emergency changes should be subject to the same testing, assessment, and authorization as normal changes, but it may be acceptable to defer some documentation until after the change has been implemented, and sometimes it will be necessary to implement the change with less testing due to time constraints. There may also be a separate change authority for emergency changes, typically including a small number of senior managers who understand the business risks involved.\nThe change schedule is used to help plan changes, assist in communication, avoid conflicts, and assign resources. It can also be used after changes have been deployed to provide information needed for incident management, problem management, and improvement planning. Regardless of who the change authority is, they may need to communicate widely across the organization. Risk assessment, for instance, may require them to gather input from many people with specialist knowledge. Additionally, there is usually a need to communicate information about the change to ensure people are fully prepared before the change is deployed.\nFigure 5.19 shows the contribution of change control to the service value chain, with the practice being involved in all value chain activities:\n•   Plan Changes to product and service portfolios, policies, and practices all require a certain level of control, and the change control practice is used to provide it.\n•   Improve Many improvements will require changes to be made, and these should be assessed and authorized in the same way as all other changes.\n•   Engage Customers and users may need to be consulted or informed about changes, depending on the nature of the change.\n•   Design and transition Many changes are initiated as a result of new or changed services. Change control activity is a major contributor to transition.\n•   Obtain/build Changes to components are subject to change control, whether they are built in house or obtained from suppliers.\n•   Deliver and support Changes may have an impact on delivery and support, and information about changes must be communicated to personnel who carry out this value chain activity. These people may also play a part in assessing and authorizing changes.\n \nFigure 5.19 Heat map of the contribution of change control to value chain activities\n\nThe IT IL story: Change control\nHenri: The car hire market is developingfaster than ever. To make sure that Axle meets customer demands and capitalizes on opportunities, we need to  have speed–to–market and to experiment with new ideas. Our new service\noferings will see a lot of change at Axle. Some teams will need to double, while others may reduce. We need to bring everyone at Axle on board.\nRadhika: The change control practice at Axle makes sure that our services achieve the right balance of flexibility and reliability.\nMarco: Some of our processes are highly automated and designedfor the fast deployment of changes. These are perfectfor changes to our booking app and some of our lT systems.\nSu: ln other cases, such as when we update our vehicles, we use a mix of\nmanual and automated testing. For example, the Axle Aware road monitoring  and safety system requires consultation and approval before we can update it.\nMarco: Systems such as Axle Aware can’t be altered like the booking app. The priorityfor those changes is that we act safely and comply with appropriate regulations. That’s more important than time to market.\n5.2.5 Incident management\nKey message\nThe purpose of the incident management practice is to minimize the negative impact of incidents by restoring normal service operation as quickly as possible.\nIncident management can have an enormous impact on customer and user satisfaction, and on how customers and users perceive the service provider. Every incident should be logged and managed to ensure that it is resolved in a time that meets the expectations of the customer and user. Target resolution times are agreed, documented, and communicated to ensure that expectations are realistic. Incidents are prioritized based on an agreed classification to ensure that incidents  with the highest business impact are resolved first.\nOrganizations should design their incident management practice to provide appropriate management and resource allocation to different types of incident.\nIncidents with a low impact must be managed efficiently to ensure that they do not consume too many resources. Incidents with a larger impact may require more resources and more complex management. There are usually separate processes for managing major incidents, and for managing information security incidents.\nInformation about incidents should be stored in incident records in a suitable tool. Ideally, this tool should also provide links to related CIs, changes, problems, known errors, and other knowledge to enable quick and efficient diagnosis and recovery. Modern IT service management tools can provide automated matching of incidents to other incidents, problems, or known errors, and can even provide intelligent analysis of incident data to generate recommendations for helping with future incidents.\nIt is important that people working on an incident provide good-quality updates in a  timely fashion. These updates should include information about symptoms, business impact, CIs affected, actions completed, and actions planned. Each of these should    have a timestamp and information about the people involved, so that the people involved or interested can be kept informed. There may also be a need for good collaboration tools so that people working on an incident can collaborate effectively.\nIncidents may be diagnosed and resolved by people in many different groups, depending on the complexity of the issue or the incident type. All of these groups need to understand the incident management process, and how their contribution to this helps to manage the value, outcomes, costs, and risks of t he services provided:\n•   Some incidents will be resolved by the users themselves, using self-help. Use of specific self-help records should be captured for use in measurement and improvement activities.\n•   Some incidents will be resolved by the service desk.\n•   More complex incidents will usually be escalated to a support team for resolution. Typically, the routing is based on the incident category, which should help to identify the correct team.\n•   Incidents can be escalated to suppliers or partners, who offer support for their products and services.\n•   The most complex incidents, and all major incidents, often require a temporary team to work together to identify the resolution. This team may include representatives of many stakeholders, including the service provider, suppliers, users, etc.\n•   In some extreme cases, disaster recovery plans may be invoked to resolve an  incident. Disaster recovery is described in the service continuity management practice (section 5.2.12).\nEffective incident management often requires a high level of collaboration within and between teams. These teams may include the service desk, technical support, application support, and vendors. Collaboration can facilitate information-sharing and learning, as well as helping to solve the incident more efficiently and effectively.\n\nThird-party products and services that are used as components of a service require support agreements which align the obligations of the supplier with the commitments made by the service provider to customers. Incident management may require frequent interaction with these suppliers, and routine management of this aspect of supplier contracts is often part of the incident management practice. A supplier can also act as a service desk, logging and managing all incidents and escalating them to subject matter experts or other parties as required.\nThere should be a formal process for logging and managing incidents. This process     does not usually include detailed procedures for how to diagnose, investigate, and    resolve incidents, but can provide techniques for making investigation and diagnosis more efficient. There may be scripts for collecting information from users during initial contact, and this may lead directly to diagnosis and resolution of simple incidents. Investigation of more complicated incidents often requires knowledge and expertise, rather than procedural steps.\nDealing with incidents is possible in every value chain activity, though t he most visible (due to effect on users) are incidents in an operational environment.\nFigure 5.20 shows the contribution of incident management to the service value chain, with the practice being applied mainly to the engage, and deliver and support value chain activities. Except for plan, other activities may use information about\nincidents to help set priorities:\n•   Improve Incident records are a key input to improvement activities, and are prioritized both in terms of incident frequency and severity.\n•   Engage Incidents are visible to users, and significant incidents are also visible to customers. Good incident management requires regular communication to understand the issues, set expectations, provide status updates, and agree that the issue has been resolved so the incident can be closed.\n•   Design and transition Incidents may occur in test environments, as well as during service release and deployment. The practice ensures these incidents are resolved in a timely and controlled manner.\n•   Obtain/build Incidents may occur in development environments. Incident management practice ensures these incidents are resolved in a timely and controlled manner.\n•   Deliver and support Incident management makes a significant contribution to support. This value chain activity includes resolving incidents and problems.\nFigure 5.20 Heat map of the contribution of incident management to value chain activities\nThe IT IL story: Axle’s incident management\nRadhika: Axle faces many potential IT and non-IT incidents. Cars can break down, road accidents might occur, or our customers mightface challenges with unfamiliar road rules.\nMarco: A car booking can be a fected by an error in our app, or by a user getting lost due to a navigation error with our software. When incidents occur, we have to be ready to restore normal services as soon as possible. We also have to make sure our team knows how and when to switchfrom pre-defined recovery procedures to swarming and collective analysis.\nRadhika: We also make sure that such cases are followed by investigation and improvements.\nHenri: Axle has developed clear processes for all types of incidents, with workarounds available for cases that happen frequently, such as a tyre puncture or loss of internet connectivity.\nRadhika: Our teams work together with our suppliers and partners to ensure fast and efective incident response. We develop and test recovery procedures together with the partners involved in any incidents we experience.",
    "reference_list": "考点1：“IT infrastructure”推荐译为“IT基础架构”\n考点2：“able to understand the risks and the expected benefits”必须译为“有能力理解风险和预期收益”，避免缩小为特定人群。\n考点3：“a major contributor”必须译为“主要贡献者”，避免夸大为“核心”。\n考点4：“based on an agreed classification”必须译为“根据商定的分类确定优先级”，不可省略“分类”。\n考点5：“outcomes”必须译为“成果”，不可漏译。\n考点6：“escalated to”必须译为“升级至”，避免泛化为“参与”。\n考点7：“well understood and fully documented”必须译为“充分理解并完整记录”，避免限定为“流程”。\n考点8：“specialist knowledge”必须译为“专业知识”，避免译为“专业人士的意见”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "113"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n最后贷款人制度的目的是什么？长期以来理论和实践中有两种不同的目的之争：第一种被称为货币主义学派，即最后贷款人立法目标在于通过流动性的注入实现币值长期稳定的目标；第二种被称为金融稳定主义学派，即央行提供流动性支持是为了避免个别金融机构严重的流动性困境引发的系统性风险，从而损害金融稳定。从时间上看，英国的模式更加偏重于金融稳定，而美国的模式则更加偏重于货币政策。\n\n1. 货币主义学派\n货币主义学派认为，最后贷款人制度的功能是向金融体系注入基础货币，从而抵消银行和批发货币市场的流动性撤出，并防止通货紧缩压力的积累。从这一角度而言，最后贷款人制度虽然是针对微观的机构进行的，但其实是货币政策在微观层面上的体现而已。如果将最后贷款人制度作为货币政策的下位概念，则最后贷款人制度的适用和限制等均应与货币政策所要追求的币值稳定的制度目的相挂钩。那么就需要从金融市场整体甚至更加长远的货币政策的影响来考虑最后贷款人制度的适用，而不是根据单个金融机构的情况进行判断。诚如有学者所概括的以货币主义视角来设计最后贷款人制度会产生两个重要的假设：“第一个假设是，即使在危机最严重的时候，批发货币市场也将继续有效地将资金分配给信誉良好的机构。因此，如果一个机构无法在货币市场上获得资金，货币主义者会将其解释为有关机构从根本上资不抵债的证据。第二个假设是，一家或多家金融机构的倒闭不会引发更广泛的不稳定，而这种不稳定本身可能会引发或加剧货币供应量的收缩，或扰乱对实体经济的信贷供应。”\n货币主义是一种长期视角，认为个别金融机构的危机包括退出市场并不会从长远上影响整个市场，因为幸存的金融机构将会吸收失败的金融机构的业务，从而使市场上金融服务的供给在长期视角下达到均衡。货币主义学派的核心原则之一是，从根本上讲，有偿付能力的银行将始终能在批发货币市场中获得资金。货币主义学派认为应通过中央银行的正常公开市场操作为整个货币市场提供流动性支持。同时，货币主义学派认为能够申请最后贷款人流动支持的适格主体应当限于吸收存款的金融机构，因为这些金融机构构成了货币的主要供给者。传统理论认为，美联储是货币主义最后贷款人的典型，美联储“通过中央银行提供紧急流动性支持，防止暂时流动性危机向清偿危机和系统性危机转化，使陷入困境的银行走出困境”。美联储提供紧急贷款的主体一般是银行金融机构。但是，2008年国际金融危机之前，美国《联邦储备法》第13（3）条赋予了美联储在非常情况下向非银行实体提供紧急贷款的权利，即“在特殊且紧急的情况下，美联储可以向任何个体、合伙企业或公司提供贷款”。此处的“特殊并且紧急”指的是贷款无法从金融市场上获得。为了获得这些紧急贷款，借款人必须提供充足的担保品，确保贷款的安全性。美国《联邦储备法》第13（3）条特别强调了在金融体系面临系统性风险时，美联储可以使用这一权力来稳定市场，防止金融危机的蔓延。这使得美联储在应对金融危机时具有更大的灵活性和操作空间。但是，2008年国际金融危机中美联储用第13（3）条对非银行金融机构发放贷款以提供流动性支持被认为加剧了道德风险，因此《多德-弗兰克法案》第1101条限制美联储利用第13（3）条的权利向特定的非银行金融机构发放贷款，除非该机构仅限于作为“具有广泛资格的计划或设施”的一部分，或者满足第806条的例外，即在“不寻常或紧急情况下”向清算所和其他指定的金融市场公用事业公司提供信贷或流动性援助；该法案第716条还禁止美联储向衍生品交易商或这些计划或设施范围之外的其他主要交易对手提供任何援助。\n\n2. 金融稳定主义学派\n金融稳定主义学派则将最后贷款人制度视为为单个金融机构提供流动性的“保险”制度，由于银行资产负债表固有的脆弱性，保险是必要的。金融稳定是一个宏观概念，它要求金融体系的三个组成部分——金融机构（商业银行、政策性银行、金融资产管理公司及证券公司等）、金融市场（股票、债券、货币和衍生品市场等）和金融基础设施（法律、支付、清算和会计体系等）都能正常运转，并能够正确评估、防范和化解金融风险。\n根据金融脆弱性理论，银行等金融机构天生具有脆弱性，因为这些金融机构往往会借短投长，这使得他们资产缺乏足够的流动性，一旦短期债权人对金融机构的稳定性产生怀疑，他们就会竞相挤兑这些金融机构，迫使金融机构火线出售（低价出售）银行的资产，从而导致其后的债权人无法得到足额清偿；对无法得到足额清偿的恐惧，将迫使更多的债权人一旦有任何风吹草动，就竞相挤兑金融机构。现代金融机构业务的复杂性使得金融机构及其短期债权人资金的信息不对称更加明显，从而使得金融机构更容易被这些短期债权人挤兑。无论是货币主义的观点抑或金融稳定的观点都会承认，由于金融系统的脆弱性和挤兑的风险，最后贷款人制度是不可或缺的。\n对于金融稳定主义学派的支持者来说，银行倒闭引发了两个重要风险。第一个风险是，银行的倒闭可能会破坏其对债权人的偿付能力，破坏其他金融机构的稳定性或支付系统的平稳高效运行；第二个风险是，一家或多家银行的倒闭可能会阻碍为实体经济提供信贷和其他金融服务。金融稳定主义者认为，央行的最后贷款人机制应当通过贴现窗口进行，是在对被贴现机构审慎监管的基础上进行的。贴现窗口贷款的有效性取决于央行是否获取有关潜在被贴现者信誉的详细信息，以及已发布的抵押品的质量。从金融稳定主义的视角看，中央银行的最后贷款人制度不仅应当覆盖传统的存款类金融机构，也应当广义包括那些因为机构的倒闭可能引起金融系统不稳定的影子银行体系。当然，把最后贷款人机制用于吸收公众存款以外的金融机构可能会面临识别的问题：即如何精确识别哪些金融机构的倒闭会引发系统性金融风险，从而避免最后贷款人援助制度的滥用引发的道德风险。",
    "ori_text": "\n\n最后贷款人制度的目的是什么？长期以来理论和实践中有两种不同的目的之争：第一种被称为货币主义学派，即最后贷款人立法目标在于通过流动性的注入实现币值长期稳定的目标；第二种被称为金融稳定主义学派，即央行提供流动性支持是为了避免个别金融机构严重的流动性困境引发的系统性风险，从而损害金融稳定。从时间上看，英国的模式更加偏重于金融稳定，而美国的模式则更加偏重于货币政策。\n\n1. 货币主义学派\n货币主义学派认为，最后贷款人制度的功能是向金融体系注入基础货币，从而抵消银行和批发货币市场的流动性撤出，并防止通货紧缩压力的积累。从这一角度而言，最后贷款人制度虽然是针对微观的机构进行的，但其实是货币政策在微观层面上的体现而已。如果将最后贷款人制度作为货币政策的下位概念，则最后贷款人制度的适用和限制等均应与货币政策所要追求的币值稳定的制度目的相挂钩。那么就需要从金融市场整体甚至更加长远的货币政策的影响来考虑最后贷款人制度的适用，而不是根据单个金融机构的情况进行判断。诚如有学者所概括的以货币主义视角来设计最后贷款人制度会产生两个重要的假设：“第一个假设是，即使在危机最严重的时候，批发货币市场也将继续有效地将资金分配给信誉良好的机构。因此，如果一个机构无法在货币市场上获得资金，货币主义者会将其解释为有关机构从根本上资不抵债的证据。第二个假设是，一家或多家金融机构的倒闭不会引发更广泛的不稳定，而这种不稳定本身可能会引发或加剧货币供应量的收缩，或扰乱对实体经济的信贷供应。”\n货币主义是一种长期视角，认为个别金融机构的危机包括退出市场并不会从长远上影响整个市场，因为幸存的金融机构将会吸收失败的金融机构的业务，从而使市场上金融服务的供给在长期视角下达到均衡。货币主义学派的核心原则之一是，从根本上讲，有偿付能力的银行将始终能在批发货币市场中获得资金。货币主义学派认为应通过中央银行的正常公开市场操作为整个货币市场提供流动性支持。同时，货币主义学派认为能够申请最后贷款人流动支持的适格主体应当限于吸收存款的金融机构，因为这些金融机构构成了货币的主要供给者。传统理论认为，美联储是货币主义最后贷款人的典型，美联储“通过中央银行提供紧急流动性支持，防止暂时流动性危机向清偿危机和系统性危机转化，使陷入困境的银行走出困境”。美联储提供紧急贷款的主体一般是银行金融机构。但是，2008年国际金融危机之前，美国《联邦储备法》第13（3）条赋予了美联储在非常情况下向非银行实体提供紧急贷款的权利，即“在特殊且紧急的情况下，美联储可以向任何个体、合伙企业或公司提供贷款”。此处的“特殊并且紧急”指的是贷款无法从金融市场上获得。为了获得这些紧急贷款，借款人必须提供充足的担保品，确保贷款的安全性。美国《联邦储备法》第13（3）条特别强调了在金融体系面临系统性风险时，美联储可以使用这一权力来稳定市场，防止金融危机的蔓延。这使得美联储在应对金融危机时具有更大的灵活性和操作空间。但是，2008年国际金融危机中美联储用第13（3）条对非银行金融机构发放贷款以提供流动性支持被认为加剧了道德风险，因此《多德-弗兰克法案》第1101条限制美联储利用第13（3）条的权利向特定的非银行金融机构发放贷款，除非该机构仅限于作为“具有广泛资格的计划或设施”的一部分，或者满足第806条的例外，即在“不寻常或紧急情况下”向清算所和其他指定的金融市场公用事业公司提供信贷或流动性援助；该法案第716条还禁止美联储向衍生品交易商或这些计划或设施范围之外的其他主要交易对手提供任何援助。\n\n2. 金融稳定主义学派\n金融稳定主义学派则将最后贷款人制度视为为单个金融机构提供流动性的“保险”制度，由于银行资产负债表固有的脆弱性，保险是必要的。金融稳定是一个宏观概念，它要求金融体系的三个组成部分——金融机构（商业银行、政策性银行、金融资产管理公司及证券公司等）、金融市场（股票、债券、货币和衍生品市场等）和金融基础设施（法律、支付、清算和会计体系等）都能正常运转，并能够正确评估、防范和化解金融风险。\n根据金融脆弱性理论，银行等金融机构天生具有脆弱性，因为这些金融机构往往会借短投长，这使得他们资产缺乏足够的流动性，一旦短期债权人对金融机构的稳定性产生怀疑，他们就会竞相挤兑这些金融机构，迫使金融机构火线出售（低价出售）银行的资产，从而导致其后的债权人无法得到足额清偿；对无法得到足额清偿的恐惧，将迫使更多的债权人一旦有任何风吹草动，就竞相挤兑金融机构。现代金融机构业务的复杂性使得金融机构及其短期债权人资金的信息不对称更加明显，从而使得金融机构更容易被这些短期债权人挤兑。无论是货币主义的观点抑或金融稳定的观点都会承认，由于金融系统的脆弱性和挤兑的风险，最后贷款人制度是不可或缺的。\n对于金融稳定主义学派的支持者来说，银行倒闭引发了两个重要风险。第一个风险是，银行的倒闭可能会破坏其对债权人的偿付能力，破坏其他金融机构的稳定性或支付系统的平稳高效运行；第二个风险是，一家或多家银行的倒闭可能会阻碍为实体经济提供信贷和其他金融服务。金融稳定主义者认为，央行的最后贷款人机制应当通过贴现窗口进行，是在对被贴现机构审慎监管的基础上进行的。贴现窗口贷款的有效性取决于央行是否获取有关潜在被贴现者信誉的详细信息，以及已发布的抵押品的质量。从金融稳定主义的视角看，中央银行的最后贷款人制度不仅应当覆盖传统的存款类金融机构，也应当广义包括那些因为机构的倒闭可能引起金融系统不稳定的影子银行体系。当然，把最后贷款人机制用于吸收公众存款以外的金融机构可能会面临识别的问题：即如何精确识别哪些金融机构的倒闭会引发系统性金融风险，从而避免最后贷款人援助制度的滥用引发的道德风险。",
    "reference_list": "考点1：“信誉良好”推荐译为“Creditworthy，Reputable”考点2：“影子银行体系”应译为“the shadow banking system”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "153"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nA. Use a tailored definition of pedagogy in pedagogical research and reform.\nDespite widespread use of the term “pedagogy,” there is no consensus on what the term means in practice. Some see pedagogy as a purely technical activity and describe it as “the science of teaching.” Others focus on how sociocultural elements such as culture, local education ecosystems, and learning theories influence pedagogical choices. And others propose some combination of these definitions (Alexander, 2009; Bremner, 2021). “Pedagogy” is ambiguous partly because the purposes of education vary and because ways of teaching and learning are contested topics (Burde, 2014; Qargha, 2022). This section explores how various individuals and entities define “pedagogy” and highlights the importance of considering Invisible Pedagogical Mindsets when defining “pedagogy” in local contexts.\n1. Understand that there is no single definition for “pedagogy.”\n“Pedagogy” is a complex term, and its meaning varies based on political, historical, or social factors in local contexts. Although many cultures value good teaching practice, the modern use of the term “pedagogy” to describe teaching and learning is predominantly a Western phenomenon. Dating back to the 16th century, the term has been adopted by non-Western localities or transferred from the outside by international actors (Loughran, 1999; Rizvi, 2009; Schweisfurth, 2013; Steiner-Khamsi & Waldow, 2012). The term “pedagogy” is more common in French-, German-, Russian-, and Spanish-speaking communities than in English-speaking ones (Hamilton, 2009). “Pedagogy” has been used to describe various concepts, including the place, practice, system, science, art, and principles of education and teaching. For instance,\nthe Oxford English Dictionary defines “pedagogy” as a place of instruction (such as a school, college, or university), a system of introductory training, and a means of guidance.\nLinguistic Definitions of “Pedagogy”\n “the science of teaching” (Oxford Shorter English Dictionary, 1993)\n “the art, science, or profession of teaching” (Merriam Webster Dictionary)\n “the function or work of a teacher” (dictionary.com)\n “the study of teaching methods” (Oxford Learners Dictionary, 2023)\nIn academic literature, the term “pedagogy” encompasses the visible aspects of teaching and learning, like teaching methods, interactions between teachers and students, the learning environment, and the curriculum, as well as the invisible theories, values, knowledge, attitudes, experiences, and research that influence classroom practice (Alexander, 2009; Moyles et al., 2002; Shah & Campus, 2020; Siraj-Blatchford et al., 2002). Academics also use the term “pedagogy” to describe interactions in diverse fields, such as health, fitness, gender, literature, management, cultural studies, and media studies (Loughran, 1999; Marton & Booth, 1997).\nMinistries of education and international development organizations also have varied definitions of “pedagogy.” For instance, the Victoria State Department of Education and Training in Australia focuses on instructional methods and sees “pedagogy” as the methods or principles of teaching (Department of Education and Training, 2018). A USAID report defines “pedagogy” as strategies and techniques supporting development and learning (Bub, 2022). Without explicitly defining “pedagogy,” the World Bank emphasizes the importance of pedagogy for teachers’ professional development and advocates for specific interventions, such as structured pedagogy (Global Education Evidence Advisory Panel, 2023). An OECD working paper defines “pedagogy” as repeated patterns or sets of teaching and learning practices that shape interactions between teachers and learners (Peterson et al., 2018). The term “innovative pedagogies” emerged in the last two decades to refer to pedagogical approaches that aim to significantly improve learning outcomes by creating transformative shifts in teaching and learning, described as leapfrogging (Istance & Paniagua, 2019). According to recent literature, two main characteristics make a pedagogy innovative: a) intentionally planned practices to enhance student learning, and b) a departure from common pedagogical approaches in a specific context (Averill & Major, 2020; Kukulska-Hulme et al., 2020). Therefore, any intentional changes to classroom practice that aim to improve student learning in a local context can be considered an “innovative pedagogy.” However, no single practice is universally “innovative.” An “innovative” practice in one local context might be common practice in another. In Working Paper II, we discuss student-centered pedagogies as a leading example of innovative pedagogies in practice. We recommend a working definition for pedagogy as a starting point for discussion in local contexts to overcome the lack of consensus on a universal definition for the term.\n2. Consider local culture, education ecosystems, and learning theories when defining pedagogy.\nIn attempting to define pedagogy, we draw from work by education scholar Robin Alexander, who emphasized the impact of culture and local context on pedagogical choices. Alexander (2009) defines “pedagogy” as “the act of teaching together with its attendant discourse of educational theories, values, evidence and justifications” (p. 928). In other words, pedagogy is not only the teaching methods but also the theories, values, and experiences that influence a teacher’s worldview, as well as the evidence and justification that impact a teacher’s choices.\nWe encourage policymakers and researchers to build on our working definition to develop a definition most appropriate for their local context and aligned with their education reform agendas. In Working Paper III, we outline a collaborative research strategy that can help researchers and education actors – which can include policymakers, academics, teachers, students, donors, civil society organizations and other actors in the local education ecosystem - jointly define and explore pedagogies in their local context. Our working definition of pedagogy aims to capture the multiple elements that make up pedagogy. In the following section, we refer to these elements as Invisible Pedagogical Mindsets.\nB. Adapt pedagogical approaches to account for Invisible Pedagogical Mindsets.\nThe act of teaching is the visible part of pedagogy—the tip of the iceberg. But beneath the surface, elements such as culture, local education ecosystems, and learning theories inform teachers’ choices and shape the teaching and learning experience. We use these three categories to encompass what we define as Invisible Pedagogical Mindsets: the multifaceted, interconnected, and unobservable elements that impact pedagogical approaches in the classroom. UNESCO defines culture as “the set of distinctive spiritual, material, intellectual and emotional features of society or a social group that encompasses, not only art and literature, but lifestyles, ways of living together, values systems, traditions and beliefs” (UNESCO, 2001). Because knowledge is situated within a social context, an individual’s learning is shaped by social processes and values within this cultural context (Kim & Davidson, 2019). Jones (1989) also underlines the importance of culture in the classroom, stating that “we cannot discuss what happens in the classroom and its significance for social change without at least an understanding of the structured, collective cultural interpretations of the pupils” (p. 22).\n",
    "ori_text": "A. Use a tailored definition of pedagogy in pedagogical research and reform.\nDespite widespread use of the term “pedagogy,” there is no consensus on what the term means in practice. Some see pedagogy as a purely technical activity and describe it as “the science of teaching.” Others focus on how sociocultural elements such as culture, local education ecosystems, and learning theories influence pedagogical choices. And others propose some combination of these definitions (Alexander, 2009; Bremner, 2021). “Pedagogy” is ambiguous partly because the purposes of education vary and because ways of teaching and learning are contested topics (Burde, 2014; Qargha, 2022). This section explores how various individuals and entities define “pedagogy” and highlights the importance of considering Invisible Pedagogical Mindsets when defining “pedagogy” in local contexts.\n1. Understand that there is no single definition for “pedagogy.”\n“Pedagogy” is a complex term, and its meaning varies based on political, historical, or social factors in local contexts. Although many cultures value good teaching practice, the modern use of the term “pedagogy” to describe teaching and learning is predominantly a Western phenomenon. Dating back to the 16th century, the term has been adopted by non-Western localities or transferred from the outside by international actors (Loughran, 1999; Rizvi, 2009; Schweisfurth, 2013; Steiner-Khamsi & Waldow, 2012). The term “pedagogy” is more common in French-, German-, Russian-, and Spanish-speaking communities than in English-speaking ones (Hamilton, 2009). “Pedagogy” has been used to describe various concepts, including the place, practice, system, science, art, and principles of education and teaching. For instance,\nthe Oxford English Dictionary defines “pedagogy” as a place of instruction (such as a school, college, or university), a system of introductory training, and a means of guidance.\nLinguistic Definitions of “Pedagogy”\n “the science of teaching” (Oxford Shorter English Dictionary, 1993)\n “the art, science, or profession of teaching” (Merriam Webster Dictionary)\n “the function or work of a teacher” (dictionary.com)\n “the study of teaching methods” (Oxford Learners Dictionary, 2023)\nIn academic literature, the term “pedagogy” encompasses the visible aspects of teaching and learning, like teaching methods, interactions between teachers and students, the learning environment, and the curriculum, as well as the invisible theories, values, knowledge, attitudes, experiences, and research that influence classroom practice (Alexander, 2009; Moyles et al., 2002; Shah & Campus, 2020; Siraj-Blatchford et al., 2002). Academics also use the term “pedagogy” to describe interactions in diverse fields, such as health, fitness, gender, literature, management, cultural studies, and media studies (Loughran, 1999; Marton & Booth, 1997).\nMinistries of education and international development organizations also have varied definitions of “pedagogy.” For instance, the Victoria State Department of Education and Training in Australia focuses on instructional methods and sees “pedagogy” as the methods or principles of teaching (Department of Education and Training, 2018). A USAID report defines “pedagogy” as strategies and techniques supporting development and learning (Bub, 2022). Without explicitly defining “pedagogy,” the World Bank emphasizes the importance of pedagogy for teachers’ professional development and advocates for specific interventions, such as structured pedagogy (Global Education Evidence Advisory Panel, 2023). An OECD working paper defines “pedagogy” as repeated patterns or sets of teaching and learning practices that shape interactions between teachers and learners (Peterson et al., 2018). The term “innovative pedagogies” emerged in the last two decades to refer to pedagogical approaches that aim to significantly improve learning outcomes by creating transformative shifts in teaching and learning, described as leapfrogging (Istance & Paniagua, 2019). According to recent literature, two main characteristics make a pedagogy innovative: a) intentionally planned practices to enhance student learning, and b) a departure from common pedagogical approaches in a specific context (Averill & Major, 2020; Kukulska-Hulme et al., 2020). Therefore, any intentional changes to classroom practice that aim to improve student learning in a local context can be considered an “innovative pedagogy.” However, no single practice is universally “innovative.” An “innovative” practice in one local context might be common practice in another. In Working Paper II, we discuss student-centered pedagogies as a leading example of innovative pedagogies in practice. We recommend a working definition for pedagogy as a starting point for discussion in local contexts to overcome the lack of consensus on a universal definition for the term.\n2. Consider local culture, education ecosystems, and learning theories when defining pedagogy.\nIn attempting to define pedagogy, we draw from work by education scholar Robin Alexander, who emphasized the impact of culture and local context on pedagogical choices. Alexander (2009) defines “pedagogy” as “the act of teaching together with its attendant discourse of educational theories, values, evidence and justifications” (p. 928). In other words, pedagogy is not only the teaching methods but also the theories, values, and experiences that influence a teacher’s worldview, as well as the evidence and justification that impact a teacher’s choices.\nWe encourage policymakers and researchers to build on our working definition to develop a definition most appropriate for their local context and aligned with their education reform agendas. In Working Paper III, we outline a collaborative research strategy that can help researchers and education actors – which can include policymakers, academics, teachers, students, donors, civil society organizations and other actors in the local education ecosystem - jointly define and explore pedagogies in their local context. Our working definition of pedagogy aims to capture the multiple elements that make up pedagogy. In the following section, we refer to these elements as Invisible Pedagogical Mindsets.\nB. Adapt pedagogical approaches to account for Invisible Pedagogical Mindsets.\nThe act of teaching is the visible part of pedagogy—the tip of the iceberg. But beneath the surface, elements such as culture, local education ecosystems, and learning theories inform teachers’ choices and shape the teaching and learning experience. We use these three categories to encompass what we define as Invisible Pedagogical Mindsets: the multifaceted, interconnected, and unobservable elements that impact pedagogical approaches in the classroom. UNESCO defines culture as “the set of distinctive spiritual, material, intellectual and emotional features of society or a social group that encompasses, not only art and literature, but lifestyles, ways of living together, values systems, traditions and beliefs” (UNESCO, 2001). Because knowledge is situated within a social context, an individual’s learning is shaped by social processes and values within this cultural context (Kim & Davidson, 2019). Jones (1989) also underlines the importance of culture in the classroom, stating that “we cannot discuss what happens in the classroom and its significance for social change without at least an understanding of the structured, collective cultural interpretations of the pupils” (p. 22).\n",
    "reference_list": "考点1：“contested topics”推荐译为“备受争议的话题”\n考点2：“tailored definition”推荐译为“因地制宜的定义”\n考点3：“leapfrogging”应译为“跨越式发展”\n考点4：“a departure from common pedagogical approaches”中的“departure”不是指“离开”，因此完整译文应为“对常规教学方法的突破”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "45"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n牛腩500g（选带筋雪花纹更软糯）、土豆2个（黄心土豆更沙糯）、番茄3个\n2. 辅料‌：姜片5片、葱段2根、蒜瓣3粒、八角1颗、香叶2片（可选）、洋葱1/4个（提香）\n3. 调料‌：料酒2勺、生抽2勺、老抽½勺、冰糖5粒、盐1小勺、‌番茄酱2勺‌（提味关键）\n\n👨‍🍳 四步家常做法\n\n🔪 ‌一、预处理（10分钟）‌\n1. 牛腩处理‌\n切3cm块，冷水浸泡30分钟去血水（中途换水）；\n冷水下锅‌ + 姜2片 + 料酒1勺，煮沸撇净浮沫 → 捞出用‌温水冲洗‌（锁住水分防变柴）。\n2. 蔬果处理‌\n- 番茄去皮：划十字烫开水，‌2个切丁‌（熬酱）、‌1个切块‌（最后加）；\n- 土豆切滚刀块，泡盐水防氧化。\n\n🔥 ‌二、炒制炖煮（核心60分钟）‌\n1. 炒香底料‌\n- 热油爆香姜片、蒜粒、洋葱丝、八角；\n- 加‌番茄丁‌ + ‌番茄酱2勺‌，小火炒至软烂出红油。\n2. 炖牛腩‌\n- 倒入牛腩翻炒，加‌料酒1勺+生抽2勺+老抽½勺+冰糖‌炒匀；\n- 加热水没过食材2cm → 大火煮沸转‌小火盖盖炖1小时‌（高压锅20分钟）。\n\n🥔 ‌三、加土豆收尾（20分钟）‌\n1. 加入土豆块 + 剩余番茄块 + ‌盐1小勺‌；\n2. 继续炖‌15分钟‌至土豆软糯（筷子轻松插入）；\n3. 开盖‌大火收汁‌至浓稠，撒葱花出锅。\n\n💡 家常秘诀\n- 肉嫩不柴‌：焯水后温水冲洗，炖煮全程小火；\n- 浓汤关键‌：番茄丁+番茄酱双组合，汤汁更红亮酸甜；\n- 土豆不碎‌：最后15分钟加入，避免过早炖化；\n- 省时技巧‌：用高压锅先压牛腩，再转移炒锅收汁。\n\n失败补救：若汤汁过酸，加冰糖调和；若过淡，补少量盐或生抽。\n\nTips: 土豆去皮切块和牛腩切块小技巧\n\n🥔土豆去皮切块\n1. 去皮：土豆划浅口 → 沸水煮3分钟 → 冰水急冷 → 从切口撕下整张皮，能保留果肉厚度均匀\n2. 适宜滚刀块：土豆斜切45° → 旋转60°再切 → 重复形成不规则多面体\n\n🥩牛腩切块\n1. 切块部位\n筋多部位（如坑腩）：切4cm块，预留筋膜收缩空间；\n瘦肉为主：3cm避免干柴。\n‌2. 切割手法‌\n‌逆纹切‌：垂直肌肉纤维下刀，缩短纤维长度更易软烂；\n‌保肥瘦粘连‌：带筋膜的块状保留脂肪层，炖化后增香润口。\n3. 尺寸\n2-3cm小块适合时间紧张的速炖：熟透快（高压锅15分钟），但易炖散失形状，肉质纤维易分离，汤汁易浑浊；\n3-4cm标准块是番茄炖牛腩的黄金尺寸：受热均匀，中心易熟透，也能保留适度嚼劲，炖煮后形状完整，可充分吸收汤汁。\n\n✅ ‌成品特点‌：牛肉酥烂裹汁，土豆绵密入味，汤汁浓郁拌饭绝佳！家常操作简单，营养丰富，适合全家享用🍅🥔🍖。",
    "ori_text": "牛腩500g（选带筋雪花纹更软糯）、土豆2个（黄心土豆更沙糯）、番茄3个\n2. 辅料‌：姜片5片、葱段2根、蒜瓣3粒、八角1颗、香叶2片（可选）、洋葱1/4个（提香）\n3. 调料‌：料酒2勺、生抽2勺、老抽½勺、冰糖5粒、盐1小勺、‌番茄酱2勺‌（提味关键）\n\n👨‍🍳 四步家常做法\n\n🔪 ‌一、预处理（10分钟）‌\n1. 牛腩处理‌\n切3cm块，冷水浸泡30分钟去血水（中途换水）；\n冷水下锅‌ + 姜2片 + 料酒1勺，煮沸撇净浮沫 → 捞出用‌温水冲洗‌（锁住水分防变柴）。\n2. 蔬果处理‌\n- 番茄去皮：划十字烫开水，‌2个切丁‌（熬酱）、‌1个切块‌（最后加）；\n- 土豆切滚刀块，泡盐水防氧化。\n\n🔥 ‌二、炒制炖煮（核心60分钟）‌\n1. 炒香底料‌\n- 热油爆香姜片、蒜粒、洋葱丝、八角；\n- 加‌番茄丁‌ + ‌番茄酱2勺‌，小火炒至软烂出红油。\n2. 炖牛腩‌\n- 倒入牛腩翻炒，加‌料酒1勺+生抽2勺+老抽½勺+冰糖‌炒匀；\n- 加热水没过食材2cm → 大火煮沸转‌小火盖盖炖1小时‌（高压锅20分钟）。\n\n🥔 ‌三、加土豆收尾（20分钟）‌\n1. 加入土豆块 + 剩余番茄块 + ‌盐1小勺‌；\n2. 继续炖‌15分钟‌至土豆软糯（筷子轻松插入）；\n3. 开盖‌大火收汁‌至浓稠，撒葱花出锅。\n\n💡 家常秘诀\n- 肉嫩不柴‌：焯水后温水冲洗，炖煮全程小火；\n- 浓汤关键‌：番茄丁+番茄酱双组合，汤汁更红亮酸甜；\n- 土豆不碎‌：最后15分钟加入，避免过早炖化；\n- 省时技巧‌：用高压锅先压牛腩，再转移炒锅收汁。\n\n失败补救：若汤汁过酸，加冰糖调和；若过淡，补少量盐或生抽。\n\nTips: 土豆去皮切块和牛腩切块小技巧\n\n🥔土豆去皮切块\n1. 去皮：土豆划浅口 → 沸水煮3分钟 → 冰水急冷 → 从切口撕下整张皮，能保留果肉厚度均匀\n2. 适宜滚刀块：土豆斜切45° → 旋转60°再切 → 重复形成不规则多面体\n\n🥩牛腩切块\n1. 切块部位\n筋多部位（如坑腩）：切4cm块，预留筋膜收缩空间；\n瘦肉为主：3cm避免干柴。\n‌2. 切割手法‌\n‌逆纹切‌：垂直肌肉纤维下刀，缩短纤维长度更易软烂；\n‌保肥瘦粘连‌：带筋膜的块状保留脂肪层，炖化后增香润口。\n3. 尺寸\n2-3cm小块适合时间紧张的速炖：熟透快（高压锅15分钟），但易炖散失形状，肉质纤维易分离，汤汁易浑浊；\n3-4cm标准块是番茄炖牛腩的黄金尺寸：受热均匀，中心易熟透，也能保留适度嚼劲，炖煮后形状完整，可充分吸收汤汁。\n\n✅ ‌成品特点‌：牛肉酥烂裹汁，土豆绵密入味，汤汁浓郁拌饭绝佳！家常操作简单，营养丰富，适合全家享用🍅🥔🍖。",
    "reference_list": "考点1: 牛腩应译为“beef brisket”\n考点2: 雪花纹推荐译为“well-marbled”\n考点3: 黄心土豆应译为“yellow-fleshed potato”，不能译成“yellow-hearted potato”\n考点4: 血水推荐译为“bloody impurities”\n考点5: 撇净有英文对应的固定搭配，应译为“skim off”\n考点6: “滚刀块”英文没有直接对应的单词，建议译成“cube”就可以，如果译为rolling cube会有歧义\n考点7: 炒香推荐译为“sauté”，有炒入味的含义，如果用stir-fry不足以传达原文的“炒香”\n考点8: 收汁应译为“reduce the sauce”，是英文对应的固定搭配\n考点9: 坑腩应译为“boneless short rib”\n考点10: 逆纹切应译为“cut against the grain”，是英文中对应的说法\n考点11：“核心60分钟”推荐译为“60 minutes total”，不建议翻译成“core 60 minutes”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "30"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nAbstract\nFood-based environmental enrichment (EE) is a valuable strategy for stimulating foraging behaviour in fish under human care, as it increases the challenge of food acquisition and encourages prolonged engagement in this activity. Curimbas (Prochilodus argenteus) and pacus (Myleus micans) are fish species for which ex situ maintenance has become an important conservation measure. In this context, providing EE is essential to ensure high welfare standards. This study aimed to assess the effects of food enrichment on the behaviour of these two endemic species from the São Francisco River basin in Brazil. Behavioural data were collected across three experimental phases, including baseline, enrichment, and post-enrichment. Slow-dissolving food items known as “acorns” were introduced during the enrichment phase. Both species exhibited a marked reduction in inactivity throughout the study. For curimbas, the enrichment phase was associated with increased foraging, elevated agonistic interactions, and greater use of specific tank areas. Among pacus, inactivity significantly declined during the enrichment period. Additionally, the presence of visitors influenced behavioural patterns, promoting foraging activity while reducing inactivity and interactions with the enrichment device. These findings reinforce the value of incorporating environmental enrichment to promote the welfare of freshwater fish in public aquariums.\n1. Introduction\nEnvironmental enrichment (EE) is a tool used to improve the welfare of animals under human care [1]. Animal welfare is generally determined by the quality of the animal’s experiences concerning five domains, namely nutrition, health, the environment, behavioural interactions, and mental state [2,3]. In other words, more positive experiences increase the animal’s well-being, and more negative experiences decrease it. Animals that live in stimulating environments and have positive experiences generally display a greater diversity of behaviours, which can be measured and used as an indicator of well-being [4]. In the case of fish, the application of EE consists of offering items to stimulate individuals, allowing them to express their motor skills, exploratory behaviours, feeding, and other behaviours that are close to natural, which tends to reduce abnormal and unwanted behaviours [5,6,7].\nForaging is a behaviour that is naturally highly exhibited in the wild, as obtaining food in this environment is often a challenge [8,9]. In zoos and aquariums, there is often a routine in the animals’ diets, with food being offered at exact times in pieces or on trays, and this does not provide a challenge to get the food, making the feeding time very quick [10,11]. Therefore, food enrichment is a documented way of stimulating foraging behaviour, making it more difficult for the animal to access the food, so it must dedicate itself to this activity for longer [12,13]. In turn, the greater display of this natural behaviour improves animal welfare [11,14,15,16].\nThe welfare of animals kept in zoos and aquariums can also be affected by the presence of visitors [17]. Since 2012, there has been an increase in research into the zoo visitor effect; however, only 4% of existing studies have been conducted with fish [18]. Fish displaying less social behaviour and becoming more active or showing neutral or inconclusive responses in the presence of visitors are results observed in the few studies on this subject [18,19].\nFish with low welfare levels kept under human care can develop health problems and behavioural changes due to the stress caused by artificial environments [20,21], such as apathy (remaining motionless at the bottom of the tank or spending a long time on the surface of the water), uncoordinated swimming, or increased aggression [22,23]. Some studies have shown a significant lack of research into the effects of EE on fish welfare [24,25,26,27,28], but some positive effects of EE on fish welfare have already been reported, such as increased brain development [29,30,31], a reduction in stress levels, analysed based on the amount of cortisol in the blood of the fish studied [32,33,34], improved foraging ability [12,35,36], aggression [34,37], and positive effects on body growth [38,39].\nAlthough environmental enrichment has been increasingly studied in aquaculture and laboratory environments, a notable gap remains in research concerning aquarium-housed fish in zoological institutions, particularly in Brazil. A recent review emphasised that only a small fraction of enrichment studies focus on aquatic species kept in public aquaria [40]. Similarly, other researchers have proposed structured enrichment protocols for diverse aquarium-housed species but have highlighted the lack of empirical data for teleosts [41]. In Brazil, while aquariums play a growing role in conservation and education [42], systematic evaluations of the impacts of enrichment on native freshwater fish in public aquarium contexts are virtually absent. Furthermore, there are no published studies investigating the effects of environmental enrichment on curimbas Prochilodus argenteus or pacus Myleus micans under managed care. This scarcity underscores the novelty and relevance of the present study, which seeks to address this knowledge gap by assessing enrichment effects on behaviour and welfare in these two species within a Brazilian zoological setting.\nInstitutions that keep animals must always ensure that the animals under their care exhibit high levels of welfare and are in good physical and mental health so that they can fulfil their role effectively [43]. Aquariums play a vital role in the conservation of fish, particularly endangered species, given the global environmental degradation scenario. Through environmental education, these institutions raise awareness among the population, sensitising and educating them about the importance of these animals to the ecological balance [44,45].\nConsidering the importance of EE in ensuring the well-being of fish under human care, this study aimed to examine the impacts of EE on the behaviour of two species of fish endemic to the São Francisco River basin in a public aquarium in Brazil (curimbas Prochilodus argenteus and pacus Myleus micans). The central hypothesis is that the EE will influence the behavioural displays of the fishes studied, resulting in a decrease in inactivity and abnormal behaviours and an increase in activity and foraging behaviours during the use of the EE. In addition, more visitors in front of the pond will result in less interaction with the enrichment and an increase in the display of inactivity, aggressive behaviour, and non-visibility by the fish.\n2. Materials and Methods\n2.1. Ethical Note\nThe Belo Horizonte Zoo’s Research and Ethics Committee approved the study (protocol no. FU011/2023).\n2.2. Study Place, Fish Species, and Maintenance\nThe study was conducted at the São Francisco River Basin Aquarium in the Belo Horizonte Zoo, Minas Gerais, Brazil (19°51′37.49″ S, 44°0′18.25″ W) (Figure 1). The São Francisco River Basin Aquarium was inaugurated in March 2010 and has 22 enclosures (tanks) that, in their various sizes and shapes, hold more than 1 million litres of water and more than 50 species of fish, most of which are native to the São Francisco basin, including endemic and endangered species [46].\nThe aquarium houses two popular species from the São Francisco River Basin in a community tank. The curimba Prochilodus argenteus Spix & Agassiz, 1829 (Characiformes), belongs to the Prochilodontidae family and has an iliophagous feeding habit, consuming detritus, filamentous algae, and benthic fauna . Due to its habit, the curimba plays an important role in the ecosystem, promoting greater utilisation of available nutrients by purifying waterways and cycling nutrients . The pacu Myleus micans (Lütken, 1875) (Characiformes), which belongs to the Serrasalmidae family and has a laterally compressed body with a high lateral profile, minor scales, and a long dorsal fin, is also kept with this species . Its eating habits are omnivorous, but its diet is predominantly herbivorous, consuming mainly aquatic macrophytes and filamentous algae .\nWe studied five pacu individuals, all adults and weighing an average of 3.2 kg, kept in the aquarium since June 2011 and originating from the Três Marias reservoir (Minas Gerais State), as well as six adult curimba individuals weighing an average of 0.6 kg, kept in the aquarium since May 2014 and originating from the São Francisco and Parnaíba Valley Development Company (Codevasf, Montes Claros, Minas Gerais, Brazil). During the study, the individuals were kept in Tank 1, which contained 32.89 m3 of water (4.4 m × 4.5 m × 2 m × 5 m × 2.3 m deep). The fish were fed daily at 4 pm with 150 g of feed produced by the zoo’s nutrition team. They were always maintained in suitable conditions for the species (mean ± SD: pH, 7.35 ± 0.14; temperature, 25.12 ± 1.02 °C; dissolved oxygen, 13.2 mg/L) .\n ",
    "ori_text": "Abstract\nFood-based environmental enrichment (EE) is a valuable strategy for stimulating foraging behaviour in fish under human care, as it increases the challenge of food acquisition and encourages prolonged engagement in this activity. Curimbas (Prochilodus argenteus) and pacus (Myleus micans) are fish species for which ex situ maintenance has become an important conservation measure. In this context, providing EE is essential to ensure high welfare standards. This study aimed to assess the effects of food enrichment on the behaviour of these two endemic species from the São Francisco River basin in Brazil. Behavioural data were collected across three experimental phases, including baseline, enrichment, and post-enrichment. Slow-dissolving food items known as “acorns” were introduced during the enrichment phase. Both species exhibited a marked reduction in inactivity throughout the study. For curimbas, the enrichment phase was associated with increased foraging, elevated agonistic interactions, and greater use of specific tank areas. Among pacus, inactivity significantly declined during the enrichment period. Additionally, the presence of visitors influenced behavioural patterns, promoting foraging activity while reducing inactivity and interactions with the enrichment device. These findings reinforce the value of incorporating environmental enrichment to promote the welfare of freshwater fish in public aquariums.\n1. Introduction\nEnvironmental enrichment (EE) is a tool used to improve the welfare of animals under human care [1]. Animal welfare is generally determined by the quality of the animal’s experiences concerning five domains, namely nutrition, health, the environment, behavioural interactions, and mental state [2,3]. In other words, more positive experiences increase the animal’s well-being, and more negative experiences decrease it. Animals that live in stimulating environments and have positive experiences generally display a greater diversity of behaviours, which can be measured and used as an indicator of well-being [4]. In the case of fish, the application of EE consists of offering items to stimulate individuals, allowing them to express their motor skills, exploratory behaviours, feeding, and other behaviours that are close to natural, which tends to reduce abnormal and unwanted behaviours [5,6,7].\nForaging is a behaviour that is naturally highly exhibited in the wild, as obtaining food in this environment is often a challenge [8,9]. In zoos and aquariums, there is often a routine in the animals’ diets, with food being offered at exact times in pieces or on trays, and this does not provide a challenge to get the food, making the feeding time very quick [10,11]. Therefore, food enrichment is a documented way of stimulating foraging behaviour, making it more difficult for the animal to access the food, so it must dedicate itself to this activity for longer [12,13]. In turn, the greater display of this natural behaviour improves animal welfare [11,14,15,16].\nThe welfare of animals kept in zoos and aquariums can also be affected by the presence of visitors [17]. Since 2012, there has been an increase in research into the zoo visitor effect; however, only 4% of existing studies have been conducted with fish [18]. Fish displaying less social behaviour and becoming more active or showing neutral or inconclusive responses in the presence of visitors are results observed in the few studies on this subject [18,19].\nFish with low welfare levels kept under human care can develop health problems and behavioural changes due to the stress caused by artificial environments [20,21], such as apathy (remaining motionless at the bottom of the tank or spending a long time on the surface of the water), uncoordinated swimming, or increased aggression [22,23]. Some studies have shown a significant lack of research into the effects of EE on fish welfare [24,25,26,27,28], but some positive effects of EE on fish welfare have already been reported, such as increased brain development [29,30,31], a reduction in stress levels, analysed based on the amount of cortisol in the blood of the fish studied [32,33,34], improved foraging ability [12,35,36], aggression [34,37], and positive effects on body growth [38,39].\nAlthough environmental enrichment has been increasingly studied in aquaculture and laboratory environments, a notable gap remains in research concerning aquarium-housed fish in zoological institutions, particularly in Brazil. A recent review emphasised that only a small fraction of enrichment studies focus on aquatic species kept in public aquaria [40]. Similarly, other researchers have proposed structured enrichment protocols for diverse aquarium-housed species but have highlighted the lack of empirical data for teleosts [41]. In Brazil, while aquariums play a growing role in conservation and education [42], systematic evaluations of the impacts of enrichment on native freshwater fish in public aquarium contexts are virtually absent. Furthermore, there are no published studies investigating the effects of environmental enrichment on curimbas Prochilodus argenteus or pacus Myleus micans under managed care. This scarcity underscores the novelty and relevance of the present study, which seeks to address this knowledge gap by assessing enrichment effects on behaviour and welfare in these two species within a Brazilian zoological setting.\nInstitutions that keep animals must always ensure that the animals under their care exhibit high levels of welfare and are in good physical and mental health so that they can fulfil their role effectively [43]. Aquariums play a vital role in the conservation of fish, particularly endangered species, given the global environmental degradation scenario. Through environmental education, these institutions raise awareness among the population, sensitising and educating them about the importance of these animals to the ecological balance [44,45].\nConsidering the importance of EE in ensuring the well-being of fish under human care, this study aimed to examine the impacts of EE on the behaviour of two species of fish endemic to the São Francisco River basin in a public aquarium in Brazil (curimbas Prochilodus argenteus and pacus Myleus micans). The central hypothesis is that the EE will influence the behavioural displays of the fishes studied, resulting in a decrease in inactivity and abnormal behaviours and an increase in activity and foraging behaviours during the use of the EE. In addition, more visitors in front of the pond will result in less interaction with the enrichment and an increase in the display of inactivity, aggressive behaviour, and non-visibility by the fish.\n2. Materials and Methods\n2.1. Ethical Note\nThe Belo Horizonte Zoo’s Research and Ethics Committee approved the study (protocol no. FU011/2023).\n2.2. Study Place, Fish Species, and Maintenance\nThe study was conducted at the São Francisco River Basin Aquarium in the Belo Horizonte Zoo, Minas Gerais, Brazil (19°51′37.49″ S, 44°0′18.25″ W) (Figure 1). The São Francisco River Basin Aquarium was inaugurated in March 2010 and has 22 enclosures (tanks) that, in their various sizes and shapes, hold more than 1 million litres of water and more than 50 species of fish, most of which are native to the São Francisco basin, including endemic and endangered species [46].\nThe aquarium houses two popular species from the São Francisco River Basin in a community tank. The curimba Prochilodus argenteus Spix & Agassiz, 1829 (Characiformes), belongs to the Prochilodontidae family and has an iliophagous feeding habit, consuming detritus, filamentous algae, and benthic fauna . Due to its habit, the curimba plays an important role in the ecosystem, promoting greater utilisation of available nutrients by purifying waterways and cycling nutrients . The pacu Myleus micans (Lütken, 1875) (Characiformes), which belongs to the Serrasalmidae family and has a laterally compressed body with a high lateral profile, minor scales, and a long dorsal fin, is also kept with this species . Its eating habits are omnivorous, but its diet is predominantly herbivorous, consuming mainly aquatic macrophytes and filamentous algae .\nWe studied five pacu individuals, all adults and weighing an average of 3.2 kg, kept in the aquarium since June 2011 and originating from the Três Marias reservoir (Minas Gerais State), as well as six adult curimba individuals weighing an average of 0.6 kg, kept in the aquarium since May 2014 and originating from the São Francisco and Parnaíba Valley Development Company (Codevasf, Montes Claros, Minas Gerais, Brazil). During the study, the individuals were kept in Tank 1, which contained 32.89 m3 of water (4.4 m × 4.5 m × 2 m × 5 m × 2.3 m deep). The fish were fed daily at 4 pm with 150 g of feed produced by the zoo’s nutrition team. They were always maintained in suitable conditions for the species (mean ± SD: pH, 7.35 ± 0.14; temperature, 25.12 ± 1.02 °C; dissolved oxygen, 13.2 mg/L) .\n ",
    "reference_list": "考点1：【environmental enrichment (EE) 】应译为 【环境丰富化】\n考点2：【food-based environmental enrichment 】应译为【食物型环境丰富化】\n考点3：【baseline, enrichment, and post-enrichment 】应译为 【基线期、丰富化期、后丰富化期】\n考点4：【agonistic interactions】 应译为 【攻击性互动/对抗性互动】\n考点5：【iliophagous feeding habit 】应译为 【食淤泥的摄食习性】\n考点6：【community tank 】应译为 【混养水缸/混养水池】\n考点7：【Parnaíba Valley Development Company (Codevasf) 】应译为 【帕尔奈巴河谷开发公司】",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "76"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 体育锻炼在延缓衰老和预防痴呆中的作用\n规律体育锻炼对维持心血管系统、肌肉骨骼系统和神经系统功能的益处已得到广泛认可。体育锻炼可使运动中骨骼肌的血流量增加高达100倍，同时也能适度增加脑部血流量；然而，在体育锻炼期间，肝脏、肾脏和睾丸等器官的血流量会减少。尽管不同器官的血流量存在差异，但所有器官都能从规律的体育锻炼中获益。体育锻炼能减轻与年龄相关的最大摄氧量下降、活性氧生成以及各器官功能衰退。此外，体育锻炼可抑制与年龄相关的细胞内稳态系统（如蛋白酶体、自噬、线粒体自噬和DNA修复系统）的退化，这些系统对多个器官的功能具有积极影响。体育锻炼还能增加大脑、心脏、肝脏和肾脏中的线粒体水平。因此，体育锻炼诱导的最大摄氧量升高有助于改善器官功能，包括增强抗氧化系统、修复系统的效能以及细胞内稳态维持活动。\n体育锻炼能增强免疫力，并调节与年龄相关的免疫衰老。免疫衰老的典型特征是免疫系统功能减弱，同时伴随先天性和适应性免疫的改变。与年龄相关的变化会影响免疫细胞的表型和功能，进而干扰免疫细胞的趋化作用、胞内杀伤作用以及对病原体的应答。免疫衰老会促使老年人患上多种与年龄相关的疾病，包括心血管疾病、阿尔茨海默病（AD）和糖尿病，同时增加自身免疫性疾病和慢性感染的发病风险。因此，体育锻炼可通过缓解免疫衰老来预防与年龄相关的疾病。体育锻炼的作用还可能有助于调节多发性硬化等疾病中的免疫系统功能。\n体育锻炼能显著改善动物和人类的大脑功能。与年龄相关的认知衰退是痴呆发病的关键危险因素，且与整体神经生理改变相关。值得注意的是，体育锻炼能延缓与年龄相关的认知衰退。在动物模型中，研究表明体育锻炼可增强记忆和情绪功能，同时伴随神经发生增加、包括脑源性神经营养因子（BDNF）在内的多种神经营养因子上调以及海马体突触可塑性改善。体育锻炼还能增加AD模型小鼠的神经发生和BDNF水平，并预防其认知功能障碍。此外，体育锻炼会促使骨骼肌、肝脏和脂肪组织等外周器官分泌多种因子，这些因子也能影响神经元功能。近期一项研究表明，骨骼肌细胞分泌的蛋白质可上调未成熟神经元标志物DCX和β-III微管蛋白的表达，这提示骨骼肌在应对体育锻炼时分泌的因子有助于体育锻炼诱导的神经发生增加。\n因此，从青年或中年时期开始进行规律的体育锻炼似乎是维持老年健康的必要生活方式改变。由于目前尚未发现能显著预防与年龄相关的认知衰退的药物，因此在神经储备仍充足的生命早期开始体育锻炼计划，对于完全避免或至少延缓认知衰退至关重要。然而，青年或中年时期需要进行多少体育锻炼才能维持老年时期的健康认知功能，这一问题尚未明确。以往的一些体育锻炼临床试验显示其对认知表现有积极影响，而另一些试验则显示影响甚微或无积极影响。尽管如此，研究认为结构化、个体化且长期坚持的体育锻炼计划有助于维持老年人的认知表现。事实上，近期一项临床试验表明，在6个月内锻炼至少52小时与有或无认知障碍的老年人认知表现改善相关。另一项研究显示，将体育活动与认知活动相结合，能改善或维持被诊断为轻度认知障碍（尤其是遗忘型）的老年人的认知和身体表现。关于多种锻炼方式对AD预防作用的临床试验表明，长期体育活动结合多成分认知干预能改善AD患者的认知功能。总体而言，这些结果提示，在轻度认知障碍或AD早期发病后，仅靠体育锻炼干预可能不够，但当与充分的认知活动结合时，仍有望改善功能。\n有望促进健康衰老的抗氧化剂和草药\n氧化应激在多种与年龄相关疾病的发生发展中具有重要影响，这些疾病包括关节炎、糖尿病、痴呆、中风、癌症、动脉粥样硬化、血管疾病、肥胖、骨质疏松症和代谢综合征。生物体内会生成活性氧，以调节细胞存活、应激反应、离子通道和炎症等细胞活动。然而，活性氧水平升高与衰老的发生和进展相关。特别是，活性氧被认为通过氧化损伤以及与线粒体的相互作用而加剧与年龄相关疾病的进展。多项研究表明，烟酰胺腺嘌呤二核苷酸磷酸氧化酶产生的瞬时或生理性活性氧可作为氧化还原信号，以恢复细胞内稳态。通常，随着衰老，重建细胞内稳态的能力会逐渐减弱。但长寿动物具有重建细胞内稳态的能力，这有助于促进健康衰老。因此，通过调控烟酰胺腺嘌呤二核苷酸磷酸氧化酶活性来实现局部和生理性氧化还原信号传导的策略，可能有助于促进健康衰老。\n由于内源性抗氧化系统效能降低，老年人更易受到氧化应激的影响。心脏和大脑的细胞更新率有限且耗氧量高，因此尤其容易受到这种现象的影响。通常情况下，血浆抗氧化剂水平与多种疾病（包括心血管疾病、糖尿病和神经系统疾病）的发生发展呈负相关。新兴研究表明，天然抗氧化剂可通过中断自由基的传播或抑制自由基的形成来控制自氧化。通过这些作用，抗氧化剂能减轻氧化应激、改善免疫功能并延长健康寿命。抗氧化剂能够清除引发过氧化的物质、阻断自氧化链式反应、淬灭自由基并防止过氧化物形成。因此，补充抗氧化剂膳食在对抗衰老方面受到了广泛关注。这种方法也与衰老的自由基理论相符，该理论认为降低体内活性氧的整体水平可延缓衰老、延长寿命并预防和治疗与衰老相关的疾病。然而，在老年人群中进行的抗氧化剂临床试验结果并不一致。目前，用于治疗衰老和AD相关认知功能障碍的最有前景的抗氧化剂包括白藜芦醇和姜黄素，它们正处于临床试验阶段。\n关于白藜芦醇，一项临床试验报道，对患有代谢综合征的中年男性进行4个月的白藜芦醇治疗，可增加肌肉周转和脂质代谢，促进长链饱和、单不饱和和多不饱和游离脂肪酸的积累，并对肠道菌群产生有益影响。另一项临床试验表明，在标准抗高血压治疗中加入白藜芦醇能有效将血压降至正常水平，且无需额外使用抗高血压药物。该研究还基于血清中肝酶谷丙转氨酶水平降低，提示摄入白藜芦醇可能具有预防肝损伤的作用。其他临床试验显示，白藜芦醇治疗可改善健康超重老年人的记忆表现，并增强海马体与内侧前额叶皮层之间的功能连接。白藜芦醇还被证实能增强2型糖尿病患者的神经血管偶联和认知表现。此外，与安慰剂治疗组相比，在轻至中度AD患者中，白藜芦醇治疗可调节血浆和脑脊液中淀粉样蛋白β-40的水平。\n在一项纳入健康老年人群的随机临床试验中对姜黄素进行了研究。该研究发现，急性给予姜黄素可改善持续注意力和工作记忆，而慢性治疗则能改善情绪并减轻疲劳。另一项近期临床试验报道，中年和老年非痴呆人群每日口服生物利用度高且安全的姜黄素，18个月后其记忆表现得到改善。此外，该研究提示每日口服姜黄素可能减少杏仁核和下丘脑的神经病理积累。因此，基于已开展的临床试验结果，白藜芦醇和姜黄素似乎都是安全、耐受性良好且有益的，副作用极少。尽管如此，仍需要开展详细、长期、大规模的临床试验，以充分了解白藜芦醇和姜黄素在改善患有轻度认知障碍或AD早期的老年人认知功能方面的效能。\n\n",
    "ori_text": "\n\n 体育锻炼在延缓衰老和预防痴呆中的作用\n规律体育锻炼对维持心血管系统、肌肉骨骼系统和神经系统功能的益处已得到广泛认可。体育锻炼可使运动中骨骼肌的血流量增加高达100倍，同时也能适度增加脑部血流量；然而，在体育锻炼期间，肝脏、肾脏和睾丸等器官的血流量会减少。尽管不同器官的血流量存在差异，但所有器官都能从规律的体育锻炼中获益。体育锻炼能减轻与年龄相关的最大摄氧量下降、活性氧生成以及各器官功能衰退。此外，体育锻炼可抑制与年龄相关的细胞内稳态系统（如蛋白酶体、自噬、线粒体自噬和DNA修复系统）的退化，这些系统对多个器官的功能具有积极影响。体育锻炼还能增加大脑、心脏、肝脏和肾脏中的线粒体水平。因此，体育锻炼诱导的最大摄氧量升高有助于改善器官功能，包括增强抗氧化系统、修复系统的效能以及细胞内稳态维持活动。\n体育锻炼能增强免疫力，并调节与年龄相关的免疫衰老。免疫衰老的典型特征是免疫系统功能减弱，同时伴随先天性和适应性免疫的改变。与年龄相关的变化会影响免疫细胞的表型和功能，进而干扰免疫细胞的趋化作用、胞内杀伤作用以及对病原体的应答。免疫衰老会促使老年人患上多种与年龄相关的疾病，包括心血管疾病、阿尔茨海默病（AD）和糖尿病，同时增加自身免疫性疾病和慢性感染的发病风险。因此，体育锻炼可通过缓解免疫衰老来预防与年龄相关的疾病。体育锻炼的作用还可能有助于调节多发性硬化等疾病中的免疫系统功能。\n体育锻炼能显著改善动物和人类的大脑功能。与年龄相关的认知衰退是痴呆发病的关键危险因素，且与整体神经生理改变相关。值得注意的是，体育锻炼能延缓与年龄相关的认知衰退。在动物模型中，研究表明体育锻炼可增强记忆和情绪功能，同时伴随神经发生增加、包括脑源性神经营养因子（BDNF）在内的多种神经营养因子上调以及海马体突触可塑性改善。体育锻炼还能增加AD模型小鼠的神经发生和BDNF水平，并预防其认知功能障碍。此外，体育锻炼会促使骨骼肌、肝脏和脂肪组织等外周器官分泌多种因子，这些因子也能影响神经元功能。近期一项研究表明，骨骼肌细胞分泌的蛋白质可上调未成熟神经元标志物DCX和β-III微管蛋白的表达，这提示骨骼肌在应对体育锻炼时分泌的因子有助于体育锻炼诱导的神经发生增加。\n因此，从青年或中年时期开始进行规律的体育锻炼似乎是维持老年健康的必要生活方式改变。由于目前尚未发现能显著预防与年龄相关的认知衰退的药物，因此在神经储备仍充足的生命早期开始体育锻炼计划，对于完全避免或至少延缓认知衰退至关重要。然而，青年或中年时期需要进行多少体育锻炼才能维持老年时期的健康认知功能，这一问题尚未明确。以往的一些体育锻炼临床试验显示其对认知表现有积极影响，而另一些试验则显示影响甚微或无积极影响。尽管如此，研究认为结构化、个体化且长期坚持的体育锻炼计划有助于维持老年人的认知表现。事实上，近期一项临床试验表明，在6个月内锻炼至少52小时与有或无认知障碍的老年人认知表现改善相关。另一项研究显示，将体育活动与认知活动相结合，能改善或维持被诊断为轻度认知障碍（尤其是遗忘型）的老年人的认知和身体表现。关于多种锻炼方式对AD预防作用的临床试验表明，长期体育活动结合多成分认知干预能改善AD患者的认知功能。总体而言，这些结果提示，在轻度认知障碍或AD早期发病后，仅靠体育锻炼干预可能不够，但当与充分的认知活动结合时，仍有望改善功能。\n有望促进健康衰老的抗氧化剂和草药\n氧化应激在多种与年龄相关疾病的发生发展中具有重要影响，这些疾病包括关节炎、糖尿病、痴呆、中风、癌症、动脉粥样硬化、血管疾病、肥胖、骨质疏松症和代谢综合征。生物体内会生成活性氧，以调节细胞存活、应激反应、离子通道和炎症等细胞活动。然而，活性氧水平升高与衰老的发生和进展相关。特别是，活性氧被认为通过氧化损伤以及与线粒体的相互作用而加剧与年龄相关疾病的进展。多项研究表明，烟酰胺腺嘌呤二核苷酸磷酸氧化酶产生的瞬时或生理性活性氧可作为氧化还原信号，以恢复细胞内稳态。通常，随着衰老，重建细胞内稳态的能力会逐渐减弱。但长寿动物具有重建细胞内稳态的能力，这有助于促进健康衰老。因此，通过调控烟酰胺腺嘌呤二核苷酸磷酸氧化酶活性来实现局部和生理性氧化还原信号传导的策略，可能有助于促进健康衰老。\n由于内源性抗氧化系统效能降低，老年人更易受到氧化应激的影响。心脏和大脑的细胞更新率有限且耗氧量高，因此尤其容易受到这种现象的影响。通常情况下，血浆抗氧化剂水平与多种疾病（包括心血管疾病、糖尿病和神经系统疾病）的发生发展呈负相关。新兴研究表明，天然抗氧化剂可通过中断自由基的传播或抑制自由基的形成来控制自氧化。通过这些作用，抗氧化剂能减轻氧化应激、改善免疫功能并延长健康寿命。抗氧化剂能够清除引发过氧化的物质、阻断自氧化链式反应、淬灭自由基并防止过氧化物形成。因此，补充抗氧化剂膳食在对抗衰老方面受到了广泛关注。这种方法也与衰老的自由基理论相符，该理论认为降低体内活性氧的整体水平可延缓衰老、延长寿命并预防和治疗与衰老相关的疾病。然而，在老年人群中进行的抗氧化剂临床试验结果并不一致。目前，用于治疗衰老和AD相关认知功能障碍的最有前景的抗氧化剂包括白藜芦醇和姜黄素，它们正处于临床试验阶段。\n关于白藜芦醇，一项临床试验报道，对患有代谢综合征的中年男性进行4个月的白藜芦醇治疗，可增加肌肉周转和脂质代谢，促进长链饱和、单不饱和和多不饱和游离脂肪酸的积累，并对肠道菌群产生有益影响。另一项临床试验表明，在标准抗高血压治疗中加入白藜芦醇能有效将血压降至正常水平，且无需额外使用抗高血压药物。该研究还基于血清中肝酶谷丙转氨酶水平降低，提示摄入白藜芦醇可能具有预防肝损伤的作用。其他临床试验显示，白藜芦醇治疗可改善健康超重老年人的记忆表现，并增强海马体与内侧前额叶皮层之间的功能连接。白藜芦醇还被证实能增强2型糖尿病患者的神经血管偶联和认知表现。此外，与安慰剂治疗组相比，在轻至中度AD患者中，白藜芦醇治疗可调节血浆和脑脊液中淀粉样蛋白β-40的水平。\n在一项纳入健康老年人群的随机临床试验中对姜黄素进行了研究。该研究发现，急性给予姜黄素可改善持续注意力和工作记忆，而慢性治疗则能改善情绪并减轻疲劳。另一项近期临床试验报道，中年和老年非痴呆人群每日口服生物利用度高且安全的姜黄素，18个月后其记忆表现得到改善。此外，该研究提示每日口服姜黄素可能减少杏仁核和下丘脑的神经病理积累。因此，基于已开展的临床试验结果，白藜芦醇和姜黄素似乎都是安全、耐受性良好且有益的，副作用极少。尽管如此，仍需要开展详细、长期、大规模的临床试验，以充分了解白藜芦醇和姜黄素在改善患有轻度认知障碍或AD早期的老年人认知功能方面的效能。\n\n",
    "reference_list": "考点1：“阿尔茨海默病（AD）” 推荐译为 “Alzheimer's disease (AD)”\n考点2：“最大摄氧量” 推荐译为 “maximal oxygen uptake”\n考点3：“活性氧” 推荐译为 “reactive oxygen species (ROS)”\n考点4：“自噬” 推荐译为 “autophagy”\n考点5：“线粒体自噬” 推荐译为 “mitophagy”\n考点6：“脑源性神经营养因子（BDNF）” 推荐译为 “brain-derived neurotrophic factor (BDNF)”\n考点7： 文中 “预防其认知功能障碍” 中的 “认知功能障碍”，不可以翻译为 “cognitive impairment”，建议翻译为 “cognitive dysfunction” .\n考点8：“β-III微管蛋白” 推荐译为 “β-III tubulin”\n考点9：“免疫衰老” 推荐译为 “immunosenescence”\n考点10：“先天性免疫” 推荐译为 “innate immunity”\n考点11：“适应性免疫” 推荐译为 “adaptive immunity”\n考点12：“趋化作用” 推荐译为 “chemotaxis”\n考点13：“多发性硬化” 推荐译为 “multiple sclerosis”\n考点14：“代谢综合征” 推荐译为 “metabolic syndrome”\n考点15：“烟酰胺腺嘌呤二核苷酸磷酸氧化酶” 推荐译为 “nicotinamide adenine dinucleotide phosphate oxidases (NADPH oxidases)”\n考点16：“谷丙转氨酶” 推荐译为 “glutamate-pyruvate transaminase”\n考点17：“白藜芦醇” 推荐译为 “resveratrol”\n考点18：“姜黄素” 推荐译为 “curcumin”\n考点19：“脑脊液” 推荐译为 “cerebrospinal fluid”\n考点20. 文中“骨骼肌的血流量增加高达100倍”中“高达100倍”需要翻译为”by up to 100-fold。不可以翻译为“by up to 100 times”。\n考点21：文中 “减轻与年龄相关的最大摄氧量下降” 中的 “减轻”，不可以翻译为侧重数量上的降低的 “reduce”，建议翻译为 “attenuate”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "125"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n Spermatogenesis is a precisely regulated and highly ordered process, including mitotic proliferation of spermatogonia, meiosis of spermatocytes, and differentiation of haploid spermatids during spermiogenesis. Any errors in this process will lead to male reproductive disorders. Male infertility, accounting for 50% of infertile couples, is a serious reproductive health problem Nonobstructive azoospermia (NOA) is the most serious form, accounting for 10–15% of male infertility. \nOnly one in three cases of azoospermia can be explained by genetic defects, such as abnormalities and deletion of the azoospermia-factor (AZF) region in the Y chromosome, whereas more than 70% of the cases are idiopathic NOA (iNOA). In addition to genetic defects, infectious and inflammatory conditions in the reproductive system contribute to male infertility. Genome-wide association studies of idiopathic male infertility have revealed a series of NOA susceptibility loci, including PEX10, PRMT6, and SIRPA. Several single- gene mutations have been reported in patients with testicular- phenotype NOA, including TEX11, TEX14, TEX15, DMC1, and MEIOB. Recent studies have used transcriptome analysis to investigate the pathogenic mechanism of NOA. Bulk transcriptome analyses have revealed that PILRA and ZNF676 are related to NOA susceptibility. Two-dimensional coculture of multiple stem cell types and three-dimensional testicular organ culture have been used to simulate the environment of testicular sperm production and promote spermatogenesis, with promising results for the treatment of azoospermia. \nTreatments for azoospermia require a better understanding of the classification of azoospermia. Single-cell RNA sequencing (scRNA-seq) enables the study of highly heterogeneous cell populations in the testes at a single-cell resolution. We previously conducted scRNA-seq analysis of adult human testis samples from normal donors and iNOA patients and reconstructed the transcriptional programs inherent to sequential cell fate transition during human spermatogenesis. The results showed that the gene expression patterns of somatic cells in iNOA differed from those in normal spermatogenesis and mainly included DNA damage genes and other stress-responsive genes. A recent study revealed that maturation disorders in Sertoli cells are in- volved in iNOA, and inhibition of the Wnt signaling pathway promoted the maturation of these cells. However, the number of reported study cases is very small, and the explanation of the iNOA mechanism is limited from a somatic perspective. The gene expression characteristics of germ cells and somatic cells, cell–cell interactions between germ cells and somatic cells, as well as the regulatory networks of transcription factors (TFs) in iNOA patients remain largely unknown. \nWe performed scRNA-seq analysis of 3696 individual testicular cells from 17 iNOA donors to construct transcriptional land- scapes of human spermatogenesis in the context of NOA. In comparison with healthy subjects with normal spermatogenesis, we assessed the gene expression characteristics of germ cells and somatic cells, cell–cell interactions between germ cells and somatic cells, as well as the regulatory networks of TFs in iNOA patients. In particular, we demonstrated that CD164 played an important role in the apoptosis of spermatogonia. Moreover, we identified a series of genes predicting spermatogenic capacity in different testicular diseases. In general, our study provides new insights into the molecular pathogenesis as well as the clinical diagnosis and therapeutic strategy of iNOA. \nOur results revealed that germ cells, including SSC, from azoospermia patients had enhanced cell cycle activity and weakened energy production, which may provide clues for the selection of factors to be added to the in vitro culture medium for round sperm. As SSC can self-renew to maintain the stem cell population and further produce sperm, sperm can be produced uninterruptedly throughout adulthood. \nTo identify candidate iNOA pathogenic genes, we analyzed the key DEGs between the four classes iNOA and the NC group. Among them, HMGB4, a member of the high-mobility group box (HMGB) family, is present in spermatocytes, spermatids, and spermatozoa in human and mice. A significant decline of HMGB4 in all cell types in the three classes of iNOA was observed. Though male fertility was not affected in Hmgb4 knock- out mice, which might be due to species variation. We speculated that HMGB4 might be a key pathogenic gene of iNOA and played an important role in spermatogenesis. More studies should be carried out in the future. Cell–cell interactions between ST and developing SSC have long received research interest. We found that the CD226/NECTIN2, LGR4/RSPO3, and NOTCH1/JAG2 interaction pairs might have an effect on human spermatogenesis. Moreover, the CSF1/SIRPA and CXCL12/CXCR4 interaction pairs were downregulated in all classes of iNOA. CSF1 (colony-stimulating factor 1) exerts a crucial impact on the development of SSC. Polymorphisms in SIRPA, its interaction partner, are strongly associated with iNOA susceptibility. Additionally, CXCL12 encodes a chemokine ex- pressed and secreted by ST and binds to the CXCR4 receptor on SSC to regulate the self-renewal and maintenance of SSC. Therefore, the downregulation of these key interaction signals may provide ideas for targeted therapy of iNOA in the future. \nApart from intercellular communication, TFs are essential in spermatogenesis. We found that HES7 (Hes family bHLH TF 7), as a transcriptional repressor. was significantly upregulated in iNOA cells. Another key TF, SOX5, is necessary for correct gene expression patterns during spermatogenesis and its expression was significantly downregulated in iNOA cells. Therefore, we speculate that the increase in HES7 transcriptional activity and decrease in SOX5 transcriptional activity may disrupt the key regulatory network during spermatogenesis and cause iNOA. \nNone of the iNOA patients in our study had mature sperm, but other indicators, such as genetic factors, were normal in all patients. We classified them into four groups based on gene expression and pathological features, and identified a series of genes that were highly associated with spermatogenic capacity. At present, testicular biopsy is an invasive method to diagnose the spermatogenic ability of patients, and a safe and noninvasive diagnostic strategy is still lacking. The genes identified in this work may be integrated into a panel for the rapid and noninvasive diagnosis of male infertility in the future. \nAs demonstrated in this study, the interactions between germ cells and somatic cells were speculated only by expression data, computational software prediction, protein localization, and quantification. Additional experiments are needed to further clarify the cell–cell communications. In addition, we used cell lines for functional validation of the key pathogenic genes we screened, indicating the reliability of our bioinformatics analysis results. Further studies using in vivo animal models are still needed to better characterize the effect of these pathogenic genes on spermatogenesis. Moreover, we used different testicular diseases to find common diagnostic predictor of spermatogenic ability, providing a large amount of data resources for clinical diagnosis. However, a large number of clinical samples still need to be included to verify its accuracy. \nAlthough there have been enormous advances in iNOA testicular microenvironment, transcriptional network of autophagy- related genes, and hub genes of azoospermia to our knowledge, this was the first study to investigate the occurrence and development of idiopathic NOA from a testicular germ cell perspective, including the largest number of cases to date. The data comprehensively and systematically reveal the transcriptional regulatory network of iNOA. Our findings not only provide valuable knowledge to improve our understanding of the molecular basis and mechanism of iNOA but also provide new insights for clinical diagnosis and treatment. \nExperimental Model and Subject Details: the donors in this study underwent sperm isolation surgery for in vitro fertilization due to male-related infertility. Men with spermatogenic cells, but without mature sperm, abnormal hormone levels, chromosomal abnormalities, Y chromosome microdeletion, and no other medical history were selected. Testis tissues were collected from 17 iNOA patients between 27 and 37 years old to map single-cell transcriptome landscapes. All testis samples for transcriptome analysis were obtained from Peking University Third Hospital with informed consent from the donors. The study was approved by the Ethics Committee of Peking University Third Hospital (2017SZ-048). All experimental procedures and animal care were approved by the Animal Care and Use Committee of the Peking University Health Science Center (LA2021579). Normal Samples data included 2854 testicular cells from 9 donors, have been deposited in NCBI GEO: GSE106487. \nIsolation of iNOA Male Testicular Cells for Transcriptional Profiling: Idiopathic NOA testis tissues were washed three times with Dulbecco’s modified Eagle’s medium (DMEM, C11995500BT, Thermo Scientific) containing 10% fetal bovine serum (FBS, 10437028, Gbico) and minced using sterilized scissors. Then, 500 μL of Accutase Cell Detachment Solution (A6964, Sigma- Aldrich) was added, and the samples were incubated at 37 °C for 15 min. To completely digest the tissues into single cells, the mixture was pipetted 30 times at 7 min and at the end of digestion. The cell suspension was filtered through 40 μm Pre-Separation Filters and centrifuged at 300× g for 8 min, and the cells were resuspended in 500 μL of DMEM (containing 10% FBS). \nScRNA-seq Library Preparation and Sequencing: After digestion, the cells were diluted in 1 mg mL−1 Ac-Bovine Serum Albumin (A9418, Sigma-Aldrich) and single cells were randomly picked using a mouth pipette and added to lysis buffer prepared in advance. Mouth pipette method can make sure that there’s only one cell in each tube. A previously reported modified STRT- seq protocol was used to construct the scRNA-seq library. In brief, after total RNA was extracted from the single cells, the mRNAs were captured using an oligo (dT) primer and subjected to reverse transcription. The cDNAs were PCR-amplified in 18 cycles to increase yields. After barcoding, the cDNAs from 48 single cells were pooled, and a biotin-modified index sequence was added to the 3′ end in four cycles of PCR. Dynabeads MyOne Streptavidin C1(65 002, Invitrogen) was used to capture the fragmented 3′ cDNAs, which were sheared using Covaris (S2). The libraries were constructed using a Kapa Hyper Prep Kit (KK8505, Kapa Biosystems) and were subjected to 150 bp paired-end sequencing on the Illumina 4000 platform. \n",
    "ori_text": "\n\n Spermatogenesis is a precisely regulated and highly ordered process, including mitotic proliferation of spermatogonia, meiosis of spermatocytes, and differentiation of haploid spermatids during spermiogenesis. Any errors in this process will lead to male reproductive disorders. Male infertility, accounting for 50% of infertile couples, is a serious reproductive health problem Nonobstructive azoospermia (NOA) is the most serious form, accounting for 10–15% of male infertility. \nOnly one in three cases of azoospermia can be explained by genetic defects, such as abnormalities and deletion of the azoospermia-factor (AZF) region in the Y chromosome, whereas more than 70% of the cases are idiopathic NOA (iNOA). In addition to genetic defects, infectious and inflammatory conditions in the reproductive system contribute to male infertility. Genome-wide association studies of idiopathic male infertility have revealed a series of NOA susceptibility loci, including PEX10, PRMT6, and SIRPA. Several single- gene mutations have been reported in patients with testicular- phenotype NOA, including TEX11, TEX14, TEX15, DMC1, and MEIOB. Recent studies have used transcriptome analysis to investigate the pathogenic mechanism of NOA. Bulk transcriptome analyses have revealed that PILRA and ZNF676 are related to NOA susceptibility. Two-dimensional coculture of multiple stem cell types and three-dimensional testicular organ culture have been used to simulate the environment of testicular sperm production and promote spermatogenesis, with promising results for the treatment of azoospermia. \nTreatments for azoospermia require a better understanding of the classification of azoospermia. Single-cell RNA sequencing (scRNA-seq) enables the study of highly heterogeneous cell populations in the testes at a single-cell resolution. We previously conducted scRNA-seq analysis of adult human testis samples from normal donors and iNOA patients and reconstructed the transcriptional programs inherent to sequential cell fate transition during human spermatogenesis. The results showed that the gene expression patterns of somatic cells in iNOA differed from those in normal spermatogenesis and mainly included DNA damage genes and other stress-responsive genes. A recent study revealed that maturation disorders in Sertoli cells are in- volved in iNOA, and inhibition of the Wnt signaling pathway promoted the maturation of these cells. However, the number of reported study cases is very small, and the explanation of the iNOA mechanism is limited from a somatic perspective. The gene expression characteristics of germ cells and somatic cells, cell–cell interactions between germ cells and somatic cells, as well as the regulatory networks of transcription factors (TFs) in iNOA patients remain largely unknown. \nWe performed scRNA-seq analysis of 3696 individual testicular cells from 17 iNOA donors to construct transcriptional land- scapes of human spermatogenesis in the context of NOA. In comparison with healthy subjects with normal spermatogenesis, we assessed the gene expression characteristics of germ cells and somatic cells, cell–cell interactions between germ cells and somatic cells, as well as the regulatory networks of TFs in iNOA patients. In particular, we demonstrated that CD164 played an important role in the apoptosis of spermatogonia. Moreover, we identified a series of genes predicting spermatogenic capacity in different testicular diseases. In general, our study provides new insights into the molecular pathogenesis as well as the clinical diagnosis and therapeutic strategy of iNOA. \nOur results revealed that germ cells, including SSC, from azoospermia patients had enhanced cell cycle activity and weakened energy production, which may provide clues for the selection of factors to be added to the in vitro culture medium for round sperm. As SSC can self-renew to maintain the stem cell population and further produce sperm, sperm can be produced uninterruptedly throughout adulthood. \nTo identify candidate iNOA pathogenic genes, we analyzed the key DEGs between the four classes iNOA and the NC group. Among them, HMGB4, a member of the high-mobility group box (HMGB) family, is present in spermatocytes, spermatids, and spermatozoa in human and mice. A significant decline of HMGB4 in all cell types in the three classes of iNOA was observed. Though male fertility was not affected in Hmgb4 knock- out mice, which might be due to species variation. We speculated that HMGB4 might be a key pathogenic gene of iNOA and played an important role in spermatogenesis. More studies should be carried out in the future. Cell–cell interactions between ST and developing SSC have long received research interest. We found that the CD226/NECTIN2, LGR4/RSPO3, and NOTCH1/JAG2 interaction pairs might have an effect on human spermatogenesis. Moreover, the CSF1/SIRPA and CXCL12/CXCR4 interaction pairs were downregulated in all classes of iNOA. CSF1 (colony-stimulating factor 1) exerts a crucial impact on the development of SSC. Polymorphisms in SIRPA, its interaction partner, are strongly associated with iNOA susceptibility. Additionally, CXCL12 encodes a chemokine ex- pressed and secreted by ST and binds to the CXCR4 receptor on SSC to regulate the self-renewal and maintenance of SSC. Therefore, the downregulation of these key interaction signals may provide ideas for targeted therapy of iNOA in the future. \nApart from intercellular communication, TFs are essential in spermatogenesis. We found that HES7 (Hes family bHLH TF 7), as a transcriptional repressor. was significantly upregulated in iNOA cells. Another key TF, SOX5, is necessary for correct gene expression patterns during spermatogenesis and its expression was significantly downregulated in iNOA cells. Therefore, we speculate that the increase in HES7 transcriptional activity and decrease in SOX5 transcriptional activity may disrupt the key regulatory network during spermatogenesis and cause iNOA. \nNone of the iNOA patients in our study had mature sperm, but other indicators, such as genetic factors, were normal in all patients. We classified them into four groups based on gene expression and pathological features, and identified a series of genes that were highly associated with spermatogenic capacity. At present, testicular biopsy is an invasive method to diagnose the spermatogenic ability of patients, and a safe and noninvasive diagnostic strategy is still lacking. The genes identified in this work may be integrated into a panel for the rapid and noninvasive diagnosis of male infertility in the future. \nAs demonstrated in this study, the interactions between germ cells and somatic cells were speculated only by expression data, computational software prediction, protein localization, and quantification. Additional experiments are needed to further clarify the cell–cell communications. In addition, we used cell lines for functional validation of the key pathogenic genes we screened, indicating the reliability of our bioinformatics analysis results. Further studies using in vivo animal models are still needed to better characterize the effect of these pathogenic genes on spermatogenesis. Moreover, we used different testicular diseases to find common diagnostic predictor of spermatogenic ability, providing a large amount of data resources for clinical diagnosis. However, a large number of clinical samples still need to be included to verify its accuracy. \nAlthough there have been enormous advances in iNOA testicular microenvironment, transcriptional network of autophagy- related genes, and hub genes of azoospermia to our knowledge, this was the first study to investigate the occurrence and development of idiopathic NOA from a testicular germ cell perspective, including the largest number of cases to date. The data comprehensively and systematically reveal the transcriptional regulatory network of iNOA. Our findings not only provide valuable knowledge to improve our understanding of the molecular basis and mechanism of iNOA but also provide new insights for clinical diagnosis and treatment. \nExperimental Model and Subject Details: the donors in this study underwent sperm isolation surgery for in vitro fertilization due to male-related infertility. Men with spermatogenic cells, but without mature sperm, abnormal hormone levels, chromosomal abnormalities, Y chromosome microdeletion, and no other medical history were selected. Testis tissues were collected from 17 iNOA patients between 27 and 37 years old to map single-cell transcriptome landscapes. All testis samples for transcriptome analysis were obtained from Peking University Third Hospital with informed consent from the donors. The study was approved by the Ethics Committee of Peking University Third Hospital (2017SZ-048). All experimental procedures and animal care were approved by the Animal Care and Use Committee of the Peking University Health Science Center (LA2021579). Normal Samples data included 2854 testicular cells from 9 donors, have been deposited in NCBI GEO: GSE106487. \nIsolation of iNOA Male Testicular Cells for Transcriptional Profiling: Idiopathic NOA testis tissues were washed three times with Dulbecco’s modified Eagle’s medium (DMEM, C11995500BT, Thermo Scientific) containing 10% fetal bovine serum (FBS, 10437028, Gbico) and minced using sterilized scissors. Then, 500 μL of Accutase Cell Detachment Solution (A6964, Sigma- Aldrich) was added, and the samples were incubated at 37 °C for 15 min. To completely digest the tissues into single cells, the mixture was pipetted 30 times at 7 min and at the end of digestion. The cell suspension was filtered through 40 μm Pre-Separation Filters and centrifuged at 300× g for 8 min, and the cells were resuspended in 500 μL of DMEM (containing 10% FBS). \nScRNA-seq Library Preparation and Sequencing: After digestion, the cells were diluted in 1 mg mL−1 Ac-Bovine Serum Albumin (A9418, Sigma-Aldrich) and single cells were randomly picked using a mouth pipette and added to lysis buffer prepared in advance. Mouth pipette method can make sure that there’s only one cell in each tube. A previously reported modified STRT- seq protocol was used to construct the scRNA-seq library. In brief, after total RNA was extracted from the single cells, the mRNAs were captured using an oligo (dT) primer and subjected to reverse transcription. The cDNAs were PCR-amplified in 18 cycles to increase yields. After barcoding, the cDNAs from 48 single cells were pooled, and a biotin-modified index sequence was added to the 3′ end in four cycles of PCR. Dynabeads MyOne Streptavidin C1(65 002, Invitrogen) was used to capture the fragmented 3′ cDNAs, which were sheared using Covaris (S2). The libraries were constructed using a Kapa Hyper Prep Kit (KK8505, Kapa Biosystems) and were subjected to 150 bp paired-end sequencing on the Illumina 4000 platform. \n",
    "reference_list": "考点1：“Donors” 应译为“供体”\n考点2：“high-mobility group box (HMGB) family” 必须译为“高迁移率族蛋白”，固定译法\n考点3：“DMEM”必须译为“杜尔贝科改良鹰培养基”，固定译法\n考点4：“PCR”必须译为“聚合酶链式反应”，固定译法",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "160"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\nApart from these three primary requirements, several other factors are worthy of emphasis. First, the structure or structural system must relate to the building's function. It should not be in conflict in terms of form. For example, a linear function demands a linear structure, and therefore it would be improper to roof a bowling alley with a dome. Similarly, a theater must have large, unobstructed spans, but a fine restaurant probably should not. Stated simply, the structure must be appropriate to the function it is to shelter.\n\nSecond, the structure must be fire-resistant. It is obvious that the structural system must be able to maintain its integrity at least until the occupants are safely out. Building codes specify the number of hours for which certain parts of a building must resist the heat without collapsing. The structural materials used for those elements must be inherently fire-resistant or be adequately protected by fireproofing materials. The degree of fire resistance to be provided will depend upon a number of items, including the use and occupancy load of the space, its dimensions, and the location of the building.\n\nThird, the structure should integrate well with the building's circulation systems. It should not be in conflict with the piping systems for water and waste, the ducting systems for air, or (most important) the movement of people. It is obvious that the various building systems must be coordinated as the design progresses. One can design in a sequential step-by-step manner within any one system, but the design of all of them should move in a parallel manner toward completion. Spatially, all the various parts of a building are interdependent.\n\nFourth, the structure must be psychologically safe as well as physically safe. A high-rise frame that sways considerably in the wind might not actually be dangerous, but may make the building uninhabitable just the same. Lightweight floor systems that are too \"bouncy\" can make the users very uncomfortable. Large glass windows, uninterrupted by dividing motions, can be quite safe but will appear very insecure to the occupant standing next to them on 40 floors above the street.\n\nSometimes the architect must make deliberate attempts to increase the apparent strength or solidness of the structure. This apparent safety may be more important than honestly expressing the building's structure, because the untrained viewer cannot distinguish between real and perceived safety.\n\nThe building designer needs to understand the behavior of physical structures under load. An ability to intuit or \"feel\" structural behavior is possessed by those having much experience involving structural analysis, both qualitative and quantitative. The consequent knowledge of how forces, stresses, and deformations build up in different materials and shapes is vital to the development of this \"sense\". Structural analysis is the process of determining the forces and deformations in structures due to specified loads, allowing for rational design and ensuring that the safety of existing structures can be checked.\n\nIn the design of structures, it is necessary to start with a concept leading to a configuration that can then be analyzed. This is done to members can be sized and the needed reinforcing determined, in order to: a) carry the design loads without distress or excessive deformations (serviceability or working condition); and b) to prevent collapse before a specified overload has been placed on the structure(safety or ultimate condition).\n\nSince normally elastic conditions will prevail under working loads, a structural theory based on the assumptions of elastic behavior is appropriate for determining serviceability conditions. The collapse of a structure will usually occur only long after the elastic range of the materials has been exceeded at critical points, so that an ultimate strength theory based on the inelastic behavior of the material is necessary for a rational determination of the safety of a structure against collapse. Nevertheless, an elastic theory can be used to determine a safe approximation to the strength of ductile structures (the lower bound approach of plasticity), and this approach is customarily followed in reinforced concrete practice. For this reason, only the elastic theory structure is pursued in this chapter.\n\nLooked at critically, all structures are assemblies of three-dimensional elements, the exact analysis of which is a forbidding task even under ideal conditions and impossible to contemplate under conditions of professional practice. For this reason, an important part of the analyst's work is the simplification of the actual structure and loading conditions to a model that is susceptible to rational analysis.\n\nThus, a structural framing system is decomposed into a slab and floor beams which in turn frame into girders carried by columns which transmit the loads to the foundations. Since traditional structural analysis has been unable to cope with the action of the slab, this has often been idealized into a system of strips acting as beams. A Iso, long-hand methods have been unable to cope with three-dimensional framing systems, so that the entire structure has been modeled by a system of planner subassemblies, to be analyzed one at a time. The modern matrix-computer methods have revolutionized structural analysis by making it possible to analyze entire systems, thus leading to more reliable predictions about the behavior of structures under loads.\n\nActual loading conditions are also both difficult to determine and to express realistically, and must be simplified for purposes of analysis. Thus, traffic loads on a bridge structure, which are essentially both of dynamic and random nature, are usually idealized into statically moving standard trucks or distributed loads, intended to simulate the most severe loading conditions occurring in practice. \n\nSimilary, continuous beams are sometimes reduced to simple beams, rigid joints to pin-joints, fillers-walls are neglected, shear walls considered as beams; in deciding how to model a structure so as to make it reasonably realistic but at the same time reasonably simple, the analyst must remember that each such idealization will make the soulation more suspect. The more realistic the analysis, the greater will be the confidence which it inspires, and the smaller may be the safety factor ( or factor of ignorance). Thus, unless code provisions control, the engineer must evaluate the extra expense of a thorough analysis as compared to possible savings in the structure.\n\nThe most important use of structure analysis is as a tool in structural design. As such, it will usually be a part of a trial-and-error procedure, in which an assumed configuration with assumed dead loads is analyzed, and the members are designed in accordance with the results of the analysis. This phase is called the preliminary design, since this design is still subject to change. Usually, a crude, fast analysis method is adequate. At this stage, the cost of the structure is estimated, loads and member properties are revised, and the design is checked for possible improvements. The changes are now incorporated in the structure, a more refined analysis is performed, and the member design is revised. This project is carried out to convergence, the rapidity of which will depend on the capability of the designer. It is clear that a variety of analysis methods, ranging from \" quick and dirty to exact \", are needed for design purposes.\n\nAn efficient analyst must thus be in command of the rigorous methods of analysis, must be able to reduce these to shortcut methods by appropriate assumptions, and must be aware of available design and analysis aids, as well as simplification permitted by applicable building codes. An up-to-date analyst must likewise be versed in the basics of matrix structural analysis and its use in digital computers, as well as in the use of available analysis programs or software.",
    "ori_text": "Apart from these three primary requirements, several other factors are worthy of emphasis. First, the structure or structural system must relate to the building's function. It should not be in conflict in terms of form. For example, a linear function demands a linear structure, and therefore it would be improper to roof a bowling alley with a dome. Similarly, a theater must have large, unobstructed spans, but a fine restaurant probably should not. Stated simply, the structure must be appropriate to the function it is to shelter.\n\nSecond, the structure must be fire-resistant. It is obvious that the structural system must be able to maintain its integrity at least until the occupants are safely out. Building codes specify the number of hours for which certain parts of a building must resist the heat without collapsing. The structural materials used for those elements must be inherently fire-resistant or be adequately protected by fireproofing materials. The degree of fire resistance to be provided will depend upon a number of items, including the use and occupancy load of the space, its dimensions, and the location of the building.\n\nThird, the structure should integrate well with the building's circulation systems. It should not be in conflict with the piping systems for water and waste, the ducting systems for air, or (most important) the movement of people. It is obvious that the various building systems must be coordinated as the design progresses. One can design in a sequential step-by-step manner within any one system, but the design of all of them should move in a parallel manner toward completion. Spatially, all the various parts of a building are interdependent.\n\nFourth, the structure must be psychologically safe as well as physically safe. A high-rise frame that sways considerably in the wind might not actually be dangerous, but may make the building uninhabitable just the same. Lightweight floor systems that are too \"bouncy\" can make the users very uncomfortable. Large glass windows, uninterrupted by dividing motions, can be quite safe but will appear very insecure to the occupant standing next to them on 40 floors above the street.\n\nSometimes the architect must make deliberate attempts to increase the apparent strength or solidness of the structure. This apparent safety may be more important than honestly expressing the building's structure, because the untrained viewer cannot distinguish between real and perceived safety.\n\nThe building designer needs to understand the behavior of physical structures under load. An ability to intuit or \"feel\" structural behavior is possessed by those having much experience involving structural analysis, both qualitative and quantitative. The consequent knowledge of how forces, stresses, and deformations build up in different materials and shapes is vital to the development of this \"sense\". Structural analysis is the process of determining the forces and deformations in structures due to specified loads, allowing for rational design and ensuring that the safety of existing structures can be checked.\n\nIn the design of structures, it is necessary to start with a concept leading to a configuration that can then be analyzed. This is done to members can be sized and the needed reinforcing determined, in order to: a) carry the design loads without distress or excessive deformations (serviceability or working condition); and b) to prevent collapse before a specified overload has been placed on the structure(safety or ultimate condition).\n\nSince normally elastic conditions will prevail under working loads, a structural theory based on the assumptions of elastic behavior is appropriate for determining serviceability conditions. The collapse of a structure will usually occur only long after the elastic range of the materials has been exceeded at critical points, so that an ultimate strength theory based on the inelastic behavior of the material is necessary for a rational determination of the safety of a structure against collapse. Nevertheless, an elastic theory can be used to determine a safe approximation to the strength of ductile structures (the lower bound approach of plasticity), and this approach is customarily followed in reinforced concrete practice. For this reason, only the elastic theory structure is pursued in this chapter.\n\nLooked at critically, all structures are assemblies of three-dimensional elements, the exact analysis of which is a forbidding task even under ideal conditions and impossible to contemplate under conditions of professional practice. For this reason, an important part of the analyst's work is the simplification of the actual structure and loading conditions to a model that is susceptible to rational analysis.\n\nThus, a structural framing system is decomposed into a slab and floor beams which in turn frame into girders carried by columns which transmit the loads to the foundations. Since traditional structural analysis has been unable to cope with the action of the slab, this has often been idealized into a system of strips acting as beams. A Iso, long-hand methods have been unable to cope with three-dimensional framing systems, so that the entire structure has been modeled by a system of planner subassemblies, to be analyzed one at a time. The modern matrix-computer methods have revolutionized structural analysis by making it possible to analyze entire systems, thus leading to more reliable predictions about the behavior of structures under loads.\n\nActual loading conditions are also both difficult to determine and to express realistically, and must be simplified for purposes of analysis. Thus, traffic loads on a bridge structure, which are essentially both of dynamic and random nature, are usually idealized into statically moving standard trucks or distributed loads, intended to simulate the most severe loading conditions occurring in practice. \n\nSimilary, continuous beams are sometimes reduced to simple beams, rigid joints to pin-joints, fillers-walls are neglected, shear walls considered as beams; in deciding how to model a structure so as to make it reasonably realistic but at the same time reasonably simple, the analyst must remember that each such idealization will make the soulation more suspect. The more realistic the analysis, the greater will be the confidence which it inspires, and the smaller may be the safety factor ( or factor of ignorance). Thus, unless code provisions control, the engineer must evaluate the extra expense of a thorough analysis as compared to possible savings in the structure.\n\nThe most important use of structure analysis is as a tool in structural design. As such, it will usually be a part of a trial-and-error procedure, in which an assumed configuration with assumed dead loads is analyzed, and the members are designed in accordance with the results of the analysis. This phase is called the preliminary design, since this design is still subject to change. Usually, a crude, fast analysis method is adequate. At this stage, the cost of the structure is estimated, loads and member properties are revised, and the design is checked for possible improvements. The changes are now incorporated in the structure, a more refined analysis is performed, and the member design is revised. This project is carried out to convergence, the rapidity of which will depend on the capability of the designer. It is clear that a variety of analysis methods, ranging from \" quick and dirty to exact \", are needed for design purposes.\n\nAn efficient analyst must thus be in command of the rigorous methods of analysis, must be able to reduce these to shortcut methods by appropriate assumptions, and must be aware of available design and analysis aids, as well as simplification permitted by applicable building codes. An up-to-date analyst must likewise be versed in the basics of matrix structural analysis and its use in digital computers, as well as in the use of available analysis programs or software.",
    "reference_list": "考点1：bouncy 可直译为 弹性，或意译为 晃动。\n考点2：serviceability 译为 适用性。\n考点3：working condition 译为 正常使用状态。\n考点4：followed 需译为 “使用”或“应用”，不可直译为 遵循。\n考点5：distributed loads 需译为 分布荷载。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "2"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n标题：从“后天”返“先天”：论丹道“炼精化气、炼气化神、炼神还虚”之内景实践与心性论\n\n摘要：\n内丹学，作为中国本土身心性命之学，其核心旨归在于实现生命的逆向飞升，即从“后天”驳杂之躯返回“先天”纯阳之体。此过程全凭一套严密的内景实践——“炼精化气、炼气化神、炼神还虚”——作为路径。本文旨在剖析这一转化过程的三个关键阶段。首先，在“炼精化气”的筑基阶段，行者如何通过凝神于下丹田，运用“武火”与“文火”，将后天有形之精，提纯为先天一炁。其次，在“炼气化神”的转捩阶段，如何以“过关服食”之法，打通小周天，使真气沿任督二脉流转，最终在泥丸宫中结成“圣胎”（婴儿）。最后，在“炼神还虚、与道合真”的终极阶段，如何打破时空幻象，实现“性命双修”之圆满，使个体神识融入宇宙太虚本体。本文认为，这一过程不仅是生理能量的转化，更是一场深刻的心性修炼，旨在降伏“心猿意马”，最终实现“身心不二”的超越性存在。\n\n正文：\n\n一、 筑基炼己：炼精化气与丹田之火\n\n丹道修行的第一步，谓之“百日筑基”。此阶段的核心任务是“炼精化气”。此处的“精”，并非单指凡俗的欲望产物，而分为“后天之精”与“先天元精”。修行者首先要做的，是“勒阳关”，以求保精不失。而后，通过凝神意守下丹田，即所谓“意守玄关”，在体内点燃“无中生有之火”。丹家将此过程比喻为“采药”。当精气充盈，即“药物”已足，便需以呼吸为风箱，催动“武火”进行急速炼化，待“水火既济”，再转为“文火”温养。\n\n这一过程充满了凶险，火候的掌握至关重要，稍有不慎则“水火未济”，前功尽弃。其本质，是将人体后天消耗性的、有形的生命能量（后天之精），通过心神的专注与呼吸的配合，逆转、提纯为一种更高级、更具创造力的生命本源能量（先天一炁）。当丹田温暖，真气流转不息，即是“筑基”成功的标志，为后续的“炼气化神”奠定了坚实基础。\n\n二、 过关服食：炼气化神与周天运转\n\n筑基功成，体内真气充盈，便进入“炼气化神”的关键阶段。此时，行者需将积蓄于下丹田的真气，引导打通人体最重要的两条经脉——任脉与督脉，此即“转小周天”。真气从督脉上升（“进阳火”），经尾闾、夹脊、玉枕三关，抵达头顶的泥丸宫；而后沿任脉下降（“退阴符”），回归丹田。如此循环往复，周流不息。\n\n在周天运转的过程中，单纯的“气”在心神（神）的导引与熔炼下，逐渐转化为更高层次的能量体。这个过程被称为“过关服食”，仿佛是将自身的真气作为食物，反复哺育那居于上丹田（泥丸宫）的神。当能量积累到极致，便会在一片混沌光明中，结成所谓的“婴儿”，也称“圣胎”。此“婴儿”并非实体，而是修行者纯阳之神与先天一炁高度凝聚的产物，是超越凡俗肉身的另一个“真我”的雏形。它的出现，标志着“炼气化神”的初步成功。\n\n三、 粉碎虚空：炼神还虚与性命合一\n\n“圣胎”既成，便进入丹道修行的最高阶段——“炼神还虚”。此处的“炼神”，是指将已经凝聚成形的“婴儿”进一步温养，使其发育成熟，最终能够“出窍”，即神识可以自由离开肉体而独立存在。这一步被称为“九年面壁”或“乳哺”。\n\n当“婴儿”长大，神通具足，修行的最后一步便是“炼神还虚，与道合真”。这要求修行者连同这个凝聚了自身全部精华的“婴儿”也一并放下，即“打破虚空”。修行者需认识到，即便是这个纯阳的“圣胎”，也仍是“道”所化生的一种“有”，仍非最终的“无”。通过甚深禅定，最终粉碎一切能所、主客的对立，将个体神识彻底消融于无边无际、无始无终的宇宙本体——“太虚”之中。至此，“性命双修”方告圆满，完成了从凡俗生命到与道合一的伟大回归。这不仅是技术的终点，更是心性的彻底解脱。\n\n结论：内丹学对现代身心观的启示\n\n内丹学这套繁复的符号与实践体系，其本质是对“身心不二”理念的极致探索。它所描述的“内景”，既是生理能量的真实体验，也是心灵意象的投射。在笛卡尔式身心二元论影响深远的今天，内丹学提醒我们，身体并非一个可供意识随意驱使的、无生命的机器。恰恰相反，身体本身就是一个充满智慧的宇宙，蕴藏着生命转化的巨大潜能。重新理解“炼精化气”中对生命本源的珍惜，“炼气化神”中意识与能量的共舞，以及“炼神还虚”中对“终极实在”的追问，对于我们克服现代性的身心分离，具有深刻的启示意义。\n\n",
    "ori_text": "\n\n标题：从“后天”返“先天”：论丹道“炼精化气、炼气化神、炼神还虚”之内景实践与心性论\n\n摘要：\n内丹学，作为中国本土身心性命之学，其核心旨归在于实现生命的逆向飞升，即从“后天”驳杂之躯返回“先天”纯阳之体。此过程全凭一套严密的内景实践——“炼精化气、炼气化神、炼神还虚”——作为路径。本文旨在剖析这一转化过程的三个关键阶段。首先，在“炼精化气”的筑基阶段，行者如何通过凝神于下丹田，运用“武火”与“文火”，将后天有形之精，提纯为先天一炁。其次，在“炼气化神”的转捩阶段，如何以“过关服食”之法，打通小周天，使真气沿任督二脉流转，最终在泥丸宫中结成“圣胎”（婴儿）。最后，在“炼神还虚、与道合真”的终极阶段，如何打破时空幻象，实现“性命双修”之圆满，使个体神识融入宇宙太虚本体。本文认为，这一过程不仅是生理能量的转化，更是一场深刻的心性修炼，旨在降伏“心猿意马”，最终实现“身心不二”的超越性存在。\n\n正文：\n\n一、 筑基炼己：炼精化气与丹田之火\n\n丹道修行的第一步，谓之“百日筑基”。此阶段的核心任务是“炼精化气”。此处的“精”，并非单指凡俗的欲望产物，而分为“后天之精”与“先天元精”。修行者首先要做的，是“勒阳关”，以求保精不失。而后，通过凝神意守下丹田，即所谓“意守玄关”，在体内点燃“无中生有之火”。丹家将此过程比喻为“采药”。当精气充盈，即“药物”已足，便需以呼吸为风箱，催动“武火”进行急速炼化，待“水火既济”，再转为“文火”温养。\n\n这一过程充满了凶险，火候的掌握至关重要，稍有不慎则“水火未济”，前功尽弃。其本质，是将人体后天消耗性的、有形的生命能量（后天之精），通过心神的专注与呼吸的配合，逆转、提纯为一种更高级、更具创造力的生命本源能量（先天一炁）。当丹田温暖，真气流转不息，即是“筑基”成功的标志，为后续的“炼气化神”奠定了坚实基础。\n\n二、 过关服食：炼气化神与周天运转\n\n筑基功成，体内真气充盈，便进入“炼气化神”的关键阶段。此时，行者需将积蓄于下丹田的真气，引导打通人体最重要的两条经脉——任脉与督脉，此即“转小周天”。真气从督脉上升（“进阳火”），经尾闾、夹脊、玉枕三关，抵达头顶的泥丸宫；而后沿任脉下降（“退阴符”），回归丹田。如此循环往复，周流不息。\n\n在周天运转的过程中，单纯的“气”在心神（神）的导引与熔炼下，逐渐转化为更高层次的能量体。这个过程被称为“过关服食”，仿佛是将自身的真气作为食物，反复哺育那居于上丹田（泥丸宫）的神。当能量积累到极致，便会在一片混沌光明中，结成所谓的“婴儿”，也称“圣胎”。此“婴儿”并非实体，而是修行者纯阳之神与先天一炁高度凝聚的产物，是超越凡俗肉身的另一个“真我”的雏形。它的出现，标志着“炼气化神”的初步成功。\n\n三、 粉碎虚空：炼神还虚与性命合一\n\n“圣胎”既成，便进入丹道修行的最高阶段——“炼神还虚”。此处的“炼神”，是指将已经凝聚成形的“婴儿”进一步温养，使其发育成熟，最终能够“出窍”，即神识可以自由离开肉体而独立存在。这一步被称为“九年面壁”或“乳哺”。\n\n当“婴儿”长大，神通具足，修行的最后一步便是“炼神还虚，与道合真”。这要求修行者连同这个凝聚了自身全部精华的“婴儿”也一并放下，即“打破虚空”。修行者需认识到，即便是这个纯阳的“圣胎”，也仍是“道”所化生的一种“有”，仍非最终的“无”。通过甚深禅定，最终粉碎一切能所、主客的对立，将个体神识彻底消融于无边无际、无始无终的宇宙本体——“太虚”之中。至此，“性命双修”方告圆满，完成了从凡俗生命到与道合一的伟大回归。这不仅是技术的终点，更是心性的彻底解脱。\n\n结论：内丹学对现代身心观的启示\n\n内丹学这套繁复的符号与实践体系，其本质是对“身心不二”理念的极致探索。它所描述的“内景”，既是生理能量的真实体验，也是心灵意象的投射。在笛卡尔式身心二元论影响深远的今天，内丹学提醒我们，身体并非一个可供意识随意驱使的、无生命的机器。恰恰相反，身体本身就是一个充满智慧的宇宙，蕴藏着生命转化的巨大潜能。重新理解“炼精化气”中对生命本源的珍惜，“炼气化神”中意识与能量的共舞，以及“炼神还虚”中对“终极实在”的追问，对于我们克服现代性的身心分离，具有深刻的启示意义。\n\n",
    "reference_list": "考点1：“炼精化气、炼气化神、炼神还虚”必须译为:“Refining Essence into Qi, Refining Qi into Spirit, and Refining Spirit to Return to the Void”或“refining essence into qi, refining qi into spirit, refining spirit to return to emptiness”\n考点2：“后天” vs. “先天”必须译为:“Postnatal” vs. “Prenatal” ；\n考点3：“心猿意马”推荐译为:“the restless and untamed mind”\n考点4:“性命双修”必须译为:“the dual cultivation of Nature and Life-Destiny”或“double cultivation of nature and life”\n考点5：“丹田”必须译为:“Dantian”;“dantian”\n考点6：“周天”必须译为：“ Microcosmic Orbit”或“ microcosmic orbit”\n考点7：“婴儿”必须译为：“ Sacred Embryo”或“sacred embryo (infant)”\n考点8：“采药” 推荐译为：“gathering the elixir ”\n考点9：“身心不二”必须译为：“the non-duality of body and mind”或“mind-body non-duality”\n考点10：“乳哺”必须译为:“nursing”\n考点11：“打通”必须译为:“to open up”；“to open”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "132"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n一、出生努尔哈赤, 中国历史上最后一个封建王朝的奠基人。金庸称他为“自成吉思汗以来, 四百多年中全世界从未出现过的军事天才”。努尔哈赤于1559年2月21日, 出生在赫图阿拉 (也就是今辽宁省新宾县) 建州一个小部酋长的家里。努尔哈赤的祖父叫觉昌安, 是后被清朝追尊为兴祖直皇帝的第四子, 而努尔哈赤的父亲也是觉昌安的第四子塔克世, 母亲是喜塔喇·厄墨气, 努尔哈赤还有两个弟弟, 名字分别为舒尔哈齐, 雅尔哈齐。父亲觉昌安是当时明朝所封的建州左卫枝部酋长, 也就是相当于明官的都指挥使, 人少势弱, 早先依附建州“强酋”王杲, 常率领部众进入抚顺马市交易, 以麻布、粮食交换猪牛, 领取抚赏的食盐、红布、兀剌等物。 (1574年) 因王杲抗命, 扰民抢掠, 扩大实力, 有不轨之心。明朝辽东总兵官李成梁率军数万, 攻打王杲之寨, 并取之, 还杀掠人畜殆尽, 其父觉昌安、其祖父塔克世为平息战火, 充当明军向导, 劝说王杲罢兵息战。 (1583年) 王杲之子阿台图为报父仇, 攻打边境, 李成梁再率大军出击, 取阿台的古勒寨以及其同党阿海的莽子寨, 杀阿台, “杲自是子孙靡孑遗”。觉昌安、塔克世再次作为明军向导, 战乱中被明兵误杀。后来, 明朝认识到误杀的错误, 归还其祖塔克世、其父觉昌安遗体, 并赔“敕书三十道, 马三十匹, 封龙虎将军, 复给都督敕书”。听到这个信息的努尔哈赤本想起兵为父仇, 但当时的他才二十五岁, 势单力薄, 怎么可能与拥有百万兵马的大明“皇帝”交锋?无可奈何之下, 努尔哈赤越过建州左卫图伦城主尼堪外兰, 上奏明臣指责其唆使明兵杀害父、祖, 并索要当时杀害祖和父的明兵。不料这一要求, 惹恼了当时的明朝边将, 被视为无理取闹, 并一口拒绝, 还宣称要于甲板筑城, 令尼堪外兰为“满洲国主”, 因而尼堪外兰威望大升, “于是国人信之, 皆归尼堪外兰”, 连亲族子弟也“对神立誓”, 要杀努尔哈赤以换取大明朝的信任, 尼堪外兰也乘机逼努尔哈赤向他“依附”, 俨然以建州国君自居。二、发展1583年5月, 努尔哈赤以十三副铠甲、部众三十人起兵。先后吞并了其他建州部落, 栋鄂部、海西叶赫、乌拉、哈达强部这些小的部落, 再降服建州、海西、“野人”数以万计的女真, 建立后金国, 登上女真王的宝座。这就是历史上的努尔哈赤了, 不过学生认为, 努尔哈赤会崛起也不是没有条件的, 因为就所看到的史料上记载, 当时的明朝将领有好多都是不可一世, 以为努尔哈赤一个小小的部落, 人又没有多少, 也翻不起什么大浪。就算看出了那个势头, 也完全不放在眼中。如果说当时的明将在努尔哈赤刚刚攻打别的小部的时候就制止了他的话, 那努尔哈赤要崛起也是很难的, 可是当时的明将却是事不关己, 高高挂起, 就是没有想到星星之火也能燎原, 不及时扑灭, 最后烧到了自己的身上。不过明将的放之任之是一个原因, 但还不是全部, 当时的建州各部太过于软弱, 因为有了几年的安心生活, 就忘了居安思危, 没有了那份热血和反抗的精神, 一有事就只知道找明朝或别的部落帮忙, 如果别人不帮, 那就只有等死。还有, 遇到事的时候各部还在计较着自己的利益, 并没有想到唇亡齿寒这个道理。所以让努尔哈赤各个击破, 这也是一个原因。还有的学生认为, 在中国人的心中有一个信念, 那就是父仇不共代天, 仇恨也是让努尔哈赤成功的一种动力。他的父亲和祖父本来是帮明朝带路的, 可明朝的士兵却将他们杀了, 事后明朝仅仅以“敕书三十道, 马三十匹, 封龙虎将军, 复给都督敕书”就想把他们打发了。让交出那个杀人的士兵, 还有严罚那个背后的指使人, 也算是人之常情, 可明将不干不说, 还把他的仇人封了大官, 这不是分明是说:“我就是要杀你的父亲、祖父, 你能把我咋样?”这无疑是火上浇油。努尔哈赤就觉得这是一种很大的耻辱, 他这时不只是想为父报仇, 还有对明将的一种恼怒, 所以他定会奋发图强。这是一个人的本性, 也可以说是一种原因。",
    "ori_text": "一、出生努尔哈赤, 中国历史上最后一个封建王朝的奠基人。金庸称他为“自成吉思汗以来, 四百多年中全世界从未出现过的军事天才”。努尔哈赤于1559年2月21日, 出生在赫图阿拉 (也就是今辽宁省新宾县) 建州一个小部酋长的家里。努尔哈赤的祖父叫觉昌安, 是后被清朝追尊为兴祖直皇帝的第四子, 而努尔哈赤的父亲也是觉昌安的第四子塔克世, 母亲是喜塔喇·厄墨气, 努尔哈赤还有两个弟弟, 名字分别为舒尔哈齐, 雅尔哈齐。父亲觉昌安是当时明朝所封的建州左卫枝部酋长, 也就是相当于明官的都指挥使, 人少势弱, 早先依附建州“强酋”王杲, 常率领部众进入抚顺马市交易, 以麻布、粮食交换猪牛, 领取抚赏的食盐、红布、兀剌等物。 (1574年) 因王杲抗命, 扰民抢掠, 扩大实力, 有不轨之心。明朝辽东总兵官李成梁率军数万, 攻打王杲之寨, 并取之, 还杀掠人畜殆尽, 其父觉昌安、其祖父塔克世为平息战火, 充当明军向导, 劝说王杲罢兵息战。 (1583年) 王杲之子阿台图为报父仇, 攻打边境, 李成梁再率大军出击, 取阿台的古勒寨以及其同党阿海的莽子寨, 杀阿台, “杲自是子孙靡孑遗”。觉昌安、塔克世再次作为明军向导, 战乱中被明兵误杀。后来, 明朝认识到误杀的错误, 归还其祖塔克世、其父觉昌安遗体, 并赔“敕书三十道, 马三十匹, 封龙虎将军, 复给都督敕书”。听到这个信息的努尔哈赤本想起兵为父仇, 但当时的他才二十五岁, 势单力薄, 怎么可能与拥有百万兵马的大明“皇帝”交锋?无可奈何之下, 努尔哈赤越过建州左卫图伦城主尼堪外兰, 上奏明臣指责其唆使明兵杀害父、祖, 并索要当时杀害祖和父的明兵。不料这一要求, 惹恼了当时的明朝边将, 被视为无理取闹, 并一口拒绝, 还宣称要于甲板筑城, 令尼堪外兰为“满洲国主”, 因而尼堪外兰威望大升, “于是国人信之, 皆归尼堪外兰”, 连亲族子弟也“对神立誓”, 要杀努尔哈赤以换取大明朝的信任, 尼堪外兰也乘机逼努尔哈赤向他“依附”, 俨然以建州国君自居。二、发展1583年5月, 努尔哈赤以十三副铠甲、部众三十人起兵。先后吞并了其他建州部落, 栋鄂部、海西叶赫、乌拉、哈达强部这些小的部落, 再降服建州、海西、“野人”数以万计的女真, 建立后金国, 登上女真王的宝座。这就是历史上的努尔哈赤了, 不过学生认为, 努尔哈赤会崛起也不是没有条件的, 因为就所看到的史料上记载, 当时的明朝将领有好多都是不可一世, 以为努尔哈赤一个小小的部落, 人又没有多少, 也翻不起什么大浪。就算看出了那个势头, 也完全不放在眼中。如果说当时的明将在努尔哈赤刚刚攻打别的小部的时候就制止了他的话, 那努尔哈赤要崛起也是很难的, 可是当时的明将却是事不关己, 高高挂起, 就是没有想到星星之火也能燎原, 不及时扑灭, 最后烧到了自己的身上。不过明将的放之任之是一个原因, 但还不是全部, 当时的建州各部太过于软弱, 因为有了几年的安心生活, 就忘了居安思危, 没有了那份热血和反抗的精神, 一有事就只知道找明朝或别的部落帮忙, 如果别人不帮, 那就只有等死。还有, 遇到事的时候各部还在计较着自己的利益, 并没有想到唇亡齿寒这个道理。所以让努尔哈赤各个击破, 这也是一个原因。还有的学生认为, 在中国人的心中有一个信念, 那就是父仇不共代天, 仇恨也是让努尔哈赤成功的一种动力。他的父亲和祖父本来是帮明朝带路的, 可明朝的士兵却将他们杀了, 事后明朝仅仅以“敕书三十道, 马三十匹, 封龙虎将军, 复给都督敕书”就想把他们打发了。让交出那个杀人的士兵, 还有严罚那个背后的指使人, 也算是人之常情, 可明将不干不说, 还把他的仇人封了大官, 这不是分明是说:“我就是要杀你的父亲、祖父, 你能把我咋样?”这无疑是火上浇油。努尔哈赤就觉得这是一种很大的耻辱, 他这时不只是想为父报仇, 还有对明将的一种恼怒, 所以他定会奋发图强。这是一个人的本性, 也可以说是一种原因。",
    "reference_list": "考点1：人名、地名不能译错：努尔哈赤（Nurhaci）、金庸（Louis Cha Leung-yung ）、 成吉思汗（Genghis Khan）、赫图阿拉（Hetu Ala）觉昌安 （Giocangga）、塔克世（Taksi）、喜塔喇·厄墨气（Hitara Emeci）、舒尔哈齐（Surgaci）、雅尔哈齐（Yargaci）、阿台图（Atatu或Atai）、尼堪外兰（nikan wailan）、图伦（turun hoton）。\n考点2： ”兀剌”应译为“boots”，在元语中表示靴子。\n考点3：“ 不轨之心”应译为“rebellious intensions”。 \n考点4： ”敕书“应译为“Command paper ”。\n考点5：”唇亡齿寒”应译为“if the lips are gone, the teeth will be cold (implying that two parties are interdependent)”，解释具体含义\n考点6：“学生认为”翻译为“student believes”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "54"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n\n“大气的热状况与大气运动——热力环流”\n\n教学设计\n\n陕西省渭南市大荔县大荔中学 刘 瑞\n\n一、设计思路\n\n(一) 教学指导思想\n\n《普通高中课程标准》对本节的要求是“运用热力环流的形成原理”，要学会灵活运用解释生活中的一些现象。此要求是在这节课的教学指导思想和教学依据。\n\n(二) 设计理念\n\n本节课的教学，和现实生活相联系，并采用情景教学，活动探究、问题讨论、对比分析的教学方法，充分体现“教师为主导，学生为主体”的教育理念，放手让学生自主探索的学习，主动参与到知识形成整个思维的过程，力求使学生在积极、愉快的课堂中提高自己的水平。\n\n(三) 教材分析\n\n新课标要求：运用图表说明大气的受热过程。热力环流是大气运动最简单的形式，在本单元中有着举足轻重的作用，是后面学习“风”“全球性大气环流”“常见的天气系统”等知识的基础。同时，热力环流的形成过程和形成原理又是一个难点，很多学生在学习后仍然思维模糊，概念混淆。如何才能突破这个难点，只有在教学过程中遵循学生的认识规律，循序渐进，步步深入，才能让学生更好地接受。因此在讲大气热力环流时采取大气运动由静态到动态的发生过程，直观深入地展示大气环流发生时气温、气压、气流 3 者之间的关系，即可突破难点。\n\n大气热力环流是大气不均匀受热的结果。大气不均匀受热主要是由太阳辐射的纬度差异和下垫面热力性质差异引起的。冷热不均是大气运动的根本原因，大气热力环流则是理解许多大气运动的理论基础。小到城市热岛环流，大到全球性大气环流，都可以用大气热力环流的原理来解释。热力环流是本节的重点，要讲清两个问题：一是大气的垂直运动是由于地面冷热不均产生的（大气垂直运动直接影响天气的变化）；二是大气的水平运动是由于大气的垂直运动导致在同一水平面上产生气压差异（大气水平运动直接影响热量与水汽的输送）。\n\n(四) 学情分析\n\n新课标中高中地理教材比较强调知识的应用，这与初中地理学习有很大的不同。由于学生在学习的过程中缺乏相关的知识，学生在学习的过程中往往会碰到比较多的问题，教材的重难点也教多，在学习的过程中，学生要处理好这些重难点是有一定的困难的。但是，学生对学习这些内容。如“热力环流”这一重难点的掌握。从教材的内容安排来看，这一重难点安排在第二章，高一新生的物理基础知识还不是十分好，要理解“热力环流”的形成必须掌握物理学习中有关“大气受热不同对气压的影响”的相关知识。在学习过程中，学生通过具体例子的分析来理解“热力环流”可以达到事半功倍的学习效果。\n\n二、教学目标\n\n知识与技能:\n\n1、掌握热力环流的定义，熟练阅读热力环流示意图，理解热力环流的形成过程。\n\n2、通过绘制热力环流图，培养学生的绘图能力。\n\n3、能够利用热力环流原理，解答生产、生活中的局地环流问题，达到知识拓展的目的。\n\n过程与方法:\n\n本节课遵循由问题→多媒体演示获得感性认识→分析推理运动过程→归纳概括运动规律（理性认识）→给出实际生活案例→应用规律解决实际问题的教学主线，在此过程中进一步培养学生用分析、推理、归纳等方法学习地理知识。\n\n情感态度与价值观：通过分析、理解、观察热力环流和局地环流，培养学生探索自然、热爱科学的精神。通过对城市风、山谷风等内容的学习，进一步提高学生的环境意识。现代教学手段：\n\n运用多媒体辅助教学提高学生读图能力。\n\n三、教学重点\n\n热力环流的形成过程及应用\n\n四、 教学难点\n\n运用热力环流原理分析绘制海陆风、城市风、山谷风形成\n\n五、 教学反思\n\n1、课时的安排：1 课时。\n\n2、这节课的三维目标比较合理，围绕知识点来展开。\n\n3、这节课的理论性强，内容较抽象，另外学生必备的空间建构能力还较弱，所以授课时我用必要的多媒体课件解决这两个问题，变抽象为直观，变二维为三维。利用这个手段不仅降低了知识的难度，更是极大的调动了学生的热情和探究欲望。在运用原理分析实际问题时，联系学生身边的地理问题，引导其分析最熟悉的海陆风、城市风、山谷风，调动学生学习的主动性，激发学生探究问题的精神，使学生学习到对终身发展有用的地理。同时提前让学生利用互联网收集有关城市热岛的地理信息，培养学生在信息时代的信息收集能力。总之，通过三个案例的反复分析，不仅使知识顺利迁移拓展，而且最终突破了本节课难点。\n\n4、在教学中，设计问题时注重问题的难易结合，由浅入深，符合教学规律和认识方法。并且在教学过程中，注意及时进行每个环节的小结，强调重点内容，争取使学生当堂记忆消化。",
    "ori_text": "“大气的热状况与大气运动——热力环流”\n\n教学设计\n\n陕西省渭南市大荔县大荔中学 刘 瑞\n\n一、设计思路\n\n(一) 教学指导思想\n\n《普通高中课程标准》对本节的要求是“运用热力环流的形成原理”，要学会灵活运用解释生活中的一些现象。此要求是在这节课的教学指导思想和教学依据。\n\n(二) 设计理念\n\n本节课的教学，和现实生活相联系，并采用情景教学，活动探究、问题讨论、对比分析的教学方法，充分体现“教师为主导，学生为主体”的教育理念，放手让学生自主探索的学习，主动参与到知识形成整个思维的过程，力求使学生在积极、愉快的课堂中提高自己的水平。\n\n(三) 教材分析\n\n新课标要求：运用图表说明大气的受热过程。热力环流是大气运动最简单的形式，在本单元中有着举足轻重的作用，是后面学习“风”“全球性大气环流”“常见的天气系统”等知识的基础。同时，热力环流的形成过程和形成原理又是一个难点，很多学生在学习后仍然思维模糊，概念混淆。如何才能突破这个难点，只有在教学过程中遵循学生的认识规律，循序渐进，步步深入，才能让学生更好地接受。因此在讲大气热力环流时采取大气运动由静态到动态的发生过程，直观深入地展示大气环流发生时气温、气压、气流 3 者之间的关系，即可突破难点。\n\n大气热力环流是大气不均匀受热的结果。大气不均匀受热主要是由太阳辐射的纬度差异和下垫面热力性质差异引起的。冷热不均是大气运动的根本原因，大气热力环流则是理解许多大气运动的理论基础。小到城市热岛环流，大到全球性大气环流，都可以用大气热力环流的原理来解释。热力环流是本节的重点，要讲清两个问题：一是大气的垂直运动是由于地面冷热不均产生的（大气垂直运动直接影响天气的变化）；二是大气的水平运动是由于大气的垂直运动导致在同一水平面上产生气压差异（大气水平运动直接影响热量与水汽的输送）。\n\n(四) 学情分析\n\n新课标中高中地理教材比较强调知识的应用，这与初中地理学习有很大的不同。由于学生在学习的过程中缺乏相关的知识，学生在学习的过程中往往会碰到比较多的问题，教材的重难点也教多，在学习的过程中，学生要处理好这些重难点是有一定的困难的。但是，学生对学习这些内容。如“热力环流”这一重难点的掌握。从教材的内容安排来看，这一重难点安排在第二章，高一新生的物理基础知识还不是十分好，要理解“热力环流”的形成必须掌握物理学习中有关“大气受热不同对气压的影响”的相关知识。在学习过程中，学生通过具体例子的分析来理解“热力环流”可以达到事半功倍的学习效果。\n\n二、教学目标\n\n知识与技能:\n\n1、掌握热力环流的定义，熟练阅读热力环流示意图，理解热力环流的形成过程。\n\n2、通过绘制热力环流图，培养学生的绘图能力。\n\n3、能够利用热力环流原理，解答生产、生活中的局地环流问题，达到知识拓展的目的。\n\n过程与方法:\n\n本节课遵循由问题→多媒体演示获得感性认识→分析推理运动过程→归纳概括运动规律（理性认识）→给出实际生活案例→应用规律解决实际问题的教学主线，在此过程中进一步培养学生用分析、推理、归纳等方法学习地理知识。\n\n情感态度与价值观：通过分析、理解、观察热力环流和局地环流，培养学生探索自然、热爱科学的精神。通过对城市风、山谷风等内容的学习，进一步提高学生的环境意识。现代教学手段：\n\n运用多媒体辅助教学提高学生读图能力。\n\n三、教学重点\n\n热力环流的形成过程及应用\n\n四、 教学难点\n\n运用热力环流原理分析绘制海陆风、城市风、山谷风形成\n\n五、 教学反思\n\n1、课时的安排：1 课时。\n\n2、这节课的三维目标比较合理，围绕知识点来展开。\n\n3、这节课的理论性强，内容较抽象，另外学生必备的空间建构能力还较弱，所以授课时我用必要的多媒体课件解决这两个问题，变抽象为直观，变二维为三维。利用这个手段不仅降低了知识的难度，更是极大的调动了学生的热情和探究欲望。在运用原理分析实际问题时，联系学生身边的地理问题，引导其分析最熟悉的海陆风、城市风、山谷风，调动学生学习的主动性，激发学生探究问题的精神，使学生学习到对终身发展有用的地理。同时提前让学生利用互联网收集有关城市热岛的地理信息，培养学生在信息时代的信息收集能力。总之，通过三个案例的反复分析，不仅使知识顺利迁移拓展，而且最终突破了本节课难点。\n\n4、在教学中，设计问题时注重问题的难易结合，由浅入深，符合教学规律和认识方法。并且在教学过程中，注意及时进行每个环节的小结，强调重点内容，争取使学生当堂记忆消化。",
    "reference_list": "考点1：《普通高中课程标准》应译为”Senior High School Curriculum Standards”\n考点2：\"情景教学\"应译为“Context-Based Instruction”\n考点3：\"直观\"应译为“straightforward”\n考点4：\"一课时\"翻译为“45minutes”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "教育",
    "prompt_id": "66"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n3.1 Similarities\n\nThe purpose of all advertising is to familiarize consumers with or remind them of the benefits of particular products in the hope of increasing sales, and the techniques used by advertisers do not vary markedly. An advertisement is often merely glimpsed in passing and so, to be effective, its message must be colorful, legible, understandable and memorable. The rules governing the language of advertising are similar. We have summarized the lexical features of English advertisements. If words are leaves of a tree, and sentences branches; the branches must also possess their similarities.\n\nFirst, length of a sentence in advertising is usually short. A sentence in daily consumer goods ads has 10.3 words on average; in technical equipment ads, 11.8 words; in service ads, 12.3 words.\n\nSecond, as to sentence structure, simple sentences and elliptical sentences are often used in advertisements. Compared with complex sentences, simple sentences are more understandable and forceful. Elliptical sentences are actually incomplete in structure but complete in meaning. The adoption of elliptical sentences can spare more print space, and take less time for readers to finish reading. In addition, a group of sentence fragments may gain special advertising effectiveness. Let us compare the following two advertisements.\n\n    a. Baked. Drenched. Tested to the extreme. A Motorola cellular phone …\n\nb. The Motorola cellular phone are baked and drenched to extreme.\n\n    Obviously, by using elliptical structure, sentence a is far more brief, eye-catching and forceful than sentence b. What’s more, it conveys attitudes that sentence b lacks. Sentence a implies a kind of appreciation for the phone, by splitting the sentence into several fragments and rearranging its word order. Therefore skillful arrangement of elliptical sentences may add color to a sentence.\n\nThird, as to sentence patterns, interrogative sentences and imperative sentences are heavily used in English advertisements. Imperative sentences are short, encouraging and forceful. They are used to arouse audiences’ wants or encourage them to buy something.\n\n3.2 Differences\n    3.2.1 Headline\n    The term Headline refers to the sentences in the leading position of the advertisement—the words that will be read first or that are positioned to draw the most attention. Therefore, headlines are usually set in larger type than other portions of the advertisement. Research (Coutland L. Bovee & William F. Arens, 1992:294) has shown that, on average, three to five times as many people read the headline as read the body copy. Therefore, if the advertiser hasn’t done some selling in the headline, he has wasted the greatest percent of his money. So it might be suggested that advertisers should not be afraid of long headlines. \n    A headline has numerous functions. First of all, the headline must attract attention to the advertisement fast. It should take only a few seconds to capture the reader’s attention. Otherwise, the entire message may be lost. A headline also selects the reader, that is, it tells whether the advertisement’s subject matter interests the reader. The idea is to engage and involve the reader, suggesting a reason to read the rest of the advertisement. Therefore, the headline is the most important in an advertisement.\nGenerally, we can classify effective advertising headlines into five basic categories: benefit headline, provocative headline, news/information headline, question headline, and command headline.\nBenefit headlines make a direct promise to the reader. News/information headlines include many of the how-to headlines and headlines that seek to gain identification for their sponsors by announcing some news or providing some promise of information. Provocative headlines are used to provoke the reader’s curiosity. To learn more, the reader must read the body copy. A question headline will pique the reader’s curiosity and imagination by asking a question that the reader is interested in. A command headline orders the reader to do something. It motivates the reader through fear or emotion or because the reader understands the inherent correctness of the command.\n\n4.1 Body Copy of an Advertisement\nIn general, a written advertisement consists of five parts: headline, body copy, slogan, illustration and trade mark among which headline, body copy and slogan are the main parts. Headline plays a role in catching attention from readers; slogan can be used as a device to create a corporate image and a common practice to conclude advertisement.\nIn this section we will discuss the body copy as a discourse component. The advertiser tells the complete sales story in the body copy. Set in smaller type than headlines or subheads, the body copy is a logical continuation of the headline and subheads. It is also where the sale is closed. The body copy should relate to the campaign appeal and to the reader’s self-interest, and it must explain how the product or service being advertised satisfies the customer’s need. The body copy may concentrate on one or several benefits as they relate specifically to the target audience. In some cases, especially in daily goods ads, body copy is omitted just because readers know what they are.\n\n4.2 Differences in Body Copy s\n   Copy s fall into many categories. Some common types of copy s include straight-sell copy, institutional copy, narrative copy, dialogue/monologue copy.\nIn a straight-sell copy, the text immediately explains or develops the headline in a straightforward attempt to sell the product. Since the product’s sales points are ticked off in order of their importance, straight-sell copy is particularly advantageous for technical products that may be difficult to use in direct-mail advertising and industrial situations. Many camera ads, for example, use this straight, factual copy to get the message across. The straight-sell approach emphasizes the reason why the consumer should buy something. For example:\n\nPick up right where you left off with the new C-2000 ZOOM filmless digital camera.\nYou loved taking pictures then. You’ll love it even more now with the 2.1 megapixel C-2000 ZOOM. It’ll remind you of your favorite film camera of yesterday, but with all the advantages Olympus filmless photography offers today. Only the C-2000 ZOOM, for example, incorporates an all-glass, aspherical 3x zoom lens system featuring a large aperture f2.0 lens that’s exceptionally fast and bright. Along with automatic or manual features like aperture and shutter priority, spot metering, exposure compensation, white balance and ISO settings. And just like your film camera, the C-2000 ZOOM grows with you when you add external flash, lighting equipment, lenses or filter. So bring back old memories while creating new ones with the C-2000 ZOOM from Olympus--THE WORLD LEADER IN FILM AND FILMLESS PHOTOGRAPHY.\n\nSometimes the advertiser uses the institutional copy to sell an idea or the merits of the organization or service rather than sales features of a particular product. Often institutional copy is also narrative in because it lends warmth to the organization. Service ads, such as ads of banks, insurance companies, public utilities, and large manufacturing concerns are the most common users of the institutional copy.\nAdvertisers use the narrative copy to tell a story. It often sets up a problem and then creates a solution using the particular sales features of the product or service. It may then suggest that the audiences use the same solution if they have that problem. Service advertisements are often written in this . ",
    "ori_text": "3.1 Similarities\n\nThe purpose of all advertising is to familiarize consumers with or remind them of the benefits of particular products in the hope of increasing sales, and the techniques used by advertisers do not vary markedly. An advertisement is often merely glimpsed in passing and so, to be effective, its message must be colorful, legible, understandable and memorable. The rules governing the language of advertising are similar. We have summarized the lexical features of English advertisements. If words are leaves of a tree, and sentences branches; the branches must also possess their similarities.\n\nFirst, length of a sentence in advertising is usually short. A sentence in daily consumer goods ads has 10.3 words on average; in technical equipment ads, 11.8 words; in service ads, 12.3 words.\n\nSecond, as to sentence structure, simple sentences and elliptical sentences are often used in advertisements. Compared with complex sentences, simple sentences are more understandable and forceful. Elliptical sentences are actually incomplete in structure but complete in meaning. The adoption of elliptical sentences can spare more print space, and take less time for readers to finish reading. In addition, a group of sentence fragments may gain special advertising effectiveness. Let us compare the following two advertisements.\n\n    a. Baked. Drenched. Tested to the extreme. A Motorola cellular phone …\n\nb. The Motorola cellular phone are baked and drenched to extreme.\n\n    Obviously, by using elliptical structure, sentence a is far more brief, eye-catching and forceful than sentence b. What’s more, it conveys attitudes that sentence b lacks. Sentence a implies a kind of appreciation for the phone, by splitting the sentence into several fragments and rearranging its word order. Therefore skillful arrangement of elliptical sentences may add color to a sentence.\n\nThird, as to sentence patterns, interrogative sentences and imperative sentences are heavily used in English advertisements. Imperative sentences are short, encouraging and forceful. They are used to arouse audiences’ wants or encourage them to buy something.\n\n3.2 Differences\n    3.2.1 Headline\n    The term Headline refers to the sentences in the leading position of the advertisement—the words that will be read first or that are positioned to draw the most attention. Therefore, headlines are usually set in larger type than other portions of the advertisement. Research (Coutland L. Bovee & William F. Arens, 1992:294) has shown that, on average, three to five times as many people read the headline as read the body copy. Therefore, if the advertiser hasn’t done some selling in the headline, he has wasted the greatest percent of his money. So it might be suggested that advertisers should not be afraid of long headlines. \n    A headline has numerous functions. First of all, the headline must attract attention to the advertisement fast. It should take only a few seconds to capture the reader’s attention. Otherwise, the entire message may be lost. A headline also selects the reader, that is, it tells whether the advertisement’s subject matter interests the reader. The idea is to engage and involve the reader, suggesting a reason to read the rest of the advertisement. Therefore, the headline is the most important in an advertisement.\nGenerally, we can classify effective advertising headlines into five basic categories: benefit headline, provocative headline, news/information headline, question headline, and command headline.\nBenefit headlines make a direct promise to the reader. News/information headlines include many of the how-to headlines and headlines that seek to gain identification for their sponsors by announcing some news or providing some promise of information. Provocative headlines are used to provoke the reader’s curiosity. To learn more, the reader must read the body copy. A question headline will pique the reader’s curiosity and imagination by asking a question that the reader is interested in. A command headline orders the reader to do something. It motivates the reader through fear or emotion or because the reader understands the inherent correctness of the command.\n\n4.1 Body Copy of an Advertisement\nIn general, a written advertisement consists of five parts: headline, body copy, slogan, illustration and trade mark among which headline, body copy and slogan are the main parts. Headline plays a role in catching attention from readers; slogan can be used as a device to create a corporate image and a common practice to conclude advertisement.\nIn this section we will discuss the body copy as a discourse component. The advertiser tells the complete sales story in the body copy. Set in smaller type than headlines or subheads, the body copy is a logical continuation of the headline and subheads. It is also where the sale is closed. The body copy should relate to the campaign appeal and to the reader’s self-interest, and it must explain how the product or service being advertised satisfies the customer’s need. The body copy may concentrate on one or several benefits as they relate specifically to the target audience. In some cases, especially in daily goods ads, body copy is omitted just because readers know what they are.\n\n4.2 Differences in Body Copy s\n   Copy s fall into many categories. Some common types of copy s include straight-sell copy, institutional copy, narrative copy, dialogue/monologue copy.\nIn a straight-sell copy, the text immediately explains or develops the headline in a straightforward attempt to sell the product. Since the product’s sales points are ticked off in order of their importance, straight-sell copy is particularly advantageous for technical products that may be difficult to use in direct-mail advertising and industrial situations. Many camera ads, for example, use this straight, factual copy to get the message across. The straight-sell approach emphasizes the reason why the consumer should buy something. For example:\n\nPick up right where you left off with the new C-2000 ZOOM filmless digital camera.\nYou loved taking pictures then. You’ll love it even more now with the 2.1 megapixel C-2000 ZOOM. It’ll remind you of your favorite film camera of yesterday, but with all the advantages Olympus filmless photography offers today. Only the C-2000 ZOOM, for example, incorporates an all-glass, aspherical 3x zoom lens system featuring a large aperture f2.0 lens that’s exceptionally fast and bright. Along with automatic or manual features like aperture and shutter priority, spot metering, exposure compensation, white balance and ISO settings. And just like your film camera, the C-2000 ZOOM grows with you when you add external flash, lighting equipment, lenses or filter. So bring back old memories while creating new ones with the C-2000 ZOOM from Olympus--THE WORLD LEADER IN FILM AND FILMLESS PHOTOGRAPHY.\n\nSometimes the advertiser uses the institutional copy to sell an idea or the merits of the organization or service rather than sales features of a particular product. Often institutional copy is also narrative in because it lends warmth to the organization. Service ads, such as ads of banks, insurance companies, public utilities, and large manufacturing concerns are the most common users of the institutional copy.\nAdvertisers use the narrative copy to tell a story. It often sets up a problem and then creates a solution using the particular sales features of the product or service. It may then suggest that the audiences use the same solution if they have that problem. Service advertisements are often written in this . ",
    "reference_list": "考点1：“institutional copy”应译为“机构宣传正文”或“机构广告正文”\n考点2：“advertisement slogan”推荐译为“广告标语”，不可译为“口号”。\n考点3：“exceptionally fast and bright”应译为“出色的大光圈性能和进光量”，不可直译为“异常快速且明亮”\n考点4：“wasted the greatest percent of his money”中的“the greatest percent”推荐译为“大部分的”，不可直译为“最大比例的”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "27"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nBlossomsShanghai is a Chinese television series directed and produced by Wong Kar-wai. It isadaptedfrom the novel Blossoms written by Jin Yucheng.\n\nIt follows the story of Ah Bao (played by Hu Ge) as hegoes from nothing to dubious successin the 1990s.\n\nAmong them, there are the guidance of the master uncle (played by You Benchang), the help of the boss of Night Tokyo Reiko (played by Ma Yili), the foreign trade company Miss Wang (played by Tang Yan), and the boss of Zhizhenyuan Li (played by Xin Zhilei).\n\nNow, let's take a look at the classic lines in the play：\n\nAfter the intense heat of Greater Heat, there must come a time of bitter cold. Remember, this is the law.\n\nA layman looks at the facade, an expert looks at the back door.\n\nYou think you’re eating lobster, but actually you’re eating opportunities. A lobster is an opportunity. You’re either socializing or asking for help.\n\nAlways leave a trick up your sleeve.\n\nDo you know the Empire State Building in New York? It takes an hour to run from the bottom to the top, but only 8.8 seconds to jump down from the roof. This is what stocks are like. If you want to make money from stocks, you need to learn how to lose first.\n\nShanghai people do business, pay attention to style, fun, signs.\n\nThis is all your style. This private room is your stunt. They run a so-called company, and you are the same. But your bag is bigger than others - Peace Hotel.\n\nHow many wallets should a man have? Three. The first is how much money you actually have. The second is your credit, which means how much money people can lend you from their wallets. The third one is how much money people think you have.\n\nThe market is always right, and only oneself can be wrong. Rushing too fast and running away too slowly will definitely lead to failure. The head rests on the shoulders, and the feet are on your own body. As long as you protect yourself well, opportunities are always greater than risks.\n\nDoing business is not about who earns more, but about who lives longer. Don’t think about taking a big step at once, take one step at a time and move forward steadily.\n\nIn business, the first two words to learn are ’no comment’. If you don’t know, if you can’t explain clearly, if you haven’t thought about it or planned it, if it’s difficult for yourself or others, just say no comment. Leave some room for maneuvering when doing things, right?\n\nForeign trade is like borrowing someone else’s chicken to lay your own eggs, but why should they lend you their chicken and help you lay eggs?\n\nNow we advocate market economy, and if we want to engage in the marketNow we advocate market economy, and if we want to engage in the market, we must believe in the market. Whether it is one yuan for a cup of tea or ten yuan for a cup of tea, it is up to others. If you don’t believe in the market, just live a peaceful life like us.\n\nThe revenge of the capital market will only let you go where you come from.\n\nThe heart can be hot, but the head must be cold.\n\nOpportunities are equal for everyone, and seizing an opportunity may change one’s life. Some people rise with the wind, while others return to zero in half a day.\n\nThere are some principles, such as being able to handle things and balance them. Finally, there is one more thing, which is that you should be able to afford to lose.\n\nPeople always have to be trapped by something. It’s either stocks or houses.\n\nLooking at yourself, you think you are perfect andLooking at yourself, you think you are perfect and it’s always someone else’s fault. In fact, when others look at you, they see all your flaws. Being optimistic is good, but making the worst plan is still necessary. You should always prepare for a rainy day.\n\nTo stand out from the crowd is a process of being taught by others.\n\nDon’t talk big with little strength.\n\nEveryone has a scale in their heart, when they can be rich and nobleEveryone has a scale in their heart, when they can be rich and noble together, when they can share weal and woe together, they all have some idea in their hearts.\n\nThe goal is never far away, step by step, day by day, just do your best, and leave the rest to time.\n\nPeople always have to catch up, either go or stay, only not regretPeople always have to catch up, either go or stay, only not regret, regret no medicine can be saved.\n\nHuman feelings are owed back and forth, just like painting walls, brushHuman feelings are owed back and forth, just like painting walls, brushing back and forth, so this human feeling will become deeper and deeper.\n\nThere is no such thing as true or false, what you see in frontThere is no such thing as true or false, what you see in front of you is true, and what is gone is false.\n\nI couldn’t see her clearly at that time, and ten years laterI couldn’t see her clearly at that time, and ten years later, I still didn’t see her clearly, but I saw myself.\n\nCricket is brave again, teeth again sharp, fight to the endCricket is brave again, teeth again sharp, fight to the end, or lose, to die, people are the same.\n\nWhy can’t I be my own wharf? No. 27 is not my wharf, nor is General Manager Bao. I am my own wharf.\n\nBetter strike the bell once than break it a thousand times.\n\nThe difficulties of crossing the mountains are hard to overcome, and it is a matter of pride to cross them. Another journey is far away from the mountains and rivers, and if you can’t cross them, it becomes a lesson and a warning to future generations.\n\nToday’s sun cannot dry tomorrow’s clothes. Time decides everything.\n\nIn the eyes of God, it is inevitable. A choice, a life, not you know right and wrong, can escape.\n\nThere are two problems in life. The first is to find the problem, and the second is to solve it.\n\nOnly by seeing the future can there be a future.\n\nThe weather won’t always be good, and people won’t always have the upper hand.",
    "ori_text": "BlossomsShanghai is a Chinese television series directed and produced by Wong Kar-wai. It isadaptedfrom the novel Blossoms written by Jin Yucheng.\n\nIt follows the story of Ah Bao (played by Hu Ge) as hegoes from nothing to dubious successin the 1990s.\n\nAmong them, there are the guidance of the master uncle (played by You Benchang), the help of the boss of Night Tokyo Reiko (played by Ma Yili), the foreign trade company Miss Wang (played by Tang Yan), and the boss of Zhizhenyuan Li (played by Xin Zhilei).\n\nNow, let's take a look at the classic lines in the play：\n\nAfter the intense heat of Greater Heat, there must come a time of bitter cold. Remember, this is the law.\n\nA layman looks at the facade, an expert looks at the back door.\n\nYou think you’re eating lobster, but actually you’re eating opportunities. A lobster is an opportunity. You’re either socializing or asking for help.\n\nAlways leave a trick up your sleeve.\n\nDo you know the Empire State Building in New York? It takes an hour to run from the bottom to the top, but only 8.8 seconds to jump down from the roof. This is what stocks are like. If you want to make money from stocks, you need to learn how to lose first.\n\nShanghai people do business, pay attention to style, fun, signs.\n\nThis is all your style. This private room is your stunt. They run a so-called company, and you are the same. But your bag is bigger than others - Peace Hotel.\n\nHow many wallets should a man have? Three. The first is how much money you actually have. The second is your credit, which means how much money people can lend you from their wallets. The third one is how much money people think you have.\n\nThe market is always right, and only oneself can be wrong. Rushing too fast and running away too slowly will definitely lead to failure. The head rests on the shoulders, and the feet are on your own body. As long as you protect yourself well, opportunities are always greater than risks.\n\nDoing business is not about who earns more, but about who lives longer. Don’t think about taking a big step at once, take one step at a time and move forward steadily.\n\nIn business, the first two words to learn are ’no comment’. If you don’t know, if you can’t explain clearly, if you haven’t thought about it or planned it, if it’s difficult for yourself or others, just say no comment. Leave some room for maneuvering when doing things, right?\n\nForeign trade is like borrowing someone else’s chicken to lay your own eggs, but why should they lend you their chicken and help you lay eggs?\n\nNow we advocate market economy, and if we want to engage in the marketNow we advocate market economy, and if we want to engage in the market, we must believe in the market. Whether it is one yuan for a cup of tea or ten yuan for a cup of tea, it is up to others. If you don’t believe in the market, just live a peaceful life like us.\n\nThe revenge of the capital market will only let you go where you come from.\n\nThe heart can be hot, but the head must be cold.\n\nOpportunities are equal for everyone, and seizing an opportunity may change one’s life. Some people rise with the wind, while others return to zero in half a day.\n\nThere are some principles, such as being able to handle things and balance them. Finally, there is one more thing, which is that you should be able to afford to lose.\n\nPeople always have to be trapped by something. It’s either stocks or houses.\n\nLooking at yourself, you think you are perfect andLooking at yourself, you think you are perfect and it’s always someone else’s fault. In fact, when others look at you, they see all your flaws. Being optimistic is good, but making the worst plan is still necessary. You should always prepare for a rainy day.\n\nTo stand out from the crowd is a process of being taught by others.\n\nDon’t talk big with little strength.\n\nEveryone has a scale in their heart, when they can be rich and nobleEveryone has a scale in their heart, when they can be rich and noble together, when they can share weal and woe together, they all have some idea in their hearts.\n\nThe goal is never far away, step by step, day by day, just do your best, and leave the rest to time.\n\nPeople always have to catch up, either go or stay, only not regretPeople always have to catch up, either go or stay, only not regret, regret no medicine can be saved.\n\nHuman feelings are owed back and forth, just like painting walls, brushHuman feelings are owed back and forth, just like painting walls, brushing back and forth, so this human feeling will become deeper and deeper.\n\nThere is no such thing as true or false, what you see in frontThere is no such thing as true or false, what you see in front of you is true, and what is gone is false.\n\nI couldn’t see her clearly at that time, and ten years laterI couldn’t see her clearly at that time, and ten years later, I still didn’t see her clearly, but I saw myself.\n\nCricket is brave again, teeth again sharp, fight to the endCricket is brave again, teeth again sharp, fight to the end, or lose, to die, people are the same.\n\nWhy can’t I be my own wharf? No. 27 is not my wharf, nor is General Manager Bao. I am my own wharf.\n\nBetter strike the bell once than break it a thousand times.\n\nThe difficulties of crossing the mountains are hard to overcome, and it is a matter of pride to cross them. Another journey is far away from the mountains and rivers, and if you can’t cross them, it becomes a lesson and a warning to future generations.\n\nToday’s sun cannot dry tomorrow’s clothes. Time decides everything.\n\nIn the eyes of God, it is inevitable. A choice, a life, not you know right and wrong, can escape.\n\nThere are two problems in life. The first is to find the problem, and the second is to solve it.\n\nOnly by seeing the future can there be a future.\n\nThe weather won’t always be good, and people won’t always have the upper hand.",
    "reference_list": "考点1: style, fun, signs推荐译为：派头、噱头、苗头，三个“头”字既押韵，又符合上海方言的习惯\n考点2: no comment推荐译为“不响”，“不响”源自上海话，包含了深藏不露，静观其变的心态和处事智慧\n考点3: human feelings推荐译为“人情”，更符合中国文化语境和习惯\n考点4: God推荐译为“老天爷”，更符合中文习惯\n考点5：Blossoms Shanghai 译为“《繁花》”\n考点6：Ah Bao 译为“阿宝”\n考点7：Jin Yucheng 译为“金宇澄”\n考点8：Night Tokyo 译为 “夜东京”\n考点9：Reiko 译为“玲子”\n考点10：Miss Wang 译为“汪小姐”",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "影视",
    "prompt_id": "31"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n引言\n\n       若将国家理解为一种持续形塑的地理—政治实体，俄罗斯或许是其最具“空间张力”与“疆界焦虑”的典型案例。它的地理构型——一块横跨欧亚、内嵌高寒、边界松散、腹地松散而边陲紧绷的地理体，构成了其历史上数次空间跃迁与战略重组的基础结构。尤其是东部空间的存在，既非自然延展的边缘带，也非文化逻辑上的文明边界，而是一种被历史、资源、意识形态和安全逻辑多重编码的战略“灰色地带”。本文将以远东空间为中心，透过地貌结构、生态分区、资源布设、人口迁移、战略话语与治理架构等多重视角，探讨俄罗斯如何在全球边界重组、极地通道开放、亚太秩序重构等背景下，试图通过语言与空间的重编码，赋予远东以从边陲转向枢纽的“合法性叙述”。\n一、地理范式的位移：从疆域控制到文明表述\n       俄罗斯作为“疆域国家”的原型，其空间逻辑从未真正建立在西欧式的“中心—边缘”二元结构之上。乌拉尔以东并非传统意义上的资源后方，而是“被临界化的内部”，一种结构上属于国家、一体性上却异质的存在。远东更非“边界之外”，而是一种“尚未完全被整合”的空间文化悬崖。\n      西伯利亚与远东的空间叙述，在俄罗斯民族—国家叙事中历经三次范式变迁：\n\t•\t殖民时代（17—19世纪）：以边疆开拓为主轴，远东成为毛皮、矿产等“资源—贡赋型空间”的对象。此阶段空间被客体化，语言中充斥“征服”“开发”“驯服”等表达，呈典型的殖民地语法结构；\n\t•\t苏维埃时期（20世纪）：转为“国家—空间一体化”的试验场，铁路、劳改营、军事工业等基础设施将远东“嵌入”国家权力网格，空间呈现工具理性；\n\t•\t后苏联时期（1991—至今）：则是“断裂与重建”并存，空间功能与国家意识间张力剧增，官方叙述与实际开发状况日益脱节。\n      这种“空间认知的断裂性”导致远东在国家语境中始终处于“再叙述—再失败”的循环：它既是战略必须，又是治理失败的象征。\n\n二、地貌分层与基础地理张力\n      从自然地理视角看，俄罗斯远东呈现出一种“双重空间逻辑”：地形复杂性与基础设施贫弱性并存，资源分布丰度与开发路径不匹配。中西伯利亚高原西侧为多年冻土带下沉区，地形松软且排水迟缓，导致基建成本持续居高；东西伯利亚山系纵深展开，雪线高度压低，滑坡与雪崩为常态，尤以堪察加、萨哈林岛为甚。滨海边疆区虽接壤中国，但因受季风影响、地形破碎、跨境河流沉积影响，交通运输结构呈“单向放射状”，难以形成区域闭环。2020年《俄罗斯极东交通枢纽指数报告》指出，远东内部交通平均联通度为全国最低，仅为中央联邦区的47.6%。此外，生态风险亦极为突出。气候变暖加剧冻土层深度年际波动，使得原本有限的施工季窗口进一步压缩。沿太平洋岸线出现多个气候交错带，例如鄂霍次克海沿岸可见从苔原到森林草原的急剧过渡，造成生态修复难度剧增。\n\n三、远东的资源政治与人口结构异质性\n      俄罗斯远东占据全国森林资源的32%、已探明金属矿产的27%、天然气与石油潜储的15%，然而其人口总量却不足全俄人口的6%，其中65%以上集中于阿穆尔河与滨海沿线城镇。地广人稀不仅造成资源开发的规模经济瓶颈，更在治理层面制造出“权力沉淀不足”的治理真空。“资源政治”因而成为远东治理核心语汇。近年兴起的“地区资源租金再分配机制”未能有效解决中心—地方之间的财政逆差，反而导致地方政府对资源开发的依附性增强而非减弱。以马加丹州为例，2018年该州财政中有83%来自金矿与铜矿税收，中央再分配比例不足18%。而在人口结构层面，远东呈现出高度“去均质化”的趋势：西伯利亚原住民族（如雅库特人、楚科奇人）与新迁入族群（如中国商人、中亚劳工）之间在空间使用、宗教信仰与生活方式上差异极大，民族认同的碎片化与边界感知的浮动性显著增强。\n\n四、地缘话语的再书写与边陲主体性的构造\n      近年来，随着中国“一带一路”倡议与俄“欧亚经济联盟”政策框架在远东交汇，官方话语逐渐由“边疆防御”转向“桥梁建设”。2019年《远东开发2035战略》中首次提出“通往太平洋的门户”“欧亚陆桥的前哨”这一叙述结构。但值得注意的是，这种战略语言并未完全脱离“边陲化想象”，而更像是中心在缺席有效结构性政策支持时对边陲“象征性赋能”的补偿行为。换言之，“远东的枢纽性”更多停留在语言与文件层面，其物理现实与技术结构仍表现出“边缘封闭性”。在这一点上，俄罗斯学者费多罗夫指出：“远东被定位为国家—文明接壤地，而非文明腹地，这一定位本身即暗含其主体性缺失。”\n\n\n\n",
    "ori_text": "\n\n引言\n\n       若将国家理解为一种持续形塑的地理—政治实体，俄罗斯或许是其最具“空间张力”与“疆界焦虑”的典型案例。它的地理构型——一块横跨欧亚、内嵌高寒、边界松散、腹地松散而边陲紧绷的地理体，构成了其历史上数次空间跃迁与战略重组的基础结构。尤其是东部空间的存在，既非自然延展的边缘带，也非文化逻辑上的文明边界，而是一种被历史、资源、意识形态和安全逻辑多重编码的战略“灰色地带”。本文将以远东空间为中心，透过地貌结构、生态分区、资源布设、人口迁移、战略话语与治理架构等多重视角，探讨俄罗斯如何在全球边界重组、极地通道开放、亚太秩序重构等背景下，试图通过语言与空间的重编码，赋予远东以从边陲转向枢纽的“合法性叙述”。\n一、地理范式的位移：从疆域控制到文明表述\n       俄罗斯作为“疆域国家”的原型，其空间逻辑从未真正建立在西欧式的“中心—边缘”二元结构之上。乌拉尔以东并非传统意义上的资源后方，而是“被临界化的内部”，一种结构上属于国家、一体性上却异质的存在。远东更非“边界之外”，而是一种“尚未完全被整合”的空间文化悬崖。\n      西伯利亚与远东的空间叙述，在俄罗斯民族—国家叙事中历经三次范式变迁：\n\t•\t殖民时代（17—19世纪）：以边疆开拓为主轴，远东成为毛皮、矿产等“资源—贡赋型空间”的对象。此阶段空间被客体化，语言中充斥“征服”“开发”“驯服”等表达，呈典型的殖民地语法结构；\n\t•\t苏维埃时期（20世纪）：转为“国家—空间一体化”的试验场，铁路、劳改营、军事工业等基础设施将远东“嵌入”国家权力网格，空间呈现工具理性；\n\t•\t后苏联时期（1991—至今）：则是“断裂与重建”并存，空间功能与国家意识间张力剧增，官方叙述与实际开发状况日益脱节。\n      这种“空间认知的断裂性”导致远东在国家语境中始终处于“再叙述—再失败”的循环：它既是战略必须，又是治理失败的象征。\n\n二、地貌分层与基础地理张力\n      从自然地理视角看，俄罗斯远东呈现出一种“双重空间逻辑”：地形复杂性与基础设施贫弱性并存，资源分布丰度与开发路径不匹配。中西伯利亚高原西侧为多年冻土带下沉区，地形松软且排水迟缓，导致基建成本持续居高；东西伯利亚山系纵深展开，雪线高度压低，滑坡与雪崩为常态，尤以堪察加、萨哈林岛为甚。滨海边疆区虽接壤中国，但因受季风影响、地形破碎、跨境河流沉积影响，交通运输结构呈“单向放射状”，难以形成区域闭环。2020年《俄罗斯极东交通枢纽指数报告》指出，远东内部交通平均联通度为全国最低，仅为中央联邦区的47.6%。此外，生态风险亦极为突出。气候变暖加剧冻土层深度年际波动，使得原本有限的施工季窗口进一步压缩。沿太平洋岸线出现多个气候交错带，例如鄂霍次克海沿岸可见从苔原到森林草原的急剧过渡，造成生态修复难度剧增。\n\n三、远东的资源政治与人口结构异质性\n      俄罗斯远东占据全国森林资源的32%、已探明金属矿产的27%、天然气与石油潜储的15%，然而其人口总量却不足全俄人口的6%，其中65%以上集中于阿穆尔河与滨海沿线城镇。地广人稀不仅造成资源开发的规模经济瓶颈，更在治理层面制造出“权力沉淀不足”的治理真空。“资源政治”因而成为远东治理核心语汇。近年兴起的“地区资源租金再分配机制”未能有效解决中心—地方之间的财政逆差，反而导致地方政府对资源开发的依附性增强而非减弱。以马加丹州为例，2018年该州财政中有83%来自金矿与铜矿税收，中央再分配比例不足18%。而在人口结构层面，远东呈现出高度“去均质化”的趋势：西伯利亚原住民族（如雅库特人、楚科奇人）与新迁入族群（如中国商人、中亚劳工）之间在空间使用、宗教信仰与生活方式上差异极大，民族认同的碎片化与边界感知的浮动性显著增强。\n\n四、地缘话语的再书写与边陲主体性的构造\n      近年来，随着中国“一带一路”倡议与俄“欧亚经济联盟”政策框架在远东交汇，官方话语逐渐由“边疆防御”转向“桥梁建设”。2019年《远东开发2035战略》中首次提出“通往太平洋的门户”“欧亚陆桥的前哨”这一叙述结构。但值得注意的是，这种战略语言并未完全脱离“边陲化想象”，而更像是中心在缺席有效结构性政策支持时对边陲“象征性赋能”的补偿行为。换言之，“远东的枢纽性”更多停留在语言与文件层面，其物理现实与技术结构仍表现出“边缘封闭性”。在这一点上，俄罗斯学者费多罗夫指出：“远东被定位为国家—文明接壤地，而非文明腹地，这一定位本身即暗含其主体性缺失。”\n\n\n\n",
    "reference_list": "考点1：“资源后方”推荐译为”resource hinterland”，\n考点2：“权力沉淀不足”推荐译为“lack of power consolidation”，因为根据原文，此处指的是治理能力低下\n考点3：“疆域国家”可以译为”territory country”，\n考点4：“苏维埃时期”推荐译为”Soviet era”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "195"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\"Climate change and weather-related hazards are known to adversely impact environmental determinants of human health such as air quality, water quality, food systems, and the built environment [1]. An additional 250,000 annual climate-related deaths are expected globally between 2030 and 2050 due to malnutrition, malaria, diarrhea, and heat stress—most of these deaths are predicted to occur in low- and middle-income countries (LMICs) [2]. Compounded with socio-economic challenges, climate change is likely to pose the greatest consequences to those in low-income settings, who are least likely to contribute to climate change [3, 4].\n\nLow-income urban communities, especially those in LMICs, are vulnerable to climate change. These populations have less access to services, lower-quality and infrequently maintained infrastructure, and degraded natural environments and ecosystems as compared to urban areas in high-income communities/countries [5]. These inequalities in services, infrastructure, and environmental capital are a product of historical and systemic exploitation by the global north and further exacerbated by socio-economic marginalization and insufficient social welfare funding [6,7,8,9,10].\n\nThere has been an increase in urban informal settlements due to rapid and unplanned urbanization, especially in Asia and sub-Saharan Africa [11]. Generally located in more inhospitable parts of urban areas, informal settlements have no tenure security, are cut off from formal, basic services, and housing infrastructure may not comply with current planning and building regulations [12]. Urban poor communities and residents of informal settlements are vulnerable to a variety of environmental disturbances but unlike higher income settings, lack consistent and dependable resources to cope with such disturbances [5]. Global estimates from 2020 suggest over one billion people are living in either slums or other informal settlements and currently lack adequate and affordable housing. The number is expected to grow by 200 million or 20% by 2030 [13]. With a worsening climate, there is an urgent need to build resilience among these vulnerable populations [14].\n\nResilient households and communities are better able to cope with shocks and stressors—disruptive events or the risk of such events [15]—which leads to more efficient and timely recovery [16]. Resilience is the capacity of a system to cope with, absorb, and adapt to a changing environment and resulting disturbances, while also incorporating the ability to reorganize, learn from past experiences, and transform for future challenges [17,18,19]. Resilience is often considered in terms of the following capacities: “(1) absorptive capacity—the ability to minimize exposure to shocks and recover quickly when exposed; (2) adaptive capacity—the ability to make informed choices about alternative livelihood strategies based on changing conditions; and (3) transformative capacity—system-level enabling conditions for lasting resilience” [19]. There is a growing interest in building resilience among urban households and informal settlements [20]. However, there is limited evidence for resilience-building strategies, especially among urban households in LMICs and informal settlements.\n\nA reliable and valid resilience measurement tool is needed to track progress and generate evidence towards building resilience in the face of environmental disturbances. However, resilience is a latent construct, meaning it is not directly observable or quantifiable, posing measurement challenges [21]. Existing measures often rely on direct observation, overlooking the latent nature of resilience [22]. While there is a strong theoretical foundation for resilience measurement and conceptualization, resilience frameworks require additional specificity to be applied for measures. This poses a challenge as resilience is context-specific, influenced by the system of interest (resilience of what), relevant shocks/stressors (resilience to what), and the population and cultural context (resilience by whom) [23]. There is little guidance on how to transform generalized frameworks into context-specific and field applicable tools/methods such as surveys and quantitative analyses. Limited resilience measurement data impedes the ability to test underlying theory and assess current programmatic approaches to building resilience [24]. Among the limited practical tools available, many have not retained the theoretical underpinnings of resilience measurement, often conflating resilience with concepts like vulnerability and mere counting of assets [25,26,27,28].\n\nTo address these challenges, we developed and validated scales measuring urban household resilience to environmental shocks/stressors in LMICs. The scales were internally validated using additionally collected data on topics such as financial satisfaction and community satisfaction and safety. The scales capture the latent construct of resilience through survey questions that assess the ability to cope, recover, and overcome relevant disturbances. This paper details the process from survey drafting to scale development and psychometric evaluation.\n\nOur scales were developed within the ongoing Revitalizing Informal Settlements and their Environments (RISE) study, a randomized control trial across 24 informal settlements in Makassar, Indonesia and Suva, Fiji. RISE adopts a water-sensitive approach to site-specific water and sanitation infrastructure, aiming to reduce flooding hazards and fecal contamination and improve human health (see more on study design in Leder et al.) [29]. While not explicitly designed to improve household resilience, the participatory design approach has the potential to affect resilience through changes in social capital [30], and infrastructural interventions can affect resilience through water supply diversification and flood management [31, 32]. Resilience data produced by our study serves not only to test a previously developed theoretical resilience framework[25] but will also be used to assess the effect of the RISE program on resilience among participating informal settlements.\n\nBahasa Indonesia and iTaukei (Fijian) translations of the abstract are provided in Additional File 1.\n\nMethods\n\nWe developed three separate scales to measure economic, environmental, and social urban household resilience to environmental disturbances. We used factor analysis and item response theory (IRT) methods to evaluate the factor structure and measurement properties of the scales. Additionally, we assessed the scales’ internal validity and reliability.\n\nThe RISE trial\n\nOur study was conducted within RISE study, an on-going randomized control trial being conducted across 24 informal settlements in Suva, Fiji and Makassar, Indonesia with six intervention and six control settlements in each country (inception in 2017) (Additional file 1: Fig S1). Specifics of the intervention can be found in Leder et al., Francis et al., and the RISE Knowledge Product Series [29, 33,34,35,36]. Briefly, RISE uses a water-sensitive approach to participatory design of site-specific, modular, and decentralized water and sanitation infrastructural interventions. The central hypothesis of RISE is that these water-sensitive interventions will decrease environmental fecal contamination and flooding hazards, resulting overall in reduced human exposure to fecal contamination, and thus, improved human and ecological health and well-being. The infrastructural intervention includes wet pods (toilets, hand basins, rainwater tanks); pressure sewer systems; and wastewater treatment via constructed wetlands and biofilters. Stormwater management features revitalized drains, rain gardens, and permeable pavement, while flood mitigation includes backflow prevention, terrain modification, and protection walls. Water security is enhanced through municipal connections, rainwater harvesting, and well protection, with raised pathways improving road access in flood-prone areas.\n\nHousehold resilience scale development within the RISE study\n\nTo measure potential impacts of the RISE intervention on household resilience, we developed survey questions that were embedded in the September 2022 household survey (prior to the start of intervention build), which we refer to as the “main” survey throughout this paper. The rest of the methods section details our process on survey question development, data collection, scale development, further scale evaluation, and scale validation, which are in line with best practices [22, 37].\n\nDevelopment of an urban household resilience framework for LMICs\n\nFor our a priori framework, we adapted the household resilience measurement framework developed in Serfillipi et al. [38]. We chose this framework as it was well grounded in resilience theory, being the result of a literature review and synthesis of 13 resilience frameworks [38]. We removed elements that would only pertain to rural or agricultural settings to create an adapted framework that would pertain to an urban environment. We further adapted the framework to make it more context-specific, based on the results of our scoping review of household and community resilience to environmental shocks and stressors in coastal urban environments in LMICs [25]. Because this framework consisted of three domains (economic, environmental, and social resilience), we chose to develop three separate resilience measurement scales, one for each of the three domains. While resilience is inherently multidimensional, with economic, environmental, and social resilience interacting to shape a household’s overall capacity to cope with disturbances, we developed separate measurement scales for each to enable independent assessment of the factors influencing each aspect of resilience.\n\nSurvey question development\n\nWe designed the resilience module survey questions based on an adapted framework for urban household resilience measurement in LMICs, which we developed and published through a scoping review [25]. This framework guided the selection and development of survey items to capture key sub-domains, capitals, and capacities relevant to resilience in these settings. The majority of survey items were newly developed based on this framework, and five items were adapted from the regularly deployed main RISE household survey. For example, the Household Water Insecurity Experience (HWISE) scale [39], which consists of four survey questions, was already present in the main RISE survey and was therefore also used within the environmental resilience domain questions. Table S1 details the preliminary survey questions by resilience framework domain and sub-domain, indicating whether they were newly designed or adapted from the existing RISE survey. The surveys were translated into the local languages (Bahasa Indonesia for Indonesia and iTaukei for Fiji) and back-translated to English to ensure accuracy and consistency (Additional File 1: Table S1).\n\nWe carried out cognitive interviews with our new survey questions to identify and revise questions that may be unclear, ambiguous, difficult, or not understood as intended [40]. These cognitive interviews were also conducted to ensure the survey questions reflected the experiences of the current study population, and to identify potentially irrelevant questions and revise questions to better fit the context (see Additional file 1: Table S1). The goal of cognitive interviews is to reveal issues that respondents might have with survey item content or context, understanding of the items, and retrieving and integrating personal information and experiences to answer the item. Cognitive interviews are also used to reveal issues regarding sequencing, item length, sensitivity, problematic or irrelevant response options, inappropriate vocabulary, and temporal and spatial confusion [41].\n\nWe conducted six cognitive interviews with our Indonesian team members virtually via Zoom (due to COVID-19 restrictions) and nine cognitive interviews with our team members in Fiji (in person) using our first draft of survey items. During the interviews, we asked each new survey question to a staff member, recorded their response, and then followed up with additional questions to better understand how they arrived at their answer. While it is recommended to pilot survey questions with a subset of the study population, we opted to pilot our questions with staff members to minimize survey fatigue among community members. Prior to the interviews, we met with all participating in-country team members to explain the purpose of the interviews; we instructed the team members to answer the survey questions as if they were members of the RISE communities. The RISE team members that were chosen to participate in these cognitive interviews are residents of Indonesia and Fiji, and many have been working with RISE for several years. The chosen staff members have the background knowledge and cultural context of their respective countries and were able to advise on the appropriateness of the question wording, vocabulary, and translations (see Additional file 2). Survey items were revised after approximately every three interviews. After completing all the interviews, we reconvened with the RISE team members and went through each revised survey question to discuss any outstanding issues before finalizing the survey items.\"",
    "ori_text": "\"Climate change and weather-related hazards are known to adversely impact environmental determinants of human health such as air quality, water quality, food systems, and the built environment [1]. An additional 250,000 annual climate-related deaths are expected globally between 2030 and 2050 due to malnutrition, malaria, diarrhea, and heat stress—most of these deaths are predicted to occur in low- and middle-income countries (LMICs) [2]. Compounded with socio-economic challenges, climate change is likely to pose the greatest consequences to those in low-income settings, who are least likely to contribute to climate change [3, 4].\n\nLow-income urban communities, especially those in LMICs, are vulnerable to climate change. These populations have less access to services, lower-quality and infrequently maintained infrastructure, and degraded natural environments and ecosystems as compared to urban areas in high-income communities/countries [5]. These inequalities in services, infrastructure, and environmental capital are a product of historical and systemic exploitation by the global north and further exacerbated by socio-economic marginalization and insufficient social welfare funding [6,7,8,9,10].\n\nThere has been an increase in urban informal settlements due to rapid and unplanned urbanization, especially in Asia and sub-Saharan Africa [11]. Generally located in more inhospitable parts of urban areas, informal settlements have no tenure security, are cut off from formal, basic services, and housing infrastructure may not comply with current planning and building regulations [12]. Urban poor communities and residents of informal settlements are vulnerable to a variety of environmental disturbances but unlike higher income settings, lack consistent and dependable resources to cope with such disturbances [5]. Global estimates from 2020 suggest over one billion people are living in either slums or other informal settlements and currently lack adequate and affordable housing. The number is expected to grow by 200 million or 20% by 2030 [13]. With a worsening climate, there is an urgent need to build resilience among these vulnerable populations [14].\n\nResilient households and communities are better able to cope with shocks and stressors—disruptive events or the risk of such events [15]—which leads to more efficient and timely recovery [16]. Resilience is the capacity of a system to cope with, absorb, and adapt to a changing environment and resulting disturbances, while also incorporating the ability to reorganize, learn from past experiences, and transform for future challenges [17,18,19]. Resilience is often considered in terms of the following capacities: “(1) absorptive capacity—the ability to minimize exposure to shocks and recover quickly when exposed; (2) adaptive capacity—the ability to make informed choices about alternative livelihood strategies based on changing conditions; and (3) transformative capacity—system-level enabling conditions for lasting resilience” [19]. There is a growing interest in building resilience among urban households and informal settlements [20]. However, there is limited evidence for resilience-building strategies, especially among urban households in LMICs and informal settlements.\n\nA reliable and valid resilience measurement tool is needed to track progress and generate evidence towards building resilience in the face of environmental disturbances. However, resilience is a latent construct, meaning it is not directly observable or quantifiable, posing measurement challenges [21]. Existing measures often rely on direct observation, overlooking the latent nature of resilience [22]. While there is a strong theoretical foundation for resilience measurement and conceptualization, resilience frameworks require additional specificity to be applied for measures. This poses a challenge as resilience is context-specific, influenced by the system of interest (resilience of what), relevant shocks/stressors (resilience to what), and the population and cultural context (resilience by whom) [23]. There is little guidance on how to transform generalized frameworks into context-specific and field applicable tools/methods such as surveys and quantitative analyses. Limited resilience measurement data impedes the ability to test underlying theory and assess current programmatic approaches to building resilience [24]. Among the limited practical tools available, many have not retained the theoretical underpinnings of resilience measurement, often conflating resilience with concepts like vulnerability and mere counting of assets [25,26,27,28].\n\nTo address these challenges, we developed and validated scales measuring urban household resilience to environmental shocks/stressors in LMICs. The scales were internally validated using additionally collected data on topics such as financial satisfaction and community satisfaction and safety. The scales capture the latent construct of resilience through survey questions that assess the ability to cope, recover, and overcome relevant disturbances. This paper details the process from survey drafting to scale development and psychometric evaluation.\n\nOur scales were developed within the ongoing Revitalizing Informal Settlements and their Environments (RISE) study, a randomized control trial across 24 informal settlements in Makassar, Indonesia and Suva, Fiji. RISE adopts a water-sensitive approach to site-specific water and sanitation infrastructure, aiming to reduce flooding hazards and fecal contamination and improve human health (see more on study design in Leder et al.) [29]. While not explicitly designed to improve household resilience, the participatory design approach has the potential to affect resilience through changes in social capital [30], and infrastructural interventions can affect resilience through water supply diversification and flood management [31, 32]. Resilience data produced by our study serves not only to test a previously developed theoretical resilience framework[25] but will also be used to assess the effect of the RISE program on resilience among participating informal settlements.\n\nBahasa Indonesia and iTaukei (Fijian) translations of the abstract are provided in Additional File 1.\n\nMethods\n\nWe developed three separate scales to measure economic, environmental, and social urban household resilience to environmental disturbances. We used factor analysis and item response theory (IRT) methods to evaluate the factor structure and measurement properties of the scales. Additionally, we assessed the scales’ internal validity and reliability.\n\nThe RISE trial\n\nOur study was conducted within RISE study, an on-going randomized control trial being conducted across 24 informal settlements in Suva, Fiji and Makassar, Indonesia with six intervention and six control settlements in each country (inception in 2017) (Additional file 1: Fig S1). Specifics of the intervention can be found in Leder et al., Francis et al., and the RISE Knowledge Product Series [29, 33,34,35,36]. Briefly, RISE uses a water-sensitive approach to participatory design of site-specific, modular, and decentralized water and sanitation infrastructural interventions. The central hypothesis of RISE is that these water-sensitive interventions will decrease environmental fecal contamination and flooding hazards, resulting overall in reduced human exposure to fecal contamination, and thus, improved human and ecological health and well-being. The infrastructural intervention includes wet pods (toilets, hand basins, rainwater tanks); pressure sewer systems; and wastewater treatment via constructed wetlands and biofilters. Stormwater management features revitalized drains, rain gardens, and permeable pavement, while flood mitigation includes backflow prevention, terrain modification, and protection walls. Water security is enhanced through municipal connections, rainwater harvesting, and well protection, with raised pathways improving road access in flood-prone areas.\n\nHousehold resilience scale development within the RISE study\n\nTo measure potential impacts of the RISE intervention on household resilience, we developed survey questions that were embedded in the September 2022 household survey (prior to the start of intervention build), which we refer to as the “main” survey throughout this paper. The rest of the methods section details our process on survey question development, data collection, scale development, further scale evaluation, and scale validation, which are in line with best practices [22, 37].\n\nDevelopment of an urban household resilience framework for LMICs\n\nFor our a priori framework, we adapted the household resilience measurement framework developed in Serfillipi et al. [38]. We chose this framework as it was well grounded in resilience theory, being the result of a literature review and synthesis of 13 resilience frameworks [38]. We removed elements that would only pertain to rural or agricultural settings to create an adapted framework that would pertain to an urban environment. We further adapted the framework to make it more context-specific, based on the results of our scoping review of household and community resilience to environmental shocks and stressors in coastal urban environments in LMICs [25]. Because this framework consisted of three domains (economic, environmental, and social resilience), we chose to develop three separate resilience measurement scales, one for each of the three domains. While resilience is inherently multidimensional, with economic, environmental, and social resilience interacting to shape a household’s overall capacity to cope with disturbances, we developed separate measurement scales for each to enable independent assessment of the factors influencing each aspect of resilience.\n\nSurvey question development\n\nWe designed the resilience module survey questions based on an adapted framework for urban household resilience measurement in LMICs, which we developed and published through a scoping review [25]. This framework guided the selection and development of survey items to capture key sub-domains, capitals, and capacities relevant to resilience in these settings. The majority of survey items were newly developed based on this framework, and five items were adapted from the regularly deployed main RISE household survey. For example, the Household Water Insecurity Experience (HWISE) scale [39], which consists of four survey questions, was already present in the main RISE survey and was therefore also used within the environmental resilience domain questions. Table S1 details the preliminary survey questions by resilience framework domain and sub-domain, indicating whether they were newly designed or adapted from the existing RISE survey. The surveys were translated into the local languages (Bahasa Indonesia for Indonesia and iTaukei for Fiji) and back-translated to English to ensure accuracy and consistency (Additional File 1: Table S1).\n\nWe carried out cognitive interviews with our new survey questions to identify and revise questions that may be unclear, ambiguous, difficult, or not understood as intended [40]. These cognitive interviews were also conducted to ensure the survey questions reflected the experiences of the current study population, and to identify potentially irrelevant questions and revise questions to better fit the context (see Additional file 1: Table S1). The goal of cognitive interviews is to reveal issues that respondents might have with survey item content or context, understanding of the items, and retrieving and integrating personal information and experiences to answer the item. Cognitive interviews are also used to reveal issues regarding sequencing, item length, sensitivity, problematic or irrelevant response options, inappropriate vocabulary, and temporal and spatial confusion [41].\n\nWe conducted six cognitive interviews with our Indonesian team members virtually via Zoom (due to COVID-19 restrictions) and nine cognitive interviews with our team members in Fiji (in person) using our first draft of survey items. During the interviews, we asked each new survey question to a staff member, recorded their response, and then followed up with additional questions to better understand how they arrived at their answer. While it is recommended to pilot survey questions with a subset of the study population, we opted to pilot our questions with staff members to minimize survey fatigue among community members. Prior to the interviews, we met with all participating in-country team members to explain the purpose of the interviews; we instructed the team members to answer the survey questions as if they were members of the RISE communities. The RISE team members that were chosen to participate in these cognitive interviews are residents of Indonesia and Fiji, and many have been working with RISE for several years. The chosen staff members have the background knowledge and cultural context of their respective countries and were able to advise on the appropriateness of the question wording, vocabulary, and translations (see Additional file 2). Survey items were revised after approximately every three interviews. After completing all the interviews, we reconvened with the RISE team members and went through each revised survey question to discuss any outstanding issues before finalizing the survey items.\"",
    "reference_list": "考点1： \"environmental determinants of human health\" 应译为 \"人类健康的环境决定因素\"  \n考点2： \"Compounded with\" 应译为 \"与…… 叠加\" / \"与……交织加剧\"  \n考点3： \"historical and systemic exploitation by the global north\" 应译为 \"全球北方国家的历史性和系统性剥削\"  \n考点4： \"tenure security\" 应译为 \"居住权保障\" / \"土地保有权保障\"  \n考点5： \"shocks and stressors\" 应译为 \"冲击与压力源\"  \n考点6： \"absorptive capacity, adaptive capacity, transformative capacity\" 应译为 \"吸收能力、适应能力、转型能力\"  \n考点7： \"latent construct\" 应译为 \"潜在构念\"  \n考点8： \"wet pods\" 应译为 \"湿舱\" / \"集成式卫浴单元\"  \n考点9： \"constructed wetlands and biofilters\" 应译为 \"人工湿地和生物滤池\"  \n考点10： \"scoping review\" 应译为 \"范围综述\" / \"范畴综述\"  \n考点11： \"back-translated to English\" 应译为 \"回译成英文\"  \n考点12： \"factor analysis and item response theory (IRT)\" 应译为 \"因子分析与项目反应理论\"  \n考点13： \"site-specific water and sanitation infrastructure\" 应译为 \"场地特定的水与卫生基础设施\"  \n考点14： \"flood mitigation\" 应译为 \"防洪缓解措施\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "98"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n在新能源汽车的浪潮中，小米汽车凭借其独特的雷式营销法则，成功吸引了无数消费者的目光。其背后的品牌故事、市场洞察、产品策略以及营销策略，都堪称教科书级别的营销案例。\n一、品牌背景\n1.亮眼数据彰显实力\n小米SU7自开订以来，以惊人的速度席卷市场。开订27分钟，大定突破5万台；上市24小时，大定更是高达88898台。短短时间内，超过10万人大订，锁单量已超过4万单。更为难得的是，从上市到第1批交付，小米仅用了5天时间，充分展现了其强大的营销能力和市场号召力。\n2.品牌设计\n小米SU7以C级高性能生态科技轿车的定位，瞄准了那些喜欢先进科技、有品位、热爱生活的消费者。品牌口号“人车合一我心澎湃”更是直击人心，让人对这款车充满期待。而50万以内Z好看、Z好开、Z智慧的承诺，以及全系长续航、小米全栈自研智驾技术等亮点，更是让它在众多竞品中脱颖而出。\n二、综合洞察\n1.消费者洞察：年轻、有品位、热爱生活\n通过深入洞察消费者需求，小米汽车发现年轻消费者占据了市场的较大比例。他们追求个性化和品质生活，希望通过爱车彰显自己的品味和态度。因此，小米汽车将目标用户定位为喜欢先进科技、有品位、热爱生活的年轻人。\n2.市场洞察：新能源汽车市场崛起\n随着汽车年度总销量的不断攀升，燃油车市场持续萎缩，而新能源车市场则呈现出强劲的增长势头。在这一背景下，小米汽车凭借其产品力和营销策略，成功抓住了市场机遇。\n3.消费趋势：年轻消费者偏好新势力品牌\n在买车预算为30-50万的用户中，新势力品牌备受青睐。这些用户更在意外观和智慧化程度，而小米汽车正是凭借其在这些方面的大力宣传赢得了市场的认可。\n三、产品策略\n1.定价策略：锚定价格，让用户感觉占了便宜\n小米汽车在产品定价上采用了“锚定价格”的策略。通过对比竞品价格，为消费者提供了一个颇具竞争力的价格区间。同时，通过一系列优惠活动和赠品政策，让消费者感觉占到了便宜，从而提升了消费意愿。\n2.用户需求洞察：打造差异化产品\n小米汽车洞察到年轻用户对于“既要又要还要”的痛点需求，将品牌定位为“50万以内Z好看、Z好开、Z智慧的高品质轿车”。这种多特性捆绑的方式打造了品牌差异化的优势，吸引了更广泛的目标受众。\n四、营销策略\n1.路透式营销：制造悬念\n小米汽车在营销上善于运用路透式策略，提前预热并制造悬念。从官宣造车到技术发布会预热，小米汽车始终保持着较高的市场热度。这种营销方式激发了消费者的好奇心和消费欲望，成功提升了品牌知名度和话题度。\n2.小米式文案：数字讲故事\n小米汽车擅长用数字讲故事，将复杂的概念转化为简单易懂的语言。通过一系列直观、抓眼球的数据，让消费者秒懂产品魅力和价值。这种文案风格不仅增强了消费者的认知度，还提升了品牌的传播效果。\n3.雷式营销：借势对标\n雷军作为小米汽车的核心人物，其独特的营销策略被网友称为“雷式营销”。通过找对标、借势营销的方式，小米汽车迅速建立了品牌心智。同时，其局部功能对标的策略，总是能成功吸引消费者的目光。\n4.打造大IP男主：雷军亲和力营销\n小米CEO雷军凭借其个人魅力和影响力为小米汽车造势。他亲自参与第1批交付仪式，为第1批车主开车门，并利用明星效应打造品牌话题度。这种亲和力营销不仅增强了消费者与品牌之间的情感联系，还提升了品牌的美誉度和忠诚度。\n五、分析点评\n小米汽车SU7轿跑的属性，决定了其更接近于年轻人的大玩具而非家庭用车。因此，品牌营销过程中需要深入分析真实消费者的预期，并理解他们根本的动机，通过提供超预期的产品和服务，才能使品牌赢得市场并树立了良好的品牌形象。",
    "ori_text": "在新能源汽车的浪潮中，小米汽车凭借其独特的雷式营销法则，成功吸引了无数消费者的目光。其背后的品牌故事、市场洞察、产品策略以及营销策略，都堪称教科书级别的营销案例。\n一、品牌背景\n1.亮眼数据彰显实力\n小米SU7自开订以来，以惊人的速度席卷市场。开订27分钟，大定突破5万台；上市24小时，大定更是高达88898台。短短时间内，超过10万人大订，锁单量已超过4万单。更为难得的是，从上市到第1批交付，小米仅用了5天时间，充分展现了其强大的营销能力和市场号召力。\n2.品牌设计\n小米SU7以C级高性能生态科技轿车的定位，瞄准了那些喜欢先进科技、有品位、热爱生活的消费者。品牌口号“人车合一我心澎湃”更是直击人心，让人对这款车充满期待。而50万以内Z好看、Z好开、Z智慧的承诺，以及全系长续航、小米全栈自研智驾技术等亮点，更是让它在众多竞品中脱颖而出。\n二、综合洞察\n1.消费者洞察：年轻、有品位、热爱生活\n通过深入洞察消费者需求，小米汽车发现年轻消费者占据了市场的较大比例。他们追求个性化和品质生活，希望通过爱车彰显自己的品味和态度。因此，小米汽车将目标用户定位为喜欢先进科技、有品位、热爱生活的年轻人。\n2.市场洞察：新能源汽车市场崛起\n随着汽车年度总销量的不断攀升，燃油车市场持续萎缩，而新能源车市场则呈现出强劲的增长势头。在这一背景下，小米汽车凭借其产品力和营销策略，成功抓住了市场机遇。\n3.消费趋势：年轻消费者偏好新势力品牌\n在买车预算为30-50万的用户中，新势力品牌备受青睐。这些用户更在意外观和智慧化程度，而小米汽车正是凭借其在这些方面的大力宣传赢得了市场的认可。\n三、产品策略\n1.定价策略：锚定价格，让用户感觉占了便宜\n小米汽车在产品定价上采用了“锚定价格”的策略。通过对比竞品价格，为消费者提供了一个颇具竞争力的价格区间。同时，通过一系列优惠活动和赠品政策，让消费者感觉占到了便宜，从而提升了消费意愿。\n2.用户需求洞察：打造差异化产品\n小米汽车洞察到年轻用户对于“既要又要还要”的痛点需求，将品牌定位为“50万以内Z好看、Z好开、Z智慧的高品质轿车”。这种多特性捆绑的方式打造了品牌差异化的优势，吸引了更广泛的目标受众。\n四、营销策略\n1.路透式营销：制造悬念\n小米汽车在营销上善于运用路透式策略，提前预热并制造悬念。从官宣造车到技术发布会预热，小米汽车始终保持着较高的市场热度。这种营销方式激发了消费者的好奇心和消费欲望，成功提升了品牌知名度和话题度。\n2.小米式文案：数字讲故事\n小米汽车擅长用数字讲故事，将复杂的概念转化为简单易懂的语言。通过一系列直观、抓眼球的数据，让消费者秒懂产品魅力和价值。这种文案风格不仅增强了消费者的认知度，还提升了品牌的传播效果。\n3.雷式营销：借势对标\n雷军作为小米汽车的核心人物，其独特的营销策略被网友称为“雷式营销”。通过找对标、借势营销的方式，小米汽车迅速建立了品牌心智。同时，其局部功能对标的策略，总是能成功吸引消费者的目光。\n4.打造大IP男主：雷军亲和力营销\n小米CEO雷军凭借其个人魅力和影响力为小米汽车造势。他亲自参与第1批交付仪式，为第1批车主开车门，并利用明星效应打造品牌话题度。这种亲和力营销不仅增强了消费者与品牌之间的情感联系，还提升了品牌的美誉度和忠诚度。\n五、分析点评\n小米汽车SU7轿跑的属性，决定了其更接近于年轻人的大玩具而非家庭用车。因此，品牌营销过程中需要深入分析真实消费者的预期，并理解他们根本的动机，通过提供超预期的产品和服务，才能使品牌赢得市场并树立了良好的品牌形象。",
    "reference_list": "考点1：”雷式营销法则”推荐译为“The Lei Jun marketing playbook”，翻译成 \"playbook\" (战术手册) 能更形象地表达其系统性和策略性，更显专业。\n考点2：“大定”应该译为“firm orders”，是中国汽车销售行业的特定术语，指已支付不可退定金的订单，区别于意向金“小定”。不能简单翻译成 \"pre-orders\" 或 \"orders\"。\n考点3：”锁单量“是专业术语，应该译为“locked-in orders”，“锁单”指客户确认了具体配置、订单不可再修改，并进入生产队列的状态。\n考点4：”Z好看、Z好开、Z智慧”推荐译为“The best-looking, the best-to-drive, and the smartest”。\n考点5： “全栈自研智驾技术”是一个技术术语组合，应该译为“full-stack, in-house developed intelligent driving technology”，全栈 (full-stack)源自软件开发，自研 (in-house developed)指自主研发，智驾 (intelligent driving)是智能驾驶的缩写。\n考点6： “既要又要还要”的痛点需求推荐译为“the \"want-it-all\" pain point”。\n考点7：”打造大IP男主“推荐译为“cultivating a major IP persona”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "33"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n Governing Law and Dispute Resolution\n1. The formation of this Contract, its validity, interpretation, execution and settlement of disputes in connection herewith shall be governed by the laws of the People's Republic of China (\"PRC\"), but in the event that there is no published and publicly available law in the PRC governing a particular matter relating to this Contract, reference shall be made to general international commercial practices.\n2. If, after the signing of this Agreement, the Chinese government either atthe State, provincial, municipal or local level adopts any new law, regulation,decree or rule, amends or repeals any provision of any law, regulation,decree or rule, or adopts any different interpretation or method of implementation of any law, regulation, decree or rule, which contravenes this Agreement or which materially and adversely affects a party's economic benefit under this Agreement, then upon written notice thereof from the affected party to the other Party, the Parties shall promptly consult and decide whether (i) to continue to implement this Agreement in accordance with the original provisions thereof as per the relevant provisions of the Contract Law of the People's Republic of China;or (ii) to effectuate\nnecessary adjustments in order to preserve each Party's economic benefit under this Agreement on a basis no less favorable than the economic benefit it would have received if such law, regulation, decree or rule had not been adopted, amended, repealed or so interpreted or implemented.3. Any controversy or claim arising out of, or relating to, this Agreemen shall be settled under the Rules of Conciliation and Arbitration of the International Chamber of Commerce by three(3)arbitrators appointed in accordance with said Rules. The place of Arbitration shall be Hong Kong The language of Arbitration shall be English.In no event shall any arbitration award provide a remedy beyond those permitted under these Terms and Conditions, and any award providing a remedy beyond those permitted under this Agreement shall not be confirmed, no presumption of validity shall attach, and such award shall be vacated..4. Any dispute arising from, out of, or in connection with, this Agreement shall be settled by the Parties through friendly consultation. Such consultation shall begin immediately after one Party has delivered to the other party a written request for such consultation. If the dispute cannot be settled through consultation within thirty (30) days after such notice is given.the Parties shall submit the dispute to China International Trade Arbitration Committee, Shanghai Branch(\"Arbitration Institute\") to be arbitrated according to its rules and regulations.\nThere shall be three (3) arbitrators. Party A and Party B shall appoint one (1)arbitrator each. The two arbitrators shall be selected within thirty (30) days after giving or receiving of the request for arbitration. The chairman of the Arbitration Institute shall select the third arbitrator. If a Party fails to appoint an arbitrator within thirty (30) days after the other Party has appointed an arbitrator, the chairman of the Arbitration Institute shall make the appoint-ment.\nThe arbitration proceedings shall be conducted in Chinese language. The arbitration tribunal shall apply the arbitration rules of the Arbitration Institute in effect on the date of the signing of this Agreement. However, if such rules are in conflict with the provisions of the previous paragraph of this Article, including the provisions for appointing arbitrators, the provisions of this Article shall prevail.The arbitration award shall be final and binding on both parties. No party shall appeal in connection with the matters in relation to the arbitration award.\nEach Party may request any court having jurisdiction to make a judgment for enforcing the arbitration award, or apply with such court for judicial recognition of the award or any order of enforcement thereof.During the process of arbitration, the Parties shall continue to implement this Agreement without interruption, except for the matters in dispute.\n\n1. This Agreement shall be governed by and construed in accordance with the laws of New York (USA),without regard to the conflict of laws provisions thereof, The United Nations Convention on Contracts for the International Sale of Goods shall not apply to this Agreement..\n2. The Parties will make every effort to settle amicably any dispute or claim arising in connection with the Contract. Should the Parties fail to resolve any such dispute within sixty (60) days after one Party gives a written notice of a dispute to the other, any and all such disputes shall be finally settled in accordance with the Rules of Arbitration of the International Chamber of Commerce by three (3) arbitrators appointed in accordance with said Rules.Any arbitration decision rendered in conformity with this Article shall befinal and binding upon the Parties. Arbitration shall take place in Geneva,Switzerland. The proceedings shall be conducted in English. All arbitration fees shall be borne by the losing party or, where appropriate, in conformity with the stipulations of the award. All other fees including legal fees shall be borne by the respective parties or, where appropriate, in conformity with the stipulations of the award..\n3. Should any dispute arise from the execution or implementation of this Contract or otherwise relating thereto, both Parties shall resolve the dispute through friendly negotiations. If the dispute cannot be resolved by negotiations within thirty (30) days after one Party has issued notice to the other Party requesting the commencement of such negotiations, then either Party may submit it to the Singapore International Arbitration Center (the\"Arbitration Institute\") for arbitration in accordance with the UNCITRAL rules of arbitration then in effect and the following provisions:a)The arbitration shall be conducted in the English language and three (3)arbitrators (one appointed by each Party and the third appointed by the Arbitration Institute) may refer to both the English and Chinese text of the Contract;\nb) The arbitration award shall be final and binding on the Parties and shall be enforced in accordance with its terms; and\nc)The costs of arbitration shall be borne by the Party as designated in the arbitration award.\nInsurance\n1. The JVC shall purchase appropriate comprehensive insurance to cover various kinds of risks as would be usual for a joint venture enterprise engaged in the same type of industry and in manufacturing products similar to the Products including, without limitation, product liability covering the manufacture and supply of the Products and such insurance shall be underwritten by an insurance company registered in the PRC. The typesvalue and duration of insurance shall be decided by the Board of Directors after discussion with the insurance companies and Party B.\nThe premises, plant, machinery and equipment, raw materials, components and the Products shall be insured by JVC for adequate replacement value against fire, storm, tempest, accident, flood, theft and other risks which may destroy or diminish the value of the Products or which may render the Products unfit for consumption..\n2. Insurance shall, to the extent it is available on premium and terms comparable to those abroad and as required by applicable Chinese law, be obtained in China and such policies will be denominated in Renminbi or foreign currency or both, as appropriate.\nThe Company shall, at its own cost and expense, at all times during operation of the factory and other facilities and during any construction work take out and maintain full and adequate property insurance covering the buildings, contents, and other first party risks of the Company as are customarily insured against in China.\nThe Company shall maintain product liability insurance, third party liability insurance and other relevant insurance coverage in order to protect the Company, its employees, agents and other appropriate parties from claims.3. During the term of this Agreement, Party A shall undertake, renew and maintain for its benefit and interest, and at its own cost and expense, the following primary insurance policies:.a) General Public Liability Policy with Party B being named as a co-insured covering all loss, damage or liability incurred or arising from the operation of the Services including, without limitation, for bodily injury, death or property damage, for an amount not less than RMB25,000,000 per accident or occurrence ;\nb) Employer's Liability Policy with Party B being named as a co-insured in conformity with local laws and regulations and accepted practice in the PRC;\nc)Property Damage Policy covering its premises against all risks of direct physical loss or damage from any cause, or if such a policy is not available against the risks of fire and associated risks such as explosion, electrical damage, water damage, riots, strikes, civil commotion, terrorism.windstorms, hurricanes, cyclones, floods, burglary, theft and other similar risks:\nd) Property Damage Policy with Party B being named as the sole beneficiary covering loss or damage to the materials, Products, Bulk Products, Equipment and other property of Party B as a result of natural disaster or negligence or omission by Party A; and e) Any other insurance policy or policies against such other insurable risks as shall be normal and customary in the PRC for operations similar to that of Party A, in each case with Party B named in the policy or a certificate of insurance as loss payee, additional insured, or in such manner as Party B's insurance company and Party A's insurance company may agree.\nParty A shall inform Party B of any change to its insurance policies listedabove which would result in a reduced insurance coverage.\n",
    "ori_text": "\n\n Governing Law and Dispute Resolution\n1. The formation of this Contract, its validity, interpretation, execution and settlement of disputes in connection herewith shall be governed by the laws of the People's Republic of China (\"PRC\"), but in the event that there is no published and publicly available law in the PRC governing a particular matter relating to this Contract, reference shall be made to general international commercial practices.\n2. If, after the signing of this Agreement, the Chinese government either atthe State, provincial, municipal or local level adopts any new law, regulation,decree or rule, amends or repeals any provision of any law, regulation,decree or rule, or adopts any different interpretation or method of implementation of any law, regulation, decree or rule, which contravenes this Agreement or which materially and adversely affects a party's economic benefit under this Agreement, then upon written notice thereof from the affected party to the other Party, the Parties shall promptly consult and decide whether (i) to continue to implement this Agreement in accordance with the original provisions thereof as per the relevant provisions of the Contract Law of the People's Republic of China;or (ii) to effectuate\nnecessary adjustments in order to preserve each Party's economic benefit under this Agreement on a basis no less favorable than the economic benefit it would have received if such law, regulation, decree or rule had not been adopted, amended, repealed or so interpreted or implemented.3. Any controversy or claim arising out of, or relating to, this Agreemen shall be settled under the Rules of Conciliation and Arbitration of the International Chamber of Commerce by three(3)arbitrators appointed in accordance with said Rules. The place of Arbitration shall be Hong Kong The language of Arbitration shall be English.In no event shall any arbitration award provide a remedy beyond those permitted under these Terms and Conditions, and any award providing a remedy beyond those permitted under this Agreement shall not be confirmed, no presumption of validity shall attach, and such award shall be vacated..4. Any dispute arising from, out of, or in connection with, this Agreement shall be settled by the Parties through friendly consultation. Such consultation shall begin immediately after one Party has delivered to the other party a written request for such consultation. If the dispute cannot be settled through consultation within thirty (30) days after such notice is given.the Parties shall submit the dispute to China International Trade Arbitration Committee, Shanghai Branch(\"Arbitration Institute\") to be arbitrated according to its rules and regulations.\nThere shall be three (3) arbitrators. Party A and Party B shall appoint one (1)arbitrator each. The two arbitrators shall be selected within thirty (30) days after giving or receiving of the request for arbitration. The chairman of the Arbitration Institute shall select the third arbitrator. If a Party fails to appoint an arbitrator within thirty (30) days after the other Party has appointed an arbitrator, the chairman of the Arbitration Institute shall make the appoint-ment.\nThe arbitration proceedings shall be conducted in Chinese language. The arbitration tribunal shall apply the arbitration rules of the Arbitration Institute in effect on the date of the signing of this Agreement. However, if such rules are in conflict with the provisions of the previous paragraph of this Article, including the provisions for appointing arbitrators, the provisions of this Article shall prevail.The arbitration award shall be final and binding on both parties. No party shall appeal in connection with the matters in relation to the arbitration award.\nEach Party may request any court having jurisdiction to make a judgment for enforcing the arbitration award, or apply with such court for judicial recognition of the award or any order of enforcement thereof.During the process of arbitration, the Parties shall continue to implement this Agreement without interruption, except for the matters in dispute.\n\n1. This Agreement shall be governed by and construed in accordance with the laws of New York (USA),without regard to the conflict of laws provisions thereof, The United Nations Convention on Contracts for the International Sale of Goods shall not apply to this Agreement..\n2. The Parties will make every effort to settle amicably any dispute or claim arising in connection with the Contract. Should the Parties fail to resolve any such dispute within sixty (60) days after one Party gives a written notice of a dispute to the other, any and all such disputes shall be finally settled in accordance with the Rules of Arbitration of the International Chamber of Commerce by three (3) arbitrators appointed in accordance with said Rules.Any arbitration decision rendered in conformity with this Article shall befinal and binding upon the Parties. Arbitration shall take place in Geneva,Switzerland. The proceedings shall be conducted in English. All arbitration fees shall be borne by the losing party or, where appropriate, in conformity with the stipulations of the award. All other fees including legal fees shall be borne by the respective parties or, where appropriate, in conformity with the stipulations of the award..\n3. Should any dispute arise from the execution or implementation of this Contract or otherwise relating thereto, both Parties shall resolve the dispute through friendly negotiations. If the dispute cannot be resolved by negotiations within thirty (30) days after one Party has issued notice to the other Party requesting the commencement of such negotiations, then either Party may submit it to the Singapore International Arbitration Center (the\"Arbitration Institute\") for arbitration in accordance with the UNCITRAL rules of arbitration then in effect and the following provisions:a)The arbitration shall be conducted in the English language and three (3)arbitrators (one appointed by each Party and the third appointed by the Arbitration Institute) may refer to both the English and Chinese text of the Contract;\nb) The arbitration award shall be final and binding on the Parties and shall be enforced in accordance with its terms; and\nc)The costs of arbitration shall be borne by the Party as designated in the arbitration award.\nInsurance\n1. The JVC shall purchase appropriate comprehensive insurance to cover various kinds of risks as would be usual for a joint venture enterprise engaged in the same type of industry and in manufacturing products similar to the Products including, without limitation, product liability covering the manufacture and supply of the Products and such insurance shall be underwritten by an insurance company registered in the PRC. The typesvalue and duration of insurance shall be decided by the Board of Directors after discussion with the insurance companies and Party B.\nThe premises, plant, machinery and equipment, raw materials, components and the Products shall be insured by JVC for adequate replacement value against fire, storm, tempest, accident, flood, theft and other risks which may destroy or diminish the value of the Products or which may render the Products unfit for consumption..\n2. Insurance shall, to the extent it is available on premium and terms comparable to those abroad and as required by applicable Chinese law, be obtained in China and such policies will be denominated in Renminbi or foreign currency or both, as appropriate.\nThe Company shall, at its own cost and expense, at all times during operation of the factory and other facilities and during any construction work take out and maintain full and adequate property insurance covering the buildings, contents, and other first party risks of the Company as are customarily insured against in China.\nThe Company shall maintain product liability insurance, third party liability insurance and other relevant insurance coverage in order to protect the Company, its employees, agents and other appropriate parties from claims.3. During the term of this Agreement, Party A shall undertake, renew and maintain for its benefit and interest, and at its own cost and expense, the following primary insurance policies:.a) General Public Liability Policy with Party B being named as a co-insured covering all loss, damage or liability incurred or arising from the operation of the Services including, without limitation, for bodily injury, death or property damage, for an amount not less than RMB25,000,000 per accident or occurrence ;\nb) Employer's Liability Policy with Party B being named as a co-insured in conformity with local laws and regulations and accepted practice in the PRC;\nc)Property Damage Policy covering its premises against all risks of direct physical loss or damage from any cause, or if such a policy is not available against the risks of fire and associated risks such as explosion, electrical damage, water damage, riots, strikes, civil commotion, terrorism.windstorms, hurricanes, cyclones, floods, burglary, theft and other similar risks:\nd) Property Damage Policy with Party B being named as the sole beneficiary covering loss or damage to the materials, Products, Bulk Products, Equipment and other property of Party B as a result of natural disaster or negligence or omission by Party A; and e) Any other insurance policy or policies against such other insurable risks as shall be normal and customary in the PRC for operations similar to that of Party A, in each case with Party B named in the policy or a certificate of insurance as loss payee, additional insured, or in such manner as Party B's insurance company and Party A's insurance company may agree.\nParty A shall inform Party B of any change to its insurance policies listedabove which would result in a reduced insurance coverage.\n",
    "reference_list": "考点1：“no published and publicly available law”必须译为“未正式颁布并公开发布的法律”，应保留“published”和“publicly available”的双重限制。\n考点2：“reference shall be made to general international commercial practices”必须译为“参照国际商业惯例”，为固定法律表达，应避免直译“应参照一般国际商业惯例”。\n考点3：“property insurance covering...first party risks”应理解为“财产保险，涵盖第一方风险”，注意“first party”法律术语含义，不等于“首要方”。\n考点4：“loss payee”推荐译为“损失赔偿受偿人”，准确表达保险金的最终领取人。\n考点5：“contents”在财产保险语境中应译为“室内财产”，涵盖家具、设备、存货等动产，避免限缩为“内装物”。\n考点6：“undertake（insurance policies）”在保险条款中推荐译为“购买”、“投保”或“办理”，避免使用不自然的“承担保险保单”。\n考点7：“amends or repeals any provision of any law, regulation, decree or rule”推荐译为“修订或废止任何法律、法规、法令或规章的任何条款”，避免仅译为“法律条款”而缩小范围。\n考点8：“economic benefit”在同一条款内应统一译法，避免混用“经济利益”和“经济收益”造成语义偏差。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "112"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nWhere I Lived, and What I Lived For\nAt a certain season of our life we are accustomed to consider every spot as the possible site of a house. I have thus surveyed the country on every side within a dozen miles of where I live. In imagination I have bought all the farms in succession, for all were to be bought, and I knew their price. I walked over each farmer’s premises, tasted his wild apples, discoursed on husbandry with him, took his farm at his price, at any price, mortgaging it to him in my mind; even put a higher price on it,—took everything but a deed of it,—took his word for his deed, for I dearly love to talk,—cultivated it, and him too to some extent, I trust, and withdrew when I had enjoyed it long enough, leaving him to carry it on. This experience entitled me to be regarded as a sort of real-estate broker by my friends. Wherever I sat, there I might live, and the landscape radiated from me accordingly. What is a house but a sedes, a seat?—better if a country seat. I discovered many a site for a house not likely to be soon improved, which some might have thought too far from the village, but to my eyes the village was too far from it. Well, there I might live, I said; and there I did live, for an hour, a summer and a winter life; saw how I could let the years run off, buffet the winter through, and see the spring come in. The future inhabitants of this region, wherever they may place their houses, may be sure that they have been anticipated. An afternoon sufficed to lay out the land into orchard, woodlot, and pasture, and to decide what fine oaks or pines should be left to stand before the door, and whence each blasted tree could be seen to the best advantage; and then I let it lie, fallow perchance, for a man is rich in proportion to the number of things which he can afford to let alone.\nMy imagination carried me so far that I even had the refusal of several farms,—the refusal was all I wanted,—but I never got my fingers burned by actual possession. The nearest that I came to actual possession was when I bought the Hollowell place, and had begun to sort my seeds, and collected materials with which to make a wheelbarrow to carry it on or off with; but before the owner gave me a deed of it, his wife—every man has such a wife—changed her mind and wished to keep it, and he offered me ten dollars to release him. Now, to speak the truth, I had but ten cents in the world, and it surpassed my arithmetic to tell, if I was that man who had ten cents, or who had a farm, or ten dollars, or all together. However, I let him keep the ten dollars and the farm too, for I had carried it far enough; or rather, to be generous, I sold him the farm for just what I gave for it, and, as he was not a rich man, made him a present of ten dollars, and still had my ten cents, and seeds, and materials for a wheelbarrow left. I found thus that I had been a rich man without any damage to my poverty. But I retained the landscape, and I have since annually carried off what it yielded without a wheelbarrow. With respect to landscapes,—\n“I am monarch of all I survey,\nMy right there is none to dispute.”\nI have frequently seen a poet withdraw, having enjoyed the most valuable part of a farm, while the crusty farmer supposed that he had got a few wild apples only. Why, the owner does not know it for many years when a poet has put his farm in rhyme, the most admirable kind of invisible fence, has fairly impounded it, milked it, skimmed it, and got all the cream, and left the farmer only the skimmed milk.\nThe real attractions of the Hollowell farm, to me, were; its complete retirement, being, about two miles from the village, half a mile from the nearest neighbor, and separated from the highway by a broad field; its bounding on the river, which the owner said protected it by its fogs from frosts in the spring, though that was nothing to me; the gray color and ruinous state of the house and barn, and the dilapidated fences, which put such an interval between me and the last occupant; the hollow and lichen-covered apple trees, gnawed by rabbits, showing what kind of neighbors I should have; but above all, the recollection I had of it from my earliest voyages up the river, when the house was concealed behind a dense grove of red maples, through which I heard the house-dog bark. I was in haste to buy it, before the proprietor finished getting out some rocks, cutting down the hollow apple trees, and grubbing up some young birches which had sprung up in the pasture, or, in short, had made any more of his improvements. To enjoy these advantages I was ready to carry it on; like Atlas, to take the world on my shoulders,—I never heard what compensation he received for that,—and do all those things which had no other motive or excuse but that I might pay for it and be unmolested in my possession of it; for I knew all the while that it would yield the most abundant crop of the kind I wanted if I could only afford to let it alone. But it turned out as I have said.\nAll that I could say, then, with respect to farming on a large scale, (I have always cultivated a garden,) was, that I had had my seeds ready. Many think that seeds improve with age. I have no doubt that time discriminates between the good and the bad; and when at last I shall plant, I shall be less likely to be disappointed. But I would say to my fellows, once for all, As long as possible live free and uncommitted. It makes but little difference whether you are committed to a farm or the county jail.\nOld Cato, whose “De Re Rusticâ” is my “Cultivator,” says, and the only translation I have seen makes sheer nonsense of the passage, “When you think of getting a farm, turn it thus in your mind, not to buy greedily; nor spare your pains to look at it, and do not think it enough to go round it once. The oftener you go there the more it will please you, if it is good.” I think I shall not buy greedily, but go round and round it as long as I live, and be buried in it first, that it may please me the more at last.\nThe present was my next experiment of this kind, which I purpose to describe more at length; for convenience, putting the experience of two years into one. As I have said, I do not propose to write an ode to dejection, but to brag as lustily as chanticleer in the morning, standing on his roost, if only to wake my neighbors up.\nWhen first I took up my abode in the woods, that is, began to spend my nights as well as days there, which, by accident, was on Independence Day, or the Fourth of July, 1845, my house was not finished for winter, but was merely a defence against the rain, without plastering or chimney, the walls being of rough, weather-stained boards, with wide chinks, which made it cool at night. The upright white hewn studs and freshly planed door and window casings gave it a clean and airy look, especially in the morning, when its timbers were saturated with dew, so that I fancied that by noon some sweet gum would exude from them. To my imagination it retained throughout the day more or less of this auroral character, reminding me of a certain house on a mountain which I had visited the year before. This was an airy and unplastered cabin, fit to entertain a travelling god, and where a goddess might trail her garments. The winds which passed over my dwelling were such as sweep over the ridges of mountains, bearing the broken strains, or celestial parts only, of terrestrial music. The morning wind forever blows, the poem of creation is uninterrupted; but few are the ears that hear it. Olympus is but the outside of the earth every where.",
    "ori_text": "Where I Lived, and What I Lived For\nAt a certain season of our life we are accustomed to consider every spot as the possible site of a house. I have thus surveyed the country on every side within a dozen miles of where I live. In imagination I have bought all the farms in succession, for all were to be bought, and I knew their price. I walked over each farmer’s premises, tasted his wild apples, discoursed on husbandry with him, took his farm at his price, at any price, mortgaging it to him in my mind; even put a higher price on it,—took everything but a deed of it,—took his word for his deed, for I dearly love to talk,—cultivated it, and him too to some extent, I trust, and withdrew when I had enjoyed it long enough, leaving him to carry it on. This experience entitled me to be regarded as a sort of real-estate broker by my friends. Wherever I sat, there I might live, and the landscape radiated from me accordingly. What is a house but a sedes, a seat?—better if a country seat. I discovered many a site for a house not likely to be soon improved, which some might have thought too far from the village, but to my eyes the village was too far from it. Well, there I might live, I said; and there I did live, for an hour, a summer and a winter life; saw how I could let the years run off, buffet the winter through, and see the spring come in. The future inhabitants of this region, wherever they may place their houses, may be sure that they have been anticipated. An afternoon sufficed to lay out the land into orchard, woodlot, and pasture, and to decide what fine oaks or pines should be left to stand before the door, and whence each blasted tree could be seen to the best advantage; and then I let it lie, fallow perchance, for a man is rich in proportion to the number of things which he can afford to let alone.\nMy imagination carried me so far that I even had the refusal of several farms,—the refusal was all I wanted,—but I never got my fingers burned by actual possession. The nearest that I came to actual possession was when I bought the Hollowell place, and had begun to sort my seeds, and collected materials with which to make a wheelbarrow to carry it on or off with; but before the owner gave me a deed of it, his wife—every man has such a wife—changed her mind and wished to keep it, and he offered me ten dollars to release him. Now, to speak the truth, I had but ten cents in the world, and it surpassed my arithmetic to tell, if I was that man who had ten cents, or who had a farm, or ten dollars, or all together. However, I let him keep the ten dollars and the farm too, for I had carried it far enough; or rather, to be generous, I sold him the farm for just what I gave for it, and, as he was not a rich man, made him a present of ten dollars, and still had my ten cents, and seeds, and materials for a wheelbarrow left. I found thus that I had been a rich man without any damage to my poverty. But I retained the landscape, and I have since annually carried off what it yielded without a wheelbarrow. With respect to landscapes,—\n“I am monarch of all I survey,\nMy right there is none to dispute.”\nI have frequently seen a poet withdraw, having enjoyed the most valuable part of a farm, while the crusty farmer supposed that he had got a few wild apples only. Why, the owner does not know it for many years when a poet has put his farm in rhyme, the most admirable kind of invisible fence, has fairly impounded it, milked it, skimmed it, and got all the cream, and left the farmer only the skimmed milk.\nThe real attractions of the Hollowell farm, to me, were; its complete retirement, being, about two miles from the village, half a mile from the nearest neighbor, and separated from the highway by a broad field; its bounding on the river, which the owner said protected it by its fogs from frosts in the spring, though that was nothing to me; the gray color and ruinous state of the house and barn, and the dilapidated fences, which put such an interval between me and the last occupant; the hollow and lichen-covered apple trees, gnawed by rabbits, showing what kind of neighbors I should have; but above all, the recollection I had of it from my earliest voyages up the river, when the house was concealed behind a dense grove of red maples, through which I heard the house-dog bark. I was in haste to buy it, before the proprietor finished getting out some rocks, cutting down the hollow apple trees, and grubbing up some young birches which had sprung up in the pasture, or, in short, had made any more of his improvements. To enjoy these advantages I was ready to carry it on; like Atlas, to take the world on my shoulders,—I never heard what compensation he received for that,—and do all those things which had no other motive or excuse but that I might pay for it and be unmolested in my possession of it; for I knew all the while that it would yield the most abundant crop of the kind I wanted if I could only afford to let it alone. But it turned out as I have said.\nAll that I could say, then, with respect to farming on a large scale, (I have always cultivated a garden,) was, that I had had my seeds ready. Many think that seeds improve with age. I have no doubt that time discriminates between the good and the bad; and when at last I shall plant, I shall be less likely to be disappointed. But I would say to my fellows, once for all, As long as possible live free and uncommitted. It makes but little difference whether you are committed to a farm or the county jail.\nOld Cato, whose “De Re Rusticâ” is my “Cultivator,” says, and the only translation I have seen makes sheer nonsense of the passage, “When you think of getting a farm, turn it thus in your mind, not to buy greedily; nor spare your pains to look at it, and do not think it enough to go round it once. The oftener you go there the more it will please you, if it is good.” I think I shall not buy greedily, but go round and round it as long as I live, and be buried in it first, that it may please me the more at last.\nThe present was my next experiment of this kind, which I purpose to describe more at length; for convenience, putting the experience of two years into one. As I have said, I do not propose to write an ode to dejection, but to brag as lustily as chanticleer in the morning, standing on his roost, if only to wake my neighbors up.\nWhen first I took up my abode in the woods, that is, began to spend my nights as well as days there, which, by accident, was on Independence Day, or the Fourth of July, 1845, my house was not finished for winter, but was merely a defence against the rain, without plastering or chimney, the walls being of rough, weather-stained boards, with wide chinks, which made it cool at night. The upright white hewn studs and freshly planed door and window casings gave it a clean and airy look, especially in the morning, when its timbers were saturated with dew, so that I fancied that by noon some sweet gum would exude from them. To my imagination it retained throughout the day more or less of this auroral character, reminding me of a certain house on a mountain which I had visited the year before. This was an airy and unplastered cabin, fit to entertain a travelling god, and where a goddess might trail her garments. The winds which passed over my dwelling were such as sweep over the ridges of mountains, bearing the broken strains, or celestial parts only, of terrestrial music. The morning wind forever blows, the poem of creation is uninterrupted; but few are the ears that hear it. Olympus is but the outside of the earth every where.",
    "reference_list": "考点1： “surveyed”应该译为“勘查”。\n考点2： “sedes”应译为“位置”，拉丁语表示座位的意思，此处指的是房屋的坐落之处。\n考点3： “got my fingers burned”应译为“没有损失”。\n考点4： “De Re Rusticâ”应译为“《论农业》”。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "散文",
    "prompt_id": "55"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nIntroducing the MVPs of POV: Meet the Marketers Powering Cultural Discovery\n\nAt this year’s Cannes Lions, TikTok is turning the spotlight on discovery and the marketing leaders who are shaping what comes next. As the global platform where our community comes to find, form, and share diverse points of view, TikTok is proud to introduce the MVPs of POV: a new class of marketing trailblazers whose work is redefining brand storytelling for the discovery era.\n\n“Today’s most effective marketers know that real brand love doesn’t come from shouting the loudest,\" said Sofia Hernandez, Global Head of Business Marketing at TikTok. “TikTok gives brands a chance to show up not as advertisers, but as people with personality, point of view, and purpose. The MVPs of POV are the ones who get it. They’re rewriting the rules of marketing by meeting communities where they are and showing up authentically and creatively without sacrificing ROI. This program celebrates the brands that aren’t just joining the conversation, they’re shaping it.”\n\n\"By staying true to our history while embedding our brand in modern culture, we are able to innovate without forgoing who we are, and that is key to building a strong POV on any social channel, particularly TikTok,\" said Fabiola Torres, Global CMO at Gap.\n\nA New Era of Discovery, Powered by POV\n\nIn a world moving toward perspective-led exploration, TikTok continues to spark new ideas and experiences, with billions of searches happening on the platform every day. (1) Every scroll opens a new perspective; every tap joins a conversation; and every search leads to unexpected inspiration. In fact, according to new research conducted by WARC, 64% of users say they search TikTok to find multiple perspectives, and 60% of users say TikTok’s search results are more likely to motivate them to take action, compared to other platforms. (2)\n\nTikTok is where discovery starts, and this year at Cannes Lions, we’re bringing that journey to life IRL with the MVPs of POV. The MVPs of POV program anchors TikTok’s presence at Cannes, turning the city into a live demonstration of how discovery happens on the platform, with programming and content highlighting all the innovative ways brands are engaging with the TikTok community.\n\nMeet the MVPs of POV who are flipping the script on what it means to show up in culture, leaning into creator collaborations, leaning into real-time trends, and building community-driven campaigns that don’t just land – they resonate. Their work isn’t just seen, it’s discovered, shared, and remembered.\n\nThe MVPs of POV\n\n- Avery Akkineni, CMO, VaynerX\n- Anna Lenka Jáuregui, CMO at BCP / Credicorp\n- Armagan Engel, Director, Communication Office, QNB Türkiye\n- Benjamin Braun, VP and CMO at Samsung Europe\n- Camila Ribeiro, Senior Director of Advertising, Media and Brand Management, TIM Brasil\n- Catalina Beltran, WACAM Digital Lead at Mondelēz International\n- Cecilia Schena, CMO at KIKO MILANO\n- Charlie Smith, CMO at Loewe\n- Daisy Kelly, Founder and CEO at Glow for It\n- Domingo Iudice, Director at Brainpull\n- Fabiola Torres, Global CMO at Gap\n- Philip Edsel, VP of Brand & Creative at Ladder\n- Ghadeer Khub, Creative and Production Director at the Abu Dhabi Department of Culture and Tourism\n\nTikTok for Artists: The new all-in-one music insights platform for artists\n\n- TikTok for Artists is a new artist-first platform designed to help artists build their careers and fanbase on TikTok\n- Artists can now access data and insights about their music, posts and followers\n- New 'Pre-Release' tool now available for the creation of album pre-release campaigns*\n\nJune 3 2025: Today, TikTok is proud to announce the global** launch of TikTok for Artists, the new all-in-one music insights platform for artists on TikTok. The new platform provides artists, their labels and their teams with data and insights which can help them better connect with the global TikTok community, promote their music, and drive success both on and off the platform.\n\nTikTok for Artists provides daily-updated analytics dashboards which display a wealth of detailed, actionable data about the performance of an artist's music and posts on TikTok, and comprehensive insights into how the community is engaging with the artist and their music on the platform. The tool has been designed with the goal of helping artists and their teams boost fan engagement, optimize their promotional strategies and inform content creation on TikTok.\n\nTikTok for Artists features include:\n\n- Song performance: the number of views, posts and creator engagements per track\n- Post performance: the number of views, likes, comments, shares and post completion rates\n- Follower insights: including self-declared gender, age and language\n- Step-by-step guides to TikTok's tools and features\n- Support and further resources\n\nToday's launch also sees the official global launch of the Pre-Release tool, a new self-service tool which gives artists the ability to promote the forthcoming release of an album on TikTok. The feature will allow fans to pre-save that album directly to their Spotify or Apple Music library, where it will become instantly available to listen to on their chosen music streaming service upon its release.\n\nTracy Gardner, TikTok's Global Head of Music Business Development, commented on the launch: \"TikTok is already well known for being the world's best platform for music discovery and promotion, and with the launch of TikTok for Artists, all tiers of artists will gain insights on TikTok that they can use to take their careers to a whole new level. We built the platform to give artists transparent access to useful, actionable data about their music and their fans, to help them better engage with the TikTok community and supercharge their careers both on and off the platform.\"\n\nBritish artist, Jordan Adetunji (640k followers), said: \"TikTok for Artists is a game changer. It has so much information about my music, my followers, and how they’re using my songs in their posts. And it’s brilliant that I can give access to my team who can also use the data to help us plan our campaigns.\"\n\nAustralian artist, Cyril Riley (750k followers), an early tester of the platform, commented: \"My team and I rely on TikTok for Artists daily, sometimes even hourly. In such a rapidly evolving industry, it's crucial for us to consistently monitor and review the analytics of my account.\"\n\nTikTok for Artists is available now for all artists with a certified TikTok Artist Account. Artists are also able to provide account access to their artist teams, and to label teams.",
    "ori_text": "Introducing the MVPs of POV: Meet the Marketers Powering Cultural Discovery\n\nAt this year’s Cannes Lions, TikTok is turning the spotlight on discovery and the marketing leaders who are shaping what comes next. As the global platform where our community comes to find, form, and share diverse points of view, TikTok is proud to introduce the MVPs of POV: a new class of marketing trailblazers whose work is redefining brand storytelling for the discovery era.\n\n“Today’s most effective marketers know that real brand love doesn’t come from shouting the loudest,\" said Sofia Hernandez, Global Head of Business Marketing at TikTok. “TikTok gives brands a chance to show up not as advertisers, but as people with personality, point of view, and purpose. The MVPs of POV are the ones who get it. They’re rewriting the rules of marketing by meeting communities where they are and showing up authentically and creatively without sacrificing ROI. This program celebrates the brands that aren’t just joining the conversation, they’re shaping it.”\n\n\"By staying true to our history while embedding our brand in modern culture, we are able to innovate without forgoing who we are, and that is key to building a strong POV on any social channel, particularly TikTok,\" said Fabiola Torres, Global CMO at Gap.\n\nA New Era of Discovery, Powered by POV\n\nIn a world moving toward perspective-led exploration, TikTok continues to spark new ideas and experiences, with billions of searches happening on the platform every day. (1) Every scroll opens a new perspective; every tap joins a conversation; and every search leads to unexpected inspiration. In fact, according to new research conducted by WARC, 64% of users say they search TikTok to find multiple perspectives, and 60% of users say TikTok’s search results are more likely to motivate them to take action, compared to other platforms. (2)\n\nTikTok is where discovery starts, and this year at Cannes Lions, we’re bringing that journey to life IRL with the MVPs of POV. The MVPs of POV program anchors TikTok’s presence at Cannes, turning the city into a live demonstration of how discovery happens on the platform, with programming and content highlighting all the innovative ways brands are engaging with the TikTok community.\n\nMeet the MVPs of POV who are flipping the script on what it means to show up in culture, leaning into creator collaborations, leaning into real-time trends, and building community-driven campaigns that don’t just land – they resonate. Their work isn’t just seen, it’s discovered, shared, and remembered.\n\nThe MVPs of POV\n\n- Avery Akkineni, CMO, VaynerX\n- Anna Lenka Jáuregui, CMO at BCP / Credicorp\n- Armagan Engel, Director, Communication Office, QNB Türkiye\n- Benjamin Braun, VP and CMO at Samsung Europe\n- Camila Ribeiro, Senior Director of Advertising, Media and Brand Management, TIM Brasil\n- Catalina Beltran, WACAM Digital Lead at Mondelēz International\n- Cecilia Schena, CMO at KIKO MILANO\n- Charlie Smith, CMO at Loewe\n- Daisy Kelly, Founder and CEO at Glow for It\n- Domingo Iudice, Director at Brainpull\n- Fabiola Torres, Global CMO at Gap\n- Philip Edsel, VP of Brand & Creative at Ladder\n- Ghadeer Khub, Creative and Production Director at the Abu Dhabi Department of Culture and Tourism\n\nTikTok for Artists: The new all-in-one music insights platform for artists\n\n- TikTok for Artists is a new artist-first platform designed to help artists build their careers and fanbase on TikTok\n- Artists can now access data and insights about their music, posts and followers\n- New 'Pre-Release' tool now available for the creation of album pre-release campaigns*\n\nJune 3 2025: Today, TikTok is proud to announce the global** launch of TikTok for Artists, the new all-in-one music insights platform for artists on TikTok. The new platform provides artists, their labels and their teams with data and insights which can help them better connect with the global TikTok community, promote their music, and drive success both on and off the platform.\n\nTikTok for Artists provides daily-updated analytics dashboards which display a wealth of detailed, actionable data about the performance of an artist's music and posts on TikTok, and comprehensive insights into how the community is engaging with the artist and their music on the platform. The tool has been designed with the goal of helping artists and their teams boost fan engagement, optimize their promotional strategies and inform content creation on TikTok.\n\nTikTok for Artists features include:\n\n- Song performance: the number of views, posts and creator engagements per track\n- Post performance: the number of views, likes, comments, shares and post completion rates\n- Follower insights: including self-declared gender, age and language\n- Step-by-step guides to TikTok's tools and features\n- Support and further resources\n\nToday's launch also sees the official global launch of the Pre-Release tool, a new self-service tool which gives artists the ability to promote the forthcoming release of an album on TikTok. The feature will allow fans to pre-save that album directly to their Spotify or Apple Music library, where it will become instantly available to listen to on their chosen music streaming service upon its release.\n\nTracy Gardner, TikTok's Global Head of Music Business Development, commented on the launch: \"TikTok is already well known for being the world's best platform for music discovery and promotion, and with the launch of TikTok for Artists, all tiers of artists will gain insights on TikTok that they can use to take their careers to a whole new level. We built the platform to give artists transparent access to useful, actionable data about their music and their fans, to help them better engage with the TikTok community and supercharge their careers both on and off the platform.\"\n\nBritish artist, Jordan Adetunji (640k followers), said: \"TikTok for Artists is a game changer. It has so much information about my music, my followers, and how they’re using my songs in their posts. And it’s brilliant that I can give access to my team who can also use the data to help us plan our campaigns.\"\n\nAustralian artist, Cyril Riley (750k followers), an early tester of the platform, commented: \"My team and I rely on TikTok for Artists daily, sometimes even hourly. In such a rapidly evolving industry, it's crucial for us to consistently monitor and review the analytics of my account.\"\n\nTikTok for Artists is available now for all artists with a certified TikTok Artist Account. Artists are also able to provide account access to their artist teams, and to label teams.",
    "reference_list": "考点1：“MVPs of POV”推荐译为“视角最具价值人物”或“POV杰出人物”，不可直译为“POV的MVP”\n考点2：“turning the spotlight on discovery”推荐译为“聚焦于探索”或“把注意力集中在发现上”，不可直译为“打开探照灯”或“打开聚光灯在发现上”。\n考点3：“redefining brand storytelling”推荐译为“重新定义品牌叙事”\n考点4：“show up not as advertisers, but as people with personality, point of view, and purpose”推荐译为“以有个性、有观点、有目标的人身份出现，而非传统广告主”\n考点5：“they’re rewriting the rules of marketing by meeting communities where they are”推荐译为“他们通过贴近社群实际情况来重塑营销规则”\n考点6：“every scroll opens a new perspective”推荐译为“每次滑动都带来新的视角”，不可直译为“每一次滚动开启一个新观点”。\n考点7：“flipping the script on what it means to show up in culture”推荐译为“彻底改变了品牌参与文化表达的方式”，避免直译为“翻转剧本”。\n考点8：“community-driven campaigns”推荐译为“以社群为驱动的营销活动”，不可直译为“社区驱动的活动”或“社区推动的战役”。\n考点9：“analytics dashboards”推荐译为“数据分析仪表板”或“分析面板”\n考点10：“Pre-Release tool”推荐译为“预发布工具”或“预热推广工具”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "互联网",
    "prompt_id": "23"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n藏在“星星”里的热情 \n 戴钰玲   \n我想给大家讲一个关于“星星”的故事。这 “星星”，不在浩瀚夜空闪烁，而是隐匿在临安青山翠谷间，每年金秋，随着第一缕秋风轻拂天目山，漫山遍野的山核桃树就像被点亮的绿色灯塔，颗颗饱满的山核桃便是那熠熠生辉的 “星星”，它们向世界发出诚挚邀约——来临安吧，尝尝我们藏在硬壳里的热情！   \n核桃为信，山水寄情   \n还记得去年白露，我满心欢喜地跟着爷爷上山打核桃。他扛着三米长的竹竿，像握着一支巨大的毛笔，在绿色的树冠上轻轻“作画”。“啪嗒啪嗒”，青褐色的核桃纷纷落下，打在我的遮阳帽上，仿佛奏响了一曲秋的乐章。爷爷弯腰捡起一颗核桃，他那布满老茧的大手轻轻蹭去外皮，露出裹着绒毛的“小脑袋”：“你看，每颗核桃都要在树上挂足九个月，喝的是山泉水，晒的是竹林漏下的阳光，连外壳上的纹路，都是天目山亲手刻的印章呢！” \n此后，每当我剥开一颗山核桃，爷爷劳作的身影就会浮现在眼前。这些深山里孕育的 “金果子”，历经 270 天的漫长生长，是临安山水馈赠的厚礼，静静诉说着大自然的慷慨，也彰显着这片土地对每一份等待的珍视。   \n传承匠心，三代同辉   \n在村口的加工厂里，处处都是温情的画面。八十岁的阿婆戴着老花镜，眼神专注，用镊子仔细地挑出每一颗有瑕疵的核桃；叔叔们守着不锈钢炒锅，熟练地翻炒着，山核桃在蜂蜜与桂皮营造的香气中翻滚跳跃；年轻的哥哥姐姐们则对着手机镜头，将刚出锅的酥脆果仁轻轻掰开，让金黄的果仁在镜头前闪耀。 \n去年寒假，我跟着妈妈给直播间当小助手。当屏幕里的阿姨咬下第一口山核桃，眼睛突然亮起来：“原来你们的核桃这么香，是因为炒的时候，把人情味都炒进去了呀！”那一刻我突然明白，临安人传递给世界的，远不止是美味的零食，更是爷爷竹竿上的晨曦、阿婆指尖的专注，是三代人掌心相传的温暖，是代代坚守的匠心。   \n核桃传情，宾至如归   \n上个月，家里来了位外国游客。爸爸神秘地递给他一个小布袋，笑着说：“这是我们临安的‘神奇钥匙’请你打开看看。”只见他对着核桃发愁时，妈妈递上自制的核桃夹——那是用天目山竹子削成的精巧工具，中间还刻着小巧的山核桃图案。“先敲尖，再压腰，宝贝就会对你笑。”妈妈边说边示范，果仁“蹦”出来的瞬间，外国友人惊喜地喊道：“It's like opening a treasure box!”我们坐在老桂花树下，看他把果仁放进嘴里，脸上洋溢着幸福的笑容，嘴里不停地说着“So sweet, so warm”。那一刻，飘落的桂花、香脆的核桃、还有我们的笑声，都成了临安递给世界的明信片。 \n下次当你剥开一颗山核桃，不妨仔细聆听——那“咔嗒”一声裂开的，不仅是坚硬的外壳，更是临安人敞开的心扉。让我们带着山核桃的香脆、三代人的匠心，怀揣着对家乡的热爱，让客人从舌尖甜到心间。因为，最好的待客之道，从来都藏在最纯粹的家乡味道里，藏在我们眼里闪烁的、对这片土地的骄傲里！",
    "ori_text": "藏在“星星”里的热情 \n 戴钰玲   \n我想给大家讲一个关于“星星”的故事。这 “星星”，不在浩瀚夜空闪烁，而是隐匿在临安青山翠谷间，每年金秋，随着第一缕秋风轻拂天目山，漫山遍野的山核桃树就像被点亮的绿色灯塔，颗颗饱满的山核桃便是那熠熠生辉的 “星星”，它们向世界发出诚挚邀约——来临安吧，尝尝我们藏在硬壳里的热情！   \n核桃为信，山水寄情   \n还记得去年白露，我满心欢喜地跟着爷爷上山打核桃。他扛着三米长的竹竿，像握着一支巨大的毛笔，在绿色的树冠上轻轻“作画”。“啪嗒啪嗒”，青褐色的核桃纷纷落下，打在我的遮阳帽上，仿佛奏响了一曲秋的乐章。爷爷弯腰捡起一颗核桃，他那布满老茧的大手轻轻蹭去外皮，露出裹着绒毛的“小脑袋”：“你看，每颗核桃都要在树上挂足九个月，喝的是山泉水，晒的是竹林漏下的阳光，连外壳上的纹路，都是天目山亲手刻的印章呢！” \n此后，每当我剥开一颗山核桃，爷爷劳作的身影就会浮现在眼前。这些深山里孕育的 “金果子”，历经 270 天的漫长生长，是临安山水馈赠的厚礼，静静诉说着大自然的慷慨，也彰显着这片土地对每一份等待的珍视。   \n传承匠心，三代同辉   \n在村口的加工厂里，处处都是温情的画面。八十岁的阿婆戴着老花镜，眼神专注，用镊子仔细地挑出每一颗有瑕疵的核桃；叔叔们守着不锈钢炒锅，熟练地翻炒着，山核桃在蜂蜜与桂皮营造的香气中翻滚跳跃；年轻的哥哥姐姐们则对着手机镜头，将刚出锅的酥脆果仁轻轻掰开，让金黄的果仁在镜头前闪耀。 \n去年寒假，我跟着妈妈给直播间当小助手。当屏幕里的阿姨咬下第一口山核桃，眼睛突然亮起来：“原来你们的核桃这么香，是因为炒的时候，把人情味都炒进去了呀！”那一刻我突然明白，临安人传递给世界的，远不止是美味的零食，更是爷爷竹竿上的晨曦、阿婆指尖的专注，是三代人掌心相传的温暖，是代代坚守的匠心。   \n核桃传情，宾至如归   \n上个月，家里来了位外国游客。爸爸神秘地递给他一个小布袋，笑着说：“这是我们临安的‘神奇钥匙’请你打开看看。”只见他对着核桃发愁时，妈妈递上自制的核桃夹——那是用天目山竹子削成的精巧工具，中间还刻着小巧的山核桃图案。“先敲尖，再压腰，宝贝就会对你笑。”妈妈边说边示范，果仁“蹦”出来的瞬间，外国友人惊喜地喊道：“It's like opening a treasure box!”我们坐在老桂花树下，看他把果仁放进嘴里，脸上洋溢着幸福的笑容，嘴里不停地说着“So sweet, so warm”。那一刻，飘落的桂花、香脆的核桃、还有我们的笑声，都成了临安递给世界的明信片。 \n下次当你剥开一颗山核桃，不妨仔细聆听——那“咔嗒”一声裂开的，不仅是坚硬的外壳，更是临安人敞开的心扉。让我们带着山核桃的香脆、三代人的匠心，怀揣着对家乡的热爱，让客人从舌尖甜到心间。因为，最好的待客之道，从来都藏在最纯粹的家乡味道里，藏在我们眼里闪烁的、对这片土地的骄傲里！",
    "reference_list": "考点 1：\"山核桃\" 应译为 \"Chinese hickory\"\n考点 2：\"白露\" 应译为 \"White Dew\"\n考点 3：\"外壳上的纹路\" 应译为 \"patterns on the shell\"\n考点 4：\"金果子\" 应译为 \"golden nuts\"\n考点 5：\"老花镜\" 应译为 \"reading glasses\"\n考点 6：\"人情味\" 应译为 \"human warmth\"\n考点 7：\"家乡味道\" 应译为 \"taste of home\"",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "散文",
    "prompt_id": "86"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n【黄春慧】管理学视角下“中庸之道”的现代转化与运用\n\n摘要：中庸之道思想既是一种人生哲学，又对现代领导管理有很好的启示和指导意义。从对“中”的阐释中看到事物变化发展的差异性和矛盾性，促使我们在领导管理中把握好规律；从对“度”的认识中，要求把握火候，使各项职能得到有效的发挥；从对“和”的认识上把和谐发展作为发展的目标追求，从内部各要素和外部环境协调好关系，整合资源，提高领导管理效率；从对“诚”的认识上要求领导管理者重视修身之本，只有不断提升自身素质和能力，才能真正把握中庸思想的本质，提高领导管理水平。\n\n关键词：管理/中庸之道/管理者/孔子\n \n领导管理作为一种社会实践活动，建立在一定社会文化基础之上。为实现资源的有效配置和专业化分工协调，领导管理逐渐从一般社会活动中分离出来，并随时代变迁和人类文明进步而趋于制度化。中国历史上的管理大多体现于治国理政的政治方面，并逐渐扩展到社会活动的各个方面。中庸思想作为儒学的重要内容，《尚书·大禹谟》记载“人心惟危，道心惟微，惟精惟一，允执厥中。”凡事一定要执中，做到适当、适度，它是维持社会秩序稳定的有效方式与思想。但是当“中”的观念从一种行为智慧上升到社会主导价值取向时，对“中”的认识转向于“德”的理解，《论语·雍也》“中庸之为德也，其至矣乎！民鲜久矣。”“中庸”作为人的行为规范，成为儒家追求的高道德标准和精神境界。领导管理作为一种社会发展的制度保障和文化构成的要件，其有效性和管理水平的提高必须吸收和融入到历史的文化思想中去。儒家中庸思想蕴含的这种领导智慧，对现代管理有深远影响。[1]\n\n一、从中庸“尚中”思想把握规律性问题\n\n领导管理对规律的遵循就是要用科学的理念和方法协调各系统之间的关系，实现更高的效率和效益。孔子特别的“尚中”，把它作为人性发展的基本要求，作为评判“君子”品格的标准。在孔子看来，万事万物都存在着差异性，正是这种差异性构成了事物发展的关系复杂性，这是天地间的“道”，能否实现社会协调性发展，必须理清事物间存在的矛盾复杂性，从“尚中”的“道”的遵循做起。《中庸》中说：“不偏之谓中，不易之谓庸。中者，天下之正道，庸者，天下之定理。”“中”作为天下的“正道”体现了事物变化的本来面目，它不仅成为人的行为规范标准，同时也成为管理应遵循的原则。社会治理存在各种矛盾的影响，能否实现社会协调性的发展，必须从“尚中”的遵循做起。无论从管理计划、制度控制、用人决策等，是否在各利益关系平衡中做到恰到好处，是影响效果的关键，忽视这样的规律存在，不按规律办事，必然受到规律的惩罚，导致领导管理失败。\n\n“天地之道，博也、厚也、高也、明也、悠也、久也”，领导管理活动如同“天地之道”，就是一个有目的、有意识的能动过程，领导管理中的各环节、各要素之间存在的差异性，需要通过计划、组织、控制和沟通等职能整合，处理好人与自然的关系，维护好社会生产关系，调节好内在的“博、厚、高、明、悠”等规律的复杂性，才能实现领导管理的科学化和有效性。人的天性就是顺应规律，达到中正及平衡有序，使天、地、人实现协调发展。而要达到“率性之谓道”的境界，必须“修道”，“修道”的关键是把握中庸的精髓，那就要做到恰当适度。事物发展的规律性也就在这个“度”，它是事物存在的依据，同时也是人的行为规定，把握好了“度”，同时也就更好做到了“中”，也就真正实践了“天下之定理”。因此，管理不仅要认清管理过程中的关系矛盾，认识到“中”的规律性，而且应通过适度把握做出恰当的选择，在具体的时空条件下做出适当的行为。\n\n领导管理者要认清过程中的关系矛盾，通过适度把握做出恰当的选择。中庸之道要求顺应事物的自然禀性而为，因势利导；寻求内在平衡，做到不偏不倚，平衡各种极端冲突。从这个意义上说，中庸之道既是一种领导管理循“道”，也是遵“规”的科学方法论的应用。",
    "ori_text": "【黄春慧】管理学视角下“中庸之道”的现代转化与运用\n\n摘要：中庸之道思想既是一种人生哲学，又对现代领导管理有很好的启示和指导意义。从对“中”的阐释中看到事物变化发展的差异性和矛盾性，促使我们在领导管理中把握好规律；从对“度”的认识中，要求把握火候，使各项职能得到有效的发挥；从对“和”的认识上把和谐发展作为发展的目标追求，从内部各要素和外部环境协调好关系，整合资源，提高领导管理效率；从对“诚”的认识上要求领导管理者重视修身之本，只有不断提升自身素质和能力，才能真正把握中庸思想的本质，提高领导管理水平。\n\n关键词：管理/中庸之道/管理者/孔子\n \n领导管理作为一种社会实践活动，建立在一定社会文化基础之上。为实现资源的有效配置和专业化分工协调，领导管理逐渐从一般社会活动中分离出来，并随时代变迁和人类文明进步而趋于制度化。中国历史上的管理大多体现于治国理政的政治方面，并逐渐扩展到社会活动的各个方面。中庸思想作为儒学的重要内容，《尚书·大禹谟》记载“人心惟危，道心惟微，惟精惟一，允执厥中。”凡事一定要执中，做到适当、适度，它是维持社会秩序稳定的有效方式与思想。但是当“中”的观念从一种行为智慧上升到社会主导价值取向时，对“中”的认识转向于“德”的理解，《论语·雍也》“中庸之为德也，其至矣乎！民鲜久矣。”“中庸”作为人的行为规范，成为儒家追求的高道德标准和精神境界。领导管理作为一种社会发展的制度保障和文化构成的要件，其有效性和管理水平的提高必须吸收和融入到历史的文化思想中去。儒家中庸思想蕴含的这种领导智慧，对现代管理有深远影响。[1]\n\n一、从中庸“尚中”思想把握规律性问题\n\n领导管理对规律的遵循就是要用科学的理念和方法协调各系统之间的关系，实现更高的效率和效益。孔子特别的“尚中”，把它作为人性发展的基本要求，作为评判“君子”品格的标准。在孔子看来，万事万物都存在着差异性，正是这种差异性构成了事物发展的关系复杂性，这是天地间的“道”，能否实现社会协调性发展，必须理清事物间存在的矛盾复杂性，从“尚中”的“道”的遵循做起。《中庸》中说：“不偏之谓中，不易之谓庸。中者，天下之正道，庸者，天下之定理。”“中”作为天下的“正道”体现了事物变化的本来面目，它不仅成为人的行为规范标准，同时也成为管理应遵循的原则。社会治理存在各种矛盾的影响，能否实现社会协调性的发展，必须从“尚中”的遵循做起。无论从管理计划、制度控制、用人决策等，是否在各利益关系平衡中做到恰到好处，是影响效果的关键，忽视这样的规律存在，不按规律办事，必然受到规律的惩罚，导致领导管理失败。\n\n“天地之道，博也、厚也、高也、明也、悠也、久也”，领导管理活动如同“天地之道”，就是一个有目的、有意识的能动过程，领导管理中的各环节、各要素之间存在的差异性，需要通过计划、组织、控制和沟通等职能整合，处理好人与自然的关系，维护好社会生产关系，调节好内在的“博、厚、高、明、悠”等规律的复杂性，才能实现领导管理的科学化和有效性。人的天性就是顺应规律，达到中正及平衡有序，使天、地、人实现协调发展。而要达到“率性之谓道”的境界，必须“修道”，“修道”的关键是把握中庸的精髓，那就要做到恰当适度。事物发展的规律性也就在这个“度”，它是事物存在的依据，同时也是人的行为规定，把握好了“度”，同时也就更好做到了“中”，也就真正实践了“天下之定理”。因此，管理不仅要认清管理过程中的关系矛盾，认识到“中”的规律性，而且应通过适度把握做出恰当的选择，在具体的时空条件下做出适当的行为。\n\n领导管理者要认清过程中的关系矛盾，通过适度把握做出恰当的选择。中庸之道要求顺应事物的自然禀性而为，因势利导；寻求内在平衡，做到不偏不倚，平衡各种极端冲突。从这个意义上说，中庸之道既是一种领导管理循“道”，也是遵“规”的科学方法论的应用。",
    "reference_list": "考点1：中庸之道应统一译为 the Doctrine of the Mean\n考点2：尚中应译为 the principle of centrality 或 reverence for the middle way\n考点3：度推荐译为 moderation 或 appropriate measure或grasp of proportion\n考点4：和应译为 harmony\n考点5：诚应译为 sincerity\n考点6：修道应译为 cultivate the Way\n考点7：不偏不倚应译为 neither biased nor partial 或 impartial and balanced\n考点8：率性之谓道推荐译为 The Way is to follow one's innate nature\n考点9：天下之正道应译为 the rightful Way of the world 或 the universal Way\n考点10：博、厚、高、明、悠、久推荐意译为 vastness, profundity, elevation, clarity, expansiveness, and perpetuity",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "73"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 法兰克福学派文化产业批判理论\n1947 年，阿多诺和霍克海默合著了《启蒙辩证法》，在该书的《文化工业：作为欺骗群众的启蒙》一文中，阿多尔诺认为“大众文化”（massculture）一词模糊而不准确，应该用\n“文化工业”（culturalindustry）这一新术语取而代之。霍克海默和阿多尔诺在文中并没有给文化工业下明确的定义，只大致提出它指涉凭借现代科学技术手段大规模地复制、传播文化产品的娱乐工业体系。在《文化工业再考察》一文中，阿多尔诺对术语作了阐释，认为其中的“工业”不能从字面上去理解，它表示事物本身的标准化和分配技术的合理化，而不是指严格的生产过程，除了文化工业的某些主要部分（如电影工业）之外，个别的生产形式（即构思及创作）仍被保持。因此，文化工业一词并不表示生产，而是表示文化产品的“标准化”和“伪个别性”。“文化工业”概念提出后，法兰克福学派其他主要代表人物马尔库塞、本杰明、哈贝马斯等人也对这个主题加以阐述，形成了法兰克福学派“文化工业”理论。法兰克福学派“文化工业”理论体现在《文化的肯定性质》《单面人》《机械复制时代中的艺术作品》《作为“意识形态”的技术和科学》等文本中，由于每个文本都有自己的主题，\n因而在阐述文化工业时也各有侧重，但总体上都对文化工业采取了批判的、否定的态度。这与该学派的社会批判理论、文化批判理论是一致的。法兰克福学派认为批判精神才是马克思主义的生命力所在，他们秉承了马克思主义的批判精神，对资本主义工业文明进行强烈谴责和彻底抨击，展开了对文化工业的批判之维，这些批判主要集中在两个方面：第一、文化工业与文化/艺术的性质相悖。文化工业对文化/艺术产生严重的消极影响，是法兰克福学派批判文化工业的首要之点。文化/艺术彰显个性、独创性、否定性以及超越性等。而文化工业则借助于科技进步和工业化生产，把文化/艺术产品纳人市场交换的轨道，按照从生产到流通到消费的商品操作程序运作，使之服从于市场机制和价值规则，最终蜕变为纯粹的商品。首先，文化工业通过模仿、复制和包装等使文化产品具有了同质化、标准化、齐一化的性质，正如霍克海默和阿多尔诺指出的：“在文化工业中，这种摹仿最终成为绝对的”，“达到个性化的努力最终被摹仿的努力所取代”文化工业使文化/艺术失去了个性、独立自主性，降低了、损害了文化/艺术真正的、内在的价值。其次，文化工业在追求利润、形成文化同质性的过程中，剥夺了文化的批判功能，即其否定的、大拒绝的方式，使文化/艺术丧失了对社会的否定、批判的维度。再次，资本主义文化工业的发展是文化服从于资本的权力、资本的逻辑的结果，在其中，价值原则支配了文化的各个方面，工具理性支配了文化领域，甚至支配着社会生活的一切领域，意味着文化的人文意义和内在价值的全面覆灭。\n4\n总而言之，文化/艺术沦为商品，带来了文化/艺术产品标准化和齐一化，引起了文化/艺术的质变。第二、文化工业与人性相悖。文化工业行使着意识形态的功能，通过大量标准化、齐一化的文化产品的影响和渗透，不知不觉中实现对人的思想、心理的控制。阿多诺清醒地意识到这一点，他认为现代社会对个人的控制程度大大超过以往，这种控制不是通过暴力和恐怖手段实现，而是通过文化工业的意识形态功能完成；马尔库塞在《单面人》中提到：“娱乐和信息工业不可抗拒的产品所带来的是各种定式的态度和习惯以及精神和情感方面的某些反应，这种反应使消费者在不同程度上愉快地与生产者紧密结合起来，并通过后者与整个娱乐和信息工业紧密结合起来。这些产品向消费者灌输某些思想并操纵他们的行为；它们提倡一种不受其虚伪影响的虚伪意识，这成为一种生活方式。”他们都致力于说明，文化工业通过文化商品的生产，控制和规范着消费者的需要，成了一种支配人的力量。文化工业造成“启蒙在意识形态方面的倒退”，人们逐步习惯于看似丰富多彩、实际上却单一机械的生活方式，缺乏对社会现实的批判精神和否定意识，丧失了主体意识、感性能力和主动性，失去了从事更有价值和更为充实的活动的潜力。文化工业不仅侵人了人们的生活世界，更渗透到人的“私人空间”。“私人空间”本是人具有内在自由的空间，在这个空间里，人可以成为并仍然是“他自己”。但是文化下业控制了大众日常生活直至内心意识，一体化的公共舆论侵人了“私人空间”，剥夺了个人的内在自由，使人丧失了“他自己”。“文化工业的每个运动都不可避免地把人们再现为社会需要塑造的那种样子”，成为与人的本性相背离的物化存在。法兰克福学派对资本主义文化的一种模式——文化工业进行了深刻的、否定性的分析和批判，其批判的主题是与当时的社会历史条件紧密相关的。与法兰克福学派所关注，反映和批判的 20 世纪 40、50 年代相比，20 世纪后半叶至今的社会状况发生了很大的变化。在现时代，文化工业作为文化生产的一种手段，在全世界各个国家和地区都获得了迅速的发展，即出现了文化工业全球化的现象。就资本主义世界而言，美国学者杰姆逊在《晚期资本主义的文化逻辑》一书中，着眼于“后工业社会”或“晚期资本主义”的文化状况，指出当代资本的一大特点在于其势力已扩张到精神领域、文化领域，资本主义文化已被彻底商品化、工业化；当代资本主义或晚期资本主义的发展、科学技术的进步为文化工业提供了重要的前提和基础，使得当代资本主义世界在原有的基础上，形成了更为系统的文化工业体系；而在非资本主义世界，就我国而言，随着市场经济体制的建立和改革开放的进一步深入，文化/艺术的商品化、工业化也成了一种不可避免的趋势，发展我国的文化工业，规范我国的文化市场势在必行。总体而言，文化工业已成了一种全球性的文化现象。\n5\n单向度的人\n发达工业社会成功地压制了人们心中的否定性、批判性、超越性的向度，使这个社会成为单向度的社会，而生活在其中的人就成了单向的人，这种人丧失了自由和创造力，不再想像或追求与现实生活不同的另一种生活。简单来说，单向度的人就是只知道物质享受而丧失了精神追求，只有物欲没有灵魂，对社会只有屈从没有批判精神的人，这样的人不会去追求更高的生活，甚至没有能力去想像更好的生活。同时，马尔库塞分析了现代资本主义社会对人的“消费控制”。在他看来，文化工业的先进手段使得“那些为了某些特殊的社会利益，从外部强加于个人的需求”不断大量生产出来，特别是所谓“强迫性消费”。在大众传播媒介的诱导下，人们在消费过程中不断得到一种虚假的满足，“人们似乎是为商品而生活，小轿车高清晰度的传真装置、错层式家庭住宅以及厨房设备成了人们生活的灵魂。”在马尔库塞看来，追求物质享受并不是人的本质特征，但是，在现代西方社会里，由于商人和传媒的共同操纵，人们把物质需求作为自己的最基本的需求，一旦把追求物质享受这种“虚假的需求”奉为信条，实际上人们已把“商品作为自己生活灵魂的中心”。人同产品的关系被颠倒了，不是产品为了满足人的需要而被生产，而是人为了使产品得到消费而存在。人拜倒在物面前，把物作为自己的灵魂，这就意味着忘却了、失去了自己的灵魂，这就是“物化”和“异化”的结局。工业社会技术发展带来的人的单向度，在当今网络社会中仍然存在并呈现加剧的态势。沉溺于虚拟现实、信息爆炸和自由的幻象削弱着人的批判性和反抗性，加强技术及其背后力量的社会控制。这种反思并非否定技术进步的积极功能和作用，而是提出一个参照和警示——虚拟社会并不是“乌托邦”，而只是一种媒介的形式\n",
    "ori_text": "\n\n 法兰克福学派文化产业批判理论\n1947 年，阿多诺和霍克海默合著了《启蒙辩证法》，在该书的《文化工业：作为欺骗群众的启蒙》一文中，阿多尔诺认为“大众文化”（massculture）一词模糊而不准确，应该用\n“文化工业”（culturalindustry）这一新术语取而代之。霍克海默和阿多尔诺在文中并没有给文化工业下明确的定义，只大致提出它指涉凭借现代科学技术手段大规模地复制、传播文化产品的娱乐工业体系。在《文化工业再考察》一文中，阿多尔诺对术语作了阐释，认为其中的“工业”不能从字面上去理解，它表示事物本身的标准化和分配技术的合理化，而不是指严格的生产过程，除了文化工业的某些主要部分（如电影工业）之外，个别的生产形式（即构思及创作）仍被保持。因此，文化工业一词并不表示生产，而是表示文化产品的“标准化”和“伪个别性”。“文化工业”概念提出后，法兰克福学派其他主要代表人物马尔库塞、本杰明、哈贝马斯等人也对这个主题加以阐述，形成了法兰克福学派“文化工业”理论。法兰克福学派“文化工业”理论体现在《文化的肯定性质》《单面人》《机械复制时代中的艺术作品》《作为“意识形态”的技术和科学》等文本中，由于每个文本都有自己的主题，\n因而在阐述文化工业时也各有侧重，但总体上都对文化工业采取了批判的、否定的态度。这与该学派的社会批判理论、文化批判理论是一致的。法兰克福学派认为批判精神才是马克思主义的生命力所在，他们秉承了马克思主义的批判精神，对资本主义工业文明进行强烈谴责和彻底抨击，展开了对文化工业的批判之维，这些批判主要集中在两个方面：第一、文化工业与文化/艺术的性质相悖。文化工业对文化/艺术产生严重的消极影响，是法兰克福学派批判文化工业的首要之点。文化/艺术彰显个性、独创性、否定性以及超越性等。而文化工业则借助于科技进步和工业化生产，把文化/艺术产品纳人市场交换的轨道，按照从生产到流通到消费的商品操作程序运作，使之服从于市场机制和价值规则，最终蜕变为纯粹的商品。首先，文化工业通过模仿、复制和包装等使文化产品具有了同质化、标准化、齐一化的性质，正如霍克海默和阿多尔诺指出的：“在文化工业中，这种摹仿最终成为绝对的”，“达到个性化的努力最终被摹仿的努力所取代”文化工业使文化/艺术失去了个性、独立自主性，降低了、损害了文化/艺术真正的、内在的价值。其次，文化工业在追求利润、形成文化同质性的过程中，剥夺了文化的批判功能，即其否定的、大拒绝的方式，使文化/艺术丧失了对社会的否定、批判的维度。再次，资本主义文化工业的发展是文化服从于资本的权力、资本的逻辑的结果，在其中，价值原则支配了文化的各个方面，工具理性支配了文化领域，甚至支配着社会生活的一切领域，意味着文化的人文意义和内在价值的全面覆灭。\n4\n总而言之，文化/艺术沦为商品，带来了文化/艺术产品标准化和齐一化，引起了文化/艺术的质变。第二、文化工业与人性相悖。文化工业行使着意识形态的功能，通过大量标准化、齐一化的文化产品的影响和渗透，不知不觉中实现对人的思想、心理的控制。阿多诺清醒地意识到这一点，他认为现代社会对个人的控制程度大大超过以往，这种控制不是通过暴力和恐怖手段实现，而是通过文化工业的意识形态功能完成；马尔库塞在《单面人》中提到：“娱乐和信息工业不可抗拒的产品所带来的是各种定式的态度和习惯以及精神和情感方面的某些反应，这种反应使消费者在不同程度上愉快地与生产者紧密结合起来，并通过后者与整个娱乐和信息工业紧密结合起来。这些产品向消费者灌输某些思想并操纵他们的行为；它们提倡一种不受其虚伪影响的虚伪意识，这成为一种生活方式。”他们都致力于说明，文化工业通过文化商品的生产，控制和规范着消费者的需要，成了一种支配人的力量。文化工业造成“启蒙在意识形态方面的倒退”，人们逐步习惯于看似丰富多彩、实际上却单一机械的生活方式，缺乏对社会现实的批判精神和否定意识，丧失了主体意识、感性能力和主动性，失去了从事更有价值和更为充实的活动的潜力。文化工业不仅侵人了人们的生活世界，更渗透到人的“私人空间”。“私人空间”本是人具有内在自由的空间，在这个空间里，人可以成为并仍然是“他自己”。但是文化下业控制了大众日常生活直至内心意识，一体化的公共舆论侵人了“私人空间”，剥夺了个人的内在自由，使人丧失了“他自己”。“文化工业的每个运动都不可避免地把人们再现为社会需要塑造的那种样子”，成为与人的本性相背离的物化存在。法兰克福学派对资本主义文化的一种模式——文化工业进行了深刻的、否定性的分析和批判，其批判的主题是与当时的社会历史条件紧密相关的。与法兰克福学派所关注，反映和批判的 20 世纪 40、50 年代相比，20 世纪后半叶至今的社会状况发生了很大的变化。在现时代，文化工业作为文化生产的一种手段，在全世界各个国家和地区都获得了迅速的发展，即出现了文化工业全球化的现象。就资本主义世界而言，美国学者杰姆逊在《晚期资本主义的文化逻辑》一书中，着眼于“后工业社会”或“晚期资本主义”的文化状况，指出当代资本的一大特点在于其势力已扩张到精神领域、文化领域，资本主义文化已被彻底商品化、工业化；当代资本主义或晚期资本主义的发展、科学技术的进步为文化工业提供了重要的前提和基础，使得当代资本主义世界在原有的基础上，形成了更为系统的文化工业体系；而在非资本主义世界，就我国而言，随着市场经济体制的建立和改革开放的进一步深入，文化/艺术的商品化、工业化也成了一种不可避免的趋势，发展我国的文化工业，规范我国的文化市场势在必行。总体而言，文化工业已成了一种全球性的文化现象。\n5\n单向度的人\n发达工业社会成功地压制了人们心中的否定性、批判性、超越性的向度，使这个社会成为单向度的社会，而生活在其中的人就成了单向的人，这种人丧失了自由和创造力，不再想像或追求与现实生活不同的另一种生活。简单来说，单向度的人就是只知道物质享受而丧失了精神追求，只有物欲没有灵魂，对社会只有屈从没有批判精神的人，这样的人不会去追求更高的生活，甚至没有能力去想像更好的生活。同时，马尔库塞分析了现代资本主义社会对人的“消费控制”。在他看来，文化工业的先进手段使得“那些为了某些特殊的社会利益，从外部强加于个人的需求”不断大量生产出来，特别是所谓“强迫性消费”。在大众传播媒介的诱导下，人们在消费过程中不断得到一种虚假的满足，“人们似乎是为商品而生活，小轿车高清晰度的传真装置、错层式家庭住宅以及厨房设备成了人们生活的灵魂。”在马尔库塞看来，追求物质享受并不是人的本质特征，但是，在现代西方社会里，由于商人和传媒的共同操纵，人们把物质需求作为自己的最基本的需求，一旦把追求物质享受这种“虚假的需求”奉为信条，实际上人们已把“商品作为自己生活灵魂的中心”。人同产品的关系被颠倒了，不是产品为了满足人的需要而被生产，而是人为了使产品得到消费而存在。人拜倒在物面前，把物作为自己的灵魂，这就意味着忘却了、失去了自己的灵魂，这就是“物化”和“异化”的结局。工业社会技术发展带来的人的单向度，在当今网络社会中仍然存在并呈现加剧的态势。沉溺于虚拟现实、信息爆炸和自由的幻象削弱着人的批判性和反抗性，加强技术及其背后力量的社会控制。这种反思并非否定技术进步的积极功能和作用，而是提出一个参照和警示——虚拟社会并不是“乌托邦”，而只是一种媒介的形式\n",
    "reference_list": "考点1:伪个别性推荐翻译pseudo-individuality，不可译为“pseudo-individualization”\n考点2：“阿多诺清醒地意识到这一点”中的“清醒地意识到”不可译为“clearly realized”，推荐译为“acutely aware”或“soberly realized”\n考点3：“感性能力”不可译为“sensual ability”，推荐译为“aesthetic sensibility”或“perceptual ability”\n考点4：“商品操作程序”不可译为“commodity operation procedures”，表达生硬。推荐译为“operates according to commercial processes”或“follows the logic of commodity production”\n考点5：“人们心中的”不可直译为“in people's hearts”，在学术语境下显得过于文学化和情绪化。推荐译为“in people's minds”或“in human consciousness”\n考点6：“主体意识”和“感性能力”可分别译为“subjectivity”或“sense of self”，以及“sensibility”\n考点7：“批判性和反抗性”，不可译为“critical and resistant consciousness”，推荐译为“capacity for criticism and resistance”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "192"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n1. 蜀道集团：“蜀畅一号”TBM即将投入西香高速建设西宁高速全线开工建设\n8月3日，由蜀道集团四川路桥和铁建重工集团联合打造的隧道工程利器一敞开式TBM“蜀畅一号”在长沙下线验收通过。顺利下线后，预计9月下旬在西香高速5标段完成安装调试及进洞首发。西香高速作为交通强国“十四五”重点项目，是四川建设交通强省、蜀道集团推进“五网融合”的重要支撑项目，是目前四川省内由单个项目公司管理单体投资建设体量最大的高速公路建设项目。项目包含“三桥五隧一地下互通”九大超级工程，施工区艰险陡峭，地质条件复杂。其中，盐源隧道全长14.15公里，不仅是西香高速五大隧道中10公里级最长隧道，还是目前全国在建第四、全省第二长隧道。针对施工隧址区地势艰险陡峭、地质条件复杂的特点，项目将采用TBM施工平导+大型机械钻爆法施工主洞模式，按“五横通六区间”布局，实现超特长隧道地下多掌子面的同步作业，确保项目工期可控，推动西香高速早日建成，早日结束凉山州盐源县、木里县不通高速的历史。\n2. 省能投集团：与日本住友商事株式会社、北京兆泰集团开展工作会谈\n8月1日，日本住友商事株式会社、北京兆泰集团到访四川能投，同四川能投进行工作座谈。四川能投作为四川省能源化工领军型企业，正围绕四川清洁能源优势，大力发展电力链、气体链、化工链、锂电链、氢能链五大链条。住友商事在能源资源、化学品、电子等方面与四川能投集团发展战略高度契合，北京兆泰集团在清洁能源业务有独特优势，三方将进一步深化清洁能源、绿氢绿氨、新材料、储能、动力电池回收等方面的合作，助力四川绿色低碳优势产业高质量发展，共同应对全球产业发展变革和全球气候变化挑战，续写中日经贸互利合作新篇章。\n3. 川煤集团：嘉华机械公司与俄罗斯马珂自动化公司签订战略合作协议\n8月1日，嘉华机械公司与俄罗斯马珂自动化公司签订了战略合作协议，标志川煤华荣嘉华向国际化又迈出了一大步。俄罗斯马珂自动化公司总经理瓦吉姆（Gruzdev Vadim）一行深入绿水洞煤矿井下现场查看嘉华机械公司综采装备应用情况，对嘉华机械公司在薄煤层、大倾角、急倾斜综采成套装备专业制造的水平给予了充分肯定。双方就产品质量、产品售后、“EAC”认证、品牌授权等细节进行了深入细致的探讨，并签定了战略合作协议。俄罗斯马珂公司成为嘉华机械公司在俄罗斯唯一一家具有代理嘉华机械公司煤机装备的企业，也为嘉华机械公司走出国门开辟了新通道。\n4. 省旅投集团：正式上线数字旅投等保云平台护航集团数字信息安全\n近日，旅投信产正式上线数字旅投等保云平台，进一步提高集团信息安全管理水平，促进集团数字化转型发展，为集团信息数字安全保驾护航。数字旅投等保云平台具有数据安全保护、数据统一合规管理、优化资源共享、快速风险应对等方面特点，将全方面、多领域为集团信息系统安全提供技术保障。",
    "ori_text": "1. 蜀道集团：“蜀畅一号”TBM即将投入西香高速建设西宁高速全线开工建设\n8月3日，由蜀道集团四川路桥和铁建重工集团联合打造的隧道工程利器一敞开式TBM“蜀畅一号”在长沙下线验收通过。顺利下线后，预计9月下旬在西香高速5标段完成安装调试及进洞首发。西香高速作为交通强国“十四五”重点项目，是四川建设交通强省、蜀道集团推进“五网融合”的重要支撑项目，是目前四川省内由单个项目公司管理单体投资建设体量最大的高速公路建设项目。项目包含“三桥五隧一地下互通”九大超级工程，施工区艰险陡峭，地质条件复杂。其中，盐源隧道全长14.15公里，不仅是西香高速五大隧道中10公里级最长隧道，还是目前全国在建第四、全省第二长隧道。针对施工隧址区地势艰险陡峭、地质条件复杂的特点，项目将采用TBM施工平导+大型机械钻爆法施工主洞模式，按“五横通六区间”布局，实现超特长隧道地下多掌子面的同步作业，确保项目工期可控，推动西香高速早日建成，早日结束凉山州盐源县、木里县不通高速的历史。\n2. 省能投集团：与日本住友商事株式会社、北京兆泰集团开展工作会谈\n8月1日，日本住友商事株式会社、北京兆泰集团到访四川能投，同四川能投进行工作座谈。四川能投作为四川省能源化工领军型企业，正围绕四川清洁能源优势，大力发展电力链、气体链、化工链、锂电链、氢能链五大链条。住友商事在能源资源、化学品、电子等方面与四川能投集团发展战略高度契合，北京兆泰集团在清洁能源业务有独特优势，三方将进一步深化清洁能源、绿氢绿氨、新材料、储能、动力电池回收等方面的合作，助力四川绿色低碳优势产业高质量发展，共同应对全球产业发展变革和全球气候变化挑战，续写中日经贸互利合作新篇章。\n3. 川煤集团：嘉华机械公司与俄罗斯马珂自动化公司签订战略合作协议\n8月1日，嘉华机械公司与俄罗斯马珂自动化公司签订了战略合作协议，标志川煤华荣嘉华向国际化又迈出了一大步。俄罗斯马珂自动化公司总经理瓦吉姆（Gruzdev Vadim）一行深入绿水洞煤矿井下现场查看嘉华机械公司综采装备应用情况，对嘉华机械公司在薄煤层、大倾角、急倾斜综采成套装备专业制造的水平给予了充分肯定。双方就产品质量、产品售后、“EAC”认证、品牌授权等细节进行了深入细致的探讨，并签定了战略合作协议。俄罗斯马珂公司成为嘉华机械公司在俄罗斯唯一一家具有代理嘉华机械公司煤机装备的企业，也为嘉华机械公司走出国门开辟了新通道。\n4. 省旅投集团：正式上线数字旅投等保云平台护航集团数字信息安全\n近日，旅投信产正式上线数字旅投等保云平台，进一步提高集团信息安全管理水平，促进集团数字化转型发展，为集团信息数字安全保驾护航。数字旅投等保云平台具有数据安全保护、数据统一合规管理、优化资源共享、快速风险应对等方面特点，将全方面、多领域为集团信息系统安全提供技术保障。",
    "reference_list": "考点1：“蜀道集团”需译为“SHUDAO INVESTMENT GROUP”或“Shudao Investment Group”\n考点2：“高速”推荐译为“Expressway”\n考点3：“四川路桥”推荐译为“Sichuan Road & Bridge Group”\n考点4：“铁建重工集团”推荐译为“China Railway Construction Heavy Industry Corporation Limited”或者“China Railway Construction Heavy Industry Corporation”\n考点5：“西香高速”需译为“Xichang-Shangrila Express Way”\n考点6：“十四五”推荐译为“the 14th Five-Year Plan”\n考点7：“平导”推荐译为“parallel adit”或“pilot tunnel”\n考点8：“爆钻法”推荐译为“Drill and Blast Method”\n考点9：“五通道六区间”推荐译为“Excavation of five connecting adits completed within six running tunnel sections”\n考点10：“凉山州”需译为“Liangshan Yi Autonomous Prefecture”\n考点11：“木里县”需译为“Muli Tibetan Autonomous County”\n考点12：“省能投集团”推荐译为“Sichuan Provincial Investment Group”\n考点13：“日本住友商事株式会社”推荐译为“Sumitomo Corporation”\n考点14：“北京兆泰集团”推荐译为“Zhao Tai Group”\n考点15：“川煤集团”推荐译为“Sichuan Coal Industry Group”\n考点16：“嘉华机械”推荐译为“Sichuan Jiahua Machinery”\n考点17：“西宁高速”推荐译为“Xining Expressway”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "17"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nCHAPTER III.\nBEAUTY.\nA NOBLER want of man is served by nature, namely, the love of Beauty.\nThe ancient Greeks called the world κοσμος, beauty. Such is the constitution of all things, or such the plastic power of the human eye, that the primary forms, as the sky, the mountain, the tree, the animal, give us a delight in and for themselves; a pleasure arising from outline, color, motion, and grouping. This seems partly owing to the eye itself. The eye is the best of artists. By the mutual action of its structure and of the laws of light, perspective is produced, which integrates every mass of objects, of what character soever, into a well colored and shaded globe, so that where the particular objects are mean and unaffecting, the landscape which they compose, is round and symmetrical. And as the eye is the best composer, so light is the first of painters. There is no object so foul that intense light will not make beautiful. And the stimulus it affords to the sense, and a sort of infinitude which it hath, like space and time, make all matter gay. Even the corpse has its own beauty. But besides this general grace diffused over nature, almost all the individual forms are agreeable to the eye, as is proved by our endless imitations of some of them, as the acorn, the grape, the pine-cone, the wheat-ear, the egg, the wings and forms of most birds, the lion's claw, the serpent, the butterfly, sea-shells, flames, clouds, buds, leaves, and the forms of many trees, as the palm.\nFor better consideration, we may distribute the aspects of Beauty in a threefold manner.\n1. First, the simple perception of natural forms is a delight. The influence of the forms and actions in nature, is so needful to man, that, in its lowest functions, it seems to lie on the confines of commodity and beauty. To the body and mind which have been cramped by noxious work or company, nature is medicinal and restores their tone. The tradesman, the attorney comes out of the din and craft of the street, and sees the sky and the woods, and is a man again. In their eternal calm, he finds himself. The health of the eye seems to demand a horizon. We are never tired, so long as we can see far enough.\nBut in other hours, Nature satisfies by its loveliness, and without any mixture of corporeal benefit. I see the spectacle of morning from the hill-top over against my house, from day-break to sun-rise, with emotions which an angel might share. The long slender bars of cloud float like fishes in the sea of crimson light. From the earth, as a shore, I look out into that silent sea. I seem to partake its rapid transformations: the active enchantment reaches my dust, and I dilate and conspire with the morning wind. How does Nature deify us with a few and cheap elements! Give me health and a day, and I will make the pomp of emperors ridiculous. The dawn is my Assyria; the sun-set and moon-rise my Paphos, and unimaginable realms of faerie; broad noon shall be my England of the senses and the understanding; the night shall be my Germany of mystic philosophy and dreams.\nNot less excellent, except for our less susceptibility in the afternoon, was the charm, last evening, of a January sunset. The western clouds divided and subdivided themselves into pink flakes modulated with tints of unspeakable softness; and the air had so much life and sweetness, that it was a pain to come within doors. What was it that nature would say? Was there no meaning in the live repose of the valley behind the mill, and which Homer or Shakspeare could not reform for me in words? The leafless trees become spires of flame in the sunset, with the blue east for their back-ground, and the stars of the dead calices of flowers, and every withered stem and stubble rimed with frost, contribute something to the mute music.\nThe inhabitants of cities suppose that the country landscape is pleasant only half the year. I please myself with the graces of the winter scenery, and believe that we are as much touched by it as by the genial influences of summer. To the attentive eye, each moment of the year has its own beauty, and in the same field, it beholds, every hour, a picture which was never seen before, and which shall never be seen again. The heavens change every moment, and reflect their glory or gloom on the plains beneath. The state of the crop in the surrounding farms alters the expression of the earth from week to week. The succession of native plants in the pastures and roadsides, which makes the silent clock by which time tells the summer hours, will make even the divisions of the day sensible to a keen observer. The tribes of birds and insects, like the plants punctual to their time, follow each other, and the year has room for all. By water-courses, the variety is greater. In July, the blue pontederia or pickerel-weed blooms in large beds in the shallow parts of our pleasant river, and swarms with yellow butterflies in continual motion. Art cannot rival this pomp of purple and gold. Indeed the river is a perpetual gala, and boasts each month a new ornament.\nBut this beauty of Nature which is seen and felt as beauty, is the least part. The shows of day, the dewy morning, the rainbow, mountains, orchards in blossom, stars, moonlight, shadows in still water, and the like, if too eagerly hunted, become shows merely, and mock us with their unreality. Go out of the house to see the moon, and 't is mere tinsel; it will not please as when its light shines upon your necessary journey. The beauty that shimmers in the yellow afternoons of October, who ever could clutch it? Go forth to find it, and it is gone: 't is only a mirage as you look from the windows of diligence.\n2. The presence of a higher, namely, of the spiritual element is essential to its perfection. The high and divine beauty which can be loved without effeminacy, is that which is found in combination with the human will. Beauty is the mark God sets upon virtue. Every natural action is graceful. Every heroic act is also decent, and causes the place and the bystanders to shine. We are taught by great actions that the universe is the property of every individual in it. Every rational creature has all nature for his dowry and estate. It is his, if he will. He may divest himself of it; he may creep into a corner, and abdicate his kingdom, as most men do, but he is entitled to the world by his constitution. In proportion to the energy of his thought and will, he takes up the world into himself. \"All those things for which men plough, build, or sail, obey virtue;\" said Sallust. \"The winds and waves,\" said Gibbon, \"are always on the side of the ablest navigators.\" So are the sun and moon and all the stars of heaven. When a noble act is done,—perchance in a scene of great natural beauty; when Leonidas and his three hundred martyrs consume one day in dying, and the sun and moon come each and look at them once in the steep defile of Thermopylae; when Arnold Winkelried, in the high Alps, under the shadow of the avalanche, gathers in his side a sheaf of Austrian spears to break the line for his comrades; are not these heroes entitled to add the beauty of the scene to the beauty of the deed? When the bark of Columbus nears the shore of America;—before it, the beach lined with savages, fleeing out of all their huts of cane; the sea behind; and the purple mountains of the Indian Archipelago around, can we separate the man from the living picture? Does not the New World clothe his form with her palm-groves and savannahs as fit drapery? Ever does natural beauty steal in like air, and envelope great actions. When Sir Harry Vane was dragged up the Tower-hill, sitting on a sled, to suffer death, as the champion of the English laws, one of the multitude cried out to him, \"You never sate on so glorious a seat.\" Charles II., to intimidate the citizens of London, caused the patriot Lord Russel to be drawn in an open coach, through the principal streets of the city, on his way to the scaffold. \"But,\" his biographer says, \"the multitude imagined they saw liberty and virtue sitting by his side.\" In private places, among sordid objects, an act of truth or heroism seems at once to draw to itself the sky as its temple, the sun as its candle. Nature stretcheth out her arms to embrace man, only let his thoughts be of equal greatness. Willingly does she follow his steps with the rose and the violet, and bend her lines of grandeur and grace to the decoration of her darling child. Only let his thoughts be of equal scope, and the frame will suit the picture. A virtuous man is in unison with her works, and makes the central figure of the visible sphere. Homer, Pindar, Socrates, Phocion, associate themselves fitly in our memory with the geography and climate of Greece. The visible heavens and earth sympathize with Jesus. And in common life, whosoever has seen a person of powerful character and happy genius, will have remarked how easily he took all things along with him,—the persons, the opinions, and the day, and nature became ancillary to a man.",
    "ori_text": "CHAPTER III.\nBEAUTY.\nA NOBLER want of man is served by nature, namely, the love of Beauty.\nThe ancient Greeks called the world κοσμος, beauty. Such is the constitution of all things, or such the plastic power of the human eye, that the primary forms, as the sky, the mountain, the tree, the animal, give us a delight in and for themselves; a pleasure arising from outline, color, motion, and grouping. This seems partly owing to the eye itself. The eye is the best of artists. By the mutual action of its structure and of the laws of light, perspective is produced, which integrates every mass of objects, of what character soever, into a well colored and shaded globe, so that where the particular objects are mean and unaffecting, the landscape which they compose, is round and symmetrical. And as the eye is the best composer, so light is the first of painters. There is no object so foul that intense light will not make beautiful. And the stimulus it affords to the sense, and a sort of infinitude which it hath, like space and time, make all matter gay. Even the corpse has its own beauty. But besides this general grace diffused over nature, almost all the individual forms are agreeable to the eye, as is proved by our endless imitations of some of them, as the acorn, the grape, the pine-cone, the wheat-ear, the egg, the wings and forms of most birds, the lion's claw, the serpent, the butterfly, sea-shells, flames, clouds, buds, leaves, and the forms of many trees, as the palm.\nFor better consideration, we may distribute the aspects of Beauty in a threefold manner.\n1. First, the simple perception of natural forms is a delight. The influence of the forms and actions in nature, is so needful to man, that, in its lowest functions, it seems to lie on the confines of commodity and beauty. To the body and mind which have been cramped by noxious work or company, nature is medicinal and restores their tone. The tradesman, the attorney comes out of the din and craft of the street, and sees the sky and the woods, and is a man again. In their eternal calm, he finds himself. The health of the eye seems to demand a horizon. We are never tired, so long as we can see far enough.\nBut in other hours, Nature satisfies by its loveliness, and without any mixture of corporeal benefit. I see the spectacle of morning from the hill-top over against my house, from day-break to sun-rise, with emotions which an angel might share. The long slender bars of cloud float like fishes in the sea of crimson light. From the earth, as a shore, I look out into that silent sea. I seem to partake its rapid transformations: the active enchantment reaches my dust, and I dilate and conspire with the morning wind. How does Nature deify us with a few and cheap elements! Give me health and a day, and I will make the pomp of emperors ridiculous. The dawn is my Assyria; the sun-set and moon-rise my Paphos, and unimaginable realms of faerie; broad noon shall be my England of the senses and the understanding; the night shall be my Germany of mystic philosophy and dreams.\nNot less excellent, except for our less susceptibility in the afternoon, was the charm, last evening, of a January sunset. The western clouds divided and subdivided themselves into pink flakes modulated with tints of unspeakable softness; and the air had so much life and sweetness, that it was a pain to come within doors. What was it that nature would say? Was there no meaning in the live repose of the valley behind the mill, and which Homer or Shakspeare could not reform for me in words? The leafless trees become spires of flame in the sunset, with the blue east for their back-ground, and the stars of the dead calices of flowers, and every withered stem and stubble rimed with frost, contribute something to the mute music.\nThe inhabitants of cities suppose that the country landscape is pleasant only half the year. I please myself with the graces of the winter scenery, and believe that we are as much touched by it as by the genial influences of summer. To the attentive eye, each moment of the year has its own beauty, and in the same field, it beholds, every hour, a picture which was never seen before, and which shall never be seen again. The heavens change every moment, and reflect their glory or gloom on the plains beneath. The state of the crop in the surrounding farms alters the expression of the earth from week to week. The succession of native plants in the pastures and roadsides, which makes the silent clock by which time tells the summer hours, will make even the divisions of the day sensible to a keen observer. The tribes of birds and insects, like the plants punctual to their time, follow each other, and the year has room for all. By water-courses, the variety is greater. In July, the blue pontederia or pickerel-weed blooms in large beds in the shallow parts of our pleasant river, and swarms with yellow butterflies in continual motion. Art cannot rival this pomp of purple and gold. Indeed the river is a perpetual gala, and boasts each month a new ornament.\nBut this beauty of Nature which is seen and felt as beauty, is the least part. The shows of day, the dewy morning, the rainbow, mountains, orchards in blossom, stars, moonlight, shadows in still water, and the like, if too eagerly hunted, become shows merely, and mock us with their unreality. Go out of the house to see the moon, and 't is mere tinsel; it will not please as when its light shines upon your necessary journey. The beauty that shimmers in the yellow afternoons of October, who ever could clutch it? Go forth to find it, and it is gone: 't is only a mirage as you look from the windows of diligence.\n2. The presence of a higher, namely, of the spiritual element is essential to its perfection. The high and divine beauty which can be loved without effeminacy, is that which is found in combination with the human will. Beauty is the mark God sets upon virtue. Every natural action is graceful. Every heroic act is also decent, and causes the place and the bystanders to shine. We are taught by great actions that the universe is the property of every individual in it. Every rational creature has all nature for his dowry and estate. It is his, if he will. He may divest himself of it; he may creep into a corner, and abdicate his kingdom, as most men do, but he is entitled to the world by his constitution. In proportion to the energy of his thought and will, he takes up the world into himself. \"All those things for which men plough, build, or sail, obey virtue;\" said Sallust. \"The winds and waves,\" said Gibbon, \"are always on the side of the ablest navigators.\" So are the sun and moon and all the stars of heaven. When a noble act is done,—perchance in a scene of great natural beauty; when Leonidas and his three hundred martyrs consume one day in dying, and the sun and moon come each and look at them once in the steep defile of Thermopylae; when Arnold Winkelried, in the high Alps, under the shadow of the avalanche, gathers in his side a sheaf of Austrian spears to break the line for his comrades; are not these heroes entitled to add the beauty of the scene to the beauty of the deed? When the bark of Columbus nears the shore of America;—before it, the beach lined with savages, fleeing out of all their huts of cane; the sea behind; and the purple mountains of the Indian Archipelago around, can we separate the man from the living picture? Does not the New World clothe his form with her palm-groves and savannahs as fit drapery? Ever does natural beauty steal in like air, and envelope great actions. When Sir Harry Vane was dragged up the Tower-hill, sitting on a sled, to suffer death, as the champion of the English laws, one of the multitude cried out to him, \"You never sate on so glorious a seat.\" Charles II., to intimidate the citizens of London, caused the patriot Lord Russel to be drawn in an open coach, through the principal streets of the city, on his way to the scaffold. \"But,\" his biographer says, \"the multitude imagined they saw liberty and virtue sitting by his side.\" In private places, among sordid objects, an act of truth or heroism seems at once to draw to itself the sky as its temple, the sun as its candle. Nature stretcheth out her arms to embrace man, only let his thoughts be of equal greatness. Willingly does she follow his steps with the rose and the violet, and bend her lines of grandeur and grace to the decoration of her darling child. Only let his thoughts be of equal scope, and the frame will suit the picture. A virtuous man is in unison with her works, and makes the central figure of the visible sphere. Homer, Pindar, Socrates, Phocion, associate themselves fitly in our memory with the geography and climate of Greece. The visible heavens and earth sympathize with Jesus. And in common life, whosoever has seen a person of powerful character and happy genius, will have remarked how easily he took all things along with him,—the persons, the opinions, and the day, and nature became ancillary to a man.",
    "reference_list": "考点1：【company 】应译为“人际往来”。\n考点2：【my dust】应译为“我的身躯”。\n考点3：【and the air had so much life】中的【life】应译为“清新”。\n考点4：【attentive eye】应译为“有心人”，不可直译为“专注的眼睛”\n考点5：【decent】应译为“正道”。\n考点6：【Tower-hill】应译为“塔丘”，英国伦敦中心的地区。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "小说",
    "prompt_id": "61"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nThe Diversity Elevator: On R. F. Kuang’s “Yellowface”\nHistorically, yellowface was a Hollywood phenomenon. The portmanteau, like the offense it characterizes, is hideously obvious, wherein a white actor transforms into an Orientalist caricature for racist comic relief. On the page, however, this minstrelsy is more subtle. The fraudulence is professional, encased within a name. \n \nSince the 1990s, at least two instances of literary yellowface have arisen in the world of American poetry. The poet Kent Johnson contrived an exhaustive biography and body of work for a fictitious Japanese poet named Araki Yasusada. Johnson never expressly admitted to fabricating the persona, but served as its “executor,” overseeing all matters of correspondence and even compiling a volume of his poetry. Similarly, Michael Derrick Hudson adopted the Chinese moniker Yi-Fen Chou to submit poems previously rejected under his real name, a move that apparently increased his work’s prospects for publication. Hudson only admitted to doing so in 2015 when one of his poems was selected for that year’s Best American Poetry.\n \nThese poetic provocations were not malicious, so Johnson and Hudson have claimed. Johnson has, more or less, insisted that the fabricated persona was a postmodernist response to “the unrepresentable acts of Hiroshima [and] Nagasaki.” Meanwhile, Hudson’s deception seems to be a sorry attempt at validating the artistic viability of his rejected work. The implications of this racial subterfuge have been subject to much literary debate, and constitute the central theme of R.F. Kuang’s unsubtly-titled novel Yellowface. I don’t intend to relitigate the rationale behind these hoaxes, except to remark that if Kuang’s protagonist, the young white novelist June Hayward, had possessed a sliver of Johnson’s or Hudson’s delusional gall, Yellowface would have made for a much more exciting read. Instead, the novel is a lackluster examination of plagiarism, privilege, and cultural appropriation that is too assured of its own righteousness; that fails, in its moral assertions and limp characterizations, to conclude anything besides the painstakingly obvious. With a contrived plot and colorless, cliché-ridden prose, Yellowface, which is billed as a “razor sharp” satire, offers remarkably little novelty and nuance into contested artistic territory.\n \n•\n \nJune Hayward is a novelist whose coming-of-age debut was released to middling acclaim. Wracked by careerist envy, June is debilitated by the success of her friend and fellow writer Athena Liu, the newly-crowned Asian American darling of the literary world. Athena, at the ripe age of 27, has three bestselling novels, a Netflix deal, and “a history of awards nominations longer than [a] grocery list,” while June is adrift with an agent who doesn’t seem to even like her work. Knowledge of Athena’s success only exacerbates June’s writer’s block. She was “derailed for days” after hearing of her friend’s six-figure option deal, an admission that leads the reader to wonder: Was June ever much of a writer at all?\n \nTurns out, she’s more of a plagiarist—and a puzzlingly diligent one at that. After bearing witness to Athena’s untimely death, June steals an unfinished manuscript off her dead friend’s desk, substantially reworks the stolen material, and claims it as an original work. The manuscript, a historical epic about Chinese laborers in World War I, launches June to literary stardom. But June’s duplicity doesn’t stop after she rejoices in “breaking the glass ceiling.” At the behest of the white editors who acquired her manuscript, June rebrands as the vaguely Asian-sounding Juniper Song “to have a clean start.” She manipulates Athena’s mother to keep her from sharing her dead daughter’s diaries with the public, fearing they contained evidence of her plagiarism. She extorts Athena’s ex-boyfriend and gets an editorial assistant who harbored suspicions about her writing fired. She even briefly considers murder. \n \nContrary to this aforementioned plot summary, the novel’s tone is not one of Ripley-esque malice, but is self-consciously confessional à la Sally Rooney. The novel’s sophomoric and humorless prose is cluttered with banal exposition (“I shut the lid and push my laptop across the desk, breathless at my own audacity”), dull dialogue, trivial observations (“The line at the campus Starbucks was moving at a glacial pace”), and weak clichés (“I can tell this book is going to dazzle”; “I glimpse something that makes my heart stop”; “I fall in love with writing again”). The diaristic narration speeds through June’s most shocking transgressions and skips past the manuscript theft, effacing the novel of any psychological momentum. The chapters end hastily, often with a foreboding sentiment, dangled like a carrot to entice the reader on. The first chapter features one such example: “Meanwhile, in my bag, tossed at the floor of my bed, Athena’s manuscript sits like a hot sack of coals.” \n \nAs the novel progresses, these narrative cliffhangers serve as fleeting proof of June’s entitled delusion. The perfunctory dialogue is set up to be a weak defense of June’s worst, cancel-worthy traits. Consider this feeble rebuttal mounted amidst her impending Twitter cancellation: “It’s the internet that’s fucked, not me. It’s this contingent of social justice warriors, these clout-chasing white ‘allies,’ and Asian activists seeking attention who are acting up. I am not the bad guy. I am the victim here.” This is, of course, a roundabout reminder that June is the bad guy. Her objections are not persuasive, as they are an unsophisticated ploy to peel back the authorial curtain, revealing the earnest plot designer behind the page, ready to clue readers into her manufactured conclusions. Yellowface, then, becomes an excruciatingly cumbersome mental exercise, as the reader is asked to suspend disbelief that such an eminently skittish and stupid character, on the basis of her whiteness, could fool the publishing industry with little more than a half-baked plan in place. When sustained over the course of 336 pages, the narration sags in its inverted moral didacticism. The novel doesn’t seem to “grapple with questions of diversity, racism, and cultural appropriation,” as the jacket copy claims, as much as it regurgitates palatable groupthink on the matters at hand. \n \nJune is no Rachel Dolezal, strategic and self-righteous in her racist ruse. We learn that her plagiarism is motivated by puerile revenge, a tit-for-tat since Athena, so June claims, stole from her first. June was sexually assaulted in college (“my maybe-rape”), an experience that’s callously recounted in a few pages over the novel’s halfway mark. The assault is alluded to only once beyond that section. June claimed to bury her trauma “so deep in the back of my mind that [it] wouldn’t resurface until therapy sessions many years later.” We learn that June first disclosed this sexual trauma to Athena, who, in a “Cat Person”-like twist of events, mined it for a short story.\n \nOne could recognize how Athena’s emotional theft fueled June’s rage over time, her success finally pushing June off the embittered edge. But June, as far as we know, had no ongoing scheme against her nemesis, nor was she a compulsive plagiarist in college. In the third chapter, which was crafted to function as an anticipatory aside, June mounts a self-reflexive defense of the theft, declaring that it “felt like reparations, payback for the things that Athena took from me.” It’s a rare instance of the character’s deranged folly on display, as her postmortem resentment is felt in timid doses, and her jealous obsession (“I feel this hot coiling in my stomach, a bizarre urge to stick my fingers in her berry-red-painted mouth and rip her face apart”) is alluded to but left largely unexplored.\n \nThere are many discrepancies in Yellowface, least of which is how a white girl from Philadelphia can physically pass as a part-Asian writer by adopting the surname Song and donning a bad tan: “I’ve never pretended to be Chinese,” June says, after an older Chinese woman confuses her to be of Asian heritage. But the most incongruous aspect of Yellowface is the self-conscious moral schema imposed upon June, who should be, by all accounts, a far more shameless and shrewd anti-hero. June is so skittishly insecure that she lives more in fear of cancel culture than a hefty lawsuit from her publishers. She is preoccupied with appearances (“I want bloggers, reviewers, and readers to know I’m the kind of person who, you know, cares about the right issues”), an obsession that leads her to fund an annual scholarship in Athena’s name and volunteer to mentor young AAPI writers. “I’m going to be better than Athena. I am a woman who helps other women,” she says. \n\nJune’s moral framework—specifically her compulsion to perform goodness—seems to be imported directly from Twitter, the virtual world where the novel briefly achieves its parodic foothold. But let’s not mistake parody for profundity. Anyone who has spent time scrolling through literary Twitter is capable of imitating its dialogic absurdities. This uneven characterization is puzzling, as Kuang has said that she set out to write an unlikable narrator in the vein of Gone Girl and The Girl in the Window. Fictional narrators are generally understood to be unreliable, though unlikability is, as of late, a trendy provocation. The novel’s form has become “a tool for moral instruction,” argued the critic Lauren Oyler, a technique to “make [a] feminist argument about how the shiftiness of narrative can be used and abused in imbalanced power relations.” Yellowface attempts to subvert this from a racial vantage point, though Kuang does little to disguise her didacticism.",
    "ori_text": "The Diversity Elevator: On R. F. Kuang’s “Yellowface”\nHistorically, yellowface was a Hollywood phenomenon. The portmanteau, like the offense it characterizes, is hideously obvious, wherein a white actor transforms into an Orientalist caricature for racist comic relief. On the page, however, this minstrelsy is more subtle. The fraudulence is professional, encased within a name. \n \nSince the 1990s, at least two instances of literary yellowface have arisen in the world of American poetry. The poet Kent Johnson contrived an exhaustive biography and body of work for a fictitious Japanese poet named Araki Yasusada. Johnson never expressly admitted to fabricating the persona, but served as its “executor,” overseeing all matters of correspondence and even compiling a volume of his poetry. Similarly, Michael Derrick Hudson adopted the Chinese moniker Yi-Fen Chou to submit poems previously rejected under his real name, a move that apparently increased his work’s prospects for publication. Hudson only admitted to doing so in 2015 when one of his poems was selected for that year’s Best American Poetry.\n \nThese poetic provocations were not malicious, so Johnson and Hudson have claimed. Johnson has, more or less, insisted that the fabricated persona was a postmodernist response to “the unrepresentable acts of Hiroshima [and] Nagasaki.” Meanwhile, Hudson’s deception seems to be a sorry attempt at validating the artistic viability of his rejected work. The implications of this racial subterfuge have been subject to much literary debate, and constitute the central theme of R.F. Kuang’s unsubtly-titled novel Yellowface. I don’t intend to relitigate the rationale behind these hoaxes, except to remark that if Kuang’s protagonist, the young white novelist June Hayward, had possessed a sliver of Johnson’s or Hudson’s delusional gall, Yellowface would have made for a much more exciting read. Instead, the novel is a lackluster examination of plagiarism, privilege, and cultural appropriation that is too assured of its own righteousness; that fails, in its moral assertions and limp characterizations, to conclude anything besides the painstakingly obvious. With a contrived plot and colorless, cliché-ridden prose, Yellowface, which is billed as a “razor sharp” satire, offers remarkably little novelty and nuance into contested artistic territory.\n \n•\n \nJune Hayward is a novelist whose coming-of-age debut was released to middling acclaim. Wracked by careerist envy, June is debilitated by the success of her friend and fellow writer Athena Liu, the newly-crowned Asian American darling of the literary world. Athena, at the ripe age of 27, has three bestselling novels, a Netflix deal, and “a history of awards nominations longer than [a] grocery list,” while June is adrift with an agent who doesn’t seem to even like her work. Knowledge of Athena’s success only exacerbates June’s writer’s block. She was “derailed for days” after hearing of her friend’s six-figure option deal, an admission that leads the reader to wonder: Was June ever much of a writer at all?\n \nTurns out, she’s more of a plagiarist—and a puzzlingly diligent one at that. After bearing witness to Athena’s untimely death, June steals an unfinished manuscript off her dead friend’s desk, substantially reworks the stolen material, and claims it as an original work. The manuscript, a historical epic about Chinese laborers in World War I, launches June to literary stardom. But June’s duplicity doesn’t stop after she rejoices in “breaking the glass ceiling.” At the behest of the white editors who acquired her manuscript, June rebrands as the vaguely Asian-sounding Juniper Song “to have a clean start.” She manipulates Athena’s mother to keep her from sharing her dead daughter’s diaries with the public, fearing they contained evidence of her plagiarism. She extorts Athena’s ex-boyfriend and gets an editorial assistant who harbored suspicions about her writing fired. She even briefly considers murder. \n \nContrary to this aforementioned plot summary, the novel’s tone is not one of Ripley-esque malice, but is self-consciously confessional à la Sally Rooney. The novel’s sophomoric and humorless prose is cluttered with banal exposition (“I shut the lid and push my laptop across the desk, breathless at my own audacity”), dull dialogue, trivial observations (“The line at the campus Starbucks was moving at a glacial pace”), and weak clichés (“I can tell this book is going to dazzle”; “I glimpse something that makes my heart stop”; “I fall in love with writing again”). The diaristic narration speeds through June’s most shocking transgressions and skips past the manuscript theft, effacing the novel of any psychological momentum. The chapters end hastily, often with a foreboding sentiment, dangled like a carrot to entice the reader on. The first chapter features one such example: “Meanwhile, in my bag, tossed at the floor of my bed, Athena’s manuscript sits like a hot sack of coals.” \n \nAs the novel progresses, these narrative cliffhangers serve as fleeting proof of June’s entitled delusion. The perfunctory dialogue is set up to be a weak defense of June’s worst, cancel-worthy traits. Consider this feeble rebuttal mounted amidst her impending Twitter cancellation: “It’s the internet that’s fucked, not me. It’s this contingent of social justice warriors, these clout-chasing white ‘allies,’ and Asian activists seeking attention who are acting up. I am not the bad guy. I am the victim here.” This is, of course, a roundabout reminder that June is the bad guy. Her objections are not persuasive, as they are an unsophisticated ploy to peel back the authorial curtain, revealing the earnest plot designer behind the page, ready to clue readers into her manufactured conclusions. Yellowface, then, becomes an excruciatingly cumbersome mental exercise, as the reader is asked to suspend disbelief that such an eminently skittish and stupid character, on the basis of her whiteness, could fool the publishing industry with little more than a half-baked plan in place. When sustained over the course of 336 pages, the narration sags in its inverted moral didacticism. The novel doesn’t seem to “grapple with questions of diversity, racism, and cultural appropriation,” as the jacket copy claims, as much as it regurgitates palatable groupthink on the matters at hand. \n \nJune is no Rachel Dolezal, strategic and self-righteous in her racist ruse. We learn that her plagiarism is motivated by puerile revenge, a tit-for-tat since Athena, so June claims, stole from her first. June was sexually assaulted in college (“my maybe-rape”), an experience that’s callously recounted in a few pages over the novel’s halfway mark. The assault is alluded to only once beyond that section. June claimed to bury her trauma “so deep in the back of my mind that [it] wouldn’t resurface until therapy sessions many years later.” We learn that June first disclosed this sexual trauma to Athena, who, in a “Cat Person”-like twist of events, mined it for a short story.\n \nOne could recognize how Athena’s emotional theft fueled June’s rage over time, her success finally pushing June off the embittered edge. But June, as far as we know, had no ongoing scheme against her nemesis, nor was she a compulsive plagiarist in college. In the third chapter, which was crafted to function as an anticipatory aside, June mounts a self-reflexive defense of the theft, declaring that it “felt like reparations, payback for the things that Athena took from me.” It’s a rare instance of the character’s deranged folly on display, as her postmortem resentment is felt in timid doses, and her jealous obsession (“I feel this hot coiling in my stomach, a bizarre urge to stick my fingers in her berry-red-painted mouth and rip her face apart”) is alluded to but left largely unexplored.\n \nThere are many discrepancies in Yellowface, least of which is how a white girl from Philadelphia can physically pass as a part-Asian writer by adopting the surname Song and donning a bad tan: “I’ve never pretended to be Chinese,” June says, after an older Chinese woman confuses her to be of Asian heritage. But the most incongruous aspect of Yellowface is the self-conscious moral schema imposed upon June, who should be, by all accounts, a far more shameless and shrewd anti-hero. June is so skittishly insecure that she lives more in fear of cancel culture than a hefty lawsuit from her publishers. She is preoccupied with appearances (“I want bloggers, reviewers, and readers to know I’m the kind of person who, you know, cares about the right issues”), an obsession that leads her to fund an annual scholarship in Athena’s name and volunteer to mentor young AAPI writers. “I’m going to be better than Athena. I am a woman who helps other women,” she says. \n\nJune’s moral framework—specifically her compulsion to perform goodness—seems to be imported directly from Twitter, the virtual world where the novel briefly achieves its parodic foothold. But let’s not mistake parody for profundity. Anyone who has spent time scrolling through literary Twitter is capable of imitating its dialogic absurdities. This uneven characterization is puzzling, as Kuang has said that she set out to write an unlikable narrator in the vein of Gone Girl and The Girl in the Window. Fictional narrators are generally understood to be unreliable, though unlikability is, as of late, a trendy provocation. The novel’s form has become “a tool for moral instruction,” argued the critic Lauren Oyler, a technique to “make [a] feminist argument about how the shiftiness of narrative can be used and abused in imbalanced power relations.” Yellowface attempts to subvert this from a racial vantage point, though Kuang does little to disguise her didacticism.",
    "reference_list": "考点1： “R. F. Kuang”应该译为“匡灵秀”。\n考点2： “Yellowface”应译为“黄色脸孔”。\n考点3： “expressly”应译为“明确地”。 \n考点4：“Araki Yasusada” 推荐翻译成 ”荒木安貞”\n考点5： “coming-of-age debut”应译为“成长题材处女作”。\n考点6：“She even briefly considers murder”中的“briefly”应译为“闪过”。\n考点7：“AAPI”应译为“亚裔和太平洋岛裔美国人”。\n考点8：“Gone Girl”中应译为“《消失的爱人》”。\n考点9：“The Girl in the Window”应译为“窗里的女人”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "59"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n Representativeness of measurements for underlying dynamics The above modeling uncertainties arise when one assumes that the time series used are a direct representation of the climate system in question. In practice, that is rarely the case. Tipping elements in the climate are complex, spatially extended systems with many degrees of freedom, and it is always a crude simplification to describe their dynamics by a 1D observational time series. Moreover, it is often unclear whether the relevant dynamical properties of the system in question are captured well by the available measurements. For example, the Amazon rainforest is observed using different remotely sensed vegetation indices, but it remains hard to tell which one is appropriate for understanding its stability (11, 23). The problem is further complicated by the relatively short time span of many climate observations. Tipping elements such as the polar ice sheets or the AMOC evolve over long timescales, and so, time series of a hundred years or more would be necessary to understand and predict their dynamics. When there are no direct measurements on such long timescales, studies use different proxies (“fingerprints”) for the systems. These fingerprints are climate variables that have some physical connection to the system of interest and are thus, to some extent, correlated with the changes of the system. For example, ice core–derived Greenland melt rates have been used as a fingerprint for ice sheet height and SST patterns as a fingerprint for the AMOC streamfunction strength (9, 24). Similarly, satellite-derived vegetation indices should be interpreted as—uncertain and potentially biased—fingerprints of the actual vegetation dynamics (11, 23). Fingerprints that are useful for understanding the evolution of the mean trend are not necessarily useful for predicting tipping times. \nIn conclusion, there are often no fingerprints available with the precision required for predicting tipping times, as we will discuss for the AMOC in the next section.  Effect of dataset preprocessing and underlying uncertainties / nonstationary coverage  In addition to the uncertainties arising from the modeling approach and the choice of fingerprint, there are also substantial uncertainties in CSD indicators that originate from the dataset preprocessing steps and the nonstationarity of observational data coverage (23, 25, 26). The number of available climate observations has grown exponentially since 1850 (27, 28), especially with the increase of remote sensing measurements since the 1970s. In earlier years, these measurements are often concentrated in a small number of areas on the globe, resulting in uneven and sparse global coverage until at least the mid-20th century (28). Therefore, to produce globally complete datasets, researchers often merge a number of different instrumental records and fill in the gaps in data using a processing procedure. The bias correction for the different measurements and the infilling methods often prioritize the accuracy of the mean trend over the accuracy of the higher-order statistics [see, for example, (23, 29–32)]. This can cause problems for the detection of CSD (23, 25, 26, 33) and especially for the calculation of the future tipping time. Any calculation of the future tipping time is strongly reliant on the time evolution of the data’s higher-order statistics, and the dataset preprocessing can induce artificial trends in these statistics. To this point, we show the effect of adding white measurement noise of a decreasing amplitude to the synthetic model data of the fold normal form and estimate tipping times using the introduced methods. Figure 2D shows how a small amount of observational uncertainty can incur substantial changes in the estimations. One real-world example of such an effect is the merging of multiple satellite signals. The change in signal-tonoise ratio from one satellite to the next can cause an artificial increase in autocorrelation (23). \nAnother issue emerges when missing data are infilled with some sort of principal components analysis, in which case there will be more artificial smoothing in earlier times due to the lack of data, and so quantities like the variance could increase artificially (26, 29). In the next section, we will discuss such dataset uncertainties in detail for the AMOC SST fingerprints.  Uncertainties in predicting the AMOC tipping time  We now address these uncertainties for the specific case of predicting the tipping time of a system by applying DD23’s MLE-based method to SST-based fingerprints of the AMOC (14). We choose to use DD23’s methodology because among the three discussed methods, it performs best for a fold normal form with white noise (Fig. 2A) and was designed for AMOC tipping time prediction. Modeling assumptions  There has long been a discussion about whether the AMOC, when investigated as a complex system under external forcing of, e.g., GMT (or better, regional freshwater forcing), exhibits multiple stable states (34–36). Transitions between such stable states could be bifurcation induced and thus abrupt and irreversible. The so-called fold bifurcation constitutes a minimal example of such behavior. For instance, the conceptual Stommel model of the AMOC features a fold bifurcation (34). Taking this reasoning another step further, the application of the MLE method assumes that the 1D observable of AMOC strength is well represented by the following normal form model  where Xt is the system state at time t, α is the external control parameter, b is a timescale parameter, m is a translation parameter, and the white noise term σdWt represents noisy perturbations within the system. A similar simplification has been applied to more complex AMOC models in multiple studies (37, 38) and is justified by arguing that all fold bifurcations are topologically equivalent to this model. This, however, is only true locally, in potentially very close proximity to the bifurcation point, while the proposed estimation method banks on the assumption that it would hold in arbitrary distance to the bifurcation point. On the basis of the arguments brought forth, we do not see a direct constraint on the dynamics away from the tipping point. When applying the MLE method to data of the closely related 2D Stommel-Cessi AMOC model (39), one obtains a considerable bias in tipping time estimates toward earlier times (Fig. 3A). \nThis should be seen as an indication that even models with an underlying fold bifurcation structure, yet not following the very specific normal form model equation above, produce time series which, when applying the MLE method, yield biased tipping time estimates. The AMOC exhibits pronounced decadal variability (40). Before the commencing of the destabilisation at time t0, the AMOC is assumed to resemble paths of a stationary stochastic process X defined by  When applying their MLE method to the AMOC, DD23 estimates  a value of 2b√α ≈ 3.1 [year−1], corresponding to a characteristic correlation time of 0.32 [year]. In contrast, frequency spectra of AMOC evolutions in general circulation models show strongest variability between 5 and 100 years [e.g., figure 6 in (41)]. Such pronounced additional variability on long timescales is not captured by the above Ornstein-Uhlenbeck model. Internal variability independent of the  model noise will thus cause large excursions from the transient mean. The proposed method is not equipped to incorporate the impact of these excursions on the estimated tipping time, since they may be misinterpreted as trends toward a tipping point. This exposes the estimation method to risks of false alarms of a similar nature as in Fig. 1. In addition, recent application of DD23’s MLE method to AMOC tipping in a complex climate model (42) has shown that the tipping time prediction is very sensitive to the time interval analyzed due to the decadal variability of the AMOC, and most 150-year windows cannot accurately estimate the tipping time. Moreover, for quantitative extrapolations of tipping time, any simplifying assumptions on the driving noise would need to be carefully checked. Since disturbances to the equilibrium state are themselves of atmospheric and oceanic origin, time correlation of the noise should be taken into consideration, e.g., via a red noise model (8). Nonstationary red noise present in the system can incur substantial biases in the estimation of the tipping time and even result in false alarms of an approaching bifurcation (as seen in Figs. 1 and 2B).\nAssumptions on future AMOC forcing  Previously, we discussed the fact that not only can we not assume the future evolution of the forcing of climate tipping elements to be known, we also cannot assume that the forcing evolved linearly in the past. This is also true for the AMOC: Several studies show that radiative anomalies due to aerosol pollution likely attenuated the AMOC weakening of the past decades (43, 44), and such changes cannot be modeled with a linearly changing control parameter. Moreover, the GMT forcing itself influences the AMOC due to many different nonlinear mechanisms, e.g., via thermal expansion, a strengthening hydrological cycle, as well as sea ice and ice sheet melt (with the influence of the latter in the historical period still under debate) (45, 46). The effective freshwater flux might serve as a better forcing parameter (35, 47), but we do not have long-term measurements of this parameter, and there is evidence that it does not linearly depend on GMT; e.g., Greenland runoff increases nonlinearly over time (48, 49).",
    "ori_text": "\n\n Representativeness of measurements for underlying dynamics The above modeling uncertainties arise when one assumes that the time series used are a direct representation of the climate system in question. In practice, that is rarely the case. Tipping elements in the climate are complex, spatially extended systems with many degrees of freedom, and it is always a crude simplification to describe their dynamics by a 1D observational time series. Moreover, it is often unclear whether the relevant dynamical properties of the system in question are captured well by the available measurements. For example, the Amazon rainforest is observed using different remotely sensed vegetation indices, but it remains hard to tell which one is appropriate for understanding its stability (11, 23). The problem is further complicated by the relatively short time span of many climate observations. Tipping elements such as the polar ice sheets or the AMOC evolve over long timescales, and so, time series of a hundred years or more would be necessary to understand and predict their dynamics. When there are no direct measurements on such long timescales, studies use different proxies (“fingerprints”) for the systems. These fingerprints are climate variables that have some physical connection to the system of interest and are thus, to some extent, correlated with the changes of the system. For example, ice core–derived Greenland melt rates have been used as a fingerprint for ice sheet height and SST patterns as a fingerprint for the AMOC streamfunction strength (9, 24). Similarly, satellite-derived vegetation indices should be interpreted as—uncertain and potentially biased—fingerprints of the actual vegetation dynamics (11, 23). Fingerprints that are useful for understanding the evolution of the mean trend are not necessarily useful for predicting tipping times. \nIn conclusion, there are often no fingerprints available with the precision required for predicting tipping times, as we will discuss for the AMOC in the next section.  Effect of dataset preprocessing and underlying uncertainties / nonstationary coverage  In addition to the uncertainties arising from the modeling approach and the choice of fingerprint, there are also substantial uncertainties in CSD indicators that originate from the dataset preprocessing steps and the nonstationarity of observational data coverage (23, 25, 26). The number of available climate observations has grown exponentially since 1850 (27, 28), especially with the increase of remote sensing measurements since the 1970s. In earlier years, these measurements are often concentrated in a small number of areas on the globe, resulting in uneven and sparse global coverage until at least the mid-20th century (28). Therefore, to produce globally complete datasets, researchers often merge a number of different instrumental records and fill in the gaps in data using a processing procedure. The bias correction for the different measurements and the infilling methods often prioritize the accuracy of the mean trend over the accuracy of the higher-order statistics [see, for example, (23, 29–32)]. This can cause problems for the detection of CSD (23, 25, 26, 33) and especially for the calculation of the future tipping time. Any calculation of the future tipping time is strongly reliant on the time evolution of the data’s higher-order statistics, and the dataset preprocessing can induce artificial trends in these statistics. To this point, we show the effect of adding white measurement noise of a decreasing amplitude to the synthetic model data of the fold normal form and estimate tipping times using the introduced methods. Figure 2D shows how a small amount of observational uncertainty can incur substantial changes in the estimations. One real-world example of such an effect is the merging of multiple satellite signals. The change in signal-tonoise ratio from one satellite to the next can cause an artificial increase in autocorrelation (23). \nAnother issue emerges when missing data are infilled with some sort of principal components analysis, in which case there will be more artificial smoothing in earlier times due to the lack of data, and so quantities like the variance could increase artificially (26, 29). In the next section, we will discuss such dataset uncertainties in detail for the AMOC SST fingerprints.  Uncertainties in predicting the AMOC tipping time  We now address these uncertainties for the specific case of predicting the tipping time of a system by applying DD23’s MLE-based method to SST-based fingerprints of the AMOC (14). We choose to use DD23’s methodology because among the three discussed methods, it performs best for a fold normal form with white noise (Fig. 2A) and was designed for AMOC tipping time prediction. Modeling assumptions  There has long been a discussion about whether the AMOC, when investigated as a complex system under external forcing of, e.g., GMT (or better, regional freshwater forcing), exhibits multiple stable states (34–36). Transitions between such stable states could be bifurcation induced and thus abrupt and irreversible. The so-called fold bifurcation constitutes a minimal example of such behavior. For instance, the conceptual Stommel model of the AMOC features a fold bifurcation (34). Taking this reasoning another step further, the application of the MLE method assumes that the 1D observable of AMOC strength is well represented by the following normal form model  where Xt is the system state at time t, α is the external control parameter, b is a timescale parameter, m is a translation parameter, and the white noise term σdWt represents noisy perturbations within the system. A similar simplification has been applied to more complex AMOC models in multiple studies (37, 38) and is justified by arguing that all fold bifurcations are topologically equivalent to this model. This, however, is only true locally, in potentially very close proximity to the bifurcation point, while the proposed estimation method banks on the assumption that it would hold in arbitrary distance to the bifurcation point. On the basis of the arguments brought forth, we do not see a direct constraint on the dynamics away from the tipping point. When applying the MLE method to data of the closely related 2D Stommel-Cessi AMOC model (39), one obtains a considerable bias in tipping time estimates toward earlier times (Fig. 3A). \nThis should be seen as an indication that even models with an underlying fold bifurcation structure, yet not following the very specific normal form model equation above, produce time series which, when applying the MLE method, yield biased tipping time estimates. The AMOC exhibits pronounced decadal variability (40). Before the commencing of the destabilisation at time t0, the AMOC is assumed to resemble paths of a stationary stochastic process X defined by  When applying their MLE method to the AMOC, DD23 estimates  a value of 2b√α ≈ 3.1 [year−1], corresponding to a characteristic correlation time of 0.32 [year]. In contrast, frequency spectra of AMOC evolutions in general circulation models show strongest variability between 5 and 100 years [e.g., figure 6 in (41)]. Such pronounced additional variability on long timescales is not captured by the above Ornstein-Uhlenbeck model. Internal variability independent of the  model noise will thus cause large excursions from the transient mean. The proposed method is not equipped to incorporate the impact of these excursions on the estimated tipping time, since they may be misinterpreted as trends toward a tipping point. This exposes the estimation method to risks of false alarms of a similar nature as in Fig. 1. In addition, recent application of DD23’s MLE method to AMOC tipping in a complex climate model (42) has shown that the tipping time prediction is very sensitive to the time interval analyzed due to the decadal variability of the AMOC, and most 150-year windows cannot accurately estimate the tipping time. Moreover, for quantitative extrapolations of tipping time, any simplifying assumptions on the driving noise would need to be carefully checked. Since disturbances to the equilibrium state are themselves of atmospheric and oceanic origin, time correlation of the noise should be taken into consideration, e.g., via a red noise model (8). Nonstationary red noise present in the system can incur substantial biases in the estimation of the tipping time and even result in false alarms of an approaching bifurcation (as seen in Figs. 1 and 2B).\nAssumptions on future AMOC forcing  Previously, we discussed the fact that not only can we not assume the future evolution of the forcing of climate tipping elements to be known, we also cannot assume that the forcing evolved linearly in the past. This is also true for the AMOC: Several studies show that radiative anomalies due to aerosol pollution likely attenuated the AMOC weakening of the past decades (43, 44), and such changes cannot be modeled with a linearly changing control parameter. Moreover, the GMT forcing itself influences the AMOC due to many different nonlinear mechanisms, e.g., via thermal expansion, a strengthening hydrological cycle, as well as sea ice and ice sheet melt (with the influence of the latter in the historical period still under debate) (45, 46). The effective freshwater flux might serve as a better forcing parameter (35, 47), but we do not have long-term measurements of this parameter, and there is evidence that it does not linearly depend on GMT; e.g., Greenland runoff increases nonlinearly over time (48, 49).",
    "reference_list": "考点1：“Tipping elements”必须译为“临界要素”，避免“临界点要素”等不一致表达。\n考点2：“CSD”必须译为“临界减速”，临界减速是指接近临界点时系统动态的减缓。\n考点3：“a minimal example”建议译为“最简化例子”，避免翻译为“基本例子”，准确传达“minimal”的含义。\n考点4：“white measurement noise”必须译为“测量的白噪声”，避免遗漏“measurement”一词，确保精确性。\n考点5：“tipping times”必须译为“临界时间”，确保对“tipping time”术语的标准化翻译。\n考点6：“Fingerprint”推荐译为“指纹 / 代理指标”，避免在科学语境中误用“指纹”单独的译法，需附加说明。\n考点7：“decadal variability”建议译为“年代际变率”，避免使用“年代际变化”等不准确的翻译。\n考点8：“GMT”必须译为“全球平均气温”，避免使用“全球平均温度”或其他混淆表达。确保气候学术语准确传达，避免模糊。\n考点9：“underlying dynamics”必须译为“潜在动力学”，避免误用“潜在动态”，保持术语一致性。\n考点10：“SST patterns”建议译为“海表温度（SST）模式”，并在首次出现时明确解释“SST”的含义。\n考点11：“nonstationary coverage”建议译为“非平稳覆盖范围”，避免遗漏“覆盖范围”的表达。\n考点12：“higher-order statistics”建议译为“高阶统计量”，保持术语一致性。\n考点13：“autocorrelation”建议译为“自相关”，避免误译为“自相关性”。自相关用于描述数据序列间的相似性，需精确翻译。\n考点14：“topologically equivalent”统一译为“拓扑等价的”，避免使用其他含糊的翻译。拓扑等价是数学和物理中常用术语，需确保精准传达。\n考点15：“spatially extended systems”建议译为“空间延展系统”，保持准确的术语翻译。确保译文精准传递了系统在空间上的广泛扩展特性。\n考点16：“Stommel–Cessi AMOC model”建议译为“斯托梅尔—切西大西洋经向翻转环流模型”，确保音译一致。确认模型的全名和背景，以免误导读者。\n考点17：“hydrological cycle”推荐译为“水文循环”，保持正式且准确的翻译。水文循环在气候系统中是核心概念，需确保译文清晰。\n考点18：“Greenland runoff”统一译为“格陵兰径流”，避免翻译为“格陵兰的径流量”或其他不标准翻译。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "108"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n 最新数据显示，截至6月末，我国央行已连续8个月增持黄金，我国黄金储备规模达7390万盎司。这一稳健增持节奏与世界黄金协会近期发布的《2025年全球央行黄金储备调查》（以下简称《调查》）结果形成呼应——逾九成的受访央行预计未来12个月内全球央行将继续增持黄金，这一比例创下自2019年首次针对该问题进行调查以来的最高纪录。 黄金储备是各国国际储备多元化构成的重要内容。笔者认为，我国黄金储备“八连增”，蕴含着调节优化国际储备组合、稳步推进人民币国际化、应对全球经济不确定性的考量。 其一，我国央行连续8个月扩大黄金储备，是优化国际储备组合的主动作为。 当前，美元在全球外汇储备中的占比已降至历史低位。这一变化缘于美国债务攀升、经济减速等多重因素导致的美元信用弱化，美元指数承压下行。在此背景下，黄金作为非主权信用储备资产，其价格通常与美元指数呈负相关性，成为对冲美元资产贬值等风险的理想选择。 我国黄金储备“八连增”，既是顺应全球趋势，更是对国际储备资产韧性的战略加固。这种配置策略也成为多国央行的共同选择。 其二，我国央行连续8个月扩大黄金储备，是夯实人民币国际化的信用基石。 《调查》显示，受访央行同时认为，欧元、人民币等其他货币以及黄金在全球储备中的占比将在未来五年内上升。这一共识印证了国际货币体系正向多极化发展。货币国际化既需以强大的经济和金融实力为支撑，也需要多元化的国际储备提供信用背书。我国央行有序增持黄金，向国际市场传递了人民币具有坚实价值支撑的信号，有力推动全球经济主体在贸易结算、投融资以及外汇储备等维度扩大人民币的使用。 这种“强基固本”的布局，正与人民币国际地位的稳步上升形成良性互动。6月18日，中国人民银行行长潘功胜在2025陆家嘴论坛上表示：“人民币已成为全球第二大贸易融资货币；按全口径计算，人民币已成为全球第三大支付货币；在国际货币基金组织（IMF）特别提款权（SDR）货币篮子中的权重位列全球第三。” 其三，我国央行连续8个月扩大黄金储备，是应对全球经济不确定性的有效手段。 受地缘政治紧张等因素影响，全球经济面临严峻挑战。黄金作为具备避险属性、抗通胀功能和长期价值稳定特征的特殊资产，契合国际储备管理对安全性、流动性和保值增值的核心需求。此外，黄金还具有金融和商品的多重属性，在复杂国际环境中“稳定器”功能凸显，我国央行保持每月合理幅度的稳健增持，既避免了市场波动，又为防范外部冲击构建了可靠的“安全垫”。 总体而言，央行“八连增”黄金，既展现了对国际货币体系变革的敏锐把握，也为应对全球经济格局调整提供了“中国方案”。",
    "ori_text": " 最新数据显示，截至6月末，我国央行已连续8个月增持黄金，我国黄金储备规模达7390万盎司。这一稳健增持节奏与世界黄金协会近期发布的《2025年全球央行黄金储备调查》（以下简称《调查》）结果形成呼应——逾九成的受访央行预计未来12个月内全球央行将继续增持黄金，这一比例创下自2019年首次针对该问题进行调查以来的最高纪录。 黄金储备是各国国际储备多元化构成的重要内容。笔者认为，我国黄金储备“八连增”，蕴含着调节优化国际储备组合、稳步推进人民币国际化、应对全球经济不确定性的考量。 其一，我国央行连续8个月扩大黄金储备，是优化国际储备组合的主动作为。 当前，美元在全球外汇储备中的占比已降至历史低位。这一变化缘于美国债务攀升、经济减速等多重因素导致的美元信用弱化，美元指数承压下行。在此背景下，黄金作为非主权信用储备资产，其价格通常与美元指数呈负相关性，成为对冲美元资产贬值等风险的理想选择。 我国黄金储备“八连增”，既是顺应全球趋势，更是对国际储备资产韧性的战略加固。这种配置策略也成为多国央行的共同选择。 其二，我国央行连续8个月扩大黄金储备，是夯实人民币国际化的信用基石。 《调查》显示，受访央行同时认为，欧元、人民币等其他货币以及黄金在全球储备中的占比将在未来五年内上升。这一共识印证了国际货币体系正向多极化发展。货币国际化既需以强大的经济和金融实力为支撑，也需要多元化的国际储备提供信用背书。我国央行有序增持黄金，向国际市场传递了人民币具有坚实价值支撑的信号，有力推动全球经济主体在贸易结算、投融资以及外汇储备等维度扩大人民币的使用。 这种“强基固本”的布局，正与人民币国际地位的稳步上升形成良性互动。6月18日，中国人民银行行长潘功胜在2025陆家嘴论坛上表示：“人民币已成为全球第二大贸易融资货币；按全口径计算，人民币已成为全球第三大支付货币；在国际货币基金组织（IMF）特别提款权（SDR）货币篮子中的权重位列全球第三。” 其三，我国央行连续8个月扩大黄金储备，是应对全球经济不确定性的有效手段。 受地缘政治紧张等因素影响，全球经济面临严峻挑战。黄金作为具备避险属性、抗通胀功能和长期价值稳定特征的特殊资产，契合国际储备管理对安全性、流动性和保值增值的核心需求。此外，黄金还具有金融和商品的多重属性，在复杂国际环境中“稳定器”功能凸显，我国央行保持每月合理幅度的稳健增持，既避免了市场波动，又为防范外部冲击构建了可靠的“安全垫”。 总体而言，央行“八连增”黄金，既展现了对国际货币体系变革的敏锐把握，也为应对全球经济格局调整提供了“中国方案”。",
    "reference_list": "考点 1：\"我国央行\" 应译为 ”China’s central bank”\n考点 2：\"世界黄金协会 \"应译为 “World Gold Council”\n考点 3：\"2025 年全球央行黄金储备调查\" 应译为 ”2025 Global Central Bank Gold Reserves Survey“\n考点 4：\"国际储备多元化构成\" 应译为 ”diversified composition of international reserves”\n考点 5：\"黄金储备 “八连增” 应译为 \"eight consecutive months of gold reserve increases\"\n考点 6：\"人民币国际化\" 应译为 \"RMB internationalization\"\n考点 7：\"国际储备组合\" 应译为 \"international reserve portfolio\"\n考点 8：\"美元指数\" 应译为 \"US Dollar Index\"\n考点 9：\"非主权信用储备资产\" 应译为 \"non-sovereign credit reserve asset\"\n考点10：\"对冲美元资产贬值风险\"应译为 \"hedge against depreciation risk of dollar-denominated assets“\n考点 11：\"国际储备资产韧性\" 应译为 “resilience of international reserve assets”\n考点 12：\"信用基石\" 应译为 “credit cornerstone“\n考点 13：\"国际货币体系多极化\" 应译为 ”multipolarization of the international monetary system“\n考点 14：\"信用背书\" 应译为 “credit backing”\n考点 15：\"外汇储备\" 应译为 “foreign exchange reserves“\n考点 16：\"2025 陆家嘴论坛\" 应译为 ”2025 Lujiazui Forum“\n考点 17：\"全球第二大贸易融资货币\" 应译为 “world’s second-largest trade financing currency”\n考点 18：\"全球第三大支付货币\" 应译为 ”world’s third-largest payment currency”\n考点 19：\"国际货币基金组织（IMF）特别提款权（SDR）货币篮子\" 应译为 “IMF Special Drawing Rights currency basket“\n考点 20：\"避险属性\" 应译为 “safe-haven attribute”\n考点 21：\"抗通胀功能\" 应译为 ”hedge against inflation“\n考点 22：\"长期价值稳定特征\" 应译为 ”long-term value stability characteristic”\n考点 23：\"安全性、流动性和保值增值\" 应译为 “security, liquidity, and value preservation and appreciation”\n考点 24：\"安全垫\" 应译为 ”safety cushion“",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "84"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n上周，美国政府签署《大规模税收与支出法案》（“大而美”法案），这项争议日久的法案正式成为法律。该法案恰似给美国经济注入代价高昂的“兴奋剂”，一边减税举债对内加大刺激，一边持续对外转嫁经济风险。这种对美国经济“竭泽而渔”、对世界经济“祸水东引”的行为，折射出美国国内治理所面临的深层困境。\n这份近千页的法案核心内容并不复杂：通过永久性降低企业税率至20%、对富人实施大规模减税、免除小费与加班收入税收，试图刺激企业投资与居民消费。同时，1570亿美元的新增军费与1500亿美元的边境安全拨款，则打上了“创造就业”的旗号。\n法案对美国经济具有刺激兴奋作用，然而要为之付出的代价也不小。为平衡减税造成的财政收入窟窿，法案削减了1万亿美元以上的社会福利支出——约1200万低收入者将失去医疗保险，300万人被剥夺食品券资格，医疗补助门槛也被大幅提高。根据美国国会预算办公室的分析，仅法案中的延长减税措施在未来10年就将带来超过4.5万亿美元支出成本。同时，参议院版本法案在未来10年将使美国赤字增加近3.3万亿美元，美国债务上限也将提高5万亿美元。\n法案这种“劫贫济富”的设计，将使财富加速向顶层聚集，而社会成本则甩给最脆弱的群体，更直接透支了美国未来的财政健康。美国企业家埃隆·马斯克就痛批法案“极其疯狂且具破坏性”“给夕阳产业提供施舍，却严重损害未来产业”。\n在本届美国政府看来，该法案可以通过永久性降低企业税率、免除特定劳动收入税收等措施来释放企业投资与居民消费的短期动能，减税带来企业资本开支的回升与股市的乐观反应，能被包装为政府创造经济增长的“证据”，在选举周期内具有显著政治吸引力。分析认为，这有助于在短期内压制美国国内社会矛盾，同时也为美国政府对外转嫁风险提供操作空间。\n实际上，就在该法案通过参议院投票后不久，美国政府就已经迅速将矛头指向世界，宣布将每日向10个国家发送关税通知函，税率从10%到70%不等。有分析认为，此举旨在“用外国关税收入填补美国国内减税缺口”。同时，美国所谓“对等关税”90天暂缓期临近，美国政府突然强硬的表态，迫使各国在高压下接受不平等条款的意图一览无余。\n“大而美”法案的支持者声称，法案将通过企业回流与投资增长重塑美国经济竞争力。不过，当减税红利被关税成本抵消，企业实际承担的合规成本与供应链中断损失，可能远超税收优惠。更关键的是，以邻为壑的政策必然引发反制——欧盟已酝酿针对性关税，新兴市场则在加速“去美元化”布局。这种对抗性循环一旦形成，全球经济增长的整体蛋糕将持续萎缩，最终反噬美国企业的海外利润根基。\n本届美国政府就职以来推出的种种争议政策，反映出美国国内经济治理失序的困境。这种政策变动正对世界经济带来多重冲击。\n首先，多边贸易体系遭遇信任危机。当美国以国内法案为由单方面调整关税，其行为违背了世界贸易组织（WTO）框架下的互惠原则。欧盟、日本等传统盟友被迫重新评估与美国的贸易关系，新兴经济体则加速推进区域自贸协定以规避系统性风险。全球供应链从效率优先转向安全优先的重构进程，因美国政策不可预测性而显著提速。\n其次，美元信用基础面临持续侵蚀。法案再度提升债务上限，虽然暂时避免债务违约，却让美国国债规模突破40万亿美元。当财政纪律让位于政治周期，各国央行对美元资产的长期信心必然受损。历史表明，主权货币的全球地位不仅依赖市场，更需要货币发行国的财政自律——而当前法案正在消耗这种稀缺的政治资本。\n此外，气候治理共识受到局部冲击。法案中清洁能源补贴的取消与化石能源的政策倾斜，不仅削弱《巴黎协定》的执行力度和机制，阻滞全球应对气候变化的努力，更可能引发连锁效应：部分工业化国家可能以竞争力为由推迟低碳转型，发展中国家则面临技术合作中断的风险。\n当前美国一些人的政策路径，正将世界推向“零和博弈”的危险轨道。这也让世人更加看清，世界经济的真正风险，不在于美国经济的短期波动，而在于其政策引发的系统性信任危机。",
    "ori_text": "上周，美国政府签署《大规模税收与支出法案》（“大而美”法案），这项争议日久的法案正式成为法律。该法案恰似给美国经济注入代价高昂的“兴奋剂”，一边减税举债对内加大刺激，一边持续对外转嫁经济风险。这种对美国经济“竭泽而渔”、对世界经济“祸水东引”的行为，折射出美国国内治理所面临的深层困境。\n这份近千页的法案核心内容并不复杂：通过永久性降低企业税率至20%、对富人实施大规模减税、免除小费与加班收入税收，试图刺激企业投资与居民消费。同时，1570亿美元的新增军费与1500亿美元的边境安全拨款，则打上了“创造就业”的旗号。\n法案对美国经济具有刺激兴奋作用，然而要为之付出的代价也不小。为平衡减税造成的财政收入窟窿，法案削减了1万亿美元以上的社会福利支出——约1200万低收入者将失去医疗保险，300万人被剥夺食品券资格，医疗补助门槛也被大幅提高。根据美国国会预算办公室的分析，仅法案中的延长减税措施在未来10年就将带来超过4.5万亿美元支出成本。同时，参议院版本法案在未来10年将使美国赤字增加近3.3万亿美元，美国债务上限也将提高5万亿美元。\n法案这种“劫贫济富”的设计，将使财富加速向顶层聚集，而社会成本则甩给最脆弱的群体，更直接透支了美国未来的财政健康。美国企业家埃隆·马斯克就痛批法案“极其疯狂且具破坏性”“给夕阳产业提供施舍，却严重损害未来产业”。\n在本届美国政府看来，该法案可以通过永久性降低企业税率、免除特定劳动收入税收等措施来释放企业投资与居民消费的短期动能，减税带来企业资本开支的回升与股市的乐观反应，能被包装为政府创造经济增长的“证据”，在选举周期内具有显著政治吸引力。分析认为，这有助于在短期内压制美国国内社会矛盾，同时也为美国政府对外转嫁风险提供操作空间。\n实际上，就在该法案通过参议院投票后不久，美国政府就已经迅速将矛头指向世界，宣布将每日向10个国家发送关税通知函，税率从10%到70%不等。有分析认为，此举旨在“用外国关税收入填补美国国内减税缺口”。同时，美国所谓“对等关税”90天暂缓期临近，美国政府突然强硬的表态，迫使各国在高压下接受不平等条款的意图一览无余。\n“大而美”法案的支持者声称，法案将通过企业回流与投资增长重塑美国经济竞争力。不过，当减税红利被关税成本抵消，企业实际承担的合规成本与供应链中断损失，可能远超税收优惠。更关键的是，以邻为壑的政策必然引发反制——欧盟已酝酿针对性关税，新兴市场则在加速“去美元化”布局。这种对抗性循环一旦形成，全球经济增长的整体蛋糕将持续萎缩，最终反噬美国企业的海外利润根基。\n本届美国政府就职以来推出的种种争议政策，反映出美国国内经济治理失序的困境。这种政策变动正对世界经济带来多重冲击。\n首先，多边贸易体系遭遇信任危机。当美国以国内法案为由单方面调整关税，其行为违背了世界贸易组织（WTO）框架下的互惠原则。欧盟、日本等传统盟友被迫重新评估与美国的贸易关系，新兴经济体则加速推进区域自贸协定以规避系统性风险。全球供应链从效率优先转向安全优先的重构进程，因美国政策不可预测性而显著提速。\n其次，美元信用基础面临持续侵蚀。法案再度提升债务上限，虽然暂时避免债务违约，却让美国国债规模突破40万亿美元。当财政纪律让位于政治周期，各国央行对美元资产的长期信心必然受损。历史表明，主权货币的全球地位不仅依赖市场，更需要货币发行国的财政自律——而当前法案正在消耗这种稀缺的政治资本。\n此外，气候治理共识受到局部冲击。法案中清洁能源补贴的取消与化石能源的政策倾斜，不仅削弱《巴黎协定》的执行力度和机制，阻滞全球应对气候变化的努力，更可能引发连锁效应：部分工业化国家可能以竞争力为由推迟低碳转型，发展中国家则面临技术合作中断的风险。\n当前美国一些人的政策路径，正将世界推向“零和博弈”的危险轨道。这也让世人更加看清，世界经济的真正风险，不在于美国经济的短期波动，而在于其政策引发的系统性信任危机。",
    "reference_list": "考点1：大规模税收与支出法案应统一译为 One Big Beautiful Bill Act（OBBBA/OBBB/BBB/OB3)\n考点2：兴奋剂应译为 economic stimulant 或 adrenaline shot to the economy\n考点3：竭泽而渔推荐译为 draining the pond to catch the fish或 short-sighted exploitation\n考点4：祸水东引推荐译为 shifting the burden to others 或 passing on risks to the world\n考点5：永久性降低企业税率应译为 permanently lower the corporate tax rate\n考点6：小费与加班收入统一译为 tips and overtime income\n考点7：延长减税措施应译为 extended tax cuts\n考点8：赤字应统一译为 fiscal deficit 或 budget deficit\n考点9：发送关税通知函应译为 issue tariff notices\n考点10：对等关税应译为 reciprocal tariffs\n考点11：企业回流推荐译为 reshoring of enterprises 或 business relocation back\n考点12：互惠原则应译为 principle of reciprocity\n考点13：供应链从效率优先转向安全优先应译为 shift from efficiency-first to security-first supply chains\n考点14：美元信用基础应译为 dollar’s credit foundation 或 the credibility of the U.S. dollar\n考点15：货币发行国的财政自律应译为 the issuer’s fiscal responsibility\n考点16：稀缺的政治资本应译为 scarce political capital\n考点17：清洁能源补贴的取消应译为 repeal of clean energy subsidies\n考点18：系统性信任危机应译为 systemic crisis of trust 或 systemic credibility crisis",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "72"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nNumerous pamphlets and printings were published. These works agitated revolutionary people not only in America but also around the world.\n Among the most renowned was the work Common Sense (1776) of Thomas Paine (1737-1809). It’s the ringing call for the decoration of liberty. He also wrote Crisis (1774-1783) and The Age of Reason (1794-1796), according to Wu, “He thought that religion should be based on rational, reasonable ground. ” (Wu Dingbo, 12) The pamphlets helped complete the debate that resulted in America's separation from England.\n\nAnd of course for all the Americans, the most important document from this period was a single sheet of paper called The Declaration of Independence (1776), mainly written by Thomas Jefferson and Benjamin Franklin.\n\nBenjamin Franklin (1706-1790), the most distinguished person and giant in American history, he wrote and worked for American independence hardly and had made so many great efforts to America that he has been called \"The First American.\" a world-renowned scientist, diplomat, philosopher, and writer. He perfected the smooth, clear, short sentences of the Puritan plain style. His Autobiography encourages hard work and emphasizes the importance of achievement. Another work that is well known is Poor Richard's Almanack, and many of the sentences have become popular quotations.\n\nDuring this time writers thought that the truth should be relied on Bible, churchmen, authorities, or practice and experience.\n\n (2) Early National Literature\n\nDuring the period of American Revolution War, American national literature came into being. Since before the war, American people have already had the awareness of national independence, so they wrote many political writings revolutionary poems.\n\nThe war helped the first important American prose writers and poets grow up both culturally and artistically. Furthermore, the independence of nation led to the independence of national literature. From this moment on, American people began to understand of meaning of being a real ”American“.\n3. The flourishing of American literature in 19th century\n\nFrom the 1820’s to the Civil War broke out, American literature entered a period of full blooming. Writings all characterized by a distinct national style and flavor. At the same time, the world as a whole was experiencing a change in ways of thinking: there was a move from classical ideas to romantic ones. This change was taking place in all areas of culture around the world. This was an exciting period in the history of American literature. Like the flowers of spring, there were suddenly many different kinds of writing at the same time. All the works have an optimistic spirit. They represented the various and quick development of American national literature.\n\n(1)  Early Romantics\n\nIn early 19th century, Washington Irving (1783-1859), the person born with the new nation, his The Sketch Book created a new style of American literature—short novel. James Fenimore Cooper (1789-1851) His \"Leather-Stocking\" novels told us a story about how the brave immigrants fight with savage using what they have learnt from nature.\nAnother famous writer of this time was William Cullen Bryant (1794-1878), he was regarded one of the earliest naturalist poets in American history. His greatest poem Thanatopsis was published in the North American Review in 1817. He appreciates normal birds and flowers, through which appreciated harmonious relationship between human and nature. The Romantics emphasized individualism and they thought feelings and emotions were more important than reason and common sense.\n(2) The Transcendentalism\n\n “The New England Transcendentalism was romantic idealism on puritan soil” (Wu Dingbo: 28). It stressed the power of intuition placed spirit first, and it took nature as symbolic of spirit or God. There were three main features of Transcendentalism were Unitarianism, idealistic philosophy, and oriental mysticism. \nRalph Waldo Emerson (1803-1882), the leader of American Transcendentalism. “He captained a group of enthusiast and formed a transcendental club with them. He also helped to set up and edited the transcendentalist journal The Dial. ” He had written many famous essays. Among the best are Nature and The American Scholar, which has been called “America’s Declaration of Intellectual Independence”. Emerson wrote in The American Scholar (1837), a man must \"learn to detect and watch that gleam of light which flashes across his mind from within.\" The main key to this inner world is the imagination. Man's imagination leads to expression. Our expression makes each of us a unique human. Romanticism became the way of thinking for this generation of writers.\nHenry David Thoreau was also one of the writers of Transcendentalism, and his famous essay was Walden, in which he revealed the hidden spiritual possibilities in everyone’s life, and to considerate the pursuit of material things.\n\n(3) High Romantics\nDue to the great effort made by those geniuses such as Emerson and Thoreau, a wild-ranged national American literature had been laid a solid foundation by the mid-19th century.\nThere are four important names in American literature to remember from this period: Washington Irving (1783-1859), Walt Whitman (1819-1892), James Fennimore Cooper (1789-1851), and Edgar Allan Poe (1809-49).\nIrving will long be remembered for his book of essays and stories, The Sketch Book of Geoffrey Crayon (1819), which helping this new nation started its first step confidently. Cooper and Whitman described the character of the nation, which combined the courage and cleverness of expansion, the great sense of destination, and the optimistic spirit together. Hawthorne and Melville expressed the dark side of American dream though their profound and symbolized works.\nWalt Whitman (1819-1892), father of free verse, “he threw aside the traditional ornaments and prettiness of verse, and created his own form” (Wu Dingbo, 44). His Leaves of Grass (1855), which contains such well-known poems as I Hear America Singing, and Song of Myself, was regarded America’s first genuine epic poem. He rejected regular meter and rhyme in favor of flowing free verse and celebrated patriotic love, ragged individualism, democracy and equality and stressed an almost mystical identification with America.\nNathaniel Hawthorne (1804-1864), due to his family background, his works always concerned with sin, morality, romance, and had complex Puritanism. His masterpiece was the novel The Scarlet Letter, and his The House of Seven Gables was also well liked. In these works he presented material on the alienation between facts and fancy, by using many symbols and setting to reveal the psychology of the character.\n",
    "ori_text": "Numerous pamphlets and printings were published. These works agitated revolutionary people not only in America but also around the world.\n Among the most renowned was the work Common Sense (1776) of Thomas Paine (1737-1809). It’s the ringing call for the decoration of liberty. He also wrote Crisis (1774-1783) and The Age of Reason (1794-1796), according to Wu, “He thought that religion should be based on rational, reasonable ground. ” (Wu Dingbo, 12) The pamphlets helped complete the debate that resulted in America's separation from England.\n\nAnd of course for all the Americans, the most important document from this period was a single sheet of paper called The Declaration of Independence (1776), mainly written by Thomas Jefferson and Benjamin Franklin.\n\nBenjamin Franklin (1706-1790), the most distinguished person and giant in American history, he wrote and worked for American independence hardly and had made so many great efforts to America that he has been called \"The First American.\" a world-renowned scientist, diplomat, philosopher, and writer. He perfected the smooth, clear, short sentences of the Puritan plain style. His Autobiography encourages hard work and emphasizes the importance of achievement. Another work that is well known is Poor Richard's Almanack, and many of the sentences have become popular quotations.\n\nDuring this time writers thought that the truth should be relied on Bible, churchmen, authorities, or practice and experience.\n\n (2) Early National Literature\n\nDuring the period of American Revolution War, American national literature came into being. Since before the war, American people have already had the awareness of national independence, so they wrote many political writings revolutionary poems.\n\nThe war helped the first important American prose writers and poets grow up both culturally and artistically. Furthermore, the independence of nation led to the independence of national literature. From this moment on, American people began to understand of meaning of being a real ”American“.\n3. The flourishing of American literature in 19th century\n\nFrom the 1820’s to the Civil War broke out, American literature entered a period of full blooming. Writings all characterized by a distinct national style and flavor. At the same time, the world as a whole was experiencing a change in ways of thinking: there was a move from classical ideas to romantic ones. This change was taking place in all areas of culture around the world. This was an exciting period in the history of American literature. Like the flowers of spring, there were suddenly many different kinds of writing at the same time. All the works have an optimistic spirit. They represented the various and quick development of American national literature.\n\n(1)  Early Romantics\n\nIn early 19th century, Washington Irving (1783-1859), the person born with the new nation, his The Sketch Book created a new style of American literature—short novel. James Fenimore Cooper (1789-1851) His \"Leather-Stocking\" novels told us a story about how the brave immigrants fight with savage using what they have learnt from nature.\nAnother famous writer of this time was William Cullen Bryant (1794-1878), he was regarded one of the earliest naturalist poets in American history. His greatest poem Thanatopsis was published in the North American Review in 1817. He appreciates normal birds and flowers, through which appreciated harmonious relationship between human and nature. The Romantics emphasized individualism and they thought feelings and emotions were more important than reason and common sense.\n(2) The Transcendentalism\n\n “The New England Transcendentalism was romantic idealism on puritan soil” (Wu Dingbo: 28). It stressed the power of intuition placed spirit first, and it took nature as symbolic of spirit or God. There were three main features of Transcendentalism were Unitarianism, idealistic philosophy, and oriental mysticism. \nRalph Waldo Emerson (1803-1882), the leader of American Transcendentalism. “He captained a group of enthusiast and formed a transcendental club with them. He also helped to set up and edited the transcendentalist journal The Dial. ” He had written many famous essays. Among the best are Nature and The American Scholar, which has been called “America’s Declaration of Intellectual Independence”. Emerson wrote in The American Scholar (1837), a man must \"learn to detect and watch that gleam of light which flashes across his mind from within.\" The main key to this inner world is the imagination. Man's imagination leads to expression. Our expression makes each of us a unique human. Romanticism became the way of thinking for this generation of writers.\nHenry David Thoreau was also one of the writers of Transcendentalism, and his famous essay was Walden, in which he revealed the hidden spiritual possibilities in everyone’s life, and to considerate the pursuit of material things.\n\n(3) High Romantics\nDue to the great effort made by those geniuses such as Emerson and Thoreau, a wild-ranged national American literature had been laid a solid foundation by the mid-19th century.\nThere are four important names in American literature to remember from this period: Washington Irving (1783-1859), Walt Whitman (1819-1892), James Fennimore Cooper (1789-1851), and Edgar Allan Poe (1809-49).\nIrving will long be remembered for his book of essays and stories, The Sketch Book of Geoffrey Crayon (1819), which helping this new nation started its first step confidently. Cooper and Whitman described the character of the nation, which combined the courage and cleverness of expansion, the great sense of destination, and the optimistic spirit together. Hawthorne and Melville expressed the dark side of American dream though their profound and symbolized works.\nWalt Whitman (1819-1892), father of free verse, “he threw aside the traditional ornaments and prettiness of verse, and created his own form” (Wu Dingbo, 44). His Leaves of Grass (1855), which contains such well-known poems as I Hear America Singing, and Song of Myself, was regarded America’s first genuine epic poem. He rejected regular meter and rhyme in favor of flowing free verse and celebrated patriotic love, ragged individualism, democracy and equality and stressed an almost mystical identification with America.\nNathaniel Hawthorne (1804-1864), due to his family background, his works always concerned with sin, morality, romance, and had complex Puritanism. His masterpiece was the novel The Scarlet Letter, and his The House of Seven Gables was also well liked. In these works he presented material on the alienation between facts and fancy, by using many symbols and setting to reveal the psychology of the character.\n",
    "reference_list": "考点1：\"The First American\"不能译为“第一位美国人”。\n考点2： \"sense of destination\"推荐译为“宿命感”。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "43"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。 以下是你本次的任务：\n在一些学者看来，儒教也可以被视为一种宗教，儒家思想的创始人孔子成为了子孙后代崇拜的对象。2000多年以来，供奉孔子的庙宇来一直是中国传统文化中一种重要的神圣空间。中国古代许多朝代的皇帝都尊崇儒家思想，因此，各级城市都建立了正式的孔庙。在漫长的历史过程中，中国人逐渐形成并传承了孔庙的建设模式。本文以北京孔庙作为研究案例，利用历史文献、现代文献和实地调查证据，目的是展示在不同尺度下所形成的北京孔庙的神圣性，以及不同主体在互动过程中如何将从对孔庙神圣性的多元认识逐渐转变为统一认识。本文探究的尺度包括城市尺度、街道尺度、建筑尺度和身体尺度，参与互动的对象不仅包括来自不同的民族的人，还包括来自不同阶级和代际的人。本文的结论是：多主体互动所形成的神圣空间遗产是可以被传承的。\n北京孔庙共有三进院落。依据每个院落中的中的建筑功能不同，各个院落因此分别形成了前导空间、祭祀空间和尾部空间。中间的院落和中轴线都是最为尊贵的位置。\n第一个进院落为前导空间。它位于孔庙入口和先师门之间。南北长46米，东西宽108米。这里没有其他大多数文庙中建设的棂星门和泮池，取而代之的是先师门、历代进士题名碑和御制记功碑亭。院落内多种植柏树，这是本文开篇的诗歌中所提到的元素。这里还有供斋戒人居住的房子“室”。“步”（即走两步的长度） 是中国古代用来衡量长度的一种单位。 在中国的不同朝代，“步”所代表的长度不一。在元朝，一“步”被定义为1.575米。孔庙和学宫用地范围东西方向长度为144步，其中孔庙占80步，比例关系近似为九比五，南北方向长度为150步，与东西长度的比例同样近似九比五。在中国古代，数字九和五是只有皇帝能使用的数字，因此这里的长宽比例体现了院落是按照最高等级来设计的。这里还有用来制作献祭贡品的厨房，名为“神厨”。还有用于存放祭祀礼仪用品的仓库，名为“神库”。院内有元、明、清三个朝代的进士题名碑，共198块，它们为研究中国古代科举制度提供了重要的文献资料。\n第二进院落是很重要的祭祀空间。它在大成门和崇圣门之间，南北长和东西宽均为93米。院落中由大成门、有大成殿和东西两庑围成，这里供奉的有其他儒家先圣和先师。院内建有十一座碑亭，配有黄瓦朱栏，屋顶的规制为重檐歇山顶。\n第三进院落为尾声空间。它在崇圣门到崇圣祠后墙之间。此院落南北长50.8米，东西宽44.6米。大成殿两侧各有一条路径，人们可以由这两条路进入第三个院落。首先要进入的是崇圣门。之后可以看见崇圣祠，它是这个院落中的主体建筑。由于北京孔庙等级高，所以这个殿内除了供奉孔子五代先人外，还有及颜回、孔伋、曾参和孟轲四位圣人的父亲先哲之父。院内还有东西配殿，这些殿宇用于供奉程颐、程颢兄弟、张载、蔡沈、周敦颐和朱熹六位历史上著名儒学大师的父亲。在建筑规制上，崇圣祠比大成殿少两间，屋顶、台基、装饰等级也相应降低。\n北京孔庙的建筑布局严格遵循礼制规定。 “间”是中国古代建筑的宽度计量单位，它指两个古代宫殿建筑柱子之间的距离。大成殿宽度为九间，长度为五间。在介绍院落的部分，我们提到在中国古代，数字九和五是只有皇帝能使用的数字。从这两个数字就可以看出，大成殿的建筑等级是最高的。明代1600年，大成殿用的一般灰色陶瓦被改为了琉璃瓦。而如今大成殿所用的这种黄色琉璃瓦，与皇家建筑等级是一致的。大成殿所在的院落中有11座御制石碑，它们分别在1686-1791年间建成。大成殿门窗的窗棂的图案为“三交六椀”。这个图案的基本单元是有三个直线相交，分割出六个三角，组成一个六边形。这是最高等级的窗棂图案（见图5），其含义是皇帝与天和地的精神相交汇。相比之下， 顺天府（都城市政府）下辖的大兴县（北京老城的东半部分）的孔庙内，大成殿面阔五间，等级就相对低很多了。",
    "ori_text": "在一些学者看来，儒教也可以被视为一种宗教，儒家思想的创始人孔子成为了子孙后代崇拜的对象。2000多年以来，供奉孔子的庙宇来一直是中国传统文化中一种重要的神圣空间。中国古代许多朝代的皇帝都尊崇儒家思想，因此，各级城市都建立了正式的孔庙。在漫长的历史过程中，中国人逐渐形成并传承了孔庙的建设模式。本文以北京孔庙作为研究案例，利用历史文献、现代文献和实地调查证据，目的是展示在不同尺度下所形成的北京孔庙的神圣性，以及不同主体在互动过程中如何将从对孔庙神圣性的多元认识逐渐转变为统一认识。本文探究的尺度包括城市尺度、街道尺度、建筑尺度和身体尺度，参与互动的对象不仅包括来自不同的民族的人，还包括来自不同阶级和代际的人。本文的结论是：多主体互动所形成的神圣空间遗产是可以被传承的。\n北京孔庙共有三进院落。依据每个院落中的中的建筑功能不同，各个院落因此分别形成了前导空间、祭祀空间和尾部空间。中间的院落和中轴线都是最为尊贵的位置。\n第一个进院落为前导空间。它位于孔庙入口和先师门之间。南北长46米，东西宽108米。这里没有其他大多数文庙中建设的棂星门和泮池，取而代之的是先师门、历代进士题名碑和御制记功碑亭。院落内多种植柏树，这是本文开篇的诗歌中所提到的元素。这里还有供斋戒人居住的房子“室”。“步”（即走两步的长度） 是中国古代用来衡量长度的一种单位。 在中国的不同朝代，“步”所代表的长度不一。在元朝，一“步”被定义为1.575米。孔庙和学宫用地范围东西方向长度为144步，其中孔庙占80步，比例关系近似为九比五，南北方向长度为150步，与东西长度的比例同样近似九比五。在中国古代，数字九和五是只有皇帝能使用的数字，因此这里的长宽比例体现了院落是按照最高等级来设计的。这里还有用来制作献祭贡品的厨房，名为“神厨”。还有用于存放祭祀礼仪用品的仓库，名为“神库”。院内有元、明、清三个朝代的进士题名碑，共198块，它们为研究中国古代科举制度提供了重要的文献资料。\n第二进院落是很重要的祭祀空间。它在大成门和崇圣门之间，南北长和东西宽均为93米。院落中由大成门、有大成殿和东西两庑围成，这里供奉的有其他儒家先圣和先师。院内建有十一座碑亭，配有黄瓦朱栏，屋顶的规制为重檐歇山顶。\n第三进院落为尾声空间。它在崇圣门到崇圣祠后墙之间。此院落南北长50.8米，东西宽44.6米。大成殿两侧各有一条路径，人们可以由这两条路进入第三个院落。首先要进入的是崇圣门。之后可以看见崇圣祠，它是这个院落中的主体建筑。由于北京孔庙等级高，所以这个殿内除了供奉孔子五代先人外，还有及颜回、孔伋、曾参和孟轲四位圣人的父亲先哲之父。院内还有东西配殿，这些殿宇用于供奉程颐、程颢兄弟、张载、蔡沈、周敦颐和朱熹六位历史上著名儒学大师的父亲。在建筑规制上，崇圣祠比大成殿少两间，屋顶、台基、装饰等级也相应降低。\n北京孔庙的建筑布局严格遵循礼制规定。 “间”是中国古代建筑的宽度计量单位，它指两个古代宫殿建筑柱子之间的距离。大成殿宽度为九间，长度为五间。在介绍院落的部分，我们提到在中国古代，数字九和五是只有皇帝能使用的数字。从这两个数字就可以看出，大成殿的建筑等级是最高的。明代1600年，大成殿用的一般灰色陶瓦被改为了琉璃瓦。而如今大成殿所用的这种黄色琉璃瓦，与皇家建筑等级是一致的。大成殿所在的院落中有11座御制石碑，它们分别在1686-1791年间建成。大成殿门窗的窗棂的图案为“三交六椀”。这个图案的基本单元是有三个直线相交，分割出六个三角，组成一个六边形。这是最高等级的窗棂图案（见图5），其含义是皇帝与天和地的精神相交汇。相比之下， 顺天府（都城市政府）下辖的大兴县（北京老城的东半部分）的孔庙内，大成殿面阔五间，等级就相对低很多了。",
    "reference_list": "考点1：\"儒教\" 推荐翻译为：\"Confucianism\"\n考点2：\"尺度\" 推荐翻译为：\"scale\"\n考点3：\"互动\" 推荐翻译为：\"interaction\"\n考点4：\"三进院落\" 推荐翻译为：\"three courtyards\"\n考点5：\"入口\" 推荐翻译为：\"main entrance\"\n考点6：\"先师门\" 推荐翻译为：\"Xianshi gate\"\n考点7：\"棂星门\" 推荐翻译为：\"Lingxing gate\"\n考点8：\"泮池\" 推荐翻译为：\"Pan Chi\"\n考点9：\"进士\" 推荐翻译为：\"scholars\"\n考点10：\"御制记功碑亭\" 推荐翻译为：\"imperial monuments\"\n考点11：\"斋戒人\" 推荐翻译为：\"fasting people\"\n考点12：\"步\" 推荐翻译为：\"Bu\"\n考点13：\"神厨\" 推荐翻译为：\"Shenchu\"\n考点14：\"神库\" 推荐翻译为：\"Shenku\"\n考点15：\"大成门\" 推荐翻译为：\"Dacheng gate\"\n考点16：\"崇圣门\" 推荐翻译为：\"Chongsheng gate\"\n考点17：\"大成殿\" 推荐翻译为：\"Dacheng Hall\"\n考点18：\"庑\" 推荐翻译为：\"wing\"\n考点19：\"儒家先圣、先师\" 推荐翻译为：\"Confucian saints and masters\"\n考点20：\"黄瓦\" 推荐翻译为：\"yellow tiles\"\n考点21：\"朱栏\" 推荐翻译为：\"vermilion columns\"\n考点22：\"重檐歇山顶\" 推荐翻译为：\"gable and hip roof with multiple eaves\"\n考点23：\"东西配殿\" 推荐翻译为：\"East and West Hall\"\n考点24：\"间\" 推荐翻译为：\"Jian\"\n考点25：\"九间\" 推荐翻译为：\"nine of Jian（注意写法，五间也是相似的）\"\n考点26：\"三交六椀\" 推荐翻译为：\"San Jiao Liu Wan\"\n考点27：\"窗棂\" 推荐翻译为：\"window lattice\"\n考点28:  \"学宫\"推荐翻译为：\"school palace\"\n考点29:  \"崇圣祠\"推荐翻译为：\"Chongsheng Shrine\"\n考点30:  \"前导空间\"推荐翻译为：\"leading space\"\n考点31:  \"祭祀空间\"推荐翻译为：\"worship space\"\n考点32:  \"尾声空间\"推荐翻译为：\"epilogue space\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "102"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\nAbstract--Economists' productivity over their careers and as measured by publication in leading journals declines very sharply with age. There is no difference by age in the probability that an article submitted to a leading journal will be accepted. Rates of declining productivity are no greater among the very top publishers than among others, and the probability of acceptance is increasingly related to the author's quality rather than the author's age.\n\nIt is well known that productivity declines with age in a wide range of activities. Lehman (1953) suggests an early peak in productivity in a variety of scientific and artistic endeavors, and Diamond (1986) documents the pattern for several scholarly pursuits. Levin and Stephan (1992) provide clear evidence that this decline exists even after careful attempts to account for individual and cohort differences. Fair (1994) finds declines in physical ability among elite runners, as does Lydall (1968,pp. 113 passim) in physical abilities of the population generally. In this study we examine productivity declines in our own field. The main new results arise from our use of two different types of information, the equivalent of household and establishment data, to study the stone field over essentially the same period of time. Section I discusses the general results on aging and productivity, whereas section II presents evidence of the importance of heterogeneity.\n\nI. Declining Productivity with Age\n\nUsing the American Economic Association (AEA) Directory of Members, we identified tenured economics faculty at 17 top research institutions and obtained the years of their Ph.D. degrees. With the citation index of the Journal of Economic Literature we replicated portions of the curricala vitae of each of the 208 economists currently in the economics departments of those institutions who received Ph.D. degrees between 1959 and 1983.\n\nTo measure productivity we construct three indexes, combining papers published in refereed journals. Prior research suggests that, at least in terms of salary determination, the returns from nonreferred publications are quite low Sauer (1988), so that we ignore such publications in calculating these measures. I1 weights an article by the journal where it appears based on citations to that journal, using values generated by Laband and Piette (1994). This index distinguishes strongly among journals. For example, the Journal of Political Economy has a weight of 59.1, whereas Economic Inquiry has a weight of 7.9. In constructing I1 we use the weights associated with the decade in which the articles were published. I2 distinguishes somewhat less among journals by assigning all articles in the nine \"core\" journals identified by Laband and Piette a value of 1, whereas all other journals are valued at 0.5.Finally, I3 gives all papers a weight of 1. Coauthored articles were given half credit, consistent with Sauer's (1988) findings on the economic returns to coauthorship.\n\nWe measure the change in productivity over the life cycle by the percentage change in the number of publications from 9-10 years past the Ph.D. to the periods 14-15 years and then 19-20 years after. For most of the elite economists the base period is equivalent (accounting for publication lags) to the time of tenure, when one might expect that incentives to produce are at a peak. Using two-year publication records at each point reduces the effects of noise in the performance measures. One might argue that still other scientific life-cycle mileposts (e.g., attaining a full professorship) should be accounted for too (and to some extent the 14-15-year point does this). But our main purpose is simply to provide detailed evidence on the relationship to age, and our data are not sufficient to infer the impact of every possible milepost.\n\nII. Heterogeneity in Declining Productivity\n\nThe evidence in section I documents the decline in productivity at the sample means. Information on the age-productivity relationship at the extremes of the sample is interesting in its own right and might help shed some light on the possible causes of the apparent decline in productivity with age. The simplest test compares productivity losses among the top early performers with that of the entire sample of economists at elite institutions. Among the top 10% of early producers the mean values of I1, I2, and I3 at year 20 were 64, 50, and 22%, respectively. These means are quite close to those listed for the entire sample in table 1. Thus on average early promise seems to be sustained in this sample. Of the 12 top researchers on whom we have 20 years of data, five were still among the top dozen producers at year 20.\n\nAnother way of examining heterogeneity is to look at how authors of different quality fare in the publication process conditional on their efforts. We obtained data on a random sample of initial submissions to a major general journal during a four-month period in 1991. (Some of the data were initially supplied by the journal's office for use in Hamermesh (1994).) Refereeing at this journal is double-blind, so that the chance that referees (though possibly not the editors) were affected by authors' reputations is reduced. The ages of the authors of these 313 papers are measured as of 1993 to account for the probable two-year average lag between the submission of a paper and its publication.\n\nThe probits included interaction terms between indicator variables for age and the extent of citations. (Low-cited economists were defined as those with fewer than 10 citations per year, well-cited with at least 10.) As figure 1 clearly shows, acceptance rates for each age group differ sharply by citation status. Comparing authors age 36-50 to those over 50, it is quite clear that the degree of heterogeneity increases with age. This appears to be less true in comparing the oldest to the youngest group, but that inference is due mainly to a very small sample. (Only six authors under age 36, the future superstars of the profession, were well cited.) The general tenor of the combined results from this sample is that the profession signals to less able scholars that their work no longer meets the profession's highest standards, and most of them respond by reducing their submissions to the highest quality journals.\n\nIII. Conclusions\n\nWe have followed the careers of economists and measured the demographic characteristics of publishers in leading journals. The evidence seems quite clear that publishing diminishes with age, especially publishing in leading journals, at rates as rapid as in the physical sciences. Indeed, remarkably few older people publish successfully in the scholarly outlets on which the profession places the highest value. As economists age, those who were the most productive early in their careers are among the few \"survivors\" still contributing to scholarship through the leading scholarly outlets.\n\nWhether this relationship is due to natural declines in capacity or decreased incentives to produce is extremely difficult to discern. Unlike athletes, where it is likely that pure physical deterioration causes the reduction in productivity with age, among scholars even the fairly subtle facts that we have uncovered can be marshaled as support for each of these competing hypotheses. Without direct observation on how scholars' use of time changes as they age, we are unlikely to be able to distinguish between explanations of the declining ageproductivity relationship in science.",
    "ori_text": "Abstract--Economists' productivity over their careers and as measured by publication in leading journals declines very sharply with age. There is no difference by age in the probability that an article submitted to a leading journal will be accepted. Rates of declining productivity are no greater among the very top publishers than among others, and the probability of acceptance is increasingly related to the author's quality rather than the author's age.\n\nIt is well known that productivity declines with age in a wide range of activities. Lehman (1953) suggests an early peak in productivity in a variety of scientific and artistic endeavors, and Diamond (1986) documents the pattern for several scholarly pursuits. Levin and Stephan (1992) provide clear evidence that this decline exists even after careful attempts to account for individual and cohort differences. Fair (1994) finds declines in physical ability among elite runners, as does Lydall (1968,pp. 113 passim) in physical abilities of the population generally. In this study we examine productivity declines in our own field. The main new results arise from our use of two different types of information, the equivalent of household and establishment data, to study the stone field over essentially the same period of time. Section I discusses the general results on aging and productivity, whereas section II presents evidence of the importance of heterogeneity.\n\nI. Declining Productivity with Age\n\nUsing the American Economic Association (AEA) Directory of Members, we identified tenured economics faculty at 17 top research institutions and obtained the years of their Ph.D. degrees. With the citation index of the Journal of Economic Literature we replicated portions of the curricala vitae of each of the 208 economists currently in the economics departments of those institutions who received Ph.D. degrees between 1959 and 1983.\n\nTo measure productivity we construct three indexes, combining papers published in refereed journals. Prior research suggests that, at least in terms of salary determination, the returns from nonreferred publications are quite low Sauer (1988), so that we ignore such publications in calculating these measures. I1 weights an article by the journal where it appears based on citations to that journal, using values generated by Laband and Piette (1994). This index distinguishes strongly among journals. For example, the Journal of Political Economy has a weight of 59.1, whereas Economic Inquiry has a weight of 7.9. In constructing I1 we use the weights associated with the decade in which the articles were published. I2 distinguishes somewhat less among journals by assigning all articles in the nine \"core\" journals identified by Laband and Piette a value of 1, whereas all other journals are valued at 0.5.Finally, I3 gives all papers a weight of 1. Coauthored articles were given half credit, consistent with Sauer's (1988) findings on the economic returns to coauthorship.\n\nWe measure the change in productivity over the life cycle by the percentage change in the number of publications from 9-10 years past the Ph.D. to the periods 14-15 years and then 19-20 years after. For most of the elite economists the base period is equivalent (accounting for publication lags) to the time of tenure, when one might expect that incentives to produce are at a peak. Using two-year publication records at each point reduces the effects of noise in the performance measures. One might argue that still other scientific life-cycle mileposts (e.g., attaining a full professorship) should be accounted for too (and to some extent the 14-15-year point does this). But our main purpose is simply to provide detailed evidence on the relationship to age, and our data are not sufficient to infer the impact of every possible milepost.\n\nII. Heterogeneity in Declining Productivity\n\nThe evidence in section I documents the decline in productivity at the sample means. Information on the age-productivity relationship at the extremes of the sample is interesting in its own right and might help shed some light on the possible causes of the apparent decline in productivity with age. The simplest test compares productivity losses among the top early performers with that of the entire sample of economists at elite institutions. Among the top 10% of early producers the mean values of I1, I2, and I3 at year 20 were 64, 50, and 22%, respectively. These means are quite close to those listed for the entire sample in table 1. Thus on average early promise seems to be sustained in this sample. Of the 12 top researchers on whom we have 20 years of data, five were still among the top dozen producers at year 20.\n\nAnother way of examining heterogeneity is to look at how authors of different quality fare in the publication process conditional on their efforts. We obtained data on a random sample of initial submissions to a major general journal during a four-month period in 1991. (Some of the data were initially supplied by the journal's office for use in Hamermesh (1994).) Refereeing at this journal is double-blind, so that the chance that referees (though possibly not the editors) were affected by authors' reputations is reduced. The ages of the authors of these 313 papers are measured as of 1993 to account for the probable two-year average lag between the submission of a paper and its publication.\n\nThe probits included interaction terms between indicator variables for age and the extent of citations. (Low-cited economists were defined as those with fewer than 10 citations per year, well-cited with at least 10.) As figure 1 clearly shows, acceptance rates for each age group differ sharply by citation status. Comparing authors age 36-50 to those over 50, it is quite clear that the degree of heterogeneity increases with age. This appears to be less true in comparing the oldest to the youngest group, but that inference is due mainly to a very small sample. (Only six authors under age 36, the future superstars of the profession, were well cited.) The general tenor of the combined results from this sample is that the profession signals to less able scholars that their work no longer meets the profession's highest standards, and most of them respond by reducing their submissions to the highest quality journals.\n\nIII. Conclusions\n\nWe have followed the careers of economists and measured the demographic characteristics of publishers in leading journals. The evidence seems quite clear that publishing diminishes with age, especially publishing in leading journals, at rates as rapid as in the physical sciences. Indeed, remarkably few older people publish successfully in the scholarly outlets on which the profession places the highest value. As economists age, those who were the most productive early in their careers are among the few \"survivors\" still contributing to scholarship through the leading scholarly outlets.\n\nWhether this relationship is due to natural declines in capacity or decreased incentives to produce is extremely difficult to discern. Unlike athletes, where it is likely that pure physical deterioration causes the reduction in productivity with age, among scholars even the fairly subtle facts that we have uncovered can be marshaled as support for each of these competing hypotheses. Without direct observation on how scholars' use of time changes as they age, we are unlikely to be able to distinguish between explanations of the declining ageproductivity relationship in science.",
    "reference_list": "考点1：“productivity”推荐译为“学术产出”\n考点2：“household and establishment data”推荐译为“ 家庭数据和机构数据”\n考点3：“ heterogeneity”推荐译为“异质性”\n考点4：“refereed journals / non-refereed publications”推荐译为“同行评审期刊 / 非同行评审出版物”\n考点5：“ life cycle”推荐译为“职业生命周期”\n考点6：“ sample means”推荐译为“ 样本均值”\n考点7：“double-blind”推荐译为“ 双盲”（评审）\n考点8：“probits”推荐译为“概率单位模型”\n考点9：“marshaled as support”推荐译为“ 被用来支持；被引为证据”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "11"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nFor the facemask miniplate protocol, 2 anchor surgical miniplates (55-0851; Stryker Leibinger, Freiburg, Germany) were placed 1 at each zygomatic buttress area. Surgical miniplates were adapted and bent according to the anatomy of the zygomatic buttress in a curvilinear pattern according to the anatomic shape of the zygomatic buttress area and fixed with 3 self-tapping bone screws per side (2-mm diameter, 6-mm length; 50-20706; Stryker Leibinger). The distal end of the miniplate was exposed through the keratinized attached gingiva near the canine to prevent gingival irritation, and the end holes of the miniplates were cut to create hooks for elastics. Three weeks after the surgery, an orthopedic force of 400 to 500 g per side was applied by heavy extraoral elastics directed 30 downward and forward from the occlusal plane from the miniplates to the facemasks. The patients were asked to replace the elastics once each day. A removable maxillary biteplate covering the posterior occlusal surfaces was placed to eliminate occlusal interference in the incisor region until correction of the anterior crossbite was obtained. For the Class III elastics and miniplate protocol, 4 straight miniplates (55-0851; Stryker Leibinger) were placed. In the maxilla, straight surgical miniplates, 25 mm or 6 holes in length, were adapted to the anatomy of the infrazygomatic buttress and fixed with 3 selftapping bone screws per side (2-mm diameter, 6-mm length; 50-20706; Stryker Leibinger). In the mandible, straight miniplates of 21 mm or 5 holes in length were adapted to the bone anatomy inferiorly between the mandibular lateral incisors and canines and fixed with 2 or 3 self-tapping bone screws per side so that the upper screw was at the level of root apices. All mucoperiosteal flaps were secured and sutured, exposing the ends of the miniplates over the keratinized attached gingiva to prevent gingival irritation. The distal end holes of the miniplates were cut to create hooks for elastics.\nThree weeks after the surgery, the miniplates were loaded with Class III elastics on each side to provide a force of approximately 250 g to each side. The patients were instructed to wear the elastics 24 hours per day. The elastics were replaced at least once each day. A removable biteplate covering the occlusal surface of maxillary teeth was placed to eliminate occlusal interference in the incisor region until correction of the anterior crossbite was obtained . The decision to discontinue orthopedic treatment in groups 1 and 2 was made by the operator when the patients had 3 to 4 mm of positive anterior overjet. For each patient, a lateral cephalogram and facial moulage were obtained before treatment (T1) and at the end of protraction therapy or the observation period (T2), All facial moulages were scanned with the Facial Insight 3D Scanner (Motion View Software, Chattanooga, Tenn). Hence, 3D photographs of all patients and controls were acquired. All subjects were in centric occlusion, with relaxed facial musculature and lips. The 3D photographs were imported in stereolithography binary file format (*.stl) into an advanced processing software package (Geomagic Control 14; Geomagic, Research Triangle Park, NC) for further analysis. All 3D photographs were acquired in a similar way and had the same orientation. The facial soft tissue changes after maxillary protraction were evaluated by superimposition of the T1 and T2 3D photographs for every patient by a surface-based registration, Maal et al concluded that surface-based registration is an accurate method to compare 3D photographs of the same subject at different times rather than reference frame-based registration.\nFor the initial register of T1 and T2 scans, 9 markers were used as references to superimpose the images: (1) left endocanthion, (2) left exocanthion, (3) right  endocanthion, (4) right exocanthion, (5) soft tissue nasion, (6) left palpebrale superius, (7) left palpebrale inferius, (8) right palpebrale superius, and (9) right palpebrale inferius.20-22 The 3D photographs at T1 were set as fixed, and the T2 3D photographs were set as floating objects. For more refining of the superimpositions, the final register was made on the wide surface starting from right and left exocanthion and extending upward over all the forehead on the area that would not be influenced by the treatment. The T1 and T2 3D images were superimposed with the same coordinate system .23 For the 3D analysis of each subject, the T1 face scan was set as a reference, and the T2 scan was set as the test, and then the 3D compare analysis was performed. The 3D compare analysis generated a 3D color-coded map that displayed the areas and magnitudes of changes in facial soft tissues between the T1 (reference) and T2 (test) scans . Soft tissue landmarks, including right and left buccale points, right and left points of the cheek, subnasale, labiale superius, labiale inferius, soft tissue B-point, soft tissue pogonion, and soft tissue menton, were defined using the Create Annotation function in the Geomagic Control 14 software.21,22 The Annotation function measured the magnitude of deviation between the T1 and T2 scans at the selected points corresponding to x-, y-, and z-axes (Dx, deviation in the transverse direction; Dy, deviation in the vertical direction; Dz, deviation in the anteroposterior direction). The magnitudes of deviations were analyzed statistically. Cephalometric radiographs were obtained at T1 and T2 for all subjects to evaluate the amounts of maxillary advancement and the changes. Hence, the soft tissue changes were compared with actual skeletal movements. All cephalometric radiographs were scanned and analyzed by 1 investigator (M.H.E) using software (version 11.7; Dolphin Imaging and Management Solutions, Chatsworth, Calif). The analysis consisted of the following.\nSkeletally anchored maxillary protraction using miniplates was introduced to transfer the orthopedic forces directly to the maxilla, to achieve an outcome not possible by conventional tooth-anchored facemask therapy in which a large portion of the force is dissipated to the periodontal ligament area. The application of orthopedic force through the teeth results in unwanted dentoalveolar changes such as extrusion and mesial movement of the maxillary molars, proclination of the maxillary incisors, and retroclination of the mandibular incisors. Moreover, studies have shown that facemask and rapid maxillary expansion therapies produce greater dental than skeletal changes; in contrast, bone-anchored maxillary protraction produces greater skeletal changes and open circummaxillary sutures. This is the first study to use a 3D approach to evaluate the facial soft tissue changes associated with skeletally anchored maxillary protraction protocols: skeletally anchored facemask with miniplates, and Class III elastics from infrazygomatic miniplates in the maxilla to symphyseal miniplates in the mandible. The conventional lateral cephalometric analysis evaluates the soft tissue changes only at the midsagittal area. However, patients usually evaluate their own soft tissue esthetics on the basis of how they look in the frontal view. Therefore, imaging methods, such as 3D computed tomography and 3D facial scan images are needed to analyze and evaluate the soft tissues of the entire face.\nOne major application of 3D imaging in orthodontics and oral and maxillofacial surgery is preintervention and postinterventions assessment of facial esthetics. To evaluate treatment outcomes with regard to soft tissues, preoperative and postoperative 3D photographs of the patient's face are registered. After registration of the 3D photographs, the differences between them can be visualized on a color scale or a distance map. In this way, the results of surgical and orthodontic treatment can be evaluated quantitatively and objectively. Investigators concluded that surface-based registration is an accurate method to compare 3D photographs of the same subject at different times. Therefore, 3D stereophotogrammetry is an accurate tool to evaluate facial changes (surgical or nonsurgical) over time. The soft tissue landmarks used in this study proved to be reproducible, easy to designate, and useful for facial soft tissue analysis. For superimposition and registration of pretreatment and postreatment 3D photographs, Day and Lee used a broad surface on the forehead, Soncul and Bamber used 5 points (right and left exocanthions and endocanthions, and soft-tissue nasion), and McCance et al used these 5 points and an additional 5 arbitrary points on the forehead. Recently, Baik and Kim used the 5 landmarks on the right and left exocanthions and endocanthions, and soft-tissue nasion for point registration, followed by area registration using the wide surface of the forehead as the reference for superimposing the 3D images to evaluate the soft-tissue changes after the correction of thye skeletal Class III malocclusion by 2-jaw surgery with genioplasty. Hence, in this study, we used initial point registration followed by the wide surface registration starting from right and left exocanthions and extending upward over the forehead on the area that would not be influenced by the treatment.\nThe maxilla was protracted forward significantly in groups 1 and 2 when compared with the untreated control group (group 1, 4.87 mm; group 2, 5.81 mm). The protraction rates were 0.61 and 0.65 mm per month for groups 1 and 2, respectively, without a significant difference between them. In previous studies, Cha and Ngan achieved 3.42 mm of maxillary advancement, and Lee et al reported 3.11 mm of advancement using facemasks anchored by miniplates at the zygomatic buttress area. Sar et al46 had 2.83 mm of maxillary advancement using facemasks anchored by miniplates fixed in the lateral nasal wall.\n",
    "ori_text": "\n\nFor the facemask miniplate protocol, 2 anchor surgical miniplates (55-0851; Stryker Leibinger, Freiburg, Germany) were placed 1 at each zygomatic buttress area. Surgical miniplates were adapted and bent according to the anatomy of the zygomatic buttress in a curvilinear pattern according to the anatomic shape of the zygomatic buttress area and fixed with 3 self-tapping bone screws per side (2-mm diameter, 6-mm length; 50-20706; Stryker Leibinger). The distal end of the miniplate was exposed through the keratinized attached gingiva near the canine to prevent gingival irritation, and the end holes of the miniplates were cut to create hooks for elastics. Three weeks after the surgery, an orthopedic force of 400 to 500 g per side was applied by heavy extraoral elastics directed 30 downward and forward from the occlusal plane from the miniplates to the facemasks. The patients were asked to replace the elastics once each day. A removable maxillary biteplate covering the posterior occlusal surfaces was placed to eliminate occlusal interference in the incisor region until correction of the anterior crossbite was obtained. For the Class III elastics and miniplate protocol, 4 straight miniplates (55-0851; Stryker Leibinger) were placed. In the maxilla, straight surgical miniplates, 25 mm or 6 holes in length, were adapted to the anatomy of the infrazygomatic buttress and fixed with 3 selftapping bone screws per side (2-mm diameter, 6-mm length; 50-20706; Stryker Leibinger). In the mandible, straight miniplates of 21 mm or 5 holes in length were adapted to the bone anatomy inferiorly between the mandibular lateral incisors and canines and fixed with 2 or 3 self-tapping bone screws per side so that the upper screw was at the level of root apices. All mucoperiosteal flaps were secured and sutured, exposing the ends of the miniplates over the keratinized attached gingiva to prevent gingival irritation. The distal end holes of the miniplates were cut to create hooks for elastics.\nThree weeks after the surgery, the miniplates were loaded with Class III elastics on each side to provide a force of approximately 250 g to each side. The patients were instructed to wear the elastics 24 hours per day. The elastics were replaced at least once each day. A removable biteplate covering the occlusal surface of maxillary teeth was placed to eliminate occlusal interference in the incisor region until correction of the anterior crossbite was obtained . The decision to discontinue orthopedic treatment in groups 1 and 2 was made by the operator when the patients had 3 to 4 mm of positive anterior overjet. For each patient, a lateral cephalogram and facial moulage were obtained before treatment (T1) and at the end of protraction therapy or the observation period (T2), All facial moulages were scanned with the Facial Insight 3D Scanner (Motion View Software, Chattanooga, Tenn). Hence, 3D photographs of all patients and controls were acquired. All subjects were in centric occlusion, with relaxed facial musculature and lips. The 3D photographs were imported in stereolithography binary file format (*.stl) into an advanced processing software package (Geomagic Control 14; Geomagic, Research Triangle Park, NC) for further analysis. All 3D photographs were acquired in a similar way and had the same orientation. The facial soft tissue changes after maxillary protraction were evaluated by superimposition of the T1 and T2 3D photographs for every patient by a surface-based registration, Maal et al concluded that surface-based registration is an accurate method to compare 3D photographs of the same subject at different times rather than reference frame-based registration.\nFor the initial register of T1 and T2 scans, 9 markers were used as references to superimpose the images: (1) left endocanthion, (2) left exocanthion, (3) right  endocanthion, (4) right exocanthion, (5) soft tissue nasion, (6) left palpebrale superius, (7) left palpebrale inferius, (8) right palpebrale superius, and (9) right palpebrale inferius.20-22 The 3D photographs at T1 were set as fixed, and the T2 3D photographs were set as floating objects. For more refining of the superimpositions, the final register was made on the wide surface starting from right and left exocanthion and extending upward over all the forehead on the area that would not be influenced by the treatment. The T1 and T2 3D images were superimposed with the same coordinate system .23 For the 3D analysis of each subject, the T1 face scan was set as a reference, and the T2 scan was set as the test, and then the 3D compare analysis was performed. The 3D compare analysis generated a 3D color-coded map that displayed the areas and magnitudes of changes in facial soft tissues between the T1 (reference) and T2 (test) scans . Soft tissue landmarks, including right and left buccale points, right and left points of the cheek, subnasale, labiale superius, labiale inferius, soft tissue B-point, soft tissue pogonion, and soft tissue menton, were defined using the Create Annotation function in the Geomagic Control 14 software.21,22 The Annotation function measured the magnitude of deviation between the T1 and T2 scans at the selected points corresponding to x-, y-, and z-axes (Dx, deviation in the transverse direction; Dy, deviation in the vertical direction; Dz, deviation in the anteroposterior direction). The magnitudes of deviations were analyzed statistically. Cephalometric radiographs were obtained at T1 and T2 for all subjects to evaluate the amounts of maxillary advancement and the changes. Hence, the soft tissue changes were compared with actual skeletal movements. All cephalometric radiographs were scanned and analyzed by 1 investigator (M.H.E) using software (version 11.7; Dolphin Imaging and Management Solutions, Chatsworth, Calif). The analysis consisted of the following.\nSkeletally anchored maxillary protraction using miniplates was introduced to transfer the orthopedic forces directly to the maxilla, to achieve an outcome not possible by conventional tooth-anchored facemask therapy in which a large portion of the force is dissipated to the periodontal ligament area. The application of orthopedic force through the teeth results in unwanted dentoalveolar changes such as extrusion and mesial movement of the maxillary molars, proclination of the maxillary incisors, and retroclination of the mandibular incisors. Moreover, studies have shown that facemask and rapid maxillary expansion therapies produce greater dental than skeletal changes; in contrast, bone-anchored maxillary protraction produces greater skeletal changes and open circummaxillary sutures. This is the first study to use a 3D approach to evaluate the facial soft tissue changes associated with skeletally anchored maxillary protraction protocols: skeletally anchored facemask with miniplates, and Class III elastics from infrazygomatic miniplates in the maxilla to symphyseal miniplates in the mandible. The conventional lateral cephalometric analysis evaluates the soft tissue changes only at the midsagittal area. However, patients usually evaluate their own soft tissue esthetics on the basis of how they look in the frontal view. Therefore, imaging methods, such as 3D computed tomography and 3D facial scan images are needed to analyze and evaluate the soft tissues of the entire face.\nOne major application of 3D imaging in orthodontics and oral and maxillofacial surgery is preintervention and postinterventions assessment of facial esthetics. To evaluate treatment outcomes with regard to soft tissues, preoperative and postoperative 3D photographs of the patient's face are registered. After registration of the 3D photographs, the differences between them can be visualized on a color scale or a distance map. In this way, the results of surgical and orthodontic treatment can be evaluated quantitatively and objectively. Investigators concluded that surface-based registration is an accurate method to compare 3D photographs of the same subject at different times. Therefore, 3D stereophotogrammetry is an accurate tool to evaluate facial changes (surgical or nonsurgical) over time. The soft tissue landmarks used in this study proved to be reproducible, easy to designate, and useful for facial soft tissue analysis. For superimposition and registration of pretreatment and postreatment 3D photographs, Day and Lee used a broad surface on the forehead, Soncul and Bamber used 5 points (right and left exocanthions and endocanthions, and soft-tissue nasion), and McCance et al used these 5 points and an additional 5 arbitrary points on the forehead. Recently, Baik and Kim used the 5 landmarks on the right and left exocanthions and endocanthions, and soft-tissue nasion for point registration, followed by area registration using the wide surface of the forehead as the reference for superimposing the 3D images to evaluate the soft-tissue changes after the correction of thye skeletal Class III malocclusion by 2-jaw surgery with genioplasty. Hence, in this study, we used initial point registration followed by the wide surface registration starting from right and left exocanthions and extending upward over the forehead on the area that would not be influenced by the treatment.\nThe maxilla was protracted forward significantly in groups 1 and 2 when compared with the untreated control group (group 1, 4.87 mm; group 2, 5.81 mm). The protraction rates were 0.61 and 0.65 mm per month for groups 1 and 2, respectively, without a significant difference between them. In previous studies, Cha and Ngan achieved 3.42 mm of maxillary advancement, and Lee et al reported 3.11 mm of advancement using facemasks anchored by miniplates at the zygomatic buttress area. Sar et al46 had 2.83 mm of maxillary advancement using facemasks anchored by miniplates fixed in the lateral nasal wall.\n",
    "reference_list": "考点 1：“zygomatic buttress” 推荐译为 “颧牙槽嵴”\n考点 2：“self-tapping bone screws” 推荐译为 “自攻骨螺钉”\n考点 3：“orthopedic force” 推荐译为 “矫形力”\n考点 4：“centric occlusion” 推荐译为 “正中咬合”\n考点 5：“cephalometric radiographs” 推荐译为 “头影测量片”\n考点 6：“anterior crossbite” 推荐译为 “前牙反𬌗”\n考点 7：“facial moulages” 必须译为 “面部扫描模型”，不能翻译为 “面部印模”\n考点 8：“infrazygomatic buttress” 推荐译为 “颧下嵴”\n考点 9：“mucoperiosteal flaps” 推荐译为 “粘骨膜瓣”\n考点 10：“circummaxillary sutures” 推荐译为 “上颌周围骨缝”\n考点 11：“soft tissue pogonion” 推荐译为 “软组织颏前点”\n考点 12：“rapid maxillary expansion” 推荐译为 “快速上颌扩弓”\n考点 13：“periodontal ligament” 推荐译为 “牙周膜”\n考点 14：“symphyseal miniplates” 必须译为 “颏部微型钢板”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "127"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n21世纪以后，我国民间借贷的规模逐渐扩大，影响日益深远，在当前中国的经济发展中发挥着重要的作用。民间借贷既有积极作用，也有消极作用。一方面，民间借贷的存在和发展在弥补正规金融不足的同时也带动了正规金融的发展。而另一方面，我们必须看到民间借贷的存在和发展在一定程度上削弱了宏观调控的力度，并且其风险的危害性也大。因此，如何定位我国的民间借贷并采取相应的政策措施已经成为当前亟需解决的问题。\n\n一、我国目前有关民间借贷的法律规定及规定之间存在的相互冲突\n\n（一）目前有关民间借贷的法律规定 　　\n\n目前，在我国的法律体系之中，尚没有专门规范民间借贷的法律或是行政法规，有关民间借贷的规定分散在《合同法》和最高人民法院的两个司法解释中。\n\n在《合同法》中，借款合同作为一种有名的民事合同被集中地归入在第12章之中。《合同法》第12章第1条规定：“借款合同是指借款人向贷款人借款，到期返还借款并支付利息的合同。”第210条规定：“自然人之间的借贷合同，自贷款人提供贷款时生效”.第211条规定：“自然人之间的借款合同对支会利息没有约定或约定不明的，视为不支付利息，自然人之间的借款合同约定支付利息的，借款的利率不得违反国家有关限制利率的规定”.很明显，《合同法》对民间借贷合同是采取区别对待的，主要表现在借款主体和无息推定原则上。民间借贷既然是借贷合同的一种形式，就应该准用金融借贷的有关规定，然而实践中却不是如此。\n\n（二）现有民间借贷法律规定存在相互冲突且协调性较差在现有有关民间借贷的法律规定之中，存在着规定相互冲突的问题，协调性较差。比如《意见》第8条的规定：“借贷双方对有无约定利率发生争议又不能证明的，可参照银行同类贷款利率计息。借贷双方对约定的利率发生争议，又不能证明的，可参照本意见第6条规定计息”即由各地人民法院根据本地区的实际情况掌握，但最高不超过银行同类贷款利率的4倍。而根据《合同法》第211条之规定，“自然人之间的借款合同对支付利息没有约定或约定不明的，视为不支付利息”.即实行无息推定原则，很明显，这两条规定是互相冲突的。\n\n我国有关民间借贷的法律规定，但民间借贷的实践己经发生了太多的变化，原来的规定早已经是捉襟见肘，为了能够满足现实的需要对相应的规定进行修改己经是当务之急，从长远来看应该制定《民间借贷法》对民间借贷行为进行规范。\n\n二、当前我国民间借贷存在纠纷的主要形式 　　\n\n（一）案例引发的思考 　　\n\n本色集团是在浙江省东阳市注册的一家大型企业集团，法人代表吴英，总资产达30余亿之多，26岁的东阳女子创造了这样的本色集团，不能不说是个神话。2007年2月10日吴英因涉嫌非法吸收公众存款罪而被依法采取强制措施，随之本色的神话似乎到了终结的边缘。随着本色集团的土崩瓦解人们也渐渐开始思考本色后面并不本色的东西。各种媒体在争相报道本色事件的同时，都提到“非法集资”、“高利贷”、“民间游资”、“非法吸收公众存款罪”等字眼。可见人民所关心的己经不仅仅是事件的表面，而是事件背后的思考。 　　\n\n以上案例中，在民间大量闲置资金的背景下，巨额资金的所有者为了自身利益不断尝试为资金寻找出路。除了传统的投资途径外是否还有可以拓展的空间，在我国现有的金融体制之下是否存在更加高额的回报之路，民间借贷长期存在的原因及其与“非法集资”、“高利贷”、“非法吸收公众存款罪”等的界限等厂这些都是我们不得不思考的问题。",
    "ori_text": "21世纪以后，我国民间借贷的规模逐渐扩大，影响日益深远，在当前中国的经济发展中发挥着重要的作用。民间借贷既有积极作用，也有消极作用。一方面，民间借贷的存在和发展在弥补正规金融不足的同时也带动了正规金融的发展。而另一方面，我们必须看到民间借贷的存在和发展在一定程度上削弱了宏观调控的力度，并且其风险的危害性也大。因此，如何定位我国的民间借贷并采取相应的政策措施已经成为当前亟需解决的问题。\n\n一、我国目前有关民间借贷的法律规定及规定之间存在的相互冲突\n\n（一）目前有关民间借贷的法律规定 　　\n\n目前，在我国的法律体系之中，尚没有专门规范民间借贷的法律或是行政法规，有关民间借贷的规定分散在《合同法》和最高人民法院的两个司法解释中。\n\n在《合同法》中，借款合同作为一种有名的民事合同被集中地归入在第12章之中。《合同法》第12章第1条规定：“借款合同是指借款人向贷款人借款，到期返还借款并支付利息的合同。”第210条规定：“自然人之间的借贷合同，自贷款人提供贷款时生效”.第211条规定：“自然人之间的借款合同对支会利息没有约定或约定不明的，视为不支付利息，自然人之间的借款合同约定支付利息的，借款的利率不得违反国家有关限制利率的规定”.很明显，《合同法》对民间借贷合同是采取区别对待的，主要表现在借款主体和无息推定原则上。民间借贷既然是借贷合同的一种形式，就应该准用金融借贷的有关规定，然而实践中却不是如此。\n\n（二）现有民间借贷法律规定存在相互冲突且协调性较差在现有有关民间借贷的法律规定之中，存在着规定相互冲突的问题，协调性较差。比如《意见》第8条的规定：“借贷双方对有无约定利率发生争议又不能证明的，可参照银行同类贷款利率计息。借贷双方对约定的利率发生争议，又不能证明的，可参照本意见第6条规定计息”即由各地人民法院根据本地区的实际情况掌握，但最高不超过银行同类贷款利率的4倍。而根据《合同法》第211条之规定，“自然人之间的借款合同对支付利息没有约定或约定不明的，视为不支付利息”.即实行无息推定原则，很明显，这两条规定是互相冲突的。\n\n我国有关民间借贷的法律规定，但民间借贷的实践己经发生了太多的变化，原来的规定早已经是捉襟见肘，为了能够满足现实的需要对相应的规定进行修改己经是当务之急，从长远来看应该制定《民间借贷法》对民间借贷行为进行规范。\n\n二、当前我国民间借贷存在纠纷的主要形式 　　\n\n（一）案例引发的思考 　　\n\n本色集团是在浙江省东阳市注册的一家大型企业集团，法人代表吴英，总资产达30余亿之多，26岁的东阳女子创造了这样的本色集团，不能不说是个神话。2007年2月10日吴英因涉嫌非法吸收公众存款罪而被依法采取强制措施，随之本色的神话似乎到了终结的边缘。随着本色集团的土崩瓦解人们也渐渐开始思考本色后面并不本色的东西。各种媒体在争相报道本色事件的同时，都提到“非法集资”、“高利贷”、“民间游资”、“非法吸收公众存款罪”等字眼。可见人民所关心的己经不仅仅是事件的表面，而是事件背后的思考。 　　\n\n以上案例中，在民间大量闲置资金的背景下，巨额资金的所有者为了自身利益不断尝试为资金寻找出路。除了传统的投资途径外是否还有可以拓展的空间，在我国现有的金融体制之下是否存在更加高额的回报之路，民间借贷长期存在的原因及其与“非法集资”、“高利贷”、“非法吸收公众存款罪”等的界限等厂这些都是我们不得不思考的问题。",
    "reference_list": "考点1：“民间借贷“应该译为“private lending”，不能直译为 \"folk\" 或 \"civilian\"。\n考点2：”有名合同“应该译为“nominate contract”，指法律上已经确定了一定名称和特定规则的合同，源于大陆法系的概念。\n考点3：“本色后面并不本色的东西”推荐译为“the unsavory truths behind the Bense Group”。\n考点4：“寻找出路“不能直译为“finding a way out”。\n考点5：”捉襟见肘“推荐译为“be stretched to its limits”。\n考点6：“本色集团”应该翻译为：“Bense Group”\n考点7： “我国”应译为“China”，而不是“our country”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "36"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n【美食地理】中国最著名的48种地方小吃，看看你吃过几个，中国最值得打卡的十大美食地点 \n在中国这片神奇的土地上，饮食文化传承数千载，各省份、地区、民族的不同文化、习俗皆可在饮食中有所体现。要说最令吃货们念念不忘的，也许不是那些山珍海味，而是一道道风味各异的特色小吃。它们是那么平凡、朴素，甚至被认为难登大雅之堂，但它们也正是无数吃货舌尖上最深的念想。今天小编就为大家盘点一下全国各地最有名的风味小吃，如有疏漏之处，欢迎在留言中补充，让大家来共同了解祖国各地的特色美食！\n\n1.长沙臭豆腐\n\n小吃中当之无愧的王者，“臭名远扬”，即使不喜欢它的味道，也绝不会没有听说过它的名字。长沙臭豆腐，长沙人又称臭干子。“臭豆腐 ”其名虽俗气，但外陋内秀、平中见奇、源远流长，却是一种极具特色的休闲风味。色墨黑，外焦里嫩，鲜而香辣。焦脆而不糊、细嫩而不腻、初闻臭气扑鼻，细嗅浓香诱人。\n\n2.小龙虾\n\n不知从何时起，小龙虾悄悄出现在人们的餐桌上，从此一发不可收拾，以迅雷不及掩耳之势征服了中国人刁钻的胃口。在全国的任何一条小吃街，都绝不会少了小龙虾的身影。过去说“有井水处，可歌柳词”，如今是有人烟处，必烹龙虾。如果中国人的宵夜有图腾，那么必然是非小龙虾莫属。小龙虾常被做成香辣、蒜蓉、十三香等口味，其特点是 色艳、汤浓、味重、香辣无比，深受各路吃货喜欢。\n\n3.天津煎饼果子\n\n煎饼果子是天津的传统小吃。实际上，煎饼果子应当写作煎饼馃（guǒ）子，馃子是北方方言，即油条。还记得那句网络流行语吗，“哟哟,切克劳,煎饼果子来一套!”这句话足可说明煎饼果子的受欢迎程度。\n\n正宗的天津煎饼果子，必须是绿豆磨成面作为主料，白面和黄豆面按比例搭配，“果子” 就是油条或者馃篦(北京叫薄脆)。调料方面，葱花必不可少，其次就是天津产的甜面酱、蒜蓉辣酱或者油炸辣子，以及红色的北方豆腐乳调味，这些就是一套正宗天津煎饼果子的全部内容了，另外再加鸡蛋的实际要叫鸡蛋煎饼果子（鸡蛋还可以自带哦）。除此之外，一切加烤肠、生菜、榨菜、肉松、海带丝的都是邪教，在天津人看来，食理难容。\n\n4.天津狗不理包子\n\n狗不理包子是天津市中国传统风味小吃，始创于公元1858年（清朝咸丰年间）。狗不理包子是包子中的“LV”，被誉为“津门老字号，中华第一包”，以其鲜美的味道和独特的样式而闻名。 狗不理包子的面、馅选料精细，制作工艺严格，外形美观，特别是包子褶花匀称，每个包子都是18个褶，“薄皮大馅十八褶”便是对其最生动的描写。刚出笼的包子，鲜而不腻，清香适口。\n",
    "ori_text": "【美食地理】中国最著名的48种地方小吃，看看你吃过几个，中国最值得打卡的十大美食地点 \n在中国这片神奇的土地上，饮食文化传承数千载，各省份、地区、民族的不同文化、习俗皆可在饮食中有所体现。要说最令吃货们念念不忘的，也许不是那些山珍海味，而是一道道风味各异的特色小吃。它们是那么平凡、朴素，甚至被认为难登大雅之堂，但它们也正是无数吃货舌尖上最深的念想。今天小编就为大家盘点一下全国各地最有名的风味小吃，如有疏漏之处，欢迎在留言中补充，让大家来共同了解祖国各地的特色美食！\n\n1.长沙臭豆腐\n\n小吃中当之无愧的王者，“臭名远扬”，即使不喜欢它的味道，也绝不会没有听说过它的名字。长沙臭豆腐，长沙人又称臭干子。“臭豆腐 ”其名虽俗气，但外陋内秀、平中见奇、源远流长，却是一种极具特色的休闲风味。色墨黑，外焦里嫩，鲜而香辣。焦脆而不糊、细嫩而不腻、初闻臭气扑鼻，细嗅浓香诱人。\n\n2.小龙虾\n\n不知从何时起，小龙虾悄悄出现在人们的餐桌上，从此一发不可收拾，以迅雷不及掩耳之势征服了中国人刁钻的胃口。在全国的任何一条小吃街，都绝不会少了小龙虾的身影。过去说“有井水处，可歌柳词”，如今是有人烟处，必烹龙虾。如果中国人的宵夜有图腾，那么必然是非小龙虾莫属。小龙虾常被做成香辣、蒜蓉、十三香等口味，其特点是 色艳、汤浓、味重、香辣无比，深受各路吃货喜欢。\n\n3.天津煎饼果子\n\n煎饼果子是天津的传统小吃。实际上，煎饼果子应当写作煎饼馃（guǒ）子，馃子是北方方言，即油条。还记得那句网络流行语吗，“哟哟,切克劳,煎饼果子来一套!”这句话足可说明煎饼果子的受欢迎程度。\n\n正宗的天津煎饼果子，必须是绿豆磨成面作为主料，白面和黄豆面按比例搭配，“果子” 就是油条或者馃篦(北京叫薄脆)。调料方面，葱花必不可少，其次就是天津产的甜面酱、蒜蓉辣酱或者油炸辣子，以及红色的北方豆腐乳调味，这些就是一套正宗天津煎饼果子的全部内容了，另外再加鸡蛋的实际要叫鸡蛋煎饼果子（鸡蛋还可以自带哦）。除此之外，一切加烤肠、生菜、榨菜、肉松、海带丝的都是邪教，在天津人看来，食理难容。\n\n4.天津狗不理包子\n\n狗不理包子是天津市中国传统风味小吃，始创于公元1858年（清朝咸丰年间）。狗不理包子是包子中的“LV”，被誉为“津门老字号，中华第一包”，以其鲜美的味道和独特的样式而闻名。 狗不理包子的面、馅选料精细，制作工艺严格，外形美观，特别是包子褶花匀称，每个包子都是18个褶，“薄皮大馅十八褶”便是对其最生动的描写。刚出笼的包子，鲜而不腻，清香适口。\n",
    "reference_list": "考点1：“臭豆腐”应统一译为：stinky tofu\n考点2：“臭名远扬”推荐译为：notorious yet beloved或famous for its pungent smell\n考点3：“迅雷不及掩耳之势”应译为：took China by storm或exploded in popularity\n考点4：“刁钻的胃口”应译为：discerning palates\n考点5：“宵夜图腾”应译为：symbol of Chinese late-night food\n考点6：“煎饼果子”应译为：Tianjin-style jianbing或Jianbing guozi",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "广告营销",
    "prompt_id": "70"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nAutomated decision support systems are one type of automation that supports human operators by providing information about a particular state of the world (Mosier and Manzey 2020). Typical examples are alarm systems or detection systems (Rieger, Heilmann, and Manzey 2021) in security contexts (Goh, Wiegmann, and Madhavan 2005; Hättenschwiler et al. 2018; Huegli, Merks, and Schwaninger 2020), process control (Chavaillaz, Wastell, and Sauer 2016, Chavaillaz et  al. 2019; Chavaillaz and Sauer 2017; Sauer, Chavaillaz, and Wastell 2016), or medical screening tasks (Alberdi et  al. 2004; Drew, Cunningham, and Wolfe 2012; Xiao et al. 2021). One function of decision support systems in visual inspection tasks is to provide direct cues that operators must resolve. Direct cues attract the attention of human operators by indicating the exact location of a possible target (Chavaillaz et  al. 2018; Darnell and Lamy 2022; Posner, Snyder, and Davidson 1980)Such direct cues have two goals: First, they should support the operator’s search during a visual inspection task (Chavaillaz et al. 2018; Goh, Wiegmann, and Madhavan 2005; Wiegmann et al. 2006) by guiding attention towards the cued area (Wolfe 2021); and second, they should improve the operator’s decision making regarding the detection of critical events or targets (Wickens et  al. 2015). However, the reliability of most decision support systems is imperfect, and system designers must decide how to set their decision criterion. \nUsually, the priority is to set a more liberal decision criterion (Sorkin and Woods 1985) to detect more targets (automation hits). But a liberal decision criterion comes at the cost of producing more alarms where no target is present (automation false alarms) or producing automation miscues. Based on previous studies (Chavaillaz et  al. 2020; Goh, Wiegmann, and Madhavan 2005), we define automation miscues as alarms in the wrong location when a target is located elsewhere in the image. Because of the decision support system’s imperfect reliability, operators should assess the validity of its alarms and act appropriately. Such behaviour would improve human–machine system performance (Meyer and Kuchar 2021). Unfortunately, operators often do not react optimally to the decision support system’s presence, resulting in insufficient human–machine system performance (Bartlett and McCarley 2017, 2019; Boskemper, Bartlett, and McCarley 2022). Although direct cues can improve human–machine system performance (Chavaillaz et  al. 2018), they can also have adverse effects when false alarms and miscues become frequent. It has been well-researched that operators will ignore automation alarms if they experience many false alarms, a so-called ‘cry wolf’ effect (Bliss, Gilson, and Deaton 1995; Dixon and Wickens 2006; Parasuraman and Wickens 2008; Zirk, Wiczorek, and Manzey 2020). Several studies have found this phenomenon and described it as a lack of operator compliance (Bliss, Gilson, and Deaton 1995; Huegli, Merks, and Schwaninger 2020, 2023; Parasuraman, Sheridan, and Wickens 2000; Zirk, Wiczorek, and Manzey 2020). We define compliance operationally as the proportion of target-present responses given by operators on trials with automation alarms—regardless of whether true or false (Dixon and Wickens 2006; Manzey, Gérard, and Wiczorek 2014). Compliance has been described as a behavioural expression of trust in automation (Hoff and Bashir 2015; Lee and See 2004). Although there is some evidence that compliance somehow relates to subjective trust in automation (Avril et  al. 2022; Chancey et  al. 2017; Lee and Moray 1992), subjective trust and objective compliance do not always correlate strongly (Chavaillaz, Wastell, and Sauer 2016, Chavaillaz et  al. 2019; Rovira, McGarry, and Parasuraman 2007). Eye-tracking research has shown that the marked areas are the ones that are mainly inspected by operators (Drew, Cunningham, and Wolfe 2012), which implies strong attentional guidance (Wolfe 2021) by direct cues. However, if the marked area is a miscue, this can become a problem if operators get distracted by it and visual search for prohibited articles in other areas of the X-ray image is impaired. Alberdi et al. (2004) and Kunar et al. (2017) analysed the performance data of radiologists detecting breast cancer cells with the help of an automated decision support that provided direct cues. Radiologists benefitted from the alarms when they located cancer cells correctly, but less when miscues were given.\nGoh, Wiegmann, and Madhavan (2005) tested student participants in a simulated baggage X-ray screening task in which they had to detect knives in greyscale images with the help of a decision support system. Participants benefitted from direct cues, especially when automation reliability was high, but they missed most of the targets when miscues were present. We extend this research by using highly realistic colourised X-ray images with professional airport security officers supported by an explosive detection system (EDSCB) for cabin baggage screening. Moreover, whereas previous studies investigated whether miscues impair the detection of the same type of target located elsewhere in the X-ray image, we investigated spill-over effects from a cueing system for one type of target (EDSCB for explosive) on detection of different types of targets (guns and knives). X-ray baggage screening at airports aims to prevent passengers from bringing prohibited articles (e.g. guns, knives, bombs) onto an aircraft (Harris 2002; Petrozziello and Jordanov 2019). Bombs are the most dangerous prohibited articles in passenger baggage and are technically called improvised explosive devices (IEDs). Screeners can detect IEDs when they are trained well (Halbherr et al. 2013; Koller et  al. 2008, Koller, Drury, and Schwaninger 2009; Schuster et al. 2013; Schwaninger and Hofer 2004) and when they are supported with explosives detection systems for cabin baggage (EDSCB) screening (Hättenschwiler et al. 2018; Huegli, Merks, and Schwaninger 2020, 2023). EDSCB support screeners by providing direct cues in areas in the X-ray image that might contain explosive material. When the EDSCB is used as a decision support system in primary screening, the screeners conduct on-screen alarm resolution. That is, the screeners visually inspect the X-ray image and decide whether the EDSCB alarm is correct or incorrect (Hättenschwiler et  al. 2018;Schwaninger and Merks 2019). When the screeners decide that the bag could contain a prohibited article, the bag is sent to secondary screening where another screener inspects the bag by applying explosives trace detection or manual baggage opening (Sterchi and Schwaninger 2015). An alternative to on-screen alarm resolution in primary screening is automated decision: Bags on which EDSCB has alarmed are sent directly to secondary screening for further inspection (Hättenschwiler et  al. 2018; Huegli, Merks, and Schwaninger 2020). State-of-the-art multi-view EDSCB technologies (EDSCB of Standard C2) achieve automation hit rates in the range of 75%–90% and automation false alarm rates of 6%–20% (Hättenschwiler et  al. 2018). \nBecause such false alarm rates can impair checkpoint efficiency (Sterchi and Schwaninger 2015), some countries still use EDSCB with on-screen alarm resolution. EDSCB false alarms can either occur on target-absent images not containing prohibited articles (genuine false alarms) or on images containing other prohibited articles such as guns or knives (miscues). The goal of the present study was to investigate whether the failure proneness of a decision support system affects operator performance during a visual inspection task. More specifically, we wanted to examine spill-over effects from a cueing system for one type of target (EDSCB for explosives) on human detection of different types of targets (guns and knives). Besides the theoretical relevance of the study, we also wanted to answer the practically relevant question whether miscues are a problem that needs to be considered when conducting EDSCB on-screen alarm resolution in primary screening. \nThe present study used highly realistic X-ray images in colour with professional airport security officers supported by EDSCB with a realistic automation reliability. The screeners had to detect prohibited articles (guns, knives, and IEDs). Screeners were tested in three experimental conditions: a false alarm prone condition where all EDSCB alarms were false alarms, a miscue prone condition where all EDSCB alarms were miscues, and a multiple failures condition where EDSCB false alarms and miscues appeared equally often. \nThe dependent variables were performance measures (hit rate, false alarm rate, response time), behavioural trust (operator compliance), and subjective trust perception. Basic research on visual search has shown that salient cues capture attention, which can result in lower detection of targets, particularly in difficult visual search tasks (Gaspelin, Ruthruff, and Lien 2016; Luck et  al. 2021; Ruthruff et  al. 2020). Therefore, we expected lowest performance in the miscue prone condition, because screeners get distracted by the miscue and visual search for prohibited articles in other areas of the X-ray image gets impaired. Because knives are more difficult to detect than guns (Halbherr et  al. 2013; Koller et al. 2008, Koller, Drury, and Schwaninger 2009), we expected to find the negative effect of miscues for detecting knives and less, if at all, for detecting guns. Because well trained screeners achieve a high detection of IEDs (Halbherr et  al. 2013; Koller et  al. 2008, Koller, Drury, and Schwaninger 2009), we expected that screeners would comply more with correct EDSCB alarms than with incorrect EDSCB alarms. That is, they should recognise such automation failures.",
    "ori_text": "\n\nAutomated decision support systems are one type of automation that supports human operators by providing information about a particular state of the world (Mosier and Manzey 2020). Typical examples are alarm systems or detection systems (Rieger, Heilmann, and Manzey 2021) in security contexts (Goh, Wiegmann, and Madhavan 2005; Hättenschwiler et al. 2018; Huegli, Merks, and Schwaninger 2020), process control (Chavaillaz, Wastell, and Sauer 2016, Chavaillaz et  al. 2019; Chavaillaz and Sauer 2017; Sauer, Chavaillaz, and Wastell 2016), or medical screening tasks (Alberdi et  al. 2004; Drew, Cunningham, and Wolfe 2012; Xiao et al. 2021). One function of decision support systems in visual inspection tasks is to provide direct cues that operators must resolve. Direct cues attract the attention of human operators by indicating the exact location of a possible target (Chavaillaz et  al. 2018; Darnell and Lamy 2022; Posner, Snyder, and Davidson 1980)Such direct cues have two goals: First, they should support the operator’s search during a visual inspection task (Chavaillaz et al. 2018; Goh, Wiegmann, and Madhavan 2005; Wiegmann et al. 2006) by guiding attention towards the cued area (Wolfe 2021); and second, they should improve the operator’s decision making regarding the detection of critical events or targets (Wickens et  al. 2015). However, the reliability of most decision support systems is imperfect, and system designers must decide how to set their decision criterion. \nUsually, the priority is to set a more liberal decision criterion (Sorkin and Woods 1985) to detect more targets (automation hits). But a liberal decision criterion comes at the cost of producing more alarms where no target is present (automation false alarms) or producing automation miscues. Based on previous studies (Chavaillaz et  al. 2020; Goh, Wiegmann, and Madhavan 2005), we define automation miscues as alarms in the wrong location when a target is located elsewhere in the image. Because of the decision support system’s imperfect reliability, operators should assess the validity of its alarms and act appropriately. Such behaviour would improve human–machine system performance (Meyer and Kuchar 2021). Unfortunately, operators often do not react optimally to the decision support system’s presence, resulting in insufficient human–machine system performance (Bartlett and McCarley 2017, 2019; Boskemper, Bartlett, and McCarley 2022). Although direct cues can improve human–machine system performance (Chavaillaz et  al. 2018), they can also have adverse effects when false alarms and miscues become frequent. It has been well-researched that operators will ignore automation alarms if they experience many false alarms, a so-called ‘cry wolf’ effect (Bliss, Gilson, and Deaton 1995; Dixon and Wickens 2006; Parasuraman and Wickens 2008; Zirk, Wiczorek, and Manzey 2020). Several studies have found this phenomenon and described it as a lack of operator compliance (Bliss, Gilson, and Deaton 1995; Huegli, Merks, and Schwaninger 2020, 2023; Parasuraman, Sheridan, and Wickens 2000; Zirk, Wiczorek, and Manzey 2020). We define compliance operationally as the proportion of target-present responses given by operators on trials with automation alarms—regardless of whether true or false (Dixon and Wickens 2006; Manzey, Gérard, and Wiczorek 2014). Compliance has been described as a behavioural expression of trust in automation (Hoff and Bashir 2015; Lee and See 2004). Although there is some evidence that compliance somehow relates to subjective trust in automation (Avril et  al. 2022; Chancey et  al. 2017; Lee and Moray 1992), subjective trust and objective compliance do not always correlate strongly (Chavaillaz, Wastell, and Sauer 2016, Chavaillaz et  al. 2019; Rovira, McGarry, and Parasuraman 2007). Eye-tracking research has shown that the marked areas are the ones that are mainly inspected by operators (Drew, Cunningham, and Wolfe 2012), which implies strong attentional guidance (Wolfe 2021) by direct cues. However, if the marked area is a miscue, this can become a problem if operators get distracted by it and visual search for prohibited articles in other areas of the X-ray image is impaired. Alberdi et al. (2004) and Kunar et al. (2017) analysed the performance data of radiologists detecting breast cancer cells with the help of an automated decision support that provided direct cues. Radiologists benefitted from the alarms when they located cancer cells correctly, but less when miscues were given.\nGoh, Wiegmann, and Madhavan (2005) tested student participants in a simulated baggage X-ray screening task in which they had to detect knives in greyscale images with the help of a decision support system. Participants benefitted from direct cues, especially when automation reliability was high, but they missed most of the targets when miscues were present. We extend this research by using highly realistic colourised X-ray images with professional airport security officers supported by an explosive detection system (EDSCB) for cabin baggage screening. Moreover, whereas previous studies investigated whether miscues impair the detection of the same type of target located elsewhere in the X-ray image, we investigated spill-over effects from a cueing system for one type of target (EDSCB for explosive) on detection of different types of targets (guns and knives). X-ray baggage screening at airports aims to prevent passengers from bringing prohibited articles (e.g. guns, knives, bombs) onto an aircraft (Harris 2002; Petrozziello and Jordanov 2019). Bombs are the most dangerous prohibited articles in passenger baggage and are technically called improvised explosive devices (IEDs). Screeners can detect IEDs when they are trained well (Halbherr et al. 2013; Koller et  al. 2008, Koller, Drury, and Schwaninger 2009; Schuster et al. 2013; Schwaninger and Hofer 2004) and when they are supported with explosives detection systems for cabin baggage (EDSCB) screening (Hättenschwiler et al. 2018; Huegli, Merks, and Schwaninger 2020, 2023). EDSCB support screeners by providing direct cues in areas in the X-ray image that might contain explosive material. When the EDSCB is used as a decision support system in primary screening, the screeners conduct on-screen alarm resolution. That is, the screeners visually inspect the X-ray image and decide whether the EDSCB alarm is correct or incorrect (Hättenschwiler et  al. 2018;Schwaninger and Merks 2019). When the screeners decide that the bag could contain a prohibited article, the bag is sent to secondary screening where another screener inspects the bag by applying explosives trace detection or manual baggage opening (Sterchi and Schwaninger 2015). An alternative to on-screen alarm resolution in primary screening is automated decision: Bags on which EDSCB has alarmed are sent directly to secondary screening for further inspection (Hättenschwiler et  al. 2018; Huegli, Merks, and Schwaninger 2020). State-of-the-art multi-view EDSCB technologies (EDSCB of Standard C2) achieve automation hit rates in the range of 75%–90% and automation false alarm rates of 6%–20% (Hättenschwiler et  al. 2018). \nBecause such false alarm rates can impair checkpoint efficiency (Sterchi and Schwaninger 2015), some countries still use EDSCB with on-screen alarm resolution. EDSCB false alarms can either occur on target-absent images not containing prohibited articles (genuine false alarms) or on images containing other prohibited articles such as guns or knives (miscues). The goal of the present study was to investigate whether the failure proneness of a decision support system affects operator performance during a visual inspection task. More specifically, we wanted to examine spill-over effects from a cueing system for one type of target (EDSCB for explosives) on human detection of different types of targets (guns and knives). Besides the theoretical relevance of the study, we also wanted to answer the practically relevant question whether miscues are a problem that needs to be considered when conducting EDSCB on-screen alarm resolution in primary screening. \nThe present study used highly realistic X-ray images in colour with professional airport security officers supported by EDSCB with a realistic automation reliability. The screeners had to detect prohibited articles (guns, knives, and IEDs). Screeners were tested in three experimental conditions: a false alarm prone condition where all EDSCB alarms were false alarms, a miscue prone condition where all EDSCB alarms were miscues, and a multiple failures condition where EDSCB false alarms and miscues appeared equally often. \nThe dependent variables were performance measures (hit rate, false alarm rate, response time), behavioural trust (operator compliance), and subjective trust perception. Basic research on visual search has shown that salient cues capture attention, which can result in lower detection of targets, particularly in difficult visual search tasks (Gaspelin, Ruthruff, and Lien 2016; Luck et  al. 2021; Ruthruff et  al. 2020). Therefore, we expected lowest performance in the miscue prone condition, because screeners get distracted by the miscue and visual search for prohibited articles in other areas of the X-ray image gets impaired. Because knives are more difficult to detect than guns (Halbherr et  al. 2013; Koller et al. 2008, Koller, Drury, and Schwaninger 2009), we expected to find the negative effect of miscues for detecting knives and less, if at all, for detecting guns. Because well trained screeners achieve a high detection of IEDs (Halbherr et  al. 2013; Koller et  al. 2008, Koller, Drury, and Schwaninger 2009), we expected that screeners would comply more with correct EDSCB alarms than with incorrect EDSCB alarms. That is, they should recognise such automation failures.",
    "reference_list": "考点1 ：“ visual search tasks ”推荐译为\"视觉搜索任务 \"\n考点2：\" direct cues \"需要译为\"直接提示\"\n考点3：\" hit rates \" 推荐译为\"击中率\"\n考点4：\"false alarm rates \"推荐译为 \"虚报率 \"\n考点5：\" validity \"推荐译为\"效度\"\n考点6：\" Eye-tracking research \"应译为\"眼动追踪 \"\n考点7：\" secondary screening\"推荐译为\"二次扫描 \"\n考点8：\" multi-view\"推荐译为\"多视图 \"\n考点9：\"response time\"推荐译为\"反应时 \"\n考点10：\"miscues\"推荐译为\" 错误线索\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "135"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n2.相关工作\n装配精度预测的准确性与效率取决于三大核心要素：表面形状表征的保真度、几何量-物理量融合偏差建模的完备性、以及预测方法的计算效能。本节从上述维度系统评述现有研究进展与局限。\n2.1零件表面形状构建\n（1）公差表达模型\n公差表达模型是计算机辅助设计系统中用于描述零件几何尺寸与公差信息的数学工具，旨在通过工程语义来界定公差域的边界及变动要素，为装配精度预测提供基础数据支持。自20世纪80年代以来，学者们提出了多种公差表达模型，如工艺和拓扑相关曲面模型、矩阵模型、矢量环模型、公差映射图模型、雅可比-旋量模型、GapSpace模型等。然而，这些模型多集中于尺寸、位置与方向的公差描述，通常简化或忽略了零件表面形状的表征。在复杂的精密装配中，这一缺陷会导致装配表面形状误差的几何分布特性无法准确捕捉，从而影响装配精度预测的准确性。\n鉴于实际表面形状对装配精度的重要影响，Ballu等人提出了肤面模型，从物理几何角度出发，构建了一个能反映零件制造误差的产品设计模型，提供了一种设计与制造阶段几何形状一致性表达的方法，进而提高了装配精度预测的准确性。本文也采用这一肤面模型，通过高效融合虚拟模型与实测数据，构建零件的实际表面形貌。\n（2）实际表面构建方法\n针对零件实际表面的构建，学者们开展了大量研究，方法可分为两类：第一类，基于数字空间的模拟数据，通过函数式方法表征实际形貌。例如，Yan等人提出了一种基于有限元分析的网格变形方法，能够生成与实际零件形状偏差一致的肤面模型；Xue等人基于离散余弦变换方法，结合虚拟样本生成与代理模型，实现了航空结构件装配偏差的快速响应与准确预测。尽管这些方法提高了仿真精度，但仍与实际工件表面特征存在差距，难以完全再现实际零件表面。Huang等人利用模态分解方法识别和预测增材制造零件的几何偏差，通过将复杂的几何形状偏差分解为多个独立的缺陷模式，从而能够更准确地描述和预测增材制造零件的形状偏差。\n第二类，基于物理空间的实测数据，采用多尺度分析实现滤波与重构。例如，Luo等人通过离散化点集描述形状偏差，并利用点云配准技术将物理空间中的零件表面映射到虚拟空间，从而解决了虚实同步问题。Sun等人利用小波变换方法预处理测量的表面数据，滤除噪声、粗糙度等不影响装配精度的因素，仅保留对配合表面影响较大的宏观成分。\nZhang等针对加工零件的粗糙表面，提出了一种融合了分形理论、Weibull分布和遗传算法的创新方法，旨在刻画非高斯粗糙表面的特定偏度和峰度。通过优化遗传算法的参数生成尺度独立且更实际的粗糙表面模型，为工程接触力学的研究提供了一个有效且精确的工具。尽管这些方法能较好地再现实际表面形貌，但在大型复杂零件的应用中，由于点云数据的庞大规模，仍然存在计算量大、同步困难的问题。考虑到表面形状的建模效率问题，Haitjema提出了一种结合离散勒让德多项式和离散傅里叶变换的创新方法，通过将实测数据分解为不同阶数的多项式系数，实现了零件表面形状的快速重构。\n综上所述，现有的公差表达与表面重构方法要么依赖全局曲面拟合导致高维点云运算开销巨大，要么在多尺度统计特性与几何连续性之间难以兼顾，难以满足大型薄壁碳纤维增强复合材料构件实时更新、高精度描述和大规模批量三者的需求。因此，本研究引入基于几何协方差的点云直算肤面模型，以期在保证统计一致性与空间连续性的同时，实现与现场测量数据的无缝对接，从而为后续装配偏差预测提供高效且可扩展的表面形貌基础。\n2.2装配偏差建模\n装配偏差传递模型的核心在于揭示多源偏差在装配链中的累积与融合机制。针对CFRP构件装配流程，偏差主要来源于几何定位偏差与物理变形偏差。这两类偏差通过非线性传递与交互作用，共同影响装配系统的几何约束场（体现为定位精度的偏移）和物理交互场（例如装配接触力场、位移约束场）。特别地，CFRP薄壁结构的层级装配过程（零件级—组件级—部件级）呈现出较高的误差累积效应：初始制造偏差、定位系统偏差以及载荷诱导变形的相互作用，经过多阶段传递后，最终导致装配体几何形态特征的非确定性分布。\n基于几何量的装配偏差传递模型包括尺寸链模型和确定性定位模型。例如，Liu等人结合肤面模型与雅可比模型，提出了一种考虑实际表面形状的装配偏差传递分析模型；Iaccarino等人则通过结合统计预测与确定性装配优化了航空结构装配中的精度。然而，这些模型多基于刚性假设，主要关注几何变动量，缺乏对装配过程中的物理因素的全面考虑。\n在CFRP薄壁结构装配过程中，考虑到多约束、装配载荷等物理特性，变形效应不可忽视。因此，必须将物理因素纳入装配偏差传递模型。目前，主流的物理因素建模方法包括有限元法、影响系数法和混合方法。有限元法通过对装配体进行建模，赋予材料属性、边界条件等，进行力学分析，能够有效处理复杂装配体的非理想状态。然而，有限元法在计算效率上存在一定局限，尤其在处理大规模结构时，可能无法满足工程应用中的实时响应需求。例如，Camelio等人提出了一种结合主成分分析和有限元分析的方法，通过分析零件的几何协方差，并考虑零件装配过程中的变形与回弹，从而提高柔性零件装配偏差传递分析的计算效率。影响系数法则通过预先计算并存储影响系数矩阵，提高了计算效率，特别适用于柔性装配体的变形和应力分布分析。然而，该方法在面对多源偏差较多的装配过程中，可能在建模效率上存在不足。例如，Polini等人利用影响系数法评估柔性装配体中的偏差和应力分布，并通过不同案例对比该方法的模拟时间和结果准确性。但由于该方法的模型参数是通过有限元分析数据回归拟合的，当装配步骤和偏差源较多时，其建模效率仍然不足，导致在复杂装配场景下存在一定的局限性。此外，现代控制理论中的状态空间模型能够有效处理多工位装配中的偏差传递与累积效应。然而，该模型假设偏差传递是线性关系，这可能未能准确捕捉装配偏差传递中的非线性特征。Zhang等人采用状态空间模型对复合材料单工位装配过程中的偏差传递进行了分析，并结合有限元法评估了零件制造误差和工装定位误差对装配偏差的影响。然而，由于假设各工位之间的多源偏差传递为线性关系，这一方法在处理复杂装配任务时存在局限，未能全面捕捉装配偏差传递中的非线性特征。此外，在同时考虑零件的几何变动与物理因素时，映射关系会变得更为繁杂，不能将其简单视为多源误差的线性传递过程。\n从尺寸链、影响系数法到状态空间模型，常规装配偏差传递方法在几何定位和静态物理分析上各具优势，却因刚性假设或线性叠加限制，对多源非线性耦合的装配偏差场描述不足。有限元法虽能捕捉非线性物理效应，却在计算效率上难以实现秒级响应。由此可见，亟需一种兼顾几何-物理复合建模精度与快速响应能力的端到端预测框架，以支持高精度装配公差的动态决策与闭环优化。\n",
    "ori_text": "\n\n2.相关工作\n装配精度预测的准确性与效率取决于三大核心要素：表面形状表征的保真度、几何量-物理量融合偏差建模的完备性、以及预测方法的计算效能。本节从上述维度系统评述现有研究进展与局限。\n2.1零件表面形状构建\n（1）公差表达模型\n公差表达模型是计算机辅助设计系统中用于描述零件几何尺寸与公差信息的数学工具，旨在通过工程语义来界定公差域的边界及变动要素，为装配精度预测提供基础数据支持。自20世纪80年代以来，学者们提出了多种公差表达模型，如工艺和拓扑相关曲面模型、矩阵模型、矢量环模型、公差映射图模型、雅可比-旋量模型、GapSpace模型等。然而，这些模型多集中于尺寸、位置与方向的公差描述，通常简化或忽略了零件表面形状的表征。在复杂的精密装配中，这一缺陷会导致装配表面形状误差的几何分布特性无法准确捕捉，从而影响装配精度预测的准确性。\n鉴于实际表面形状对装配精度的重要影响，Ballu等人提出了肤面模型，从物理几何角度出发，构建了一个能反映零件制造误差的产品设计模型，提供了一种设计与制造阶段几何形状一致性表达的方法，进而提高了装配精度预测的准确性。本文也采用这一肤面模型，通过高效融合虚拟模型与实测数据，构建零件的实际表面形貌。\n（2）实际表面构建方法\n针对零件实际表面的构建，学者们开展了大量研究，方法可分为两类：第一类，基于数字空间的模拟数据，通过函数式方法表征实际形貌。例如，Yan等人提出了一种基于有限元分析的网格变形方法，能够生成与实际零件形状偏差一致的肤面模型；Xue等人基于离散余弦变换方法，结合虚拟样本生成与代理模型，实现了航空结构件装配偏差的快速响应与准确预测。尽管这些方法提高了仿真精度，但仍与实际工件表面特征存在差距，难以完全再现实际零件表面。Huang等人利用模态分解方法识别和预测增材制造零件的几何偏差，通过将复杂的几何形状偏差分解为多个独立的缺陷模式，从而能够更准确地描述和预测增材制造零件的形状偏差。\n第二类，基于物理空间的实测数据，采用多尺度分析实现滤波与重构。例如，Luo等人通过离散化点集描述形状偏差，并利用点云配准技术将物理空间中的零件表面映射到虚拟空间，从而解决了虚实同步问题。Sun等人利用小波变换方法预处理测量的表面数据，滤除噪声、粗糙度等不影响装配精度的因素，仅保留对配合表面影响较大的宏观成分。\nZhang等针对加工零件的粗糙表面，提出了一种融合了分形理论、Weibull分布和遗传算法的创新方法，旨在刻画非高斯粗糙表面的特定偏度和峰度。通过优化遗传算法的参数生成尺度独立且更实际的粗糙表面模型，为工程接触力学的研究提供了一个有效且精确的工具。尽管这些方法能较好地再现实际表面形貌，但在大型复杂零件的应用中，由于点云数据的庞大规模，仍然存在计算量大、同步困难的问题。考虑到表面形状的建模效率问题，Haitjema提出了一种结合离散勒让德多项式和离散傅里叶变换的创新方法，通过将实测数据分解为不同阶数的多项式系数，实现了零件表面形状的快速重构。\n综上所述，现有的公差表达与表面重构方法要么依赖全局曲面拟合导致高维点云运算开销巨大，要么在多尺度统计特性与几何连续性之间难以兼顾，难以满足大型薄壁碳纤维增强复合材料构件实时更新、高精度描述和大规模批量三者的需求。因此，本研究引入基于几何协方差的点云直算肤面模型，以期在保证统计一致性与空间连续性的同时，实现与现场测量数据的无缝对接，从而为后续装配偏差预测提供高效且可扩展的表面形貌基础。\n2.2装配偏差建模\n装配偏差传递模型的核心在于揭示多源偏差在装配链中的累积与融合机制。针对CFRP构件装配流程，偏差主要来源于几何定位偏差与物理变形偏差。这两类偏差通过非线性传递与交互作用，共同影响装配系统的几何约束场（体现为定位精度的偏移）和物理交互场（例如装配接触力场、位移约束场）。特别地，CFRP薄壁结构的层级装配过程（零件级—组件级—部件级）呈现出较高的误差累积效应：初始制造偏差、定位系统偏差以及载荷诱导变形的相互作用，经过多阶段传递后，最终导致装配体几何形态特征的非确定性分布。\n基于几何量的装配偏差传递模型包括尺寸链模型和确定性定位模型。例如，Liu等人结合肤面模型与雅可比模型，提出了一种考虑实际表面形状的装配偏差传递分析模型；Iaccarino等人则通过结合统计预测与确定性装配优化了航空结构装配中的精度。然而，这些模型多基于刚性假设，主要关注几何变动量，缺乏对装配过程中的物理因素的全面考虑。\n在CFRP薄壁结构装配过程中，考虑到多约束、装配载荷等物理特性，变形效应不可忽视。因此，必须将物理因素纳入装配偏差传递模型。目前，主流的物理因素建模方法包括有限元法、影响系数法和混合方法。有限元法通过对装配体进行建模，赋予材料属性、边界条件等，进行力学分析，能够有效处理复杂装配体的非理想状态。然而，有限元法在计算效率上存在一定局限，尤其在处理大规模结构时，可能无法满足工程应用中的实时响应需求。例如，Camelio等人提出了一种结合主成分分析和有限元分析的方法，通过分析零件的几何协方差，并考虑零件装配过程中的变形与回弹，从而提高柔性零件装配偏差传递分析的计算效率。影响系数法则通过预先计算并存储影响系数矩阵，提高了计算效率，特别适用于柔性装配体的变形和应力分布分析。然而，该方法在面对多源偏差较多的装配过程中，可能在建模效率上存在不足。例如，Polini等人利用影响系数法评估柔性装配体中的偏差和应力分布，并通过不同案例对比该方法的模拟时间和结果准确性。但由于该方法的模型参数是通过有限元分析数据回归拟合的，当装配步骤和偏差源较多时，其建模效率仍然不足，导致在复杂装配场景下存在一定的局限性。此外，现代控制理论中的状态空间模型能够有效处理多工位装配中的偏差传递与累积效应。然而，该模型假设偏差传递是线性关系，这可能未能准确捕捉装配偏差传递中的非线性特征。Zhang等人采用状态空间模型对复合材料单工位装配过程中的偏差传递进行了分析，并结合有限元法评估了零件制造误差和工装定位误差对装配偏差的影响。然而，由于假设各工位之间的多源偏差传递为线性关系，这一方法在处理复杂装配任务时存在局限，未能全面捕捉装配偏差传递中的非线性特征。此外，在同时考虑零件的几何变动与物理因素时，映射关系会变得更为繁杂，不能将其简单视为多源误差的线性传递过程。\n从尺寸链、影响系数法到状态空间模型，常规装配偏差传递方法在几何定位和静态物理分析上各具优势，却因刚性假设或线性叠加限制，对多源非线性耦合的装配偏差场描述不足。有限元法虽能捕捉非线性物理效应，却在计算效率上难以实现秒级响应。由此可见，亟需一种兼顾几何-物理复合建模精度与快速响应能力的端到端预测框架，以支持高精度装配公差的动态决策与闭环优化。\n",
    "reference_list": "考点1：“工艺和拓扑相关曲面模型” 推荐翻译为“Technologically and topologically related surfaces, TTRS”；\n考点2：“公差映射图模型” 必须译为“Tolerance-Map models”；\n考点3：“雅可比-旋量模型” 必须译为“Jacobian-Torsor models”；\n考点4：“碳纤维增强型复合材料” 必须译为“Carbon Fiber Reinforced Plastics, CFRP”；\n考点5：“零件-组件-部件” 推荐翻译为“part-level -> sub-assembly-level -> component-level”；\n考点6：“尺寸链”推荐翻译为“dimension chain”；\n考点7：“确定性装配”推荐翻译为“determinant assembly”；\n考点8：“有限元法”推荐翻译为“Finite Element Method ,FEM”；\n考点9：“影响系数法”必须译为“Method of Influence Coefficients,MIC”；",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "119"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThis review evaluates the paper \"A Self-Aligned Elevated Source/Drain MOSFET\", which presents an innovative CMOS fabrication process featuring self-aligned lightly doped drain (LDD) and channel implantation. The proposed method simplifies the manufacturing process by using a single selective silicon deposition step to define both the epitaxial source/drain and polycrystalline gate regions. The process demonstrates excellent short-channel device characteristics, reduced leakage currents, and minimal series resistance, making it suitable for high-performance submicron CMOS applications. While the paper is well-structured and provides comprehensive experimental validation, it lacks a detailed discussion on limitations, scalability to smaller technology nodes, and long-term reliability. A deeper exploration of comparative benchmarks and integration with emerging CMOS technologies would enhance its impact. Overall, the work offers valuable insights into addressing fabrication challenges in advanced semiconductor devices.\nThe paper \"A Self-Aligned Elevated Source/Drain MOSFET\" presents an innovative fabrication process for MOSFET devices that integrates elevated source/drain (ESD) structures with self-aligned lightly doped drain (LDD) and channel implantation. This process is distinguished by its use of a single selective silicon deposition step to simultaneously define the epitaxial source/drain and polycrystalline gate regions, streamlining fabrication and reducing complexity compared to conventional methods. A single sidewall spacer is employed to achieve both LDD and salicide definition, ensuring precise alignment of the LDD regions with heavily doped channel regions, thereby minimizing dopant compensation effects that typically degrade device performance.\nThe authors provide a detailed description of the process, supported by experimental results and SEM photomicrographs. The fabricated devices exhibit excellent short-channel behavior, low junction leakage, and minimal series resistance, making them suitable for high-performance submicron CMOS applications. Electrical characteristics, such as threshold voltage, subthreshold slope, and I-V behavior, are comparable to or better than conventional MOSFETs. The paper highlights the advantages of this approach, including its ability to simplify the manufacturing process while improving device performance and reducing leakage currents.\nThe authors conclude that their self-aligned elevated source/drain MOSFET process is an effective solution to the challenges posed by short-channel effects in submicron CMOS technology. This work provides a significant contribution to semiconductor device fabrication by demonstrating how innovative process integration can enhance performance while addressing practical manufacturing concerns.\nThe paper introduces a novel and streamlined fabrication process for MOSFETs, leveraging a single selective silicon deposition step to simultaneously define the source/drain and gate regions. This integration reduces the number of processing steps compared to conventional elevated source/drain (ESD) methods, which typically require separate deposition for the gate and source/drain. By doing so, the proposed approach not only simplifies the fabrication process but also minimizes alignment errors between different regions, which can be a major source of device variability. Furthermore, the self-alignment of the lightly doped drain (LDD) regions with heavily doped channel regions eliminates dopant compensation effects, a common issue that degrades device performance. This innovative integration demonstrates a profound understanding of the challenges in advanced CMOS technology and proposes an effective, scalable solution.\nThe paper emphasizes the superior electrical characteristics of the proposed MOSFET design. The devices fabricated using this process exhibit:\nExcellent short-channel behavior, with low leakage currents and reduced short-channel effects.\nHigh threshold voltage stability, supported by a well-optimized channel implantation process.\nMinimal series resistance, achieved by confining source/drain implant damage to the elevated epitaxial silicon region and employing salicidation.\nThese results suggest that the process can effectively address the challenges of submicron CMOS technology, which are critical for achieving high performance in modern electronics. The experimental data validate these claims, with measurable improvements in subthreshold slopes, I-V characteristics, and junction leakage over conventional designs.\nThe proposed process is highly relevant to the semiconductor industry, as it directly addresses the key challenges in submicron CMOS technology, such as short-channel effects, leakage currents, and scalability. The integration of elevated source/drain structures with self-aligned LDD and channel implantation not only enhances device performance but also simplifies the back-end metallization process. This streamlined approach could potentially reduce manufacturing costs and increase production yield, making it attractive for industrial adoption. Furthermore, the process is compatible with existing CMOS fabrication techniques, which ensures feasibility for large-scale implementation without requiring extensive modifications to current manufacturing infrastructure.\nThe authors support their claims with extensive experimental evidence, including:\nSEM photomicrographs, which visually confirm the precise definition of device structures and the integrity of the fabrication process.\nElectrical measurements, such as threshold voltage, subthreshold slope, and leakage currents, which provide quantitative validation of the device’s performance.\nProcess flow diagrams, which offer clarity and transparency about the fabrication steps.\nThis level of detail not only enhances the credibility of the proposed method but also provides valuable insights for other researchers or engineers seeking to replicate or build upon the work.\nThe process design prioritizes simplicity and scalability, addressing the need for manufacturing efficiency in advanced CMOS technology. The use of a single selective silicon deposition step and a single sidewall spacer to define both LDD and salicide regions reduces process complexity, which is critical for maintaining high yields in semiconductor fabrication. The elimination of additional deposition steps for separate regions minimizes potential misalignments and improves device reliability. These features make the process inherently scalable for submicron nodes, laying the groundwork for its applicability in the rapidly advancing semiconductor industry.\nThe paper is a significant contribution to the field of semiconductor fabrication, presenting a highly innovative and practically viable solution to the challenges in submicron CMOS technology. Its emphasis on performance improvement, manufacturing simplicity, and industry relevance ensures its applicability in both academic research and industrial settings. By addressing critical issues like short-channel effects and leakage currents, the work provides a pathway for advancing CMOS technology into the next generation of high-performance, low-power electronics.\nThe paper presents a well-structured and innovative fabrication process, but there are several areas where it could improve to provide a more comprehensive and impactful contribution.\nFirstly, while the proposed process appears effective, the paper lacks a thorough discussion of its potential limitations or challenges. Manufacturing processes in the semiconductor industry often face hurdles such as yield issues, which can significantly affect the economic viability of a new approach. The authors could have addressed whether their method might encounter problems in maintaining high yields, especially given the complexity of selective silicon deposition. Similarly, scalability to mass production is critical for any fabrication technique, and a discussion on how this process might perform under industrial-scale conditions is notably absent. Moreover, as modern CMOS technologies increasingly adopt high-k/metal gate (HKMG) stacks for enhanced performance at smaller nodes, it is unclear whether the proposed process is compatible with such advanced materials and architectures. Addressing these aspects would have provided a more balanced and practical perspective on the applicability of their approach.\nSecondly, the paper’s claims of superior performance could be strengthened with a more rigorous comparative analysis. While the authors highlight the advantages of their process, they do not provide detailed quantitative benchmarks against competing technologies. For instance, direct comparisons of parameters such as leakage current, threshold voltage stability, or process variability with conventional elevated source/drain methods would have offered stronger evidence of the process's relative benefits. Without such comparisons, it is challenging to assess the true significance of the proposed innovation in the broader context of semiconductor fabrication.\nAnother area for improvement is the lack of discussion on the long-term reliability of the devices fabricated using this process. Semiconductor devices are subject to various reliability challenges over time, such as thermal stability, stress-induced degradation, and process-induced variability. For instance, the thermal conditions used during the selective silicon deposition and salicidation steps could introduce stress or defects that affect the device's performance over extended periods. The authors do not address whether these factors have been considered or how they might impact the practical adoption of the technology. Including such an analysis would have enhanced the paper’s credibility and provided valuable insights into the robustness of the proposed approach.\nFinally, while the paper focuses on submicron dimensions, it does not explore the scalability of the process to more advanced nodes, such as those below 45 nm. As the industry continues to push towards smaller feature sizes, it is crucial to evaluate whether the process can maintain its advantages under the constraints of extreme miniaturization. Challenges such as increased variability, higher leakage, and the need for even more precise alignment could affect the applicability of this method. A discussion on how the process could be adapted or extended for future nodes would have made the paper more forward-looking and aligned with the ongoing trends in semiconductor technology.\nIn conclusion, while the paper makes a significant contribution by proposing an innovative and practical fabrication process, it could benefit from a deeper exploration of its challenges, comparative performance, long-term reliability, and scalability. Addressing these areas would not only strengthen the work but also provide a clearer roadmap for its integration into future CMOS technologies.\nThe paper presents an innovative and streamlined fabrication process for elevated source/drain MOSFETs, integrating a single selective silicon deposition step to define both source/drain and gate regions. This approach simplifies manufacturing, reduces alignment errors, and mitigates dopant compensation effects, leading to improved short-channel behavior, low leakage currents, and minimal series resistance. Supported by detailed experimental data and SEM imaging, the paper demonstrates strong technical innovation and practical relevance.\nHowever, the work has some notable gaps. It lacks a thorough discussion of potential challenges, such as yield issues and scalability to industrial-scale production. Comparisons with existing technologies are insufficient, with limited quantitative benchmarks to substantiate claims of superior performance. Furthermore, the paper does not address the long-term reliability of the devices or their compatibility with advanced materials and smaller nodes, critical for modern CMOS scaling.\nOverall, while the paper is a significant contribution with a well-supported methodology, a deeper exploration of these limitations would enhance its practical impact and relevance to advancing semiconductor technologies.\n",
    "ori_text": "\n\nThis review evaluates the paper \"A Self-Aligned Elevated Source/Drain MOSFET\", which presents an innovative CMOS fabrication process featuring self-aligned lightly doped drain (LDD) and channel implantation. The proposed method simplifies the manufacturing process by using a single selective silicon deposition step to define both the epitaxial source/drain and polycrystalline gate regions. The process demonstrates excellent short-channel device characteristics, reduced leakage currents, and minimal series resistance, making it suitable for high-performance submicron CMOS applications. While the paper is well-structured and provides comprehensive experimental validation, it lacks a detailed discussion on limitations, scalability to smaller technology nodes, and long-term reliability. A deeper exploration of comparative benchmarks and integration with emerging CMOS technologies would enhance its impact. Overall, the work offers valuable insights into addressing fabrication challenges in advanced semiconductor devices.\nThe paper \"A Self-Aligned Elevated Source/Drain MOSFET\" presents an innovative fabrication process for MOSFET devices that integrates elevated source/drain (ESD) structures with self-aligned lightly doped drain (LDD) and channel implantation. This process is distinguished by its use of a single selective silicon deposition step to simultaneously define the epitaxial source/drain and polycrystalline gate regions, streamlining fabrication and reducing complexity compared to conventional methods. A single sidewall spacer is employed to achieve both LDD and salicide definition, ensuring precise alignment of the LDD regions with heavily doped channel regions, thereby minimizing dopant compensation effects that typically degrade device performance.\nThe authors provide a detailed description of the process, supported by experimental results and SEM photomicrographs. The fabricated devices exhibit excellent short-channel behavior, low junction leakage, and minimal series resistance, making them suitable for high-performance submicron CMOS applications. Electrical characteristics, such as threshold voltage, subthreshold slope, and I-V behavior, are comparable to or better than conventional MOSFETs. The paper highlights the advantages of this approach, including its ability to simplify the manufacturing process while improving device performance and reducing leakage currents.\nThe authors conclude that their self-aligned elevated source/drain MOSFET process is an effective solution to the challenges posed by short-channel effects in submicron CMOS technology. This work provides a significant contribution to semiconductor device fabrication by demonstrating how innovative process integration can enhance performance while addressing practical manufacturing concerns.\nThe paper introduces a novel and streamlined fabrication process for MOSFETs, leveraging a single selective silicon deposition step to simultaneously define the source/drain and gate regions. This integration reduces the number of processing steps compared to conventional elevated source/drain (ESD) methods, which typically require separate deposition for the gate and source/drain. By doing so, the proposed approach not only simplifies the fabrication process but also minimizes alignment errors between different regions, which can be a major source of device variability. Furthermore, the self-alignment of the lightly doped drain (LDD) regions with heavily doped channel regions eliminates dopant compensation effects, a common issue that degrades device performance. This innovative integration demonstrates a profound understanding of the challenges in advanced CMOS technology and proposes an effective, scalable solution.\nThe paper emphasizes the superior electrical characteristics of the proposed MOSFET design. The devices fabricated using this process exhibit:\nExcellent short-channel behavior, with low leakage currents and reduced short-channel effects.\nHigh threshold voltage stability, supported by a well-optimized channel implantation process.\nMinimal series resistance, achieved by confining source/drain implant damage to the elevated epitaxial silicon region and employing salicidation.\nThese results suggest that the process can effectively address the challenges of submicron CMOS technology, which are critical for achieving high performance in modern electronics. The experimental data validate these claims, with measurable improvements in subthreshold slopes, I-V characteristics, and junction leakage over conventional designs.\nThe proposed process is highly relevant to the semiconductor industry, as it directly addresses the key challenges in submicron CMOS technology, such as short-channel effects, leakage currents, and scalability. The integration of elevated source/drain structures with self-aligned LDD and channel implantation not only enhances device performance but also simplifies the back-end metallization process. This streamlined approach could potentially reduce manufacturing costs and increase production yield, making it attractive for industrial adoption. Furthermore, the process is compatible with existing CMOS fabrication techniques, which ensures feasibility for large-scale implementation without requiring extensive modifications to current manufacturing infrastructure.\nThe authors support their claims with extensive experimental evidence, including:\nSEM photomicrographs, which visually confirm the precise definition of device structures and the integrity of the fabrication process.\nElectrical measurements, such as threshold voltage, subthreshold slope, and leakage currents, which provide quantitative validation of the device’s performance.\nProcess flow diagrams, which offer clarity and transparency about the fabrication steps.\nThis level of detail not only enhances the credibility of the proposed method but also provides valuable insights for other researchers or engineers seeking to replicate or build upon the work.\nThe process design prioritizes simplicity and scalability, addressing the need for manufacturing efficiency in advanced CMOS technology. The use of a single selective silicon deposition step and a single sidewall spacer to define both LDD and salicide regions reduces process complexity, which is critical for maintaining high yields in semiconductor fabrication. The elimination of additional deposition steps for separate regions minimizes potential misalignments and improves device reliability. These features make the process inherently scalable for submicron nodes, laying the groundwork for its applicability in the rapidly advancing semiconductor industry.\nThe paper is a significant contribution to the field of semiconductor fabrication, presenting a highly innovative and practically viable solution to the challenges in submicron CMOS technology. Its emphasis on performance improvement, manufacturing simplicity, and industry relevance ensures its applicability in both academic research and industrial settings. By addressing critical issues like short-channel effects and leakage currents, the work provides a pathway for advancing CMOS technology into the next generation of high-performance, low-power electronics.\nThe paper presents a well-structured and innovative fabrication process, but there are several areas where it could improve to provide a more comprehensive and impactful contribution.\nFirstly, while the proposed process appears effective, the paper lacks a thorough discussion of its potential limitations or challenges. Manufacturing processes in the semiconductor industry often face hurdles such as yield issues, which can significantly affect the economic viability of a new approach. The authors could have addressed whether their method might encounter problems in maintaining high yields, especially given the complexity of selective silicon deposition. Similarly, scalability to mass production is critical for any fabrication technique, and a discussion on how this process might perform under industrial-scale conditions is notably absent. Moreover, as modern CMOS technologies increasingly adopt high-k/metal gate (HKMG) stacks for enhanced performance at smaller nodes, it is unclear whether the proposed process is compatible with such advanced materials and architectures. Addressing these aspects would have provided a more balanced and practical perspective on the applicability of their approach.\nSecondly, the paper’s claims of superior performance could be strengthened with a more rigorous comparative analysis. While the authors highlight the advantages of their process, they do not provide detailed quantitative benchmarks against competing technologies. For instance, direct comparisons of parameters such as leakage current, threshold voltage stability, or process variability with conventional elevated source/drain methods would have offered stronger evidence of the process's relative benefits. Without such comparisons, it is challenging to assess the true significance of the proposed innovation in the broader context of semiconductor fabrication.\nAnother area for improvement is the lack of discussion on the long-term reliability of the devices fabricated using this process. Semiconductor devices are subject to various reliability challenges over time, such as thermal stability, stress-induced degradation, and process-induced variability. For instance, the thermal conditions used during the selective silicon deposition and salicidation steps could introduce stress or defects that affect the device's performance over extended periods. The authors do not address whether these factors have been considered or how they might impact the practical adoption of the technology. Including such an analysis would have enhanced the paper’s credibility and provided valuable insights into the robustness of the proposed approach.\nFinally, while the paper focuses on submicron dimensions, it does not explore the scalability of the process to more advanced nodes, such as those below 45 nm. As the industry continues to push towards smaller feature sizes, it is crucial to evaluate whether the process can maintain its advantages under the constraints of extreme miniaturization. Challenges such as increased variability, higher leakage, and the need for even more precise alignment could affect the applicability of this method. A discussion on how the process could be adapted or extended for future nodes would have made the paper more forward-looking and aligned with the ongoing trends in semiconductor technology.\nIn conclusion, while the paper makes a significant contribution by proposing an innovative and practical fabrication process, it could benefit from a deeper exploration of its challenges, comparative performance, long-term reliability, and scalability. Addressing these areas would not only strengthen the work but also provide a clearer roadmap for its integration into future CMOS technologies.\nThe paper presents an innovative and streamlined fabrication process for elevated source/drain MOSFETs, integrating a single selective silicon deposition step to define both source/drain and gate regions. This approach simplifies manufacturing, reduces alignment errors, and mitigates dopant compensation effects, leading to improved short-channel behavior, low leakage currents, and minimal series resistance. Supported by detailed experimental data and SEM imaging, the paper demonstrates strong technical innovation and practical relevance.\nHowever, the work has some notable gaps. It lacks a thorough discussion of potential challenges, such as yield issues and scalability to industrial-scale production. Comparisons with existing technologies are insufficient, with limited quantitative benchmarks to substantiate claims of superior performance. Furthermore, the paper does not address the long-term reliability of the devices or their compatibility with advanced materials and smaller nodes, critical for modern CMOS scaling.\nOverall, while the paper is a significant contribution with a well-supported methodology, a deeper exploration of these limitations would enhance its practical impact and relevance to advancing semiconductor technologies.\n",
    "reference_list": "考点1：“self‑aligned elevated source/drain MOSFET”推荐译为“自对准抬高源/漏MOSFET”\n考点2：“elevated source/drain; elevated S/D; ESD (structure)”推荐译为“抬高源/漏（ESD）”\n考点3：“polycrystalline gate; polysilicon gate”推荐译为“多晶硅栅极”\n考点4：“single sidewall spacer; sidewall spacer”推荐译为“单侧墙间隔层（spacer）”\n考5：“subthreshold slope; subthreshold swing (SS)”推荐译为“次阈值摆幅（SS）”\n考点6：“I–V characteristics; I–V behavior”推荐译为“I–V特性”\n考点7：“selective epitaxy; selective silicon epitaxy”推荐译为“选择性外延”\n考点8：“device variability; device‑to‑device variation”推荐译为“器件离散性”\n考点9：“comparative benchmarks; benchmark comparisons”推荐译为“基准对比”\n考点10：“salicide definition”推荐译为“硅化区域形貌”\n考点11：“heavily doped source/drain; heavily doped extensions”推荐译为“重掺杂源/漏（扩展区）”\n考点12：“industrial adoption”推荐译为“产业化采用”\n考点13：“emerging CMOS technologies”推荐译为“新兴CMOS技术”\n考点14:   “CMOS fabrication process”推荐译为“CMOS制造工艺”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "169"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n学问与趣味\n\n前辈的学者常以学问的趣味启迪后生，因为他们自己实在是得到了学问的趣味，故不惜现身说法，诱导后学，使他们也在愉快的心情之下走进学问的大门。例如，梁任公先生就说过：“我是个主张趣味主义的人，倘若用化学化分‘梁启超’这件东西，把里头所含一种原素名叫‘趣味’的抽出来，只怕所剩下的仅有个零了。”任公先生注重趣味，学问甚是渊博，而并不存有任何外在的动机，只是“无所为而为”，故能有他那样的成就。一个人在学问上果能感觉到趣味，有时真会像是着了魔一般，真能废寝忘食，真能不知老之将至，苦苦钻研，锲而不舍，在学问上焉能不有收获？不过我尝想，以任公先生而论，他后期的著述如历史研究法，先秦政治思想史，以及有关墨子佛学陶渊明的作品，都可说是他的一点“趣味”在驱使着他，可是在他在年青的时候，从师受业，诵读典籍，那时节也全然是趣味么？作八股文，作试帖诗，莫非也是趣味么？我想未必。大概趣味云云，是指年长之后自动作学问之时而言，在年青时候为学问打根底之际恐怕不能过分重视趣味。学问没有根底，趣味也很难滋生。任公先生的学问之所以那样的博大精深，涉笔成趣，左右逢源，不能不说的一大部分得力于他的学问根底之打得坚固。\n\n我尝见许多年青的朋友，聪明用功，成绩优异，而语文程度不足以达意，甚至写一封信亦难得通顺，问其故则曰其兴趣不在语文方面。又有一些位，执笔为文，斐然可诵，而视数理科目如仇讐，勉强才能及格，问其故则亦曰其兴趣不在数理方面，而且他们觉得某些科目没有趣味，便撇在一旁视如敝屣，怡然自得，振振有词，略无愧色，好像兴趣是最后的惟一的凭藉。这种态度的错误是很显然的。一个人在学校里，在求学的期间，应该奠定知识的根基。所谓根基，就是指普通的、基本的知识。在中学里，国文、英文、数学、物理、化学、史地、生物，都是人人应具备的基本知识。我们虽然不能个个都成为数学家、物理学家、化学家，但是我们不可不具备数学、物理、化学的基本知识，否则我们便不配做现代的公民。这些基本学科，我们必须在学校里专心学习，由教师的督责，由功课的压力，乃至由考试的强制，我们虽不情愿也须得接受。这些学科里面自然也有趣味，不过初学的人不能立刻发现，非下很多的苦功不能领略。我们这时候的求学，不是为趣味，而是为知识，为日后能体验趣味之时的准备。我们应该暂且把趣味压在下面，靠纪律把根基打好。没有纪律，光讲趣味，免不了要走向浅薄的路。并且，一个人在少年时代，兴趣还没有定型，若说对于某种功课没有兴趣，那常是无稽之谈，不可以为训的。其所以提不起兴趣，大半是由于懒。真确的兴趣，不是凭空可以发生的，是要由对该事物的深刻的认识和明了的理解为基础。一知半解，便谈不到趣味。譬如学画，必先由用笔用墨的基本方法学起，必先经过一个“格物”的阶段，等到对于形象色彩线条等等有了相当的认识，对于挥毫染翰有了相当的经验，那时候才能体会到画中的三昧，才能感到趣味。若仅是浅尝辄止，甚至躐等躁进，当然味同嚼蜡，自讨没趣。一个有中上天资的人，对于普通的、基本的文理科目，都同样的有学习的能力，绝不会本能的长于此而拙于彼。只有懒惰与任性，才能使一个人自甘暴弃的在“趣味”的掩护之下败退。\n\n由小学到中学，所修习的无非是一些普通的基本知识。就是大学四年，所授课业也还是相当粗浅的学识。世人常称大学为“最高学府”，这名称易滋误解，好像过此以上即无学问可言。大学的研究所才是初步研究学问的所在，在这里作学问也只能算是粗涉藩篱，注重的是研究学问的方法与实习。学无止境，一生的时间都嫌太短，所以古人皓首穷经，头发白了还是在继续研究，不过在这样的研究中确是有浓厚的趣味。\n\n在初学的阶段，由小学至大学，我们与其倡言趣味，不如偏重纪律。一个合理编列的课程表，犹如一个营养均衡的食谱，里面各个项目都是有益而必需的，不可偏废，不可再有选择。所谓选修科目也只是在某一项目范围内略有拣选余地而已。一个受过良好教育的人，犹如一个科班出身的戏剧演员，在坐科的时候他是要服从严格纪律的，唱念做打武把子都要认真学习，各种脚色的戏都要完全谙通，学成之后才能各按其趣味而单独发展其所长。学问要有根底，根底要打得平正坚实，以后永远受用。初学阶段的科目之最重要的莫过于语文与数学。语文是阅读达意的工具，国文不通便很难表达自己，外国文不通便很难吸取外来的新知。数学是思想条理之最好的训练。其他科目也各有各的用处，其重要性很难强分轩轾，例如体育，从另一方面看也是重要得无以复加。总之，我们在求学时代，应该暂且把趣味放在一旁，耐着性子接受教育的纪律，把自己锻炼成为坚实的材料。学问的趣味，留在将来慢慢享受一点也不迟。",
    "ori_text": "\n\n学问与趣味\n\n前辈的学者常以学问的趣味启迪后生，因为他们自己实在是得到了学问的趣味，故不惜现身说法，诱导后学，使他们也在愉快的心情之下走进学问的大门。例如，梁任公先生就说过：“我是个主张趣味主义的人，倘若用化学化分‘梁启超’这件东西，把里头所含一种原素名叫‘趣味’的抽出来，只怕所剩下的仅有个零了。”任公先生注重趣味，学问甚是渊博，而并不存有任何外在的动机，只是“无所为而为”，故能有他那样的成就。一个人在学问上果能感觉到趣味，有时真会像是着了魔一般，真能废寝忘食，真能不知老之将至，苦苦钻研，锲而不舍，在学问上焉能不有收获？不过我尝想，以任公先生而论，他后期的著述如历史研究法，先秦政治思想史，以及有关墨子佛学陶渊明的作品，都可说是他的一点“趣味”在驱使着他，可是在他在年青的时候，从师受业，诵读典籍，那时节也全然是趣味么？作八股文，作试帖诗，莫非也是趣味么？我想未必。大概趣味云云，是指年长之后自动作学问之时而言，在年青时候为学问打根底之际恐怕不能过分重视趣味。学问没有根底，趣味也很难滋生。任公先生的学问之所以那样的博大精深，涉笔成趣，左右逢源，不能不说的一大部分得力于他的学问根底之打得坚固。\n\n我尝见许多年青的朋友，聪明用功，成绩优异，而语文程度不足以达意，甚至写一封信亦难得通顺，问其故则曰其兴趣不在语文方面。又有一些位，执笔为文，斐然可诵，而视数理科目如仇讐，勉强才能及格，问其故则亦曰其兴趣不在数理方面，而且他们觉得某些科目没有趣味，便撇在一旁视如敝屣，怡然自得，振振有词，略无愧色，好像兴趣是最后的惟一的凭藉。这种态度的错误是很显然的。一个人在学校里，在求学的期间，应该奠定知识的根基。所谓根基，就是指普通的、基本的知识。在中学里，国文、英文、数学、物理、化学、史地、生物，都是人人应具备的基本知识。我们虽然不能个个都成为数学家、物理学家、化学家，但是我们不可不具备数学、物理、化学的基本知识，否则我们便不配做现代的公民。这些基本学科，我们必须在学校里专心学习，由教师的督责，由功课的压力，乃至由考试的强制，我们虽不情愿也须得接受。这些学科里面自然也有趣味，不过初学的人不能立刻发现，非下很多的苦功不能领略。我们这时候的求学，不是为趣味，而是为知识，为日后能体验趣味之时的准备。我们应该暂且把趣味压在下面，靠纪律把根基打好。没有纪律，光讲趣味，免不了要走向浅薄的路。并且，一个人在少年时代，兴趣还没有定型，若说对于某种功课没有兴趣，那常是无稽之谈，不可以为训的。其所以提不起兴趣，大半是由于懒。真确的兴趣，不是凭空可以发生的，是要由对该事物的深刻的认识和明了的理解为基础。一知半解，便谈不到趣味。譬如学画，必先由用笔用墨的基本方法学起，必先经过一个“格物”的阶段，等到对于形象色彩线条等等有了相当的认识，对于挥毫染翰有了相当的经验，那时候才能体会到画中的三昧，才能感到趣味。若仅是浅尝辄止，甚至躐等躁进，当然味同嚼蜡，自讨没趣。一个有中上天资的人，对于普通的、基本的文理科目，都同样的有学习的能力，绝不会本能的长于此而拙于彼。只有懒惰与任性，才能使一个人自甘暴弃的在“趣味”的掩护之下败退。\n\n由小学到中学，所修习的无非是一些普通的基本知识。就是大学四年，所授课业也还是相当粗浅的学识。世人常称大学为“最高学府”，这名称易滋误解，好像过此以上即无学问可言。大学的研究所才是初步研究学问的所在，在这里作学问也只能算是粗涉藩篱，注重的是研究学问的方法与实习。学无止境，一生的时间都嫌太短，所以古人皓首穷经，头发白了还是在继续研究，不过在这样的研究中确是有浓厚的趣味。\n\n在初学的阶段，由小学至大学，我们与其倡言趣味，不如偏重纪律。一个合理编列的课程表，犹如一个营养均衡的食谱，里面各个项目都是有益而必需的，不可偏废，不可再有选择。所谓选修科目也只是在某一项目范围内略有拣选余地而已。一个受过良好教育的人，犹如一个科班出身的戏剧演员，在坐科的时候他是要服从严格纪律的，唱念做打武把子都要认真学习，各种脚色的戏都要完全谙通，学成之后才能各按其趣味而单独发展其所长。学问要有根底，根底要打得平正坚实，以后永远受用。初学阶段的科目之最重要的莫过于语文与数学。语文是阅读达意的工具，国文不通便很难表达自己，外国文不通便很难吸取外来的新知。数学是思想条理之最好的训练。其他科目也各有各的用处，其重要性很难强分轩轾，例如体育，从另一方面看也是重要得无以复加。总之，我们在求学时代，应该暂且把趣味放在一旁，耐着性子接受教育的纪律，把自己锻炼成为坚实的材料。学问的趣味，留在将来慢慢享受一点也不迟。",
    "reference_list": "考点1.“涉笔成趣，左右逢源”推荐译为effortless and resourceful creativity或类似的表达如 writing with flair and finding inspiration at every turn。\n考点2.“浅尝辄止，甚至躐等躁进，当然味同嚼蜡”中，“浅尝辄止”、“躐等躁进”、“味同嚼蜡”三个成语，推荐译为merely scratching the surface, or even rashly skipping steps, will naturally feel as dull as chewing wax。\n考点3.“所以古人皓首穷经，头发白了还是在继续研究”中的“皓首穷经”推荐译为 spend one's entire life studying the classics, even until one's hair turns white 。\n考点4.“所谓选修科目也只是在某一项目范围内略有拣选余地而已”中的“拣选余地”是一个关键的翻译点，直接翻译成 slight choices 较为生硬，更优的翻译如 room for choice 或 leeway for selection。\n考点5.“否则我们便不配做现代的公民”中的“公民”是一个内涵广阔的社会学概念，不可译为“literates”（识字的人）。\n考点6.“必先经过一个‘格物’的阶段”中的“格物”推荐译为investigate things to acquire knowledge，不可译为subject yourself to discipline。\n考点7. “一个有中上天资的人”不可译为“An ordinary talented person”（一个普通有才华的人），推荐译为a person of above-average talent。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "186"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n1、乳腺癌组织学分型\n目前，乳腺癌的病理学诊断已从形态学结合免疫组化发展为形态学-免疫组化分子生物学特征相结合。精准的组织学分型对患者的预后判断、治疗决策有重要指导作用。如大部分三阴性乳腺癌(tiple-negative breast cancer，TNBC)恶性程度高\n预后差，但也有一些低度恶性的TNBC生物学行为相对惰性，如分泌性癌、低级别腺鳞疡、纤维瘤病样梭形细胞癌、经典型腺样性癌等。对这部分低度恶性的TNBC除非有病理学检查证实的淋巴结转移，否则无需给予全身治疗。某些组织学类型的准确区分需行免疫组织化学和(或)分子病理学检测后确定部分组织学类型的乳腺癌具有独特的分子生物学特征，例如分泌性癌常伴有ETV6-NTRK3基因重排、经典型腺样囊性癌常有MYB-NFIB重排、低级别黏液表皮样癌常有 CRTC1-MAML2重排、极性翻转的高细胞癌常伴有IDH2基因突变\n\n2、乳腺癌组织学分级\n组织学分级是重要的预后因素。推荐采用Nottingham分级系统对浸润性乳腺癌进行组织学分级。根据腺管形成的比例、核异型性和核分裂象计数三项指标分别独立评估，各给予1~3分，相加后根据总分将浸润性癌分为I级、Ⅱ级、亚级三个级别。腺管分化程度的评估针对整个肿瘤，需要在低倍镜下评估。只计数有明确中央腺腔且由有极向肿瘤细胞包绕的结构，以腺管/肿瘤区域的百分比表示。细胞核多形性的评估要选取多形性最显著的区域。该项评估参考周围正常乳腺上皮细胞的细胞核大小、形状和核仁大小。当周边缺乏正常细胞时，可用淋巴细胞作为参照。当细胞核与周围正常上皮细胞的大小和形状相似、染色质均匀分布时，视为1分;当细胞该比正常细胞大，形状和大小有中等程度差异，可见单个核仁时，视为2分;当细胞核的大小有显著差异，核仁显著，可见多个核仁时应视为3分。只计数明确的核分裂象，不计数核浓染和核碎屑。核分裂象计数区域必须根据显微镜高倍视野的直径进行校正。核分裂象计数要选取增殖最活跃的区域，一般常见于肿瘤边缘，如果存在异质性，应选择核分裂象多的区域\n\n3、乳腺癌的分期\n包括传统的解剖学分期和预后分期。解剖学分期包括肿瘤的大小、累及范围(皮肤和胸壁受累情况)、淋巴结转移和远处转移情况。肿瘤大小的测量有多种方法，包括临床体检、影像学评估、病理大体测量和显微镜下测量。乳腺癌分期中涉及的肿瘤大小是指浸润癌的大小。由于体检、影像学及大体检查均无法区分浸润性癌和DCIS，因此显微镜下测量应该是最准确的测量方式。如果浸润性癌范围较大，无法用一个蜡块全部包埋，则以巨检时的肿瘤大小为准。若浸润性癌病灶局限，可以用一个蜡块全部包埋，肿瘤大小以显微镜下测量的尺寸为准。\n(1)如果肿瘤组织中有浸润性癌和原位癌两种成分，肿瘤的大小应以浸润性成分的测量值为准。\n(2)原位癌伴微浸润:出现微浸润时，应在报告中注明，并测量微浸润灶最大径;如为多灶微浸润，浸润灶大小不累加，需在报告中注明为多灶微浸润，并测量最大浸润灶的最大径\n(3)对肉眼能确定的发生于同一象限的两个以上多发性肿瘤病灶，应在病理学检查报告中注明为多灶性肿瘤，并分别测量大小，以最大浸润病灶作为分期依据。\n(4)对肉眼能确定的发生于不同象限的两个以上肿瘤病灶，应在病理学检查报告中注明为多中心性肿瘤，并分别测量大小。\n(5)如果肿瘤组织完全由DCIS组成，应尽量测量其范围。淋巴结状态是决定彩腺癌患者治疗和预后的重要因素，要特别仔细观察淋巴结的转移数目，从而做出准确的pN分期判断。预后分期是在传统解剖学分期基础上增加生物学信息，是解剖学分期的完善和补充\n\n4、乳腺癌免疫组化和分子病理学检测及其质量控制\n(1)应对所有乳腺浸润性癌病例进行雌激素受体、孕激素受体、人表皮生长因子受体2的免疫组化染色，HER2 2+病例应进一步行原位杂交检测。对DCIS也建议进行ER、PR及HER2免疫组织化学染色ER、PR的病理学报告需包含阳性细胞强度和百分比。ER、PR检测参考中国《乳腺癌雌、孕激素受体免疫组织化学检测指南(2015版)》(参见附录V-D)，ER/PR阳性定义:>1%的浸润性癌细胞呈阳性染色;当阳性细胞1%~10%时为ER/PR低表达HER2检测参考中国《乳腺癌HER2检测指南(2019版)》(附录V-E)。HER2免疫组织化学检测结果为IHC 1+或IHC 2+ЛISH无扩增的局部晚期/晚期乳腺癌患者也可能从 ADC药物治疗中获益。目前大多数研究将IHC 1+和IHC 2+ЛSH无扩增者定义为HER2低表达。随着循证医学证据的不断积累，此定义有可能会发生改变。以下几点建议也许有助于区分 IHC0和IHC 1+:① 严格按照指南标准进行判读。② 应在高倍(40x)镜下区分判读HER2 IHC0和1+。③ 对于IHCO/HC 1+临界值附近的病例，可考虑请第二位病理科医师进行判读。④建议采用不同梯度表达水平的外对照(包含IHC 1+)。⑤ 需关注检测前、检测中和检测后的全流程质控。\n(2)应对所有乳腺浸润性癌进行Ki-67增殖指数检测，并对癌细胞中阳性染色细胞所占的百分比进行报告。\n(3)PD-L1检测:目前临床研究中采用的PD-L1检测是一套完整的系统，包括抗体、检测平台和判读系统。目前TNBC中PD-L1检测常用的抗体为22C3(DAKO)\n判读采用CPS评分。报告中应标明检测平台、抗体克隆号及评分方式。CPS评分公式如下:\nPD-L1(DAKO22C3)CPS=PD-L1 阳性细胞数 (肿瘤细胞、淋巴细胞、巨噬细胞 ) 活的肿瘤细胞总数 x100 PD-L1(DAKO22C3)CPS=PD-L1 阳性细胞数 (肿瘤细胞、淋巴细胞、巨噬细胞 )活的肿瘤细胞总数 x100\n(4)可进行肿瘤浸润淋巴细胞报告。\n(5)开展乳腺癌免疫组织化学和分子病理学检测的实验室应建立完整有效的内部质量控制体系，具有合格资质的病理实验室应满足以下条件:①具备完善的标准操作程序，并严格遵照执行，做好每次检测情况的记录和存档工作。对同一组织不同批次染色结果开展重复性分析。检测相关的仪器和设备定期维护、校验。对于任何操作程序和试剂变化均重新进行严格的验证。②从事乳腺癌免疫组织化学和分子病理学检测的实验技术人员和病理学医师定期进行必要的培训、资格考核和能力评估。③ 实验室外部质控可通过参加有关外部质控活动来实现。外部质控的阳性符合率和阴性符合率达到90%以上。外部质控活动推荐每年参加1~2次。不具备检测条件的单位应妥善地保存好标本，以供具有相关资质的病理实验室进行检测",
    "ori_text": "\n\n1、乳腺癌组织学分型\n目前，乳腺癌的病理学诊断已从形态学结合免疫组化发展为形态学-免疫组化分子生物学特征相结合。精准的组织学分型对患者的预后判断、治疗决策有重要指导作用。如大部分三阴性乳腺癌(tiple-negative breast cancer，TNBC)恶性程度高\n预后差，但也有一些低度恶性的TNBC生物学行为相对惰性，如分泌性癌、低级别腺鳞疡、纤维瘤病样梭形细胞癌、经典型腺样性癌等。对这部分低度恶性的TNBC除非有病理学检查证实的淋巴结转移，否则无需给予全身治疗。某些组织学类型的准确区分需行免疫组织化学和(或)分子病理学检测后确定部分组织学类型的乳腺癌具有独特的分子生物学特征，例如分泌性癌常伴有ETV6-NTRK3基因重排、经典型腺样囊性癌常有MYB-NFIB重排、低级别黏液表皮样癌常有 CRTC1-MAML2重排、极性翻转的高细胞癌常伴有IDH2基因突变\n\n2、乳腺癌组织学分级\n组织学分级是重要的预后因素。推荐采用Nottingham分级系统对浸润性乳腺癌进行组织学分级。根据腺管形成的比例、核异型性和核分裂象计数三项指标分别独立评估，各给予1~3分，相加后根据总分将浸润性癌分为I级、Ⅱ级、亚级三个级别。腺管分化程度的评估针对整个肿瘤，需要在低倍镜下评估。只计数有明确中央腺腔且由有极向肿瘤细胞包绕的结构，以腺管/肿瘤区域的百分比表示。细胞核多形性的评估要选取多形性最显著的区域。该项评估参考周围正常乳腺上皮细胞的细胞核大小、形状和核仁大小。当周边缺乏正常细胞时，可用淋巴细胞作为参照。当细胞核与周围正常上皮细胞的大小和形状相似、染色质均匀分布时，视为1分;当细胞该比正常细胞大，形状和大小有中等程度差异，可见单个核仁时，视为2分;当细胞核的大小有显著差异，核仁显著，可见多个核仁时应视为3分。只计数明确的核分裂象，不计数核浓染和核碎屑。核分裂象计数区域必须根据显微镜高倍视野的直径进行校正。核分裂象计数要选取增殖最活跃的区域，一般常见于肿瘤边缘，如果存在异质性，应选择核分裂象多的区域\n\n3、乳腺癌的分期\n包括传统的解剖学分期和预后分期。解剖学分期包括肿瘤的大小、累及范围(皮肤和胸壁受累情况)、淋巴结转移和远处转移情况。肿瘤大小的测量有多种方法，包括临床体检、影像学评估、病理大体测量和显微镜下测量。乳腺癌分期中涉及的肿瘤大小是指浸润癌的大小。由于体检、影像学及大体检查均无法区分浸润性癌和DCIS，因此显微镜下测量应该是最准确的测量方式。如果浸润性癌范围较大，无法用一个蜡块全部包埋，则以巨检时的肿瘤大小为准。若浸润性癌病灶局限，可以用一个蜡块全部包埋，肿瘤大小以显微镜下测量的尺寸为准。\n(1)如果肿瘤组织中有浸润性癌和原位癌两种成分，肿瘤的大小应以浸润性成分的测量值为准。\n(2)原位癌伴微浸润:出现微浸润时，应在报告中注明，并测量微浸润灶最大径;如为多灶微浸润，浸润灶大小不累加，需在报告中注明为多灶微浸润，并测量最大浸润灶的最大径\n(3)对肉眼能确定的发生于同一象限的两个以上多发性肿瘤病灶，应在病理学检查报告中注明为多灶性肿瘤，并分别测量大小，以最大浸润病灶作为分期依据。\n(4)对肉眼能确定的发生于不同象限的两个以上肿瘤病灶，应在病理学检查报告中注明为多中心性肿瘤，并分别测量大小。\n(5)如果肿瘤组织完全由DCIS组成，应尽量测量其范围。淋巴结状态是决定彩腺癌患者治疗和预后的重要因素，要特别仔细观察淋巴结的转移数目，从而做出准确的pN分期判断。预后分期是在传统解剖学分期基础上增加生物学信息，是解剖学分期的完善和补充\n\n4、乳腺癌免疫组化和分子病理学检测及其质量控制\n(1)应对所有乳腺浸润性癌病例进行雌激素受体、孕激素受体、人表皮生长因子受体2的免疫组化染色，HER2 2+病例应进一步行原位杂交检测。对DCIS也建议进行ER、PR及HER2免疫组织化学染色ER、PR的病理学报告需包含阳性细胞强度和百分比。ER、PR检测参考中国《乳腺癌雌、孕激素受体免疫组织化学检测指南(2015版)》(参见附录V-D)，ER/PR阳性定义:>1%的浸润性癌细胞呈阳性染色;当阳性细胞1%~10%时为ER/PR低表达HER2检测参考中国《乳腺癌HER2检测指南(2019版)》(附录V-E)。HER2免疫组织化学检测结果为IHC 1+或IHC 2+ЛISH无扩增的局部晚期/晚期乳腺癌患者也可能从 ADC药物治疗中获益。目前大多数研究将IHC 1+和IHC 2+ЛSH无扩增者定义为HER2低表达。随着循证医学证据的不断积累，此定义有可能会发生改变。以下几点建议也许有助于区分 IHC0和IHC 1+:① 严格按照指南标准进行判读。② 应在高倍(40x)镜下区分判读HER2 IHC0和1+。③ 对于IHCO/HC 1+临界值附近的病例，可考虑请第二位病理科医师进行判读。④建议采用不同梯度表达水平的外对照(包含IHC 1+)。⑤ 需关注检测前、检测中和检测后的全流程质控。\n(2)应对所有乳腺浸润性癌进行Ki-67增殖指数检测，并对癌细胞中阳性染色细胞所占的百分比进行报告。\n(3)PD-L1检测:目前临床研究中采用的PD-L1检测是一套完整的系统，包括抗体、检测平台和判读系统。目前TNBC中PD-L1检测常用的抗体为22C3(DAKO)\n判读采用CPS评分。报告中应标明检测平台、抗体克隆号及评分方式。CPS评分公式如下:\nPD-L1(DAKO22C3)CPS=PD-L1 阳性细胞数 (肿瘤细胞、淋巴细胞、巨噬细胞 ) 活的肿瘤细胞总数 x100 PD-L1(DAKO22C3)CPS=PD-L1 阳性细胞数 (肿瘤细胞、淋巴细胞、巨噬细胞 )活的肿瘤细胞总数 x100\n(4)可进行肿瘤浸润淋巴细胞报告。\n(5)开展乳腺癌免疫组织化学和分子病理学检测的实验室应建立完整有效的内部质量控制体系，具有合格资质的病理实验室应满足以下条件:①具备完善的标准操作程序，并严格遵照执行，做好每次检测情况的记录和存档工作。对同一组织不同批次染色结果开展重复性分析。检测相关的仪器和设备定期维护、校验。对于任何操作程序和试剂变化均重新进行严格的验证。②从事乳腺癌免疫组织化学和分子病理学检测的实验技术人员和病理学医师定期进行必要的培训、资格考核和能力评估。③ 实验室外部质控可通过参加有关外部质控活动来实现。外部质控的阳性符合率和阴性符合率达到90%以上。外部质控活动推荐每年参加1~2次。不具备检测条件的单位应妥善地保存好标本，以供具有相关资质的病理实验室进行检测",
    "reference_list": "考点1：“组织学分型” 推荐译为 Histologic type 或 Histologic subtype，保持全文一致，不建议混用 Histological Classification 与 Histologic Typing，优先采用病理学常用形式。\n考点2：“生物学行为相对惰性” 推荐译为 Biologically indolent，避免用 vague 形容词，确保医学专业语境明确。\n考点3：“纤维瘤病样梭形细胞癌” 必须译为 Fibromatosis-like spindle cell carcinoma，病理标准译法，避免用 desmoid-type 以免与其他软组织病变混淆。\n考点4：“全身治疗” 必须译为 Systemic therapy，保持肿瘤学标准术语。\n考点5：“基因重排” 必须译为 Gene rearrangement，保持分子病理学常用表达。\n考点6：“组织学分级” 推荐译为 Histologic grade，注意与 Histological grading 区分，grade 指结果，grading 指过程。\n考点7：“HER2 2+病例” 推荐译为 Cases with a HER2 IHC 2+ result，避免仅用 HER2 2+ 以免语义模糊。\n考点8：“核浓染和核碎屑” 推荐译为 Pyknosis and karyorrhexis 或 Apoptotic bodies，使用病理学专用术语而非形态描述。“核碎屑” 对应 Karyorrhexis，避免泛化为 nuclear debris。\n考点9：“病理大体测量” 推荐译为 Gross pathologic measurement，注意 pathologic 与 pathological 均可但全文需统一。\n考点10：“多灶性肿瘤” 必须译为 Multifocal tumor（单复数根据语境调整）。\n考点11：“多中心性肿瘤” 必须译为 Multicentric tumor（单复数根据语境调整）。\n考点12：“肿瘤浸润淋巴细胞” 必须译为 Tumor-infiltrating lymphocytes（缩写 TILs 在首次出现时给全称）。\n考点13：“HER2低表达” 必须译为 HER2-low expression，连字符不可省略。\n考点14：“IHC 0/IHC 1+临界值” 推荐译为 IHC 0/IHC 1+ cutoff value，cutoff 需单词连写。\n考点15：“全流程质量控制” 推荐译为 Full-process quality control，或 Pre-analytical, analytical, and post-analytical QC。\n考点16：“PD-L1检测” 推荐译为 PD-L1 testing，避免混用 detection。\n考点17：“综合阳性评分” 必须译为 Combined Positive Score（CPS），首次出现给出全称与缩写。\n考点18：“肿瘤细胞、淋巴细胞、巨噬细胞” 推荐译为 Tumor cells, lymphocytes, and macrophages，保持三类细胞顺序与原文一致。\n考点19：“染色结果可重复性分析” 推荐译为 Reproducibility analysis of staining results，注意 batch 的说明不可漏。\n考点20：“操作规程/试剂变更复核” 推荐译为 Re-verification of changes in procedures and reagents。\n考点21：“无检测条件的单位” 推荐译为 Units without testing capabilities，避免直译成 non-accredited labs。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "110"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n最高40%！特朗普威胁对日韩等14国加征关税\n当地时间7日，美国总统特朗普发信函给日韩及南非等14国威胁征税，随后，他又签署行政令，延长所谓“对等关税”暂缓期，将实施时间从7月9日推迟到8月1日。\n3个月来，美国就加征所谓“对等关税”与多个贸易对象进行谈判，但进度显著不及美方预期。目前仅与英国、越南达成贸易协议，但协议细节仍待敲定，与欧盟、日本、韩国、印度等的谈判进展艰难。\n特朗普公开致信14国威胁征税\n当地时间7日，美国总统特朗普宣称，将从8月1日起对来自14个国家的进口产品征收关税：\n日本、韩国、哈萨克斯坦、马来西亚、突尼斯：25%\n波黑、南非：30%\n印度尼西亚：32%\n孟加拉国、塞尔维亚：35%\n柬埔寨、泰国：36%\n老挝、缅甸：40%\n \n• 特朗普：若提高对美关税，将追加同等幅度\n特朗普当天在自己创立的“真实社交”网站上发布他写给日本首相石破茂和韩国总统李在明的信。在这两封内容几乎完全相同的信中，特朗普写道：“请理解，25%这一数字远远低于消除我们与贵国之间贸易逆差所需的水平。”\n特朗普警告称，如果日韩两国以提高关税作为回应，美国也将在25%的基础上再提高同等额度的关税。\n特朗普表示，贸易逆差已对美国经济乃至国家安全构成重大威胁，因此必须作出改变。此项关税将独立于各类行业性关税。此外，任何试图通过第三国转运来规避该关税的做法，也将被征以更高的关税。特朗普称，选择在美国境内建厂或生产产品的公司无需缴纳此项关税。若这些国家决定提高对美关税，则美国将在现有税率基础上追加同等幅度关税。\n• 美官员频频施压\n在刚刚过去的周末，包括财政部长贝森特等在内的美方高官频繁表态，一方面施压贸易对象加快谈判步伐，另一方面暗示未能如期达成协议的国家可选择延长谈判截止期限。\n贝森特6日接受美国有线电视新闻网采访时表示，对于在8月1日之前未能与美国达成贸易协议的国家，关税税率将恢复到4月宣布的“对等关税”水平。\n贝森特当时拒绝向媒体证实8月1日是否为最新截止日期，称“如果你想加快速度，那就行动吧”。\n \n关税谈判进度显著不及预期\n• 南非\n南非总统拉马福萨7日表示，南非将继续通过外交渠道推动与美国建立更加平衡、互惠的贸易关系。南非注意到美国政府承诺，30%的关税税率将根据双方谈判结果进行调整。\n• 欧盟\n欧盟委员会主席冯德莱恩日前表示，欧盟在关税问题上“准备好与美国达成一项原则性协议”。但若谈判失败，欧盟将坚决采取反制措施以保护欧洲经济。\n• 日本\n日本与美国已进行多轮谈判，但仍未取得突破。日本首相石破茂6日表示，日本已为所有可能的关税情况做好准备，将“坚定立场”，捍卫自身利益。\n• 韩国\n韩国总统李在明3日表示，与美国的谈判看起来非常困难，双方都不是十分确定“想要什么”。他说，无法确定能否在7月8日前完成谈判。\n李在明同时表示，将尽最大努力与美国达成协议，并尽最大努力在谈判中取得以韩国国家利益为中心、务实共赢的结果。\n• 印度\n印度方面宣布，已向世界贸易组织通报，计划对部分美国产品征收报复性关税，以回应美方对从印度进口的汽车及零部件加征关税的措施。\n• 越南\n越共中央总书记苏林日前表示，建议美方尽快承认越南市场经济地位，并取消美对越部分高科技产品的出口限制。\n美媒：高关税将由美国消费者埋单\n根据美国商务部发布的数据，去年美国总共从特朗普发出信函的其中7个国家进口了3510亿美元的商品。日本和韩国，作为美国第六和第七大贸易伙伴，去年共向美国出口了价值2800亿美元的商品。\n美国媒体分析，提高商品关税会导致美国消费者支付更高的价格。美国从韩国和日本进口的主要商品包括汽车、汽车零部件、半导体、药品和机械。特朗普政府已经对其中许多商品征收或威胁征收行业特定关税。\n ",
    "ori_text": "最高40%！特朗普威胁对日韩等14国加征关税\n当地时间7日，美国总统特朗普发信函给日韩及南非等14国威胁征税，随后，他又签署行政令，延长所谓“对等关税”暂缓期，将实施时间从7月9日推迟到8月1日。\n3个月来，美国就加征所谓“对等关税”与多个贸易对象进行谈判，但进度显著不及美方预期。目前仅与英国、越南达成贸易协议，但协议细节仍待敲定，与欧盟、日本、韩国、印度等的谈判进展艰难。\n特朗普公开致信14国威胁征税\n当地时间7日，美国总统特朗普宣称，将从8月1日起对来自14个国家的进口产品征收关税：\n日本、韩国、哈萨克斯坦、马来西亚、突尼斯：25%\n波黑、南非：30%\n印度尼西亚：32%\n孟加拉国、塞尔维亚：35%\n柬埔寨、泰国：36%\n老挝、缅甸：40%\n \n• 特朗普：若提高对美关税，将追加同等幅度\n特朗普当天在自己创立的“真实社交”网站上发布他写给日本首相石破茂和韩国总统李在明的信。在这两封内容几乎完全相同的信中，特朗普写道：“请理解，25%这一数字远远低于消除我们与贵国之间贸易逆差所需的水平。”\n特朗普警告称，如果日韩两国以提高关税作为回应，美国也将在25%的基础上再提高同等额度的关税。\n特朗普表示，贸易逆差已对美国经济乃至国家安全构成重大威胁，因此必须作出改变。此项关税将独立于各类行业性关税。此外，任何试图通过第三国转运来规避该关税的做法，也将被征以更高的关税。特朗普称，选择在美国境内建厂或生产产品的公司无需缴纳此项关税。若这些国家决定提高对美关税，则美国将在现有税率基础上追加同等幅度关税。\n• 美官员频频施压\n在刚刚过去的周末，包括财政部长贝森特等在内的美方高官频繁表态，一方面施压贸易对象加快谈判步伐，另一方面暗示未能如期达成协议的国家可选择延长谈判截止期限。\n贝森特6日接受美国有线电视新闻网采访时表示，对于在8月1日之前未能与美国达成贸易协议的国家，关税税率将恢复到4月宣布的“对等关税”水平。\n贝森特当时拒绝向媒体证实8月1日是否为最新截止日期，称“如果你想加快速度，那就行动吧”。\n \n关税谈判进度显著不及预期\n• 南非\n南非总统拉马福萨7日表示，南非将继续通过外交渠道推动与美国建立更加平衡、互惠的贸易关系。南非注意到美国政府承诺，30%的关税税率将根据双方谈判结果进行调整。\n• 欧盟\n欧盟委员会主席冯德莱恩日前表示，欧盟在关税问题上“准备好与美国达成一项原则性协议”。但若谈判失败，欧盟将坚决采取反制措施以保护欧洲经济。\n• 日本\n日本与美国已进行多轮谈判，但仍未取得突破。日本首相石破茂6日表示，日本已为所有可能的关税情况做好准备，将“坚定立场”，捍卫自身利益。\n• 韩国\n韩国总统李在明3日表示，与美国的谈判看起来非常困难，双方都不是十分确定“想要什么”。他说，无法确定能否在7月8日前完成谈判。\n李在明同时表示，将尽最大努力与美国达成协议，并尽最大努力在谈判中取得以韩国国家利益为中心、务实共赢的结果。\n• 印度\n印度方面宣布，已向世界贸易组织通报，计划对部分美国产品征收报复性关税，以回应美方对从印度进口的汽车及零部件加征关税的措施。\n• 越南\n越共中央总书记苏林日前表示，建议美方尽快承认越南市场经济地位，并取消美对越部分高科技产品的出口限制。\n美媒：高关税将由美国消费者埋单\n根据美国商务部发布的数据，去年美国总共从特朗普发出信函的其中7个国家进口了3510亿美元的商品。日本和韩国，作为美国第六和第七大贸易伙伴，去年共向美国出口了价值2800亿美元的商品。\n美国媒体分析，提高商品关税会导致美国消费者支付更高的价格。美国从韩国和日本进口的主要商品包括汽车、汽车零部件、半导体、药品和机械。特朗普政府已经对其中许多商品征收或威胁征收行业特定关税。\n ",
    "reference_list": "考点1： “石破茂”应译为“Shigeru Ishiba / Ishiba Shigeru”，人名。 \n考点2：“苏林”应译为“Tô Lâm”\n考点3： “李在明”应译为“Lee Jae-myung”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "50"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nAbstract: Literature is a mirror of real life which can reflect all aspects of people’s lives. More and more scholars have begun to study a country from the roots of economy, politics and culture. As early as ancient Greece, there were some creations of tragedy. Tragedy is a kind of literary creation, which is not a simple artistic form or technique but the repeat of real society. It can depict the piteous, sad, distressing and sentimental plots by describing some tortuous or complicated events. The British famous writer Thomas Hardy was one of the excellent novelists of the Victorian age. He delineated a lot of characters of tragedies, showing various persons’ enchantment. Besides providing the dignity of life tragedy to the readers, the novels contains the profound rationalism of the writer and Thomas Hardy’s Tess of the D’urbervilles reflected his real society. Hardy succeeded in portraying the image of heroine Tess and revealing the hypocritical ethics and morals of bourgeois society. This paper will discuss the causes of Clare’s tragedy from the hero –Angel Clare’s social background and psychology.  \n  \nKey words: Thomas Hardy, tragedy, Angel Clare  \n  \nChapter1 Introduction  \n  \nLiterature is not only an art but also a mirror of real life. When studying a literary work, scholars actually study history. Nowadays an increasing number of scholars have begun to study the history of a country’s economic, political and cultural forms from the perspective of literature because through different kinds of literary works, we can see all sorts of feelings such as joy, anger, sorrow and various truths. The manifestation of literature is manifold, one of which is tragedy. The writers often want to show the piteous, sad, distressing and sentimental plots by describing some tortuous or complicated events. In the tragedy, it is inevitable that the heroes or heroines should suffer a setback or disadvantage, cover themselves in dishonor, experience tribulation or even fail or die though they have reasonable motivation, wishes, ideal, or passion which may indicate a victory or success. But finally they will either die or get mad. With a bad ending, tragedy often contains a certain philosophy of life  \n. There are lots of tragedies in western literature such as Oedipus, Prometheus Bound, Romeo and Juliet, Macbeth, Hamlet, Faust, etc. And the famous tragedians are also legion like Aeschylus, Sophocles, Shakespeare, etc –Thomas Hardy for one. He was a prolific and excellent writer, publishing fourteen novels and four volumes of short stories. His works were noted for the intense tragic spirit and sense of fortune, from which we can feel the atmosphere of tragedy brought by fortune deeply.  \n  \n“Tess of the D’urbervilles” is one of the Hardy’s tragedies, a masterpiece which brought him into a number of literary critics notice. It reflected the writer’s real society and its social system and morals; therefore studying this novel can help us to know about the history of his age. But many papers showed that most of critics used to research the writing background from the tragedy of Tess. Many scholars have always put emphasis on the tragedy of Tess for a long time. Only a few scholars made researches for the tragedy of its hero Angel Clare. He was a contradictory unity –he was bold in struggling with the traditional view but in the meantime he could not break the shackles of feudal ideas. This paper will see the society from this perspective –Angel Clare, the hero’s tragedy and discuss the causes of Clare’s tragedy from his social background and psychology.  \n  \nChapter2 A brief account of Tess of The D’urbervilles  \n  \nIt seems that the fictional works do not concern with the real world. But we know that before the writers begin to create their works, it can be said that their social experience may be their primary material for creation. Some writers created the roles and environments in order to revolt against the worldly prejudice of their ages. These kinds of words are expected to tell people the truth of a society. In many cases, the social background of the novel is the writer’s background. Before analyzing the roots of Clare’s tragedy, this paper will discuss two aspects of this novel, namely “the writing background” and “the writer and his works” from which we can see the background of this novel.  \n  \n2.1 The writing background  \n  \nThomas Hardy was the last important novelist of the Victoria ages. The Victorian age was an age of realism rather than of romanticism –a realism which strives to tell the whole truth showing moral and physical diseases as they are. Victorian literature, in general, truthfully represented the reality and spirit of this age which was the great age of the English novel—realistic, thickly plotted, crowded with characters, and long. Hardy, who also shown the truth of this age had a high place in Western literature which came from the agitation of life and fatalism of human being. His tragedies in the history of Western literature were no an accident for the tragedy consciousness. Hardy’s tragic novels has sprung from and developed this tragic idea in form and connotation. The tragedy consciousness in Hardy’s novels originated from Western traditional tragic spirit which was full of rationalism and profound reflection on the contradictions of human society. And it also revealed an ineluctable and inevitable cond  \nitionality of fate. That is to say, the heroes or heroines would slip into the tragic path of life in the end in Western literature no matter whether they liked or not, or where they hided. Tragedy was their final arrangement.  \n  \nThomas Hardy studied Greek tragedies and Shakespearean tragedies all his life. And he was deeply influenced by Schopenhauer’s tragedy consciousness. Schopenhauer was a famous philosopher who believed that life was a tragedy –life was filled with desire. If a person had a desire but could not gain his desires, he would feel painful; however, when he could gain his desires, he would become insipid. This was another torment. Schopenhauer grouped tragedy into three types: the tragedy caused by those who committed heinous crimes, the tragedy led by the irony of fate and the tragedy caused by misunderstanding and distrust between persons in everyday life. In his opinion, the last tragedy was the most terrible one which we can see in Hardy’s works. Hardy began to creating the novels in the early 1870s. In the late 1890s, he turned to write poetry. The Britain in this period was undergoing a transition period from laisser-faire capitalism to imperialism. The capitalism thought that the social system of this period  \ncould not be changed. But Hardy’s works exactly clashed with it, which reflected the tremendous changes of society due to the invasion of industrial capital to the village. With one remark he had ripped away the mask of British society.  \n  \n2.2 The writer Thomas Hardy and his work  \n  \nLiterature is reflection of life. Almost all writers created their novels according to his social background. We can see many literary works written on the basis of their ages. They wanted to bring out the social facts by their works. It should be such a free way that they could rebuke the dark society. People can feel the society of the writers from their works and then identified with the writers. The writers hoped that they could let the people know the dark aspects of the government and then fine an echo from them by their works. To some extent, a novel should be a history. From the introduction of Thomas Hardy and the main content of Tess of The D’urbervilles must be helpful to show us the background of Clare’s tragedy.",
    "ori_text": "Abstract: Literature is a mirror of real life which can reflect all aspects of people’s lives. More and more scholars have begun to study a country from the roots of economy, politics and culture. As early as ancient Greece, there were some creations of tragedy. Tragedy is a kind of literary creation, which is not a simple artistic form or technique but the repeat of real society. It can depict the piteous, sad, distressing and sentimental plots by describing some tortuous or complicated events. The British famous writer Thomas Hardy was one of the excellent novelists of the Victorian age. He delineated a lot of characters of tragedies, showing various persons’ enchantment. Besides providing the dignity of life tragedy to the readers, the novels contains the profound rationalism of the writer and Thomas Hardy’s Tess of the D’urbervilles reflected his real society. Hardy succeeded in portraying the image of heroine Tess and revealing the hypocritical ethics and morals of bourgeois society. This paper will discuss the causes of Clare’s tragedy from the hero –Angel Clare’s social background and psychology.  \n  \nKey words: Thomas Hardy, tragedy, Angel Clare  \n  \nChapter1 Introduction  \n  \nLiterature is not only an art but also a mirror of real life. When studying a literary work, scholars actually study history. Nowadays an increasing number of scholars have begun to study the history of a country’s economic, political and cultural forms from the perspective of literature because through different kinds of literary works, we can see all sorts of feelings such as joy, anger, sorrow and various truths. The manifestation of literature is manifold, one of which is tragedy. The writers often want to show the piteous, sad, distressing and sentimental plots by describing some tortuous or complicated events. In the tragedy, it is inevitable that the heroes or heroines should suffer a setback or disadvantage, cover themselves in dishonor, experience tribulation or even fail or die though they have reasonable motivation, wishes, ideal, or passion which may indicate a victory or success. But finally they will either die or get mad. With a bad ending, tragedy often contains a certain philosophy of life  \n. There are lots of tragedies in western literature such as Oedipus, Prometheus Bound, Romeo and Juliet, Macbeth, Hamlet, Faust, etc. And the famous tragedians are also legion like Aeschylus, Sophocles, Shakespeare, etc –Thomas Hardy for one. He was a prolific and excellent writer, publishing fourteen novels and four volumes of short stories. His works were noted for the intense tragic spirit and sense of fortune, from which we can feel the atmosphere of tragedy brought by fortune deeply.  \n  \n“Tess of the D’urbervilles” is one of the Hardy’s tragedies, a masterpiece which brought him into a number of literary critics notice. It reflected the writer’s real society and its social system and morals; therefore studying this novel can help us to know about the history of his age. But many papers showed that most of critics used to research the writing background from the tragedy of Tess. Many scholars have always put emphasis on the tragedy of Tess for a long time. Only a few scholars made researches for the tragedy of its hero Angel Clare. He was a contradictory unity –he was bold in struggling with the traditional view but in the meantime he could not break the shackles of feudal ideas. This paper will see the society from this perspective –Angel Clare, the hero’s tragedy and discuss the causes of Clare’s tragedy from his social background and psychology.  \n  \nChapter2 A brief account of Tess of The D’urbervilles  \n  \nIt seems that the fictional works do not concern with the real world. But we know that before the writers begin to create their works, it can be said that their social experience may be their primary material for creation. Some writers created the roles and environments in order to revolt against the worldly prejudice of their ages. These kinds of words are expected to tell people the truth of a society. In many cases, the social background of the novel is the writer’s background. Before analyzing the roots of Clare’s tragedy, this paper will discuss two aspects of this novel, namely “the writing background” and “the writer and his works” from which we can see the background of this novel.  \n  \n2.1 The writing background  \n  \nThomas Hardy was the last important novelist of the Victoria ages. The Victorian age was an age of realism rather than of romanticism –a realism which strives to tell the whole truth showing moral and physical diseases as they are. Victorian literature, in general, truthfully represented the reality and spirit of this age which was the great age of the English novel—realistic, thickly plotted, crowded with characters, and long. Hardy, who also shown the truth of this age had a high place in Western literature which came from the agitation of life and fatalism of human being. His tragedies in the history of Western literature were no an accident for the tragedy consciousness. Hardy’s tragic novels has sprung from and developed this tragic idea in form and connotation. The tragedy consciousness in Hardy’s novels originated from Western traditional tragic spirit which was full of rationalism and profound reflection on the contradictions of human society. And it also revealed an ineluctable and inevitable cond  \nitionality of fate. That is to say, the heroes or heroines would slip into the tragic path of life in the end in Western literature no matter whether they liked or not, or where they hided. Tragedy was their final arrangement.  \n  \nThomas Hardy studied Greek tragedies and Shakespearean tragedies all his life. And he was deeply influenced by Schopenhauer’s tragedy consciousness. Schopenhauer was a famous philosopher who believed that life was a tragedy –life was filled with desire. If a person had a desire but could not gain his desires, he would feel painful; however, when he could gain his desires, he would become insipid. This was another torment. Schopenhauer grouped tragedy into three types: the tragedy caused by those who committed heinous crimes, the tragedy led by the irony of fate and the tragedy caused by misunderstanding and distrust between persons in everyday life. In his opinion, the last tragedy was the most terrible one which we can see in Hardy’s works. Hardy began to creating the novels in the early 1870s. In the late 1890s, he turned to write poetry. The Britain in this period was undergoing a transition period from laisser-faire capitalism to imperialism. The capitalism thought that the social system of this period  \ncould not be changed. But Hardy’s works exactly clashed with it, which reflected the tremendous changes of society due to the invasion of industrial capital to the village. With one remark he had ripped away the mask of British society.  \n  \n2.2 The writer Thomas Hardy and his work  \n  \nLiterature is reflection of life. Almost all writers created their novels according to his social background. We can see many literary works written on the basis of their ages. They wanted to bring out the social facts by their works. It should be such a free way that they could rebuke the dark society. People can feel the society of the writers from their works and then identified with the writers. The writers hoped that they could let the people know the dark aspects of the government and then fine an echo from them by their works. To some extent, a novel should be a history. From the introduction of Thomas Hardy and the main content of Tess of The D’urbervilles must be helpful to show us the background of Clare’s tragedy.",
    "reference_list": "考点1：“agitation of life and fatalism of human being”推荐译为“人生的动荡与宿命观”\n考点2：“are expected to tell people”推荐译为“旨在向人们揭示”，不可直译为“期望告诉人们”\n考点3：“Introduction”在论文中必须译为“引言”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "24"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nBilateral trade is considered a key driver of business-cycle transmission, as countries with higher bilateral trade have more correlated business cycles. We show, however, that when we account for the common trade exposure of a country pair to similar foreign cycles, the effect of bilateral trade on comovement falls sharply. Furthermore, common trade exposure is also a robust predictor of comovement. We conclude that trade is indeed a driver of business-cycle transmission, but often through common exposure to foreign cycles rather than just bilateral linkages. Finally, we consider the implications of these empirical results for the ‘‘trade-comovement puzzle.’’\nA large literature, starting with Frankel and Rose (1998), argues that bilateral trade is a key driver of business-cycle transmission, as countries that trade more with each other have more correlated business cycles—a phenomenon known as trade comovement.\nWe show that previous estimates of trade comovement are upward biased because they omit the common exposure of a country pair to similar foreign cycles, which is positively correlated with bilateral trade and a robust predictor of trade comovement. Thus, business cycle comovement is influenced by trade both directly through bilateral trade and indirectly through trade exposure to similar partners. We propose a novel indicator to measure common exposure and show that when one accounts for the common exposure of a country pair, the effect of bilateral trade on business cycle comovement falls substantially.\nThe comovement of Canada’s and Mexico’s business cycles illustrates the main empirical issue. Both countries’ bilateral trade with the United States accounts for nearly 70 percent of total trade. It is no surprise, then, that the business cycles of Canada and Mexico are highly correlated. If we ignore common exposure in trade-comovement analysis, we exaggerate the effect of direct bilateral trade of these two countries–less than 3 percent of total trade–on business cycle comovement.\nWe derive a measure of common trade exposure that addresses this issue. For each country in a country pair, we calculate a trade-weighted ‘‘rest of world’’ cycle using the cyclical GDP fluctuations of all its trade partners. We then define common trade exposure of a country pair as the correlation between the two countries’ rest of world cycles over time. This measure of common exposure is positively correlated with bilateral trade intensity, as countries that trade together tend to also have similar trading partners. Given this positive relationship, if common exposure increases business-cycle comovement, then a regression that fails to control for common exposure will suffer from positive omitted variable bias, as explained by Kose and Yi (2006).\nWe perform standard cross-sectional trade-comovement regressions with and without our measure of common trade exposure as a control. We find that the effect of common trade exposure on comovement is both positive and significant, with a one standard deviation increase in common trade exposure yielding an average increase in comovement of more than 5 percentage points.\nFurthermore, when common trade exposure is included in the regression, the estimated effect of bilateral trade intensity on GDP comovement falls over 40 percent, suggesting the omitted variable bias in the estimation of the effect of bilateral trade intensity is quite strong.\nA high measure of common trade exposure amounts to more than just exposure to the same trading partners. Indeed, two countries could share none of the same trading partners and still have a high amount of common trade exposure because the trade partners of each country have highly correlated business cycles. This distinction is important as it represents a broader notion of common shocks that can affect a country pair through trade. To make this point, we repeat our analysis using a measure of the similarity in trade partners for a country pair. We find that this measure has a much weaker mitigating effect on the relationship between bilateral trade and comovement and is a less robust predictor of comovement than our measure of common trade exposure.\nIndeed, we find that when we control for both common trade exposure and trade partner similarity, the coefficient on trade partner similarity turns negative, suggesting that the comovement-boosting effect of trade partner similarity is accounted for by its positive correlation with common exposure.\nPrevious studies have found that trade-comovement is stronger among more highly-developed countries. Motivated by this result, we split the data into two subsamples: one in which all country pairs are made up of high-income countries only, and one with all other country pairs. Consistent with the literature, we find that estimated trade-comovement is higher for high-income countries.\nFurthermore, adding common trade exposure to the regression reduces the trade-comovement coefficient by less for the high-income country pairs and by more for other country pairs. Common trade exposure also has a stronger relationship with comovement among high-income countries. Thus, we conclude that bilateral trade and trade exposure to similar foreign cycles are more importance sources of comovement between high-income countries than for lower-income countries.\nOur empirical results are robust to a battery of robustness tests. Among these, we pay special attention to potential issues of simultaneity bias or reverse causality by instrumenting bilateral trade and common trade exposure with gravity determinants, dividing the sample into panels to control for country-pair characteristics, and limiting the set of countries to small open economies that are assumed to not influence the foreign business cycle. These specifications confirm that common trade exposure is a robust predictor of business-cycle comovement. Indeed, we find the coefficient on common exposure to be positive and significant even when the coefficient on bilateral trade intensity is not. Furthermore, the trade-comovement relationship in these specifications still exhibits positive omitted variable bias.\nOur empirical results offer a new lens through which to view the so-called ‘‘trade-comovement puzzle.’’ Kose and Yi (2001) show that a standard international real business cycle (IRBC) model is capable of matching the qualitative result that countries with higher bilateral trade have more correlated business cycles, but that the magnitude of this relationship is far lower than in the data.\nSeveral researchers have since attempted to bridge the gap with new mechanisms in the model. We argue, however, that the target comovement to capture in the model is lower than previously thought.\nWe extend the three-country IRBC model of Drozd et al. (2021) to four countries, allowing us to match both bilateral trade intensity and common trade exposure to foreign cycles in calibration. The model features households that optimally choose imports, consumption, labor, and investment in physical capital and a non-contingent bond to maximize welfare. Similar to the previous literature, we find increasing bilateral trade in the IRBC model increases comovement but only accounts for about 11 percent of the coefficient in the data, despite our lower trade-comovement target. Furthermore, we find that the model cannot generate a statistically significant positive relationship between common trade exposure and comovement, nor the omitted variable bias in the trade-comovement relationship when omitting common trade exposure. These findings highlight additional failures of the baseline model.\nDrozd et al. (2021) find that introducing a dynamic trade elasticity in the model (via import adjustment costs) strengthens the positive relationship between trade and comovement, as it reverses the income effect of foreign productivity shocks that move trade and GDP in different directions. Introducing this mechanism in our model brings it much closer to data. Indeed, we find that with reasonably calibrated adjustment costs, the model accounts for 76 percent of the trade-comovement relationship in the data. The stronger relationship between trade and comovement also serves to increase the effect of increasing common trade exposure in the model, as each country’s comovement with its rest of world cycle increases. With the same adjustment costs, the model accounts for 31 percent of the coefficient on common trade exposure. With even more restrictive adjustment costs, the model can match both coefficients from the data quite closely, though it would still fail to match the trade-comovement relationship from our empirical analysis that does not control for common trade exposure.\nIn addition to exploring the model-implied effect of increased bilateral trade or common trade exposure, we also explore the effect of increased trade partner similarity, our alternative measure discussed previously. Throughout, we find that the model-implied coefficient from raising trade partner similarity (holding common trade exposure and bilateral trade constant) is negative. Increasing trade partner similarity while holding common trade exposure fixed implies that the business cycles of foreign countries must be less correlated. Trade partner similarity increases comovement only as far as it is associated with higher common exposure to countries with similar cycles. This result may give some intuition for the same result in the data when we control for both common trade exposure and trade partner similarity.\nIn Section 2, we present a brief literature review. Section 3 describes our measures of common exposure, trade partner similarity, and bilateral trade intensity and reports the empirical results for the effect of each on a country pair’s business cycle comovement.\nIn Section 4, we evaluate the implications of our empirical results on the trade-comovement puzzle. Section 5 concludes.\n\n",
    "ori_text": "\n\nBilateral trade is considered a key driver of business-cycle transmission, as countries with higher bilateral trade have more correlated business cycles. We show, however, that when we account for the common trade exposure of a country pair to similar foreign cycles, the effect of bilateral trade on comovement falls sharply. Furthermore, common trade exposure is also a robust predictor of comovement. We conclude that trade is indeed a driver of business-cycle transmission, but often through common exposure to foreign cycles rather than just bilateral linkages. Finally, we consider the implications of these empirical results for the ‘‘trade-comovement puzzle.’’\nA large literature, starting with Frankel and Rose (1998), argues that bilateral trade is a key driver of business-cycle transmission, as countries that trade more with each other have more correlated business cycles—a phenomenon known as trade comovement.\nWe show that previous estimates of trade comovement are upward biased because they omit the common exposure of a country pair to similar foreign cycles, which is positively correlated with bilateral trade and a robust predictor of trade comovement. Thus, business cycle comovement is influenced by trade both directly through bilateral trade and indirectly through trade exposure to similar partners. We propose a novel indicator to measure common exposure and show that when one accounts for the common exposure of a country pair, the effect of bilateral trade on business cycle comovement falls substantially.\nThe comovement of Canada’s and Mexico’s business cycles illustrates the main empirical issue. Both countries’ bilateral trade with the United States accounts for nearly 70 percent of total trade. It is no surprise, then, that the business cycles of Canada and Mexico are highly correlated. If we ignore common exposure in trade-comovement analysis, we exaggerate the effect of direct bilateral trade of these two countries–less than 3 percent of total trade–on business cycle comovement.\nWe derive a measure of common trade exposure that addresses this issue. For each country in a country pair, we calculate a trade-weighted ‘‘rest of world’’ cycle using the cyclical GDP fluctuations of all its trade partners. We then define common trade exposure of a country pair as the correlation between the two countries’ rest of world cycles over time. This measure of common exposure is positively correlated with bilateral trade intensity, as countries that trade together tend to also have similar trading partners. Given this positive relationship, if common exposure increases business-cycle comovement, then a regression that fails to control for common exposure will suffer from positive omitted variable bias, as explained by Kose and Yi (2006).\nWe perform standard cross-sectional trade-comovement regressions with and without our measure of common trade exposure as a control. We find that the effect of common trade exposure on comovement is both positive and significant, with a one standard deviation increase in common trade exposure yielding an average increase in comovement of more than 5 percentage points.\nFurthermore, when common trade exposure is included in the regression, the estimated effect of bilateral trade intensity on GDP comovement falls over 40 percent, suggesting the omitted variable bias in the estimation of the effect of bilateral trade intensity is quite strong.\nA high measure of common trade exposure amounts to more than just exposure to the same trading partners. Indeed, two countries could share none of the same trading partners and still have a high amount of common trade exposure because the trade partners of each country have highly correlated business cycles. This distinction is important as it represents a broader notion of common shocks that can affect a country pair through trade. To make this point, we repeat our analysis using a measure of the similarity in trade partners for a country pair. We find that this measure has a much weaker mitigating effect on the relationship between bilateral trade and comovement and is a less robust predictor of comovement than our measure of common trade exposure.\nIndeed, we find that when we control for both common trade exposure and trade partner similarity, the coefficient on trade partner similarity turns negative, suggesting that the comovement-boosting effect of trade partner similarity is accounted for by its positive correlation with common exposure.\nPrevious studies have found that trade-comovement is stronger among more highly-developed countries. Motivated by this result, we split the data into two subsamples: one in which all country pairs are made up of high-income countries only, and one with all other country pairs. Consistent with the literature, we find that estimated trade-comovement is higher for high-income countries.\nFurthermore, adding common trade exposure to the regression reduces the trade-comovement coefficient by less for the high-income country pairs and by more for other country pairs. Common trade exposure also has a stronger relationship with comovement among high-income countries. Thus, we conclude that bilateral trade and trade exposure to similar foreign cycles are more importance sources of comovement between high-income countries than for lower-income countries.\nOur empirical results are robust to a battery of robustness tests. Among these, we pay special attention to potential issues of simultaneity bias or reverse causality by instrumenting bilateral trade and common trade exposure with gravity determinants, dividing the sample into panels to control for country-pair characteristics, and limiting the set of countries to small open economies that are assumed to not influence the foreign business cycle. These specifications confirm that common trade exposure is a robust predictor of business-cycle comovement. Indeed, we find the coefficient on common exposure to be positive and significant even when the coefficient on bilateral trade intensity is not. Furthermore, the trade-comovement relationship in these specifications still exhibits positive omitted variable bias.\nOur empirical results offer a new lens through which to view the so-called ‘‘trade-comovement puzzle.’’ Kose and Yi (2001) show that a standard international real business cycle (IRBC) model is capable of matching the qualitative result that countries with higher bilateral trade have more correlated business cycles, but that the magnitude of this relationship is far lower than in the data.\nSeveral researchers have since attempted to bridge the gap with new mechanisms in the model. We argue, however, that the target comovement to capture in the model is lower than previously thought.\nWe extend the three-country IRBC model of Drozd et al. (2021) to four countries, allowing us to match both bilateral trade intensity and common trade exposure to foreign cycles in calibration. The model features households that optimally choose imports, consumption, labor, and investment in physical capital and a non-contingent bond to maximize welfare. Similar to the previous literature, we find increasing bilateral trade in the IRBC model increases comovement but only accounts for about 11 percent of the coefficient in the data, despite our lower trade-comovement target. Furthermore, we find that the model cannot generate a statistically significant positive relationship between common trade exposure and comovement, nor the omitted variable bias in the trade-comovement relationship when omitting common trade exposure. These findings highlight additional failures of the baseline model.\nDrozd et al. (2021) find that introducing a dynamic trade elasticity in the model (via import adjustment costs) strengthens the positive relationship between trade and comovement, as it reverses the income effect of foreign productivity shocks that move trade and GDP in different directions. Introducing this mechanism in our model brings it much closer to data. Indeed, we find that with reasonably calibrated adjustment costs, the model accounts for 76 percent of the trade-comovement relationship in the data. The stronger relationship between trade and comovement also serves to increase the effect of increasing common trade exposure in the model, as each country’s comovement with its rest of world cycle increases. With the same adjustment costs, the model accounts for 31 percent of the coefficient on common trade exposure. With even more restrictive adjustment costs, the model can match both coefficients from the data quite closely, though it would still fail to match the trade-comovement relationship from our empirical analysis that does not control for common trade exposure.\nIn addition to exploring the model-implied effect of increased bilateral trade or common trade exposure, we also explore the effect of increased trade partner similarity, our alternative measure discussed previously. Throughout, we find that the model-implied coefficient from raising trade partner similarity (holding common trade exposure and bilateral trade constant) is negative. Increasing trade partner similarity while holding common trade exposure fixed implies that the business cycles of foreign countries must be less correlated. Trade partner similarity increases comovement only as far as it is associated with higher common exposure to countries with similar cycles. This result may give some intuition for the same result in the data when we control for both common trade exposure and trade partner similarity.\nIn Section 2, we present a brief literature review. Section 3 describes our measures of common exposure, trade partner similarity, and bilateral trade intensity and reports the empirical results for the effect of each on a country pair’s business cycle comovement.\nIn Section 4, we evaluate the implications of our empirical results on the trade-comovement puzzle. Section 5 concludes.\n\n",
    "reference_list": "考点1:“common trade exposure”可以译为“共同贸易风险”，“共同贸易敞口”、“共同贸易关联度” 或 “对共同贸易伙伴的敞口”\n考点2:‘’trade-comovement puzzle‘’可以译为“贸易-联动之谜”， “贸易-协同变动之谜” 或 “贸易与商业周期同步性之谜”\n考点3:“trade comovement”推荐译为“贸易联动性”\n考点4:“country pair”推荐译为“国家对”\n考点5:“empirical issue”推荐译为“实证问题”或“实证案例”\n考点6:“common shocks”推荐译为“共同冲击”\n考点7:“non-contingent bond”必须译为“非或有债券”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "126"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nSpaceX loses contact with its Starship on 9th test flight after last 2 went down in flames\nAfter spectacular back-to-back upper stage failures in January and March, SpaceX launched another Super Heavy-Starship rocket Tuesday on the program's ninth test flight, but ran into fresh problems that resulted in the loss of both stages before they could carry out controlled descents to splashdown.\nThe Super Heavy first stage, following a deliberately steeper, more stressful descent trajectory toward splashdown near the Texas Gulf Coast, suffered a catastrophic failure at the moment its engines reignited for what would have been a relatively gentle splashdown.\nSpaceX confirmed the stage had been lost, but given the extreme nature of the testing, the loss was not an out-of-the-blue surprise. The Starship upper stage, meanwhile, managed to make it into its planned suborbital trajectory after an apparently flawless performance from its six engines.\nBut a few minutes later, a door on the side of the rocket failed to open, preventing the planned release of simulated Starlink satellites in a test of the rocket's Pez-like deployment system.\nWith that test deferred to a future flight, SpaceX engineers hoped to reignite a single Raptor engine to test its start-up capability in space. But an apparent propellant leak put the spacecraft into a slow spin that ruled out the restart and a controlled reentry and splashdown. \nThe Starship has to enter at the right angle and in a precise orientation to survive reentry heating and aerodynamic \"loads.\" Entering in a spin doomed the Starship to a catastrophic breakup.\n\"Starship made it to the scheduled ship engine cutoff, so big improvement over last flight!\" SpaceX founder and CEO Elon Musk wrote on X. \"Also, no significant loss of heat shield tiles during ascent. Leaks caused loss of main tank pressure during the coast and re-entry phase. Lot of good data to review.\"\nHe added that the Super Heavy launch cadence for the next three flights will be faster, at approximately one per month or less, assuming, of course, engineers reviewing telemetry can quickly pin down what went wrong and implement fixes to correct the problems. \nThe huge rocket's launching, known as Integrated Flight Test 9, got underway with a ground-shaking liftoff at 7:37 p.m. EDT from SpaceX's sprawling Boca Chica, Texas, manufacturing and flight facility — Starbase — on the Texas coast.\nThe mission featured the first use of a previously flown Super Heavy first stage, which flew itself back to capture by giant mechanical arms on the launch tower during the program's seventh test flight in January.\nFor the program's latest launch, the Super Heavy, powered by 33 methane-fueled Raptor engines generating up to 16 million pounds of thrust, followed the same ascent flight plan as previous missions, propelling the Starship upper stage out of the thick lower atmosphere on an easterly trajectory toward the Straits of Florida.\nEquipped with six Raptors of its own, the 160-foot-long Starship separated from its booster about two and a half minutes after liftoff, heading for a suborbital trajectory carrying it toward a planned vertical splashdown in the southern Indian Ocean.\nThe Super Heavy, meanwhile, used a different method for flipping around for the trip back to the launch site in a bid to save propellants. It was also programmed to fly a much steeper descent than usual to learn more about the thermal and aerodynamic stresses it can safely endure.\n\"The booster will attempt to fly at a higher angle of attack during its descent,\" SpaceX said on its website. \"By increasing the amount of atmospheric drag on the vehicle, a higher angle of attack can result in a lower descent speed which in turn requires less propellant for the initial landing burn.\"\n\"Getting real-world data on how the booster is able to control its flight at this higher angle of attack will contribute to improved performance on future vehicles, including the next generation of Super Heavy,\" SpaceX said.\nAs a result of the high-stress tests, SpaceX targeted a splashdown in the Gulf instead of attempting a launch pad capture where critical infrastructure could be damaged in a landing mishap.\nAs it turned out, that was a good decision.\nLaunch attempt follows two Starship breakups\nTuesday's launch came on the heels of back-to-back Starship upper stage breakups during the two previous test flights that generated spectacular showers of flaming debris along the flight paths.\nSince then, SpaceX engineers have carried out extensive testing and implemented multiple upgrades and improvements to minimize the chances for similar failures. The Federal Aviation Administration, which oversaw both failure investigations, gave SpaceX permission to proceed with IFT-9 last week after wrapping up the IFT-8 review.\n\"The FAA conducted a comprehensive safety review of the SpaceX Starship Flight 8 mishap and determined that the company has satisfactorily addressed the causes of the mishap, and therefore, the Starship vehicle can return to flight,\" the agency said in a statement. \"The FAA will verify SpaceX implements all corrective actions.\"\n \nIn both of the previous failures, commercial airline traffic in and around the Straits of Florida was held up pending confirmation falling debris was no longer a threat. For the ninth flight, the length of the Aircraft Hazard Area was expanded from about 1,000 statute miles to around 1,840 miles and SpaceX was required to launch the rocket during non-peak air travel periods.\nPlans for the moon and Mars\nThe Super Heavy-Starship rocket is critical to NASA's plans to land astronauts on the moon in the next few years and to Musk's plans to eventually send humans to Mars.\nNASA plans to use a variant of the Starship upper stage as a lunar lander in the agency's Artemis program. NASA wants to use its own rocket and crew capsule to ferry astronauts to lunar orbit where the SpaceX lander will be waiting to carry them down to the surface.\nThe Trump administration wants to cancel NASA's Space Launch System rocket and Orion crew capsule, leaving the future of the Artemis program, as it's currently envisioned, in doubt. For his part, Musk has argued the United States should pass up moon missions, which he called a \"distraction,\" and instead head directly to Mars.\nIn any case, the Super Heavy-Starship rocket is expected to play a major role in future deep space exploration, regardless of the target. But multiple successful test flights will be needed to demonstrate the safety and reliability needed for astronauts and passengers heading to the moon, Mars or beyond.\nIn an interview for \"CBS Sunday Morning,\" taped shortly before Tuesday's launch, Musk told correspondent David Pogue, \"If we're lucky, we've probably got about a 50% chance of sending ... ships from Earth to Mars at the end of next year. So November, December next year, in about 18 months.\"\n \nAsked if that timeline was realistic, Musk replied, \"Well, I try to give the 50th percentile. ... So you should expect half the time I'm wrong.\" [See more of the exclusive interview with Musk on \"CBS Sunday Morning,\" Sunday, June 1.]\nSpaceX made changes after two catastrophic explosions\nThe last two Starships, launched Jan. 16 and March 6, both ended with unrelated catastrophic explosions as they neared their planned sub-orbital trajectories.\nDuring the January flight, a propellant leak in an unpressurized \"attic\" above the Raptor engines led to sustained fires that eventually triggered shutdown of all but one of the spacecraft's engines. Telemetry was lost eight minutes and 20 seconds after launch and moments later, the vehicle broke apart.\n\"The most probable root cause for the loss of ship was identified as a harmonic response several times stronger in flight than had been seen during testing, which led to increased stress on hardware in the propulsion system,\" SpaceX said on its website. \"The subsequent propellant leaks exceeded the venting capability of the ship's attic area and resulted in sustained fires.\"\nAfter extensive ground tests, SpaceX made changes to propellant feedlines, and thrust levels and installed additional vents and a new nitrogen purge system in the attic to reduce the potential for fire.\nThose fixes appeared to work as expected during the Starship's eighth test flight in March, but the upper stage again suffered a catastrophic failure. This time around, the Starship suffered a \"hardware failure in one of the upper stage Raptor engines that resulted in inadvertent propellant mixing and ignition,\" SpaceX said on its website.\nTo fix the problem, upper stage Raptors now feature a new nitrogen purge system, improvements to the propellant drain system and tighter joints in key areas. SpaceX is also developing an improved Raptor engine that will eliminate several failure modes.",
    "ori_text": "SpaceX loses contact with its Starship on 9th test flight after last 2 went down in flames\nAfter spectacular back-to-back upper stage failures in January and March, SpaceX launched another Super Heavy-Starship rocket Tuesday on the program's ninth test flight, but ran into fresh problems that resulted in the loss of both stages before they could carry out controlled descents to splashdown.\nThe Super Heavy first stage, following a deliberately steeper, more stressful descent trajectory toward splashdown near the Texas Gulf Coast, suffered a catastrophic failure at the moment its engines reignited for what would have been a relatively gentle splashdown.\nSpaceX confirmed the stage had been lost, but given the extreme nature of the testing, the loss was not an out-of-the-blue surprise. The Starship upper stage, meanwhile, managed to make it into its planned suborbital trajectory after an apparently flawless performance from its six engines.\nBut a few minutes later, a door on the side of the rocket failed to open, preventing the planned release of simulated Starlink satellites in a test of the rocket's Pez-like deployment system.\nWith that test deferred to a future flight, SpaceX engineers hoped to reignite a single Raptor engine to test its start-up capability in space. But an apparent propellant leak put the spacecraft into a slow spin that ruled out the restart and a controlled reentry and splashdown. \nThe Starship has to enter at the right angle and in a precise orientation to survive reentry heating and aerodynamic \"loads.\" Entering in a spin doomed the Starship to a catastrophic breakup.\n\"Starship made it to the scheduled ship engine cutoff, so big improvement over last flight!\" SpaceX founder and CEO Elon Musk wrote on X. \"Also, no significant loss of heat shield tiles during ascent. Leaks caused loss of main tank pressure during the coast and re-entry phase. Lot of good data to review.\"\nHe added that the Super Heavy launch cadence for the next three flights will be faster, at approximately one per month or less, assuming, of course, engineers reviewing telemetry can quickly pin down what went wrong and implement fixes to correct the problems. \nThe huge rocket's launching, known as Integrated Flight Test 9, got underway with a ground-shaking liftoff at 7:37 p.m. EDT from SpaceX's sprawling Boca Chica, Texas, manufacturing and flight facility — Starbase — on the Texas coast.\nThe mission featured the first use of a previously flown Super Heavy first stage, which flew itself back to capture by giant mechanical arms on the launch tower during the program's seventh test flight in January.\nFor the program's latest launch, the Super Heavy, powered by 33 methane-fueled Raptor engines generating up to 16 million pounds of thrust, followed the same ascent flight plan as previous missions, propelling the Starship upper stage out of the thick lower atmosphere on an easterly trajectory toward the Straits of Florida.\nEquipped with six Raptors of its own, the 160-foot-long Starship separated from its booster about two and a half minutes after liftoff, heading for a suborbital trajectory carrying it toward a planned vertical splashdown in the southern Indian Ocean.\nThe Super Heavy, meanwhile, used a different method for flipping around for the trip back to the launch site in a bid to save propellants. It was also programmed to fly a much steeper descent than usual to learn more about the thermal and aerodynamic stresses it can safely endure.\n\"The booster will attempt to fly at a higher angle of attack during its descent,\" SpaceX said on its website. \"By increasing the amount of atmospheric drag on the vehicle, a higher angle of attack can result in a lower descent speed which in turn requires less propellant for the initial landing burn.\"\n\"Getting real-world data on how the booster is able to control its flight at this higher angle of attack will contribute to improved performance on future vehicles, including the next generation of Super Heavy,\" SpaceX said.\nAs a result of the high-stress tests, SpaceX targeted a splashdown in the Gulf instead of attempting a launch pad capture where critical infrastructure could be damaged in a landing mishap.\nAs it turned out, that was a good decision.\nLaunch attempt follows two Starship breakups\nTuesday's launch came on the heels of back-to-back Starship upper stage breakups during the two previous test flights that generated spectacular showers of flaming debris along the flight paths.\nSince then, SpaceX engineers have carried out extensive testing and implemented multiple upgrades and improvements to minimize the chances for similar failures. The Federal Aviation Administration, which oversaw both failure investigations, gave SpaceX permission to proceed with IFT-9 last week after wrapping up the IFT-8 review.\n\"The FAA conducted a comprehensive safety review of the SpaceX Starship Flight 8 mishap and determined that the company has satisfactorily addressed the causes of the mishap, and therefore, the Starship vehicle can return to flight,\" the agency said in a statement. \"The FAA will verify SpaceX implements all corrective actions.\"\n \nIn both of the previous failures, commercial airline traffic in and around the Straits of Florida was held up pending confirmation falling debris was no longer a threat. For the ninth flight, the length of the Aircraft Hazard Area was expanded from about 1,000 statute miles to around 1,840 miles and SpaceX was required to launch the rocket during non-peak air travel periods.\nPlans for the moon and Mars\nThe Super Heavy-Starship rocket is critical to NASA's plans to land astronauts on the moon in the next few years and to Musk's plans to eventually send humans to Mars.\nNASA plans to use a variant of the Starship upper stage as a lunar lander in the agency's Artemis program. NASA wants to use its own rocket and crew capsule to ferry astronauts to lunar orbit where the SpaceX lander will be waiting to carry them down to the surface.\nThe Trump administration wants to cancel NASA's Space Launch System rocket and Orion crew capsule, leaving the future of the Artemis program, as it's currently envisioned, in doubt. For his part, Musk has argued the United States should pass up moon missions, which he called a \"distraction,\" and instead head directly to Mars.\nIn any case, the Super Heavy-Starship rocket is expected to play a major role in future deep space exploration, regardless of the target. But multiple successful test flights will be needed to demonstrate the safety and reliability needed for astronauts and passengers heading to the moon, Mars or beyond.\nIn an interview for \"CBS Sunday Morning,\" taped shortly before Tuesday's launch, Musk told correspondent David Pogue, \"If we're lucky, we've probably got about a 50% chance of sending ... ships from Earth to Mars at the end of next year. So November, December next year, in about 18 months.\"\n \nAsked if that timeline was realistic, Musk replied, \"Well, I try to give the 50th percentile. ... So you should expect half the time I'm wrong.\" [See more of the exclusive interview with Musk on \"CBS Sunday Morning,\" Sunday, June 1.]\nSpaceX made changes after two catastrophic explosions\nThe last two Starships, launched Jan. 16 and March 6, both ended with unrelated catastrophic explosions as they neared their planned sub-orbital trajectories.\nDuring the January flight, a propellant leak in an unpressurized \"attic\" above the Raptor engines led to sustained fires that eventually triggered shutdown of all but one of the spacecraft's engines. Telemetry was lost eight minutes and 20 seconds after launch and moments later, the vehicle broke apart.\n\"The most probable root cause for the loss of ship was identified as a harmonic response several times stronger in flight than had been seen during testing, which led to increased stress on hardware in the propulsion system,\" SpaceX said on its website. \"The subsequent propellant leaks exceeded the venting capability of the ship's attic area and resulted in sustained fires.\"\nAfter extensive ground tests, SpaceX made changes to propellant feedlines, and thrust levels and installed additional vents and a new nitrogen purge system in the attic to reduce the potential for fire.\nThose fixes appeared to work as expected during the Starship's eighth test flight in March, but the upper stage again suffered a catastrophic failure. This time around, the Starship suffered a \"hardware failure in one of the upper stage Raptor engines that resulted in inadvertent propellant mixing and ignition,\" SpaceX said on its website.\nTo fix the problem, upper stage Raptors now feature a new nitrogen purge system, improvements to the propellant drain system and tighter joints in key areas. SpaceX is also developing an improved Raptor engine that will eliminate several failure modes.",
    "reference_list": "考点1： “Starship”应该译为“星舰”， SpaceX公司研发的飞船。\n考点2： “splashdown”应译为“溅落”，表示太空船落入海里。\n考点3： “Starbase“应译为“星港”。\n考点4： “angle of attack”应译为“迎角”，太空术语。\n考点5： “IFT”应译为“星舰轨道试飞任务”。\n考点6：“CBS”应译为“哥伦比亚广播公司”或保留CBS。\n考点7：“nitrogen purge system”应译为“氮气吹扫系统”。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "56"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n孕期是生命早期1000天中的第一个重要阶段。为了完成妊娠过程，孕妇的生理及代谢状态发生了较大适应性改变，总体营养需求增加，以满足孕期母亲生殖器官变化和胎儿的生长发育，并为产后泌乳储备营养。\n\n然而，随着经济发展和生活方式的改变，膳食摄入不合理、体重增长过多以及微量元素缺乏在部分孕妇人群中依然存在，这些问题都会影响母婴双方近期和远期健康。\n\n防宝宝畸形，叶酸不能少\n\n《健康生活方式核心要点（2023）》中建议孕妇适当补充叶酸、铁等微量营养素。妊娠早期缺乏叶酸可引起死胎、流产、脑和神经管畸形，还可导致口唇、心血管、骨骼等器官畸形。妊娠中晚期缺乏叶酸可能导致巨幼红细胞性贫血。建议女性从备孕前3个月开始每天补充0.4毫克叶酸。此外，还建议孕期常吃富含叶酸的食物，如动物肝脏、蛋类、豆类、绿叶蔬菜、水果及坚果等，但因为食物中的叶酸加热易分解，影响吸收利用，因此不能代替叶酸补充剂。 \n\n防孕期贫血，补铁是关键\n\n孕中期的女性对铁的需求量增加，如果铁的摄入量不足，可能会发生缺铁性贫血，这对孕妇和胎儿都会造成不利影响。铁的推荐摄入量为：孕早期20毫克/天、孕中期24毫克/天、孕晚期29毫克/天。孕妇可每周吃1-2次动物内脏或血，也可在医生指导下服用膳食铁补充剂。也可以适量摄入含维生素C较多的水果和蔬菜，例如鲜枣、甜椒等，有助于提高膳食铁的吸收与利用率。\n\n保骨骼健康，补钙很重要\n\n孕期缺钙，女性可能会出现骨质疏松、腿抽筋和牙齿松动的情况，对胎儿也会带来比较严重的影响，如大脑发育迟缓、先天性佝偻病等。奶类是钙良好的来源，从备孕期开始建议女性每日摄入奶类300克，孕中期增加至每日300-500克，如果不习惯喝牛奶，选择酸奶也是可以的，或是吃一些虾皮、海鱼、豆制品等含钙丰富的食物。维生素D可以促进钙吸收，对胎儿骨、牙齿的形成非常重要。孕妇平均每天晒太阳10-20分钟所合成的维生素D基本上能够满足身体的需要。\n\n保胎儿发育，碘盐海产少不了\n\n孕妇缺碘将影响胎儿发育及智力，严重的还会引起先兆流产、早产、胚胎停育和死胎等情况。我国地理环境普遍缺碘，因而国家采用食盐加碘的方式进行强化。孕期对碘的需要量增加，按每天摄入5克碘盐计算，孕妇每周还应额外摄入1-2次富含碘的海产食品，如海带、紫菜、贝类等。\n\n孕妇营养的补充，不仅要充足，还要适当，既要避免营养不良，也要防止营养过剩。践行健康的生活方式，做到食物多样，总量控制，践行“三减”也很重要。",
    "ori_text": "孕期是生命早期1000天中的第一个重要阶段。为了完成妊娠过程，孕妇的生理及代谢状态发生了较大适应性改变，总体营养需求增加，以满足孕期母亲生殖器官变化和胎儿的生长发育，并为产后泌乳储备营养。\n\n然而，随着经济发展和生活方式的改变，膳食摄入不合理、体重增长过多以及微量元素缺乏在部分孕妇人群中依然存在，这些问题都会影响母婴双方近期和远期健康。\n\n防宝宝畸形，叶酸不能少\n\n《健康生活方式核心要点（2023）》中建议孕妇适当补充叶酸、铁等微量营养素。妊娠早期缺乏叶酸可引起死胎、流产、脑和神经管畸形，还可导致口唇、心血管、骨骼等器官畸形。妊娠中晚期缺乏叶酸可能导致巨幼红细胞性贫血。建议女性从备孕前3个月开始每天补充0.4毫克叶酸。此外，还建议孕期常吃富含叶酸的食物，如动物肝脏、蛋类、豆类、绿叶蔬菜、水果及坚果等，但因为食物中的叶酸加热易分解，影响吸收利用，因此不能代替叶酸补充剂。 \n\n防孕期贫血，补铁是关键\n\n孕中期的女性对铁的需求量增加，如果铁的摄入量不足，可能会发生缺铁性贫血，这对孕妇和胎儿都会造成不利影响。铁的推荐摄入量为：孕早期20毫克/天、孕中期24毫克/天、孕晚期29毫克/天。孕妇可每周吃1-2次动物内脏或血，也可在医生指导下服用膳食铁补充剂。也可以适量摄入含维生素C较多的水果和蔬菜，例如鲜枣、甜椒等，有助于提高膳食铁的吸收与利用率。\n\n保骨骼健康，补钙很重要\n\n孕期缺钙，女性可能会出现骨质疏松、腿抽筋和牙齿松动的情况，对胎儿也会带来比较严重的影响，如大脑发育迟缓、先天性佝偻病等。奶类是钙良好的来源，从备孕期开始建议女性每日摄入奶类300克，孕中期增加至每日300-500克，如果不习惯喝牛奶，选择酸奶也是可以的，或是吃一些虾皮、海鱼、豆制品等含钙丰富的食物。维生素D可以促进钙吸收，对胎儿骨、牙齿的形成非常重要。孕妇平均每天晒太阳10-20分钟所合成的维生素D基本上能够满足身体的需要。\n\n保胎儿发育，碘盐海产少不了\n\n孕妇缺碘将影响胎儿发育及智力，严重的还会引起先兆流产、早产、胚胎停育和死胎等情况。我国地理环境普遍缺碘，因而国家采用食盐加碘的方式进行强化。孕期对碘的需要量增加，按每天摄入5克碘盐计算，孕妇每周还应额外摄入1-2次富含碘的海产食品，如海带、紫菜、贝类等。\n\n孕妇营养的补充，不仅要充足，还要适当，既要避免营养不良，也要防止营养过剩。践行健康的生活方式，做到食物多样，总量控制，践行“三减”也很重要。",
    "reference_list": "考点1：《健康生活方式核心要点（2023）》需译为 The Core Points for a Healthy Lifestyle (2023)。\n考点2：心血管 需译为 cardiovascular，不可译为heart。\n考点3：内脏 可译为offal或organ，不可译为liver。\n考点4：“也可以适量摄入含维生素C较多的水果和蔬菜”必须翻译完整，不能漏译任何内容，特别是“适量”。\n考点5：“孕妇平均每天晒太阳10-20分钟所合成的维生素D基本上能够满足身体的需要”必须翻译完整，不能漏译任何内容，特别是“孕妇”。\n考点6：“采用食盐加碘的方式进行强化”必须翻译完整，不能漏译任何内容。\n考点7：紫菜 可译为 laver，不可译为“seaweed”。\n考点8：三减 译为 Three Reductions (reducing salt, oil, and sugar) 或 Three Reductions。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "8"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n研究材料包括以下内容：  \n\n1.   人口统计问卷  ：调查年龄、性别、母语、飞行经验和训练阶段；  \n2.   罗森伯格自尊量表（Rosenberg, 1979）  ：该量表包含10个陈述项，参与者需使用4点李克特量表（1=“强烈不同意”至4=“强烈同意”）表明对每项陈述的认同程度。其中一半条目为反向计分。该量表最高得分为40分，得分越高，表明自尊水平越高。  \n3.   洛克等人（Locke et al., 1984）自我效能量表的修订版  ：洛克等人的原量表要求受试者在1分钟内尽可能多地列出一个常见物品的用途，随后填写自我效能量表，测量两个维度——  幅度  （即受试者能列出的用途数量，最多16项，在A栏中以“是/否”记录）和  强度  （在B栏中，受试者需以0%-100%表示对自己表现的确定程度）。自我效能分数为所有强度得分的总和，分数越高，表明自我效能强度越高。  \n\n在本研究中，自我效能的测量调整为评估参与者对飞行能力的信心，具体为能否在20英尺的增量范围内（±20英尺、±40英尺等）保持目标高度（1,000英尺）。与洛克等人的方法一致，本研究设置了8个幅度测量项（如“保持1,000英尺±20英尺”“保持1,000英尺±40英尺”等），要求受试者回答“能”或“不能”（是/否），而强度测量则要求受试者以0%-100%表示对自己表现的确定程度。自我效能分数为所有强度得分的总和（与洛克等人1984年的方法一致）。  \n\n4.   反馈语气感知问题  ：题目为“请指出您在飞行中接收到的反馈语气（仅圈选一项）：积极、中性、消极。”  \n5.   飞行数据参考表  ：列出Frasca飞行模拟器操作的目标高度、空速和航线程序；  \n6.   三种音频反馈脚本（积极、中性、消极语气）  ：具体描述如下。  \n\n音频反馈脚本由一名英语母语的女性录制。所有脚本内容相同，仅根据参与者在基线飞行的下风段表现调整两个关键词（以  粗体  标出）。脚本内容为：  \n\n>   “下风段的目标高度为1,000英尺；您的高度  偏低/偏高  。保持下风段1,000英尺的高度非常重要。”    \n\n为确保脚本语气尽可能接近研究的三种目标语气，进行了预实验。共使用6种录音脚本，每种语气（积极、中性、消极）各2种。对于每种语气，第一种脚本用于飞行员在下风段高度偏高的情况（脚本中提示“您的高度  偏高  ”），第二种脚本用于高度偏低的情况（提示“您的高度  偏低  ”）。  \n\n6种脚本变体的制作流程如下：首先招募4名女性朗读脚本，并由6名参与者（3名英语母语者，平均年龄27.67岁，SD=3.79；3名非英语母语者，平均年龄24.00岁，SD=1.73）进行语气评估（判断为“积极”“中性”或“消极”）。最终选择评估一致性最高的女性录音（Fleiss’ Kappa显示评估者间一致性较高，κ=0.763，95% CI [0.615, 0.910]，p<0.001）。  \n\n飞行模拟设置    \n实验在UNSW Bankstown飞行操作中心的Frasca飞行模拟器中进行。该模拟器配置为模拟Diamond DA40飞机，并获准用于飞行训练。模拟天气条件为  CAVOK  （晴空无云，能见度极佳），风向多变（风速5节），湍流等级设为5/10（模拟轻至中度湍流）。两名合格飞行教官测试后确认该设置能反映需参与者努力保持高度的气象条件，且符合晴天常见湍流情况。模拟过程中未发生故障，燃油消耗导致的重量变化正常模拟。飞机模拟重量设为1,150公斤（模拟两人满载燃油）。  \n\n反馈录音通过Apple MacBook Pro播放，参与者使用Beyerdynamic DT770 PRO监听耳机收听。播放前调整音量至清晰可听，参与者可自行调节。模拟器配备Garmin G1000电子航电系统，可记录气压高度等飞行参数。飞行数据通过SD卡导出至Microsoft Excel分析，计算平均高度偏差以确定反馈类型（偏高/偏低）。  \n\n实验流程\n参与者从UNSW飞行操作中心招募，在理论课上介绍研究目的（仅提及“反馈对表现的影响”，未说明语气因素），自愿报名者安排实验时间。实验当天，参与者按到场顺序随机分配至三种反馈语气组之一，随后填写三份问卷（人口统计、自我效能、自尊）。完成后，提供  飞行数据参考表  （含关键性能参数，如起飞速度、爬升速度、下风段目标高度、进近和着陆速度），供全程参考。  \n\n接着进行  熟悉飞行  （约15分钟），模拟从Bankstown机场29L跑道起飞，帮助参与者适应模拟器。随后，参与者接受指令，在Bankstown机场11R跑道完成一次右航线全停着陆，需遵循检查单和UNSW发布的飞行程序。模拟天气条件同前（CAVOK、风向多变5节、气压1013 hPa、湍流等级5）。  \n\n基线飞行结束后，提取下风段（起点S33.942 E150.987，终点S33.925 E150.964）的高度数据，计算平均高度偏差，按随机分配的反馈语气组播放预录反馈。随后进行  测试飞行  （再次完成11R跑道右航线全停着陆）。结束后，参与者回答反馈语气感知问题，获赠20美元礼品卡致谢。全程耗时约1小时。  \n\n反馈语气对表现的影响    \n在分析语气对飞行表现的影响前，先检验分组随机化效果。以年龄和基线飞行平均绝对高度偏差为变量进行单因素方差分析（α=0.05），结果显示三组无显著差异（年龄：F(2,35)=0.76, p=0.476, η²=0.04）。  \n\n为控制飞行经验的影响，计算飞行总时长与基线飞行高度偏差的Pearson相关系数（α=0.05），结果无显著相关性（r(36)=-0.207, p=0.212）。  \n\n随后进行3×2×2（反馈语气×自我效能×自尊）组间方差分析。反馈语气分三水平（积极/中性/消极），自我效能和自尊各分高低两组（按中位数划分）。在满足正态性和方差齐性条件下（α=0.05），结果显示  反馈语气主效应显著  （见表2），无其他主效应或交互作用。LSD事后检验表明，积极语气组（M=23.18, SD=16.07）的高度偏差显著大于中性组（M=9.55, SD=4.78; p=0.009）和消极组（M=11.46, SD=8.11; p=0.025），中性与消极组无差异（p=0.700）。  \n\n由于并非所有参与者准确感知分配的语气（见表3），进一步以  感知语气  （而非实际语气）为自变量进行二次方差分析，结果无显著主效应或交互作用（见表4），表明  感知语气不影响表现  。  \n\n语言背景可能影响语气解读，但卡方检验显示母语与非母语飞行员对语气的准确判断比例相近（约58%，见表5）。",
    "ori_text": "\n\n研究材料包括以下内容：  \n\n1.   人口统计问卷  ：调查年龄、性别、母语、飞行经验和训练阶段；  \n2.   罗森伯格自尊量表（Rosenberg, 1979）  ：该量表包含10个陈述项，参与者需使用4点李克特量表（1=“强烈不同意”至4=“强烈同意”）表明对每项陈述的认同程度。其中一半条目为反向计分。该量表最高得分为40分，得分越高，表明自尊水平越高。  \n3.   洛克等人（Locke et al., 1984）自我效能量表的修订版  ：洛克等人的原量表要求受试者在1分钟内尽可能多地列出一个常见物品的用途，随后填写自我效能量表，测量两个维度——  幅度  （即受试者能列出的用途数量，最多16项，在A栏中以“是/否”记录）和  强度  （在B栏中，受试者需以0%-100%表示对自己表现的确定程度）。自我效能分数为所有强度得分的总和，分数越高，表明自我效能强度越高。  \n\n在本研究中，自我效能的测量调整为评估参与者对飞行能力的信心，具体为能否在20英尺的增量范围内（±20英尺、±40英尺等）保持目标高度（1,000英尺）。与洛克等人的方法一致，本研究设置了8个幅度测量项（如“保持1,000英尺±20英尺”“保持1,000英尺±40英尺”等），要求受试者回答“能”或“不能”（是/否），而强度测量则要求受试者以0%-100%表示对自己表现的确定程度。自我效能分数为所有强度得分的总和（与洛克等人1984年的方法一致）。  \n\n4.   反馈语气感知问题  ：题目为“请指出您在飞行中接收到的反馈语气（仅圈选一项）：积极、中性、消极。”  \n5.   飞行数据参考表  ：列出Frasca飞行模拟器操作的目标高度、空速和航线程序；  \n6.   三种音频反馈脚本（积极、中性、消极语气）  ：具体描述如下。  \n\n音频反馈脚本由一名英语母语的女性录制。所有脚本内容相同，仅根据参与者在基线飞行的下风段表现调整两个关键词（以  粗体  标出）。脚本内容为：  \n\n>   “下风段的目标高度为1,000英尺；您的高度  偏低/偏高  。保持下风段1,000英尺的高度非常重要。”    \n\n为确保脚本语气尽可能接近研究的三种目标语气，进行了预实验。共使用6种录音脚本，每种语气（积极、中性、消极）各2种。对于每种语气，第一种脚本用于飞行员在下风段高度偏高的情况（脚本中提示“您的高度  偏高  ”），第二种脚本用于高度偏低的情况（提示“您的高度  偏低  ”）。  \n\n6种脚本变体的制作流程如下：首先招募4名女性朗读脚本，并由6名参与者（3名英语母语者，平均年龄27.67岁，SD=3.79；3名非英语母语者，平均年龄24.00岁，SD=1.73）进行语气评估（判断为“积极”“中性”或“消极”）。最终选择评估一致性最高的女性录音（Fleiss’ Kappa显示评估者间一致性较高，κ=0.763，95% CI [0.615, 0.910]，p<0.001）。  \n\n飞行模拟设置    \n实验在UNSW Bankstown飞行操作中心的Frasca飞行模拟器中进行。该模拟器配置为模拟Diamond DA40飞机，并获准用于飞行训练。模拟天气条件为  CAVOK  （晴空无云，能见度极佳），风向多变（风速5节），湍流等级设为5/10（模拟轻至中度湍流）。两名合格飞行教官测试后确认该设置能反映需参与者努力保持高度的气象条件，且符合晴天常见湍流情况。模拟过程中未发生故障，燃油消耗导致的重量变化正常模拟。飞机模拟重量设为1,150公斤（模拟两人满载燃油）。  \n\n反馈录音通过Apple MacBook Pro播放，参与者使用Beyerdynamic DT770 PRO监听耳机收听。播放前调整音量至清晰可听，参与者可自行调节。模拟器配备Garmin G1000电子航电系统，可记录气压高度等飞行参数。飞行数据通过SD卡导出至Microsoft Excel分析，计算平均高度偏差以确定反馈类型（偏高/偏低）。  \n\n实验流程\n参与者从UNSW飞行操作中心招募，在理论课上介绍研究目的（仅提及“反馈对表现的影响”，未说明语气因素），自愿报名者安排实验时间。实验当天，参与者按到场顺序随机分配至三种反馈语气组之一，随后填写三份问卷（人口统计、自我效能、自尊）。完成后，提供  飞行数据参考表  （含关键性能参数，如起飞速度、爬升速度、下风段目标高度、进近和着陆速度），供全程参考。  \n\n接着进行  熟悉飞行  （约15分钟），模拟从Bankstown机场29L跑道起飞，帮助参与者适应模拟器。随后，参与者接受指令，在Bankstown机场11R跑道完成一次右航线全停着陆，需遵循检查单和UNSW发布的飞行程序。模拟天气条件同前（CAVOK、风向多变5节、气压1013 hPa、湍流等级5）。  \n\n基线飞行结束后，提取下风段（起点S33.942 E150.987，终点S33.925 E150.964）的高度数据，计算平均高度偏差，按随机分配的反馈语气组播放预录反馈。随后进行  测试飞行  （再次完成11R跑道右航线全停着陆）。结束后，参与者回答反馈语气感知问题，获赠20美元礼品卡致谢。全程耗时约1小时。  \n\n反馈语气对表现的影响    \n在分析语气对飞行表现的影响前，先检验分组随机化效果。以年龄和基线飞行平均绝对高度偏差为变量进行单因素方差分析（α=0.05），结果显示三组无显著差异（年龄：F(2,35)=0.76, p=0.476, η²=0.04）。  \n\n为控制飞行经验的影响，计算飞行总时长与基线飞行高度偏差的Pearson相关系数（α=0.05），结果无显著相关性（r(36)=-0.207, p=0.212）。  \n\n随后进行3×2×2（反馈语气×自我效能×自尊）组间方差分析。反馈语气分三水平（积极/中性/消极），自我效能和自尊各分高低两组（按中位数划分）。在满足正态性和方差齐性条件下（α=0.05），结果显示  反馈语气主效应显著  （见表2），无其他主效应或交互作用。LSD事后检验表明，积极语气组（M=23.18, SD=16.07）的高度偏差显著大于中性组（M=9.55, SD=4.78; p=0.009）和消极组（M=11.46, SD=8.11; p=0.025），中性与消极组无差异（p=0.700）。  \n\n由于并非所有参与者准确感知分配的语气（见表3），进一步以  感知语气  （而非实际语气）为自变量进行二次方差分析，结果无显著主效应或交互作用（见表4），表明  感知语气不影响表现  。  \n\n语言背景可能影响语气解读，但卡方检验显示母语与非母语飞行员对语气的准确判断比例相近（约58%，见表5）。",
    "reference_list": "考点1. \"反向计分\"推荐翻译为\"Reverse-Scored (Items)\"\n考点2. \"监听耳机\"推荐翻译为\"Aviation Headset\"\n考点3. \"高度偏差\"推荐翻译为\"Altitude Deviation\"\n考点4. \"积极/中性/消极语气\"推荐翻译为\"Positive/Neutral/Negative Tone\"\n考点5. \"飞行数据参考表\"推荐翻译为\"Flight Data Reference Sheet\"\n考点6. “二次方差分析”推荐翻译为“a second ANOVA”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "137"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nChapter ⅠGENERAL PRINCIPLES (Articles 1-3)\n\nArticle 1\n\nThe Belt and Road News Network (hereinafter referred to as “BRNN”) is jointly established by media organizations from countries and regions involved in the Belt and Road Initiative, aiming to strengthen understanding, friendship and cooperation, and form a normalized mechanism for collaboration.\n\nArticle 2\n\nTo achieve shared growth through discussion and collaboration, BRNN shall adhere to the principles of mutual respect, equal consultation, mutual assistance and benefits, and voluntarism, as well as uphold the Silk Road spirit characterized by “peace and cooperation, openness and inclusiveness, mutual learning and mutual benefit.” BRNN will give full play to the media's social role, tap into the unique advantages of media in communication, and build an open, cooperative platform. BRNN is committed to facilitating policy coordination, facility connectivity, unimpeded trade, financial integration, and people-to-people bonds among countries and regions jointly building the Belt and Road. BRNN is also committed to turning the Belt and Road into a road of peace, prosperity, openness, green development, innovation and togetherness for different civilizations. BRNN promotes the development of international relations, better understanding and mutual trust among all countries involved, as well as cultural and friendly exchanges between the people who live there, and contributes to regional economic prosperity, world peace and development.\n\nArticle 3\n\nThe BRNN headquarters is located in Beijing, China.\n\nChapter Ⅱ PRIMARY FUNCTIONS (Articles 4-7)\n\nArticle 4\n\nTo build an open and cooperative platform. BRNN is committed to creating a platform for exchange and cooperation among media organizations of countries and regions involved in the Belt and Road Initiative, establishing operational mechanisms, and boosting project cooperation. BRNN shall enhance multilateral cooperation among its members, push forward the integration of resources, convergence of channels, combination of advantages, information aggregation, and marketing collaboration, as well as facilitate personnel exchanges, mutual assistance in reporting, content exchanges, technology exchanges, and mutual sharing of experiences. BRNN will set up a collaborative mechanism for sub-sectors such as photo and information, radio, audiovisual and documentary.\n\nArticle 5\n\nTo promote mutual assistance, collaboration and exchange. BRNN shall, on the basis of extensive consultations, organize mutual visits among its members for better understanding and cooperation. It shall hold media cooperation forums and dialogues under the theme of the Belt and Road Initiative, arrange activities such as joint reporting trips and award programs, and organize seminars, training workshops and programs. The purpose of these events is to promote dialogue and idea exchange, encourage media innovation, and to jointly combat the everyday challenges of the media industry.\n\nArticle 6\n\nTo carry out pragmatic cooperation in innovative ways. Based on respect and copyright protection, BRNN shall strengthen content cooperation exchange and information sharing among its members, following their agreement. Furthermore, BRNN shall establish a website and an aggregated platform for the distribution of news information, providing members with free content uploading and sharing services in text, image, audio and video mediums, and will thus facilitate their news content cooperation directly and conveniently. It will support and help media organizations to cooperate in areas such as page layout, channel creation, time swap, and news coverage. BRNN shall also deepen operational cooperation including exhibitions, filming co-production, copyright trading, and advertisement exchange to enhance practical cooperation, promote resource integration and achieve shared interests. The BRNN shall enhance technological collaboration, in such ways as carrying out themed activities, providing specific services, conducting cooperative research on big data and artificial intelligence, and improving technologies in the field of new media, especially the cutting-edge technologies of social media.\n\nArticle 7\n\nTo strengthen research on major issues. BRNN shall gather information, investigate, and conduct policy research on important, pressing and difficult issues relating to the joint construction of the Belt and Road Initiative. BRNN shall pool this wisdom and propose specific, constructive, and proactive suggestions on jointly building the Belt and Road, the purpose being to provide intellectual and public support for joint construction of the Belt and Road.\n\nChapter III Organization (Articles 8-13)\n\nArticle 8\n\nBRNN membership. Members must meet the following requirements:\n\n1. They must voluntarily join the Network;\n\n2. They must support the Charter;\n\n3. They must have certain influence in the country and region where they are located.\n\nArticle 9\n\nThe council of BRNN is responsible for making decisions on key issues regarding the development of BRNN. The council consists members worldwide and has a chair assumed by People’s Daily (China). The chair is responsible for convening council meetings and work coordination meetings. It shall also supervise and push forward the implementation of the major work of BRNN by means of communication and coordination activities. Each council shall have a term of two years.\n\nArticle 10\n\nThe secretariat of BRNN shall be the permanent office of BRNN. The secretariat is located at People's Daily, and is responsible for daily operations, fundraising, activity organization, and implementation of the decisions of the council.\n\nArticle 11\n\nBRNN adopts an invitation system for membership and authorizes the secretariat to undertake the related work. The secretariat will invite media organizations that meet the membership requirements, and media organizations can join BRNN after submitting relevant application materials. The secretariat shall report the accession of new members to the council.\n\nArticle 12\n\nAny member who wishes to withdraw from BRNN shall inform the secretariat in writing, at which point the secretariat will report to the council. If a member commits a serious violation of the Charter, the member may be removed by council vote.\n\nArticle 13\n\nMembers of BRNN are granted the following rights and obligations.\n\n1. Members’ rights: Obtain various services provided by BRNN; participate in activities organized by BRNN, such as annual meetings and forums; receive materials from BRNN such as briefings; enjoy the freedom to join or withdraw from BRNN.\n\n2. Members’ obligations: Comply with the Charter; actively participate in activities held by BRNN; protect the rights, interests and the reputation of BRNN.\n\n \n\nChapter Ⅳ Operational Mechanism (Articles 14-16)\n\nArticle 14\n\nBRNN shall organize meetings every two years for members to enhance partnerships, and take measures to boost cooperation through consultation and discussion.\n\nArticle 15\n\nBRNN shall hold the council meeting aperiodically, as needed, to study the major issues surrounding the development of BRNN. The council may propose relevant guiding initiatives for reference after consultations among the participating council members.\n\nArticle 16\n\nBRNN provides the following services to its members:\n\n1. Organize cooperation and exchange activities. BRNN shall organize visits among members and other visiting activities, annual meetings and forums for members, as well as the signing of bilateral and multilateral cooperative agreements.\n\n2. Provide a news service platform. BRNN shall establish a website and a mobile platform for collecting and distributing information for members.\n\n3. Promote resource sharing among members. BRNN shall build the Belt and Road database with open access to all members to provide news materials for members. BRNN shall facilitate copyright cooperation and the swap of advertisement resources among members.\n\n4. Organize joint reporting trips. BRNN shall organize cross-border joint reporting trips themed on the Belt and Road for its members to enhance their communication strength and influence.\n\n5. Design professional training programs. Based on common needs and choices of members, BRNN shall organize various training programs of different durations of time and different topics in different regions. The content may include news reporting, media convergence and technology.\n\n6. Provide technological support for media. BRNN shall provide technological support in news coverage, media development, transformation and upgrading in line with the practical needs of members.\n\n7. Set up Belt and Road media awards. BRNN shall set up the Belt and Road all-media prize with clear standards for selection and expert judges recommended by member media organizations through consultation to guarantee fairness. Strive to make it a global news award with international influence.\n\n8. Provide other tailored and customized services according to Members’ needs.\n\n \n\nChapter V Supplementary Provisions (Articles 17-20)\n\nArticle 17\n\nThe charter shall take effect on the approval of the council.\n\nArticle 18\n\nAny amendment to the Charter shall be decided by the council after discussion.\n\nArticle 19\n\nThe secretariat reserves the right of final interpretation of the Charter.\n\nArticle 20\n\nThe charter was originally written in Chinese, from which the English version has been translated. In case of any discrepancy between the Chinese and the English versions of the above Articles, the Chinese version shall prevail.\n",
    "ori_text": "\n\nChapter ⅠGENERAL PRINCIPLES (Articles 1-3)\n\nArticle 1\n\nThe Belt and Road News Network (hereinafter referred to as “BRNN”) is jointly established by media organizations from countries and regions involved in the Belt and Road Initiative, aiming to strengthen understanding, friendship and cooperation, and form a normalized mechanism for collaboration.\n\nArticle 2\n\nTo achieve shared growth through discussion and collaboration, BRNN shall adhere to the principles of mutual respect, equal consultation, mutual assistance and benefits, and voluntarism, as well as uphold the Silk Road spirit characterized by “peace and cooperation, openness and inclusiveness, mutual learning and mutual benefit.” BRNN will give full play to the media's social role, tap into the unique advantages of media in communication, and build an open, cooperative platform. BRNN is committed to facilitating policy coordination, facility connectivity, unimpeded trade, financial integration, and people-to-people bonds among countries and regions jointly building the Belt and Road. BRNN is also committed to turning the Belt and Road into a road of peace, prosperity, openness, green development, innovation and togetherness for different civilizations. BRNN promotes the development of international relations, better understanding and mutual trust among all countries involved, as well as cultural and friendly exchanges between the people who live there, and contributes to regional economic prosperity, world peace and development.\n\nArticle 3\n\nThe BRNN headquarters is located in Beijing, China.\n\nChapter Ⅱ PRIMARY FUNCTIONS (Articles 4-7)\n\nArticle 4\n\nTo build an open and cooperative platform. BRNN is committed to creating a platform for exchange and cooperation among media organizations of countries and regions involved in the Belt and Road Initiative, establishing operational mechanisms, and boosting project cooperation. BRNN shall enhance multilateral cooperation among its members, push forward the integration of resources, convergence of channels, combination of advantages, information aggregation, and marketing collaboration, as well as facilitate personnel exchanges, mutual assistance in reporting, content exchanges, technology exchanges, and mutual sharing of experiences. BRNN will set up a collaborative mechanism for sub-sectors such as photo and information, radio, audiovisual and documentary.\n\nArticle 5\n\nTo promote mutual assistance, collaboration and exchange. BRNN shall, on the basis of extensive consultations, organize mutual visits among its members for better understanding and cooperation. It shall hold media cooperation forums and dialogues under the theme of the Belt and Road Initiative, arrange activities such as joint reporting trips and award programs, and organize seminars, training workshops and programs. The purpose of these events is to promote dialogue and idea exchange, encourage media innovation, and to jointly combat the everyday challenges of the media industry.\n\nArticle 6\n\nTo carry out pragmatic cooperation in innovative ways. Based on respect and copyright protection, BRNN shall strengthen content cooperation exchange and information sharing among its members, following their agreement. Furthermore, BRNN shall establish a website and an aggregated platform for the distribution of news information, providing members with free content uploading and sharing services in text, image, audio and video mediums, and will thus facilitate their news content cooperation directly and conveniently. It will support and help media organizations to cooperate in areas such as page layout, channel creation, time swap, and news coverage. BRNN shall also deepen operational cooperation including exhibitions, filming co-production, copyright trading, and advertisement exchange to enhance practical cooperation, promote resource integration and achieve shared interests. The BRNN shall enhance technological collaboration, in such ways as carrying out themed activities, providing specific services, conducting cooperative research on big data and artificial intelligence, and improving technologies in the field of new media, especially the cutting-edge technologies of social media.\n\nArticle 7\n\nTo strengthen research on major issues. BRNN shall gather information, investigate, and conduct policy research on important, pressing and difficult issues relating to the joint construction of the Belt and Road Initiative. BRNN shall pool this wisdom and propose specific, constructive, and proactive suggestions on jointly building the Belt and Road, the purpose being to provide intellectual and public support for joint construction of the Belt and Road.\n\nChapter III Organization (Articles 8-13)\n\nArticle 8\n\nBRNN membership. Members must meet the following requirements:\n\n1. They must voluntarily join the Network;\n\n2. They must support the Charter;\n\n3. They must have certain influence in the country and region where they are located.\n\nArticle 9\n\nThe council of BRNN is responsible for making decisions on key issues regarding the development of BRNN. The council consists members worldwide and has a chair assumed by People’s Daily (China). The chair is responsible for convening council meetings and work coordination meetings. It shall also supervise and push forward the implementation of the major work of BRNN by means of communication and coordination activities. Each council shall have a term of two years.\n\nArticle 10\n\nThe secretariat of BRNN shall be the permanent office of BRNN. The secretariat is located at People's Daily, and is responsible for daily operations, fundraising, activity organization, and implementation of the decisions of the council.\n\nArticle 11\n\nBRNN adopts an invitation system for membership and authorizes the secretariat to undertake the related work. The secretariat will invite media organizations that meet the membership requirements, and media organizations can join BRNN after submitting relevant application materials. The secretariat shall report the accession of new members to the council.\n\nArticle 12\n\nAny member who wishes to withdraw from BRNN shall inform the secretariat in writing, at which point the secretariat will report to the council. If a member commits a serious violation of the Charter, the member may be removed by council vote.\n\nArticle 13\n\nMembers of BRNN are granted the following rights and obligations.\n\n1. Members’ rights: Obtain various services provided by BRNN; participate in activities organized by BRNN, such as annual meetings and forums; receive materials from BRNN such as briefings; enjoy the freedom to join or withdraw from BRNN.\n\n2. Members’ obligations: Comply with the Charter; actively participate in activities held by BRNN; protect the rights, interests and the reputation of BRNN.\n\n \n\nChapter Ⅳ Operational Mechanism (Articles 14-16)\n\nArticle 14\n\nBRNN shall organize meetings every two years for members to enhance partnerships, and take measures to boost cooperation through consultation and discussion.\n\nArticle 15\n\nBRNN shall hold the council meeting aperiodically, as needed, to study the major issues surrounding the development of BRNN. The council may propose relevant guiding initiatives for reference after consultations among the participating council members.\n\nArticle 16\n\nBRNN provides the following services to its members:\n\n1. Organize cooperation and exchange activities. BRNN shall organize visits among members and other visiting activities, annual meetings and forums for members, as well as the signing of bilateral and multilateral cooperative agreements.\n\n2. Provide a news service platform. BRNN shall establish a website and a mobile platform for collecting and distributing information for members.\n\n3. Promote resource sharing among members. BRNN shall build the Belt and Road database with open access to all members to provide news materials for members. BRNN shall facilitate copyright cooperation and the swap of advertisement resources among members.\n\n4. Organize joint reporting trips. BRNN shall organize cross-border joint reporting trips themed on the Belt and Road for its members to enhance their communication strength and influence.\n\n5. Design professional training programs. Based on common needs and choices of members, BRNN shall organize various training programs of different durations of time and different topics in different regions. The content may include news reporting, media convergence and technology.\n\n6. Provide technological support for media. BRNN shall provide technological support in news coverage, media development, transformation and upgrading in line with the practical needs of members.\n\n7. Set up Belt and Road media awards. BRNN shall set up the Belt and Road all-media prize with clear standards for selection and expert judges recommended by member media organizations through consultation to guarantee fairness. Strive to make it a global news award with international influence.\n\n8. Provide other tailored and customized services according to Members’ needs.\n\n \n\nChapter V Supplementary Provisions (Articles 17-20)\n\nArticle 17\n\nThe charter shall take effect on the approval of the council.\n\nArticle 18\n\nAny amendment to the Charter shall be decided by the council after discussion.\n\nArticle 19\n\nThe secretariat reserves the right of final interpretation of the Charter.\n\nArticle 20\n\nThe charter was originally written in Chinese, from which the English version has been translated. In case of any discrepancy between the Chinese and the English versions of the above Articles, the Chinese version shall prevail.\n",
    "reference_list": "考点1：“a normalized mechanism for collaboration”必须译为“常态化协作机制”\n考点2： \"mutual respect, equal consultation, mutual assistance and benefits, and voluntarism”必须译为“相互尊重、平等协商、互助互利、自主自愿”\n考点3：\"tap into\"推荐翻译为“彰显”\n考点4：“better understanding and mutual trust”必须译为“友好交往和文化交流互鉴”\n考点5：“countries and regions involved in the Belt and Road Initiative”必须译为“一带一路共建国家”\n考点6：“facilitate personnel exchanges, mutual assistance in reporting, content exchanges, technology exchanges, and mutual sharing of experiences”必须译为“人员互访、采访互助、内容互换、技术互学、经验互鉴”\n考点7：”audiovisual“必须译为”视听“\n考点8：”following their agreement“必须译为”自愿协商“\n考点9：” specific, constructive, and proactive“必须译为”针对性、建设性、前瞻性“\n考点10：”chair“必须译为”理事长“\n考点11：” a mobile platform for collecting and distributing information“必须译为”移动端聚合分发平台“\n考点12：” Belt and Road media awards. “推荐翻译为”国际传播“丝路”奖“",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "142"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n1993年，26岁的王祖贤跟随祖父一起回到安徽舒城老家，为家乡捐资5万元，修建了安徽第一条村建柏油路。乡亲们为了感恩王祖贤，把这条路命名为“祖贤路”。时至今日，祖贤路依然是石岗村的主干道。它见证了中国30年的飞速发展，也见证了一代女神王祖贤的跌宕起伏。\n90年代初，王祖贤已经红遍整个亚洲。尤其是在韩国，她和周润发的受欢迎程度，已经盖过了韩国本土明星。韩国大街小巷到处可见王祖贤的海报。有一次韩媒为了拍照，特意堵在王祖贤的活动现场，而王祖贤却悄悄从后台溜走，因此得罪了韩国媒体。\n可即便如此，韩国民众对王祖贤的喜爱依旧半分未减。不过王祖贤倒也无所谓，不管是韩媒对自己有意见，还是韩民众追捧热度下降，她也丝毫不以为意。\n除了韩国市场，国内的市场同样火热。王祖贤回到台湾拍摄，这一次同时接拍了《灵狐》和《阿婴》。她对《阿婴》这部作品，抱有很高的期望，一直希望带着这部作品上颁奖典礼。所以全身心扑在工作上。结果，忙碌起来她连休息的时间都没有，最后把身体都搞垮了。1990年8月，王祖贤感染肠炎被送去住院。当时她手上还有四部戏在拍，但为了健康着想，不得不推掉这四部戏。正因如此，王祖贤才萌生了退意。加上那一年，她的那部抱有希望的《阿婴》无缘金马奖，王祖贤更是失落万分……\n不过就在她的名气冷却时，又在日本市场渐渐火热起来。当时有一个日本的电影杂志，在评选最受欢迎的外国女明星时，王祖贤成为TOP1，一举收获了无数日本影迷。王祖贤的事业得以维持下去。但是王祖贤一直有一个愿望，就是打破“小倩”的标签，让自己能够塑造更多经典角色，在观众心目中留下印象。只是迟迟没能实现这个愿望。就拿91年和成龙合作的《城市猎人》来说，王祖贤虽然是女主角，但依旧没有给人太深刻的印象。\n去北京参演《画皮》时，王祖贤感慨很多。她在片场度过了自己25岁的生日。剧组随后去了山西五台山，在这佛门圣地，对王祖贤的心境影响颇深。同时，她也想起了自己的祖籍安徽……\n王祖贤这个名字家喻户晓的同时，她的身世也逐渐被更多人知道。王祖贤虽然在台湾出生，但她祖籍在安徽舒城。王家在安徽是书香世家，她的曾祖父王仁峰，是赫赫有名的人物。\n王仁峰早年受到中山先生的影响，从而投身革命，加入同盟会。1910年南京起义时，王仁峰也是成员之一，他擅长制造弹药。可当时条件有限，王仁峰的每一次实验都置身危险之中。一次制作炸弹时，刚好是春天，天气比较潮湿，有几根雷管失灵，王仁峰和几位战友用锤子轻轻敲打，结果炸弹瞬间爆炸了！\n王仁峰手臂被炸伤，巨大的爆炸声还吸引了清军，他们只能匆匆躲在一个草垛里。就这么躲了三天，这才获救。可因为没有及时得到救治，这条胳膊也保不住了。从此以后他便有了“王一手”的名号。他为革命事业立下汗马功劳。\n后来，他又回乡创办了舒城中学。至今学校仍有他的雕像。就在王祖贤出生后三个月，曾祖父便去世了。王祖贤的爷爷王国璠继承了这份事业，之后在舒城担任教师。1949年与家人定居台湾。爷爷一直以来的梦想，就是回到内地。他还以为有生之年这个梦想实现不了，谁知，孙女帮他实现了这个心愿。",
    "ori_text": "1993年，26岁的王祖贤跟随祖父一起回到安徽舒城老家，为家乡捐资5万元，修建了安徽第一条村建柏油路。乡亲们为了感恩王祖贤，把这条路命名为“祖贤路”。时至今日，祖贤路依然是石岗村的主干道。它见证了中国30年的飞速发展，也见证了一代女神王祖贤的跌宕起伏。\n90年代初，王祖贤已经红遍整个亚洲。尤其是在韩国，她和周润发的受欢迎程度，已经盖过了韩国本土明星。韩国大街小巷到处可见王祖贤的海报。有一次韩媒为了拍照，特意堵在王祖贤的活动现场，而王祖贤却悄悄从后台溜走，因此得罪了韩国媒体。\n可即便如此，韩国民众对王祖贤的喜爱依旧半分未减。不过王祖贤倒也无所谓，不管是韩媒对自己有意见，还是韩民众追捧热度下降，她也丝毫不以为意。\n除了韩国市场，国内的市场同样火热。王祖贤回到台湾拍摄，这一次同时接拍了《灵狐》和《阿婴》。她对《阿婴》这部作品，抱有很高的期望，一直希望带着这部作品上颁奖典礼。所以全身心扑在工作上。结果，忙碌起来她连休息的时间都没有，最后把身体都搞垮了。1990年8月，王祖贤感染肠炎被送去住院。当时她手上还有四部戏在拍，但为了健康着想，不得不推掉这四部戏。正因如此，王祖贤才萌生了退意。加上那一年，她的那部抱有希望的《阿婴》无缘金马奖，王祖贤更是失落万分……\n不过就在她的名气冷却时，又在日本市场渐渐火热起来。当时有一个日本的电影杂志，在评选最受欢迎的外国女明星时，王祖贤成为TOP1，一举收获了无数日本影迷。王祖贤的事业得以维持下去。但是王祖贤一直有一个愿望，就是打破“小倩”的标签，让自己能够塑造更多经典角色，在观众心目中留下印象。只是迟迟没能实现这个愿望。就拿91年和成龙合作的《城市猎人》来说，王祖贤虽然是女主角，但依旧没有给人太深刻的印象。\n去北京参演《画皮》时，王祖贤感慨很多。她在片场度过了自己25岁的生日。剧组随后去了山西五台山，在这佛门圣地，对王祖贤的心境影响颇深。同时，她也想起了自己的祖籍安徽……\n王祖贤这个名字家喻户晓的同时，她的身世也逐渐被更多人知道。王祖贤虽然在台湾出生，但她祖籍在安徽舒城。王家在安徽是书香世家，她的曾祖父王仁峰，是赫赫有名的人物。\n王仁峰早年受到中山先生的影响，从而投身革命，加入同盟会。1910年南京起义时，王仁峰也是成员之一，他擅长制造弹药。可当时条件有限，王仁峰的每一次实验都置身危险之中。一次制作炸弹时，刚好是春天，天气比较潮湿，有几根雷管失灵，王仁峰和几位战友用锤子轻轻敲打，结果炸弹瞬间爆炸了！\n王仁峰手臂被炸伤，巨大的爆炸声还吸引了清军，他们只能匆匆躲在一个草垛里。就这么躲了三天，这才获救。可因为没有及时得到救治，这条胳膊也保不住了。从此以后他便有了“王一手”的名号。他为革命事业立下汗马功劳。\n后来，他又回乡创办了舒城中学。至今学校仍有他的雕像。就在王祖贤出生后三个月，曾祖父便去世了。王祖贤的爷爷王国璠继承了这份事业，之后在舒城担任教师。1949年与家人定居台湾。爷爷一直以来的梦想，就是回到内地。他还以为有生之年这个梦想实现不了，谁知，孙女帮他实现了这个心愿。",
    "reference_list": "考点1：“扑在工作上”推荐译为“threw herself into her work”。\n考点2：“无缘金马奖”推荐译为“was snubbed by the Golden Horse Awards”。\n考点3：“心境‘’推荐译为“state of mind”。\n考点4：“书香世家‘’推荐译为“a family of scholars”或a scholarly family都可以;\n考点5：“王一手”推荐译为“One-armed Wang”。\n考点6：”立下汗马功劳”推荐译为“made outstanding contributions”。\n考点7：《灵狐》应翻译为“Fox Legend”，\n考点8：《阿婴》应翻译为“Ming Ghost”",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "传记",
    "prompt_id": "41"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n\n任务\n\n体质人类学阐述人类生物学上的发生及其进化方面的课题；确定人类同其他灵长类动物之间的差别；还要给各人种之间体质上的差异进行分类。\n\n现代体质人类学开始形成于19世纪前半期，自从达尔文《物种起源》于1859年发表后，进化论对体质人类学的发展产生巨大推动作用。达尔文的另一著作《人类的由来及性别选择》（The Descent of Man and Selection in Relation to Sex, 1871）也是一本重要论著，第一次提出了有关人类起源的有科学根据的假说。到1859∼1900年之际，人类学者承认，人种发展进化的历史可溯至几十万年以前，而不是像过去所想的只有几千年。\n\n20世纪早期，科学家揭示出遗传学上的各种原理和ABO血型，这有助于体质人类学者们对不同人种之间的变异和差别进行研究，同时由于相对的和绝对的年代测定方法的发展，也使得人类学者们能够确定人类化石和其他人造器物的年龄。\n\n研究重点\n\n人种进化的过程。这方面包括发现过去人类化石遗存并加以描述以及分析这些骨化石明显特点的重要意义，因为遗传物质是进化史高度可靠的“指示器”，所以，对于不同人种之间和人类与其他动物之间的遗传密码、染色体、线粒体、去氧核糖核酸进行比较分析，已证明在广泛的人类学研究领域是一项行之有效的新方法。\n\n体质人类学对于至少可以上溯200万年这一段时期内的人类体质方面的进化情况，提出了很多解释。\n\n分类\n\n根据所探讨的问题和所采用的研究方法的不同，传统上体质人类学再被细分成灵长目学、古人类学、种族人类学、人种测量学等分支学科。\n\n灵长目学主要通过比较人与其他灵长类动物在身体构造和行为上的异同来探讨人类在自然界的位置。\n\n古人类学通过考古发掘出来的古代人类骨骼、古人类及与之近似的动物化石来研究人类的起源和进化、演变过程。\n\n种族人类学主要研究种族分类、种族的起源和演变、种族体征差异的意义。不同种族的人体测量学主要对人类各种群的体质进行测量，对各种族的肤色、发型、头型和体质进行分类和比较研究。随着科学研究的深入发展，体质人类学不断同有关学科相结合，又产生了诸如优生学、营养人类学、医药人类学、分子人类学等边缘分支学科。\n\n意义\n\n体质人类学对人们客观地认识自身，扫除迷信，反对种族歧视和种族压迫，改善人们的卫生健康状况，促进社会经济繁荣发展等方面起着十分重要的作用。\n\n发展历程\n\n中国的体质人类学的萌芽可以上溯到2500年前战国时代的中医经典著作《黄帝内经》，该书记载了不同地域人类的体质特征，骨骼和内脏器官度量等方面的资料。\n\n汉代以后，随着中西交通的发展，中国文献中对不同体质特征的人群记载也日益增多，反映了对人类体质特征的初步观察。\n\n北宋时期的王惟一（公元1026年）著有《铜人腧穴针灸图经》，其所铸造的经络铜人是世界上最早最精巧的人体模型。刘昉（公元1150年）等的《幼幼新书》最早记录了先天性畸形的资料。\n\n南宋末年，宋慈（约1247年）的《洗冤集录》包含有体质人类学的萌芽。\n\n明代的王圻、王思义编写的《三才图会》记载有对人类五官形态的分类。这些虽然不是真正意义上的体质人类学研究，但却是对人类体质研究的早期萌芽。\n\n现代体质人类学是在19、20世纪之交开始从国外传入我国的。体质人类学在中国的百年发展历史可以大致分为四个阶段，即19、20世纪之交至20世纪20年代末的传入和接受时期，20世纪30年代至1949年的本土化时期，1949年至1976年的曲折发展时期，20世纪70年代末以来的纵深发展时期。",
    "ori_text": "任务\n\n体质人类学阐述人类生物学上的发生及其进化方面的课题；确定人类同其他灵长类动物之间的差别；还要给各人种之间体质上的差异进行分类。\n\n现代体质人类学开始形成于19世纪前半期，自从达尔文《物种起源》于1859年发表后，进化论对体质人类学的发展产生巨大推动作用。达尔文的另一著作《人类的由来及性别选择》（The Descent of Man and Selection in Relation to Sex, 1871）也是一本重要论著，第一次提出了有关人类起源的有科学根据的假说。到1859∼1900年之际，人类学者承认，人种发展进化的历史可溯至几十万年以前，而不是像过去所想的只有几千年。\n\n20世纪早期，科学家揭示出遗传学上的各种原理和ABO血型，这有助于体质人类学者们对不同人种之间的变异和差别进行研究，同时由于相对的和绝对的年代测定方法的发展，也使得人类学者们能够确定人类化石和其他人造器物的年龄。\n\n研究重点\n\n人种进化的过程。这方面包括发现过去人类化石遗存并加以描述以及分析这些骨化石明显特点的重要意义，因为遗传物质是进化史高度可靠的“指示器”，所以，对于不同人种之间和人类与其他动物之间的遗传密码、染色体、线粒体、去氧核糖核酸进行比较分析，已证明在广泛的人类学研究领域是一项行之有效的新方法。\n\n体质人类学对于至少可以上溯200万年这一段时期内的人类体质方面的进化情况，提出了很多解释。\n\n分类\n\n根据所探讨的问题和所采用的研究方法的不同，传统上体质人类学再被细分成灵长目学、古人类学、种族人类学、人种测量学等分支学科。\n\n灵长目学主要通过比较人与其他灵长类动物在身体构造和行为上的异同来探讨人类在自然界的位置。\n\n古人类学通过考古发掘出来的古代人类骨骼、古人类及与之近似的动物化石来研究人类的起源和进化、演变过程。\n\n种族人类学主要研究种族分类、种族的起源和演变、种族体征差异的意义。不同种族的人体测量学主要对人类各种群的体质进行测量，对各种族的肤色、发型、头型和体质进行分类和比较研究。随着科学研究的深入发展，体质人类学不断同有关学科相结合，又产生了诸如优生学、营养人类学、医药人类学、分子人类学等边缘分支学科。\n\n意义\n\n体质人类学对人们客观地认识自身，扫除迷信，反对种族歧视和种族压迫，改善人们的卫生健康状况，促进社会经济繁荣发展等方面起着十分重要的作用。\n\n发展历程\n\n中国的体质人类学的萌芽可以上溯到2500年前战国时代的中医经典著作《黄帝内经》，该书记载了不同地域人类的体质特征，骨骼和内脏器官度量等方面的资料。\n\n汉代以后，随着中西交通的发展，中国文献中对不同体质特征的人群记载也日益增多，反映了对人类体质特征的初步观察。\n\n北宋时期的王惟一（公元1026年）著有《铜人腧穴针灸图经》，其所铸造的经络铜人是世界上最早最精巧的人体模型。刘昉（公元1150年）等的《幼幼新书》最早记录了先天性畸形的资料。\n\n南宋末年，宋慈（约1247年）的《洗冤集录》包含有体质人类学的萌芽。\n\n明代的王圻、王思义编写的《三才图会》记载有对人类五官形态的分类。这些虽然不是真正意义上的体质人类学研究，但却是对人类体质研究的早期萌芽。\n\n现代体质人类学是在19、20世纪之交开始从国外传入我国的。体质人类学在中国的百年发展历史可以大致分为四个阶段，即19、20世纪之交至20世纪20年代末的传入和接受时期，20世纪30年代至1949年的本土化时期，1949年至1976年的曲折发展时期，20世纪70年代末以来的纵深发展时期。",
    "reference_list": "考点1：《铜人腧穴针灸图经》 应译为 \"Illustrated Manual of Acupuncture Points on Bronze Figures\"\n考点 2：《经络铜人》 应译为 \"Bronze Acupuncture Figure\"\n考点 3：《幼幼新书》 应译为 \"Newly Compiled Book for the Care of Infants\"\n考点4：《洗冤集录》应译为“Collected Cases of Injustice Rectified”\n考点5：《三才图会》应译为“Sancai Tuhui”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "93"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n特朗普对华日韩25%关税：贸易保护主义的全球冲击波\n引言：单边主义的回归\n2025年7月7日，华盛顿的夏日骄阳炙烤着白宫南草坪，而美国总统特朗普在社交媒体上投下的一枚\"关税炸弹\"，让全球金融市场瞬间降温。这位以\"美国优先\"为口号的前总统，在重返椭圆形办公室半年后，宣布自8月1日起对日本和韩国所有输美产品征收25%的惩罚性关税，理由是\"两国长期对美存在巨额贸易逆差，已威胁美国经济安全\"。这一决定不仅使美日韩三边关系降至冰点，更引发了全球贸易体系的剧烈震荡——道琼斯工业指数当日暴跌422点，日元对美元汇率创三年来最大单日跌幅，而丰田、三星等跨国巨头的市值一夜蒸发超500亿美元。\n特朗普在致日本首相石破茂和韩国总统李在明的信件中冷酷地写道：\"25%这一数字远远低于消除我们与贵国之间贸易逆差所需的水平。\"这种近乎最后通牒的语气，揭示了此次关税政策的本质——不是简单的贸易平衡工具，而是美国重塑全球产业链的战略武器。当白宫同时宣布将\"对等关税\"暂缓期延长至8月1日时，外界终于明白：这不是谈判的筹码，而是单边行动的预告。\n政策解构：关税大棒的三重逻辑\n特朗普政府的关税政策构建在一套看似自洽却充满矛盾的逻辑体系之上。最表层的是贸易逆差论，美国商务部数据显示，2024年美对日贸易逆差达678亿美元，对韩逆差582亿美元，合计占美国全球贸易逆差的18%。但深入分析可见，逆差主要集中在汽车（日本占美进口汽车市场份额34%）和半导体（韩国占美芯片进口47%）领域，而美国在农产品、能源和服务贸易上对华韩保持顺差。将特定行业失衡夸大为\"国家安全威胁\"，暴露了数据背后的政治算计。\n更深层的产业回流战略体现在政策细节中：特朗普明确表示\"在美国境内建厂的公司无需缴纳此项关税\"。这种\"关税+补贴\"的组合拳，实质是逼迫丰田、现代等企业将亚洲产能转移至美国。美国财政部长贝森特毫不掩饰地表示：\"这将创造至少50万个制造业岗位\"，却对这些岗位背后的政府补贴成本（预计年均230亿美元）讳莫如深。韩国产业通商资源部测算显示，若三星将西安半导体工厂部分产能转移至亚利桑那州，生产成本将上升37%。\n最具争议的是盟友施压逻辑。特朗普政府打破了美国战后对盟友的\"关税豁免传统\"，将日韩剧变为与中国、印度同等的关税适用对象。白宫官员私下透露，此举旨在\"测试盟友在经济主权上的让步底线\"，为后续逼迫日韩在半导体出口管制、5G建设等议题上配合美国铺路。这种\"经济杠杆化\"外交，使美日韩安全同盟与经济利益产生剧烈撕扯——驻日美军70%的后勤补给依赖日本企业，而韩国尹锡悦政府刚宣布增加12%国防预算以配合美国印太战略。\n",
    "ori_text": "特朗普对华日韩25%关税：贸易保护主义的全球冲击波\n引言：单边主义的回归\n2025年7月7日，华盛顿的夏日骄阳炙烤着白宫南草坪，而美国总统特朗普在社交媒体上投下的一枚\"关税炸弹\"，让全球金融市场瞬间降温。这位以\"美国优先\"为口号的前总统，在重返椭圆形办公室半年后，宣布自8月1日起对日本和韩国所有输美产品征收25%的惩罚性关税，理由是\"两国长期对美存在巨额贸易逆差，已威胁美国经济安全\"。这一决定不仅使美日韩三边关系降至冰点，更引发了全球贸易体系的剧烈震荡——道琼斯工业指数当日暴跌422点，日元对美元汇率创三年来最大单日跌幅，而丰田、三星等跨国巨头的市值一夜蒸发超500亿美元。\n特朗普在致日本首相石破茂和韩国总统李在明的信件中冷酷地写道：\"25%这一数字远远低于消除我们与贵国之间贸易逆差所需的水平。\"这种近乎最后通牒的语气，揭示了此次关税政策的本质——不是简单的贸易平衡工具，而是美国重塑全球产业链的战略武器。当白宫同时宣布将\"对等关税\"暂缓期延长至8月1日时，外界终于明白：这不是谈判的筹码，而是单边行动的预告。\n政策解构：关税大棒的三重逻辑\n特朗普政府的关税政策构建在一套看似自洽却充满矛盾的逻辑体系之上。最表层的是贸易逆差论，美国商务部数据显示，2024年美对日贸易逆差达678亿美元，对韩逆差582亿美元，合计占美国全球贸易逆差的18%。但深入分析可见，逆差主要集中在汽车（日本占美进口汽车市场份额34%）和半导体（韩国占美芯片进口47%）领域，而美国在农产品、能源和服务贸易上对华韩保持顺差。将特定行业失衡夸大为\"国家安全威胁\"，暴露了数据背后的政治算计。\n更深层的产业回流战略体现在政策细节中：特朗普明确表示\"在美国境内建厂的公司无需缴纳此项关税\"。这种\"关税+补贴\"的组合拳，实质是逼迫丰田、现代等企业将亚洲产能转移至美国。美国财政部长贝森特毫不掩饰地表示：\"这将创造至少50万个制造业岗位\"，却对这些岗位背后的政府补贴成本（预计年均230亿美元）讳莫如深。韩国产业通商资源部测算显示，若三星将西安半导体工厂部分产能转移至亚利桑那州，生产成本将上升37%。\n最具争议的是盟友施压逻辑。特朗普政府打破了美国战后对盟友的\"关税豁免传统\"，将日韩剧变为与中国、印度同等的关税适用对象。白宫官员私下透露，此举旨在\"测试盟友在经济主权上的让步底线\"，为后续逼迫日韩在半导体出口管制、5G建设等议题上配合美国铺路。这种\"经济杠杆化\"外交，使美日韩安全同盟与经济利益产生剧烈撕扯——驻日美军70%的后勤补给依赖日本企业，而韩国尹锡悦政府刚宣布增加12%国防预算以配合美国印太战略。\n",
    "reference_list": "考点1： “石破茂”应译为“Shigeru Ishiba / Ishiba Shigeru”，人名。\n考点2：“李在明”应译为“Lee Jae-myung” \n考点3： “财政部长贝森特”应译为“Treasury Secretary Bessent”，人名和官职。\n考点4：“关税+补贴”译文需避免保留“+”，建议把“+”意译为“and”这种能体现出并列关系的表达",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "57"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n　　自2018年安徽高考英语新题型 “任务型阅读”揭晓已有四年了，虽也是阅读，但其解题思路发生了变化。面对新的提醒，许多学生感觉无从下手。其实这样一个新的题型，对教师还是对学生都是一个新的挑战。如何有效地了解和掌握它的答题要求和技巧，适应考试的新变化，成为我们关注的焦点。　　\n任务型读写的特点：\n　　任务型阅读是语言运用类的试题，考察学生把握文章的篇章结构，获得直接信息，和综合处理信息的能力，符合新课程标准的要求及增加主观试题这个考试方向。它要求考生在阅读完一段材料后，能比较清楚地把握整篇文章的结构，较好地分析作者的观点和意图，并进行准确的表达。考生要能够获得直接信息，分析、总结信息，进而转换信息。\n　　任务型阅读文篇的题材是多种多样的，可以是说明文，记叙文或议论文。从表面上看，任务型阅读是考查学生的单词拼写能力，但是和单句的单词拼写有着极大的不同，任务型阅读考查是是考生对语篇的分析能力，它要求学生解剖文章的“脉络”，辨认语言结构，内容，事物发展的顺序和程序。学生答题是找寻信息的过程，同事也是筛选，归纳和表述信息进行的过程。也就是说不仅要求获得信息，还要求科学地表述信息。在解题的过程中，阅读能力和书面表达能力同时发挥着作用。任务型阅读试题实际上考查的能力主要为：1.获得信息的能力，即理解文章意思的能力；2.组织信息的能力,即分析文章结构的能力; 3.逻辑排序的能力, 即或以时间, 或以地点; 或以情节等加以排序的能力; 4.抽象概括的能力,即提炼中心思想,或对某些事实和现象加以命名的能力; 5.意义转述的能力, 即用不同形式表达同一意思的能力等。\n　　任务型读写由两部分组成：阅读材料和表格。它要求考生阅读所给材料，填写完成表格中空缺的信息。阅读材料为一篇300字左右的文章，在文章后设10道小题，每小题1分，满分10分，所有题目都呈现表格中。要求学生在阅读理解的基础上，对信息进行加工并以表格的形式把加工后的信息准确有序地表达出来，表格中每空只填一个词。而空格的类型有三大类：1. 筛选类: 属于基础题,只要读懂文章大意, 就可以直接找到答案, 一般为原词。2. 加工整合类：要根据已获得的信息进行第二次加工，根据句型结构变化和语法要求，在分析原文句子的基础上，结合题目，填写出相关的不同词性的派生词，同义词或近义词等等。 3.总结概括类：难度较大，要能概括标题，段落大意，文章目的，结论等，考察综合表达的能力，需要推理；还有些需要进行归纳总结或转述句子。此外，在填空是务必要注意单词大小写，单复数，词性等。　　\n任务型阅读的解题思路：\n　　一、通读短文知大意（通读全文）\n　　读懂文章是解题的第一环节，也是关键的一步。读懂了短文，才能顺利地在表格中填出相关信息。平时训练中要提醒学生了解文章结构以及段落之间的逻辑关系，关注主题句，把握文章主旨。\n　　二、理解结构是基础（理解结构）\n　　结构指的是文章的结构和表格的结构。理清短文主体结构，了解短文的写作思路和线索结构，有助于加深对篇章内容的理解，同事短文的结构往往也是很重要的命题线索。",
    "ori_text": "　　自2018年安徽高考英语新题型 “任务型阅读”揭晓已有四年了，虽也是阅读，但其解题思路发生了变化。面对新的提醒，许多学生感觉无从下手。其实这样一个新的题型，对教师还是对学生都是一个新的挑战。如何有效地了解和掌握它的答题要求和技巧，适应考试的新变化，成为我们关注的焦点。　　\n任务型读写的特点：\n　　任务型阅读是语言运用类的试题，考察学生把握文章的篇章结构，获得直接信息，和综合处理信息的能力，符合新课程标准的要求及增加主观试题这个考试方向。它要求考生在阅读完一段材料后，能比较清楚地把握整篇文章的结构，较好地分析作者的观点和意图，并进行准确的表达。考生要能够获得直接信息，分析、总结信息，进而转换信息。\n　　任务型阅读文篇的题材是多种多样的，可以是说明文，记叙文或议论文。从表面上看，任务型阅读是考查学生的单词拼写能力，但是和单句的单词拼写有着极大的不同，任务型阅读考查是是考生对语篇的分析能力，它要求学生解剖文章的“脉络”，辨认语言结构，内容，事物发展的顺序和程序。学生答题是找寻信息的过程，同事也是筛选，归纳和表述信息进行的过程。也就是说不仅要求获得信息，还要求科学地表述信息。在解题的过程中，阅读能力和书面表达能力同时发挥着作用。任务型阅读试题实际上考查的能力主要为：1.获得信息的能力，即理解文章意思的能力；2.组织信息的能力,即分析文章结构的能力; 3.逻辑排序的能力, 即或以时间, 或以地点; 或以情节等加以排序的能力; 4.抽象概括的能力,即提炼中心思想,或对某些事实和现象加以命名的能力; 5.意义转述的能力, 即用不同形式表达同一意思的能力等。\n　　任务型读写由两部分组成：阅读材料和表格。它要求考生阅读所给材料，填写完成表格中空缺的信息。阅读材料为一篇300字左右的文章，在文章后设10道小题，每小题1分，满分10分，所有题目都呈现表格中。要求学生在阅读理解的基础上，对信息进行加工并以表格的形式把加工后的信息准确有序地表达出来，表格中每空只填一个词。而空格的类型有三大类：1. 筛选类: 属于基础题,只要读懂文章大意, 就可以直接找到答案, 一般为原词。2. 加工整合类：要根据已获得的信息进行第二次加工，根据句型结构变化和语法要求，在分析原文句子的基础上，结合题目，填写出相关的不同词性的派生词，同义词或近义词等等。 3.总结概括类：难度较大，要能概括标题，段落大意，文章目的，结论等，考察综合表达的能力，需要推理；还有些需要进行归纳总结或转述句子。此外，在填空是务必要注意单词大小写，单复数，词性等。　　\n任务型阅读的解题思路：\n　　一、通读短文知大意（通读全文）\n　　读懂文章是解题的第一环节，也是关键的一步。读懂了短文，才能顺利地在表格中填出相关信息。平时训练中要提醒学生了解文章结构以及段落之间的逻辑关系，关注主题句，把握文章主旨。\n　　二、理解结构是基础（理解结构）\n　　结构指的是文章的结构和表格的结构。理清短文主体结构，了解短文的写作思路和线索结构，有助于加深对篇章内容的理解，同事短文的结构往往也是很重要的命题线索。",
    "reference_list": "考点1：\"新课程标准\" 应译为 \"the New Curriculum Standards\"\n考点2：\"篇章结构\" 应译为 \"textual structure/discourse structure\"\n考点3：\"获得直接信息\" 应译为 \"extract direct information/obtain explicit information\"\n考点4：\"综合处理信息的能力\" 应译为 \"ability to synthesise and process information\"\n考点5：\"信息加工\" 应译为 \"information processing\"\n考点6：\"解剖文章的“脉络”\" 应译为 \"analyse the thread of the text/dissect the text structure\"\n考点7：\"段落大意\" 应译为 \"main idea of the paragraph/paragraph gist\"\n考点8：\"文章主旨\" 应译为 \"main theme of the article/central idea of the text\"\n考点9：\"通读全文\" 应译为 \"read through the whole passage\"\n考点10：\"命题线索\" 应译为 \"clues for test item design/question-setting cues\"",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "教育",
    "prompt_id": "77"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n1 INTRODUCTION TO THE UNESCO SITE\n1.1 Location\nCountry: Italy\nGeographical Coordinates (Central point of the site): \nLongitude: 45°94’84.84’’ N\nLatitude: 12°17’53.03’’ E\nLocated in the Northeast of Italy, in the Veneto Region, “Le colline del Prosecco e Valdobbiadene” was recognized as a World Heritage Site in 2019. The site is located entirely in the Province of Treviso. \nIt includes the municipalities of Vidor, Miane, Farra di Soligo, Pieve di Soligo, Follina, Cison di Valmarino, Refrontolo, San Pietro di Feletto, Revine Lago, Tarzo, Vittorio Veneto, and partial territories of Valdobbiadene. \nThe buffer zone includes the municipalities of Susegana, Conegliano, and San Vendemiano. Instead, the territories of the municipalities of Segusino, Moriago della Battaglia, Sernaglia della Battaglia, Santa Lucia di Piave, Mareno di Piave, Vazzola, Codogne, San Fior, Godega Sant’Urbano, Colle Umberto, Cordignano, Cappella are part of the commitment zone.\n1.2 Boundaries and the Zones that Make up the Site\nCore zone: 9.197,45 ha\nBuffer zone: 9.769,80 ha\nTotal: 18.967,25 ha\n\nThe site includes a core zone of 9,197.45 hectares surrounded by a buffer zone (Fig. 4) of 9,769.80 hectares, ensuring the protection of its ecological and cultural integrity. When identifying these zones, the peculiar geographical and historical individuality was taken into consideration, and not the administrative limits of the Province. In fact, the site is an example of a process of adaptation to a fraught and fragile peripheral territory in which a rural and cultural evolutionary landscape has been generated strongly characterized by viticulture. The physical nature of the site is interlinked with the historical facts, and the agricultural, social, and cultural characteristics developed on the property over time. \nThe tectonic hogback hill system has been, and will continue to be, a conditioning element of the territory characteristics and land use limitations. As a result of these agricultural limitations, a highly adaptive agricultural landscape has developed on ciglionature, which over time has proven to be the most efficient way to protect the soil and make the most of the hills' soil and climate characteristics. As can be seen in the Fig. 4 a commitment zone is introduced. This zone is useful in terms of site management, which, in the southern part of the site, takes the form of highly urbanized territories where services and infrastructure that logistically support the site are located, and accommodates the population working for or within the site.\nBased on the parameters described in the previous paragraphs the perimeters of the site are defined as\nNorth: the valleys separate the hills from the foothills \nWest: the Piave River\nSouthwest: the bottom of the foothills to the great Po Valley \n1.3 Characteristics of the Site\n1.3.1 Geomorphology \nThe Conegliano Valdobbiadene region is characterized by steep hogback hills formed through tectonic processes, alongside karst (typical landri) formations that dominate its southern zones. These hogbacks consist of stratified marl and rocky layers, shaped over millions of years by tectonic activity and erosion. Landri landscapes, which feature karst formations created by water erosion on softer rocks, further diversify the terrain. \nThe dynamic topography has necessitated innovative agricultural practices. The ciglioni terraces, a hallmark of this region, demonstrate both functionality and aesthetics, solidifying the landscape’s recognition as a cultural and agricultural landmark. These terraces not only mitigate soil erosion but also facilitate the cultivation of high-quality Prosecco grapes, leveraging the region’s unique geological conditions.\nAlso, the area has a unique geomorphological structure, making it a popular building material for centuries. The inhabitants used native stones for grinding stones, millstones, architraves, sills, columns, and statues for villa gardens. The paths along these structures offer stunning views and interactive experiences, making them sacred sites. Devotional climbs and Via Crucis, such as S. Augusta and Colle S. Paolo in Vittorio Veneto, S. Gallo in Soligo, and S. Francesco da Paola in Revine, are merely extensions of previous pagan worship sites. The valleys between the hogbacks are often uncontaminated and crossed by streams.\n\n1.3.2 The Hydrographical System\nAs can be seen in the hydrological map (Fig. 6) the area has significant water resources, including small glacial lakes, and numerous fluvial incisions like the Lierza, Crevada (Fig. 7), and Cervano streams which are very important since they characterize the length of the hogback face, rivers such as the Soligo and Monticano, and a considerable number of springs. The presence of numerous waterways allowed for a varied range of morphologies, such as unique landscapes and waterfalls (Fig. 8). The recursion of underlying morphological structures, highlighted by erosion, also contributes to landscape similarity. Groundwater springs and numerous streams ensure water supply, allowing for agricultural processing and industrial activities like weaving. The unique landscapes and morphologies of the area are influenced by the recursion of erosion-influenced underlying structures.\n\n1.3.3 Climate and Vegetation\nThe Köppen climatic classification classifies the site as Cfa, with C representing a temperate-hot and rainy climate, f indicating the presence of rainy precipitation, and for areas with hotter months exceeding 22°C. The average annual temperature is 12.6°C, and the average precipitation is 1099mm/year.\nThe area’s climate and geomorphology foster a rich diversity of vegetation. The vegetation is influenced by the area's climatic and geomorphological characteristics, such as steep, thickly wooded north-facing slopes and genus south-facing slopes colonized by thermophile forests and cultivations. The cool slopes are mainly populated by chestnut tree plant associations, with seasonal changes in appearance, particularly in spring with the flowering of yellow dogwood and white wild cherry trees (Fig. 12). The warmer slopes, characterized by manna ash or Querco-ostryeto, represent a less evolved portion due to disturbances and transformations. The southern portions are characterized by juniper and cypress trees, while the warmer wooded areas take on an interesting appearance in spring with dogwood flowering and many wild or previously cultivated fruit trees.\nThe forestry vegetation of the site is primarily classified as Orno-ostrieto tipico, a type of calcareous sedimentary substrate characterized by numerous species, mostly Fraxinus ornus, Ostrya carpinifoli, and Quercus pubescens. This forestry type is widespread in the Veneto region's Piedmont area and pre-alpine zone and is influenced by zones with more evolved soil structures or less wind exposure. The typical Ostrio-querceto is one of the more prevalent forestry types in the area, characterized by Quercus pubescens and a higher number of grass species.\nThe fundamental component of a landscape is crucial for defense against erosion, reducing hydrogeological risk, and improving soil structure and habitats for various species. The presence of a uniform forest cover in upper slopes controls water flow in lower elevations, while in lower hills, it forms a fundamental component of the landscape matrix (Fig. 13-14). The combination of terraced vineyards and woodlands in the proposed property can be understood as an integrated landscape system, with each element playing an essential role in the site's value. The widespread presence of forests and human-based viticulture contributes to the system's sustainability.\n\n1.3.3.1 The flora of the Conegliano Valdobbiadene DOCG territory vineyards\nThe Conegliano-Valdobbiadene DOCG area has been entrusted with optimizing and disseminating the biodiversity heritage of the UNESCO site. For the UNESCO nomination, an interactive guide, titled “Guida alla flora dei vigneti del territorio DOCG Conegliano-Valdobbiadene,” was developed as part of a project coordinated by the University of Padua in partnership with the University of Trieste. The guide includes about 450 species surveyed in the vineyards and semi-natural habitats adjacent to them. \nThis is not an exhaustive inventory of the site's flora, but a basic representation of the main plant species found along the roads of the vineyards. The area has natural and semi-natural habitats that are closely linked to the management of viticulture sites. Many of these habitats are recognized by the European Union under the Habitats Directive as key elements in biodiversity conservation. Priority habitat 6110, characterized by calcareous rupicolous grasslands, meadows, and forests, is a prime example of these habitats.\nHabitat 6210, semi-natural dry grassland, and bush-covered strips on calcareous substrates are considered a priority if they host important orchids. This habitat includes herbaceous or partly bushy formations, from dry to mesophilic, whose persistence is guaranteed by low-intensity management practices such as occasional mowing. The typical species of these formations is Bromus erectus, flanked by Bromus condensatus in areas with drier conditions. Other species of other families vary by the dryness of the conditions.\n\n1.3.4 Agrobiodiversity\nThe site’s landscape is characterized by the continuous relation between semi-natural habitats and agricultural areas, affecting vegetational and agricultural biodiversity. Such a relationship is crucial for the ecosystem's functionality and its services, including soil formation, pathogen control, pollination, and cultural, recreational, and educational valorization. Farmers in hills are increasingly integrating production with biodiversity, recognizing the long-term maintenance of environmental assets. A study comparing vineyards in complex landscapes to vineyards in simple landscapes found the former performing better since semi-natural habitats contributed to increased plant biodiversity. This effect is even enhanced when vineyards are in contact with a forest or meadow since this provides access to species living in semi-natural habitats to the vineyard and thus increases the specific richness. The most interesting aspects of the area's biodiversity are linked to the semi-natural habitats, with arid meadows home to interesting plant species like orchids, common yet typical species such as Anthyllis vulneraria, Artemisia alba, Bromus erectus, Bromus condensatus, Chrysopogon gryllus, Helianthemum nummularium, Koeleria pyramidata, Galium verum and Galium lucidum (see Fig 20), and vineyards with species typical of ruderal environments or permanent meadows used for haymaking.\nManagement practices applied to vineyards play a fundamental role in determining biodiversity patterns. Semi-natural habitats occurring in the area show multifunctionality, providing crucial ecosystem services, such as enhancing crop ecological stability, reducing pesticide use, increasing the populations of pollinators, reducing weeds, decreasing herbicide dispersion, and reducing erosion in cropland. The simplification of the landscape and conversion of semi-natural habitats can lead to the rapid depletion of the environmental heritage of the area. However, this trend can very well be reversed by favoring sustainable practices.\nEqually important for the territory's ecological responsiveness is the increase in forest formations, which are generally more extensive due to the abandonment of previously cultivated surfaces. The BTC analysis confirms that the expansion of the forest corresponds to higher values in 2007 than those in 1960 and, therefore, the growth in the system's capacity to produce plant biomass and resist external perturbations.\nDespite the challenges, the area has great potential to meet future challenges in a landscape complicated by global changes that increasingly require the reconciliation of biodiversity and production. The analysis underlines the importance of sustainable practices for protecting the environment and promoting biodiversity.",
    "ori_text": "\n\n1 INTRODUCTION TO THE UNESCO SITE\n1.1 Location\nCountry: Italy\nGeographical Coordinates (Central point of the site): \nLongitude: 45°94’84.84’’ N\nLatitude: 12°17’53.03’’ E\nLocated in the Northeast of Italy, in the Veneto Region, “Le colline del Prosecco e Valdobbiadene” was recognized as a World Heritage Site in 2019. The site is located entirely in the Province of Treviso. \nIt includes the municipalities of Vidor, Miane, Farra di Soligo, Pieve di Soligo, Follina, Cison di Valmarino, Refrontolo, San Pietro di Feletto, Revine Lago, Tarzo, Vittorio Veneto, and partial territories of Valdobbiadene. \nThe buffer zone includes the municipalities of Susegana, Conegliano, and San Vendemiano. Instead, the territories of the municipalities of Segusino, Moriago della Battaglia, Sernaglia della Battaglia, Santa Lucia di Piave, Mareno di Piave, Vazzola, Codogne, San Fior, Godega Sant’Urbano, Colle Umberto, Cordignano, Cappella are part of the commitment zone.\n1.2 Boundaries and the Zones that Make up the Site\nCore zone: 9.197,45 ha\nBuffer zone: 9.769,80 ha\nTotal: 18.967,25 ha\n\nThe site includes a core zone of 9,197.45 hectares surrounded by a buffer zone (Fig. 4) of 9,769.80 hectares, ensuring the protection of its ecological and cultural integrity. When identifying these zones, the peculiar geographical and historical individuality was taken into consideration, and not the administrative limits of the Province. In fact, the site is an example of a process of adaptation to a fraught and fragile peripheral territory in which a rural and cultural evolutionary landscape has been generated strongly characterized by viticulture. The physical nature of the site is interlinked with the historical facts, and the agricultural, social, and cultural characteristics developed on the property over time. \nThe tectonic hogback hill system has been, and will continue to be, a conditioning element of the territory characteristics and land use limitations. As a result of these agricultural limitations, a highly adaptive agricultural landscape has developed on ciglionature, which over time has proven to be the most efficient way to protect the soil and make the most of the hills' soil and climate characteristics. As can be seen in the Fig. 4 a commitment zone is introduced. This zone is useful in terms of site management, which, in the southern part of the site, takes the form of highly urbanized territories where services and infrastructure that logistically support the site are located, and accommodates the population working for or within the site.\nBased on the parameters described in the previous paragraphs the perimeters of the site are defined as\nNorth: the valleys separate the hills from the foothills \nWest: the Piave River\nSouthwest: the bottom of the foothills to the great Po Valley \n1.3 Characteristics of the Site\n1.3.1 Geomorphology \nThe Conegliano Valdobbiadene region is characterized by steep hogback hills formed through tectonic processes, alongside karst (typical landri) formations that dominate its southern zones. These hogbacks consist of stratified marl and rocky layers, shaped over millions of years by tectonic activity and erosion. Landri landscapes, which feature karst formations created by water erosion on softer rocks, further diversify the terrain. \nThe dynamic topography has necessitated innovative agricultural practices. The ciglioni terraces, a hallmark of this region, demonstrate both functionality and aesthetics, solidifying the landscape’s recognition as a cultural and agricultural landmark. These terraces not only mitigate soil erosion but also facilitate the cultivation of high-quality Prosecco grapes, leveraging the region’s unique geological conditions.\nAlso, the area has a unique geomorphological structure, making it a popular building material for centuries. The inhabitants used native stones for grinding stones, millstones, architraves, sills, columns, and statues for villa gardens. The paths along these structures offer stunning views and interactive experiences, making them sacred sites. Devotional climbs and Via Crucis, such as S. Augusta and Colle S. Paolo in Vittorio Veneto, S. Gallo in Soligo, and S. Francesco da Paola in Revine, are merely extensions of previous pagan worship sites. The valleys between the hogbacks are often uncontaminated and crossed by streams.\n\n1.3.2 The Hydrographical System\nAs can be seen in the hydrological map (Fig. 6) the area has significant water resources, including small glacial lakes, and numerous fluvial incisions like the Lierza, Crevada (Fig. 7), and Cervano streams which are very important since they characterize the length of the hogback face, rivers such as the Soligo and Monticano, and a considerable number of springs. The presence of numerous waterways allowed for a varied range of morphologies, such as unique landscapes and waterfalls (Fig. 8). The recursion of underlying morphological structures, highlighted by erosion, also contributes to landscape similarity. Groundwater springs and numerous streams ensure water supply, allowing for agricultural processing and industrial activities like weaving. The unique landscapes and morphologies of the area are influenced by the recursion of erosion-influenced underlying structures.\n\n1.3.3 Climate and Vegetation\nThe Köppen climatic classification classifies the site as Cfa, with C representing a temperate-hot and rainy climate, f indicating the presence of rainy precipitation, and for areas with hotter months exceeding 22°C. The average annual temperature is 12.6°C, and the average precipitation is 1099mm/year.\nThe area’s climate and geomorphology foster a rich diversity of vegetation. The vegetation is influenced by the area's climatic and geomorphological characteristics, such as steep, thickly wooded north-facing slopes and genus south-facing slopes colonized by thermophile forests and cultivations. The cool slopes are mainly populated by chestnut tree plant associations, with seasonal changes in appearance, particularly in spring with the flowering of yellow dogwood and white wild cherry trees (Fig. 12). The warmer slopes, characterized by manna ash or Querco-ostryeto, represent a less evolved portion due to disturbances and transformations. The southern portions are characterized by juniper and cypress trees, while the warmer wooded areas take on an interesting appearance in spring with dogwood flowering and many wild or previously cultivated fruit trees.\nThe forestry vegetation of the site is primarily classified as Orno-ostrieto tipico, a type of calcareous sedimentary substrate characterized by numerous species, mostly Fraxinus ornus, Ostrya carpinifoli, and Quercus pubescens. This forestry type is widespread in the Veneto region's Piedmont area and pre-alpine zone and is influenced by zones with more evolved soil structures or less wind exposure. The typical Ostrio-querceto is one of the more prevalent forestry types in the area, characterized by Quercus pubescens and a higher number of grass species.\nThe fundamental component of a landscape is crucial for defense against erosion, reducing hydrogeological risk, and improving soil structure and habitats for various species. The presence of a uniform forest cover in upper slopes controls water flow in lower elevations, while in lower hills, it forms a fundamental component of the landscape matrix (Fig. 13-14). The combination of terraced vineyards and woodlands in the proposed property can be understood as an integrated landscape system, with each element playing an essential role in the site's value. The widespread presence of forests and human-based viticulture contributes to the system's sustainability.\n\n1.3.3.1 The flora of the Conegliano Valdobbiadene DOCG territory vineyards\nThe Conegliano-Valdobbiadene DOCG area has been entrusted with optimizing and disseminating the biodiversity heritage of the UNESCO site. For the UNESCO nomination, an interactive guide, titled “Guida alla flora dei vigneti del territorio DOCG Conegliano-Valdobbiadene,” was developed as part of a project coordinated by the University of Padua in partnership with the University of Trieste. The guide includes about 450 species surveyed in the vineyards and semi-natural habitats adjacent to them. \nThis is not an exhaustive inventory of the site's flora, but a basic representation of the main plant species found along the roads of the vineyards. The area has natural and semi-natural habitats that are closely linked to the management of viticulture sites. Many of these habitats are recognized by the European Union under the Habitats Directive as key elements in biodiversity conservation. Priority habitat 6110, characterized by calcareous rupicolous grasslands, meadows, and forests, is a prime example of these habitats.\nHabitat 6210, semi-natural dry grassland, and bush-covered strips on calcareous substrates are considered a priority if they host important orchids. This habitat includes herbaceous or partly bushy formations, from dry to mesophilic, whose persistence is guaranteed by low-intensity management practices such as occasional mowing. The typical species of these formations is Bromus erectus, flanked by Bromus condensatus in areas with drier conditions. Other species of other families vary by the dryness of the conditions.\n\n1.3.4 Agrobiodiversity\nThe site’s landscape is characterized by the continuous relation between semi-natural habitats and agricultural areas, affecting vegetational and agricultural biodiversity. Such a relationship is crucial for the ecosystem's functionality and its services, including soil formation, pathogen control, pollination, and cultural, recreational, and educational valorization. Farmers in hills are increasingly integrating production with biodiversity, recognizing the long-term maintenance of environmental assets. A study comparing vineyards in complex landscapes to vineyards in simple landscapes found the former performing better since semi-natural habitats contributed to increased plant biodiversity. This effect is even enhanced when vineyards are in contact with a forest or meadow since this provides access to species living in semi-natural habitats to the vineyard and thus increases the specific richness. The most interesting aspects of the area's biodiversity are linked to the semi-natural habitats, with arid meadows home to interesting plant species like orchids, common yet typical species such as Anthyllis vulneraria, Artemisia alba, Bromus erectus, Bromus condensatus, Chrysopogon gryllus, Helianthemum nummularium, Koeleria pyramidata, Galium verum and Galium lucidum (see Fig 20), and vineyards with species typical of ruderal environments or permanent meadows used for haymaking.\nManagement practices applied to vineyards play a fundamental role in determining biodiversity patterns. Semi-natural habitats occurring in the area show multifunctionality, providing crucial ecosystem services, such as enhancing crop ecological stability, reducing pesticide use, increasing the populations of pollinators, reducing weeds, decreasing herbicide dispersion, and reducing erosion in cropland. The simplification of the landscape and conversion of semi-natural habitats can lead to the rapid depletion of the environmental heritage of the area. However, this trend can very well be reversed by favoring sustainable practices.\nEqually important for the territory's ecological responsiveness is the increase in forest formations, which are generally more extensive due to the abandonment of previously cultivated surfaces. The BTC analysis confirms that the expansion of the forest corresponds to higher values in 2007 than those in 1960 and, therefore, the growth in the system's capacity to produce plant biomass and resist external perturbations.\nDespite the challenges, the area has great potential to meet future challenges in a landscape complicated by global changes that increasingly require the reconciliation of biodiversity and production. The analysis underlines the importance of sustainable practices for protecting the environment and promoting biodiversity.",
    "reference_list": "考点1：“Valdobbiadene”推荐译为“瓦尔多比亚德内”\n考点2：“manna ash\" 必须译为“花白蜡树”,不可译为“槐叶槭” \n考点3：\"increasing the populations of pollinators\" 中的\"pollinators应译为“传粉昆虫”   \n考点4：“Valdobbiadene”必须统一译为“瓦尔多比亚代内”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "175"
  },
  {
    "prompt": "翻译：英文翻译成为中文。不要输出译文以外的内容。以下是你本次的任务：\nThe GNPC dataset represents a substantial advancement in neuro­degenerative disease research, by providing a real-world clinical pro­ teomic dataset that comprises over 35,000 (11,270 with APOE genotype) individuals across AD, FTD, PDD, PD, ALS and normal aging from across more than 20 clinical sites in the US, UK and Europe. This enabled us to ask whether the APOE ε4-associated proteomic signature is shared across multiple neurodegenerative diseases. Our results demonstrate that all APOE ε4 carriers, irrespective of neurodegenerative disease, have a unique proteome signature that extends across the plasma and CSF. Unlike prospectively designed cohorts, the GNPC dataset reflects real-world clinical heterogeneity, highlighting the robustness and generalizability of our findings. This signature is associated with pro-inflammatory immune dysregulation and an enrichment for circulating immune cells, including monocytes, memory CD8 and γδ T cells, Tregs and NK cells. This molecular phenotype extends to the brains of APOE ε4 carriers in a similar disease-independent manner and is not associated with the presence of any disease-specific brain pathology. Although all APOE ε4 carriers have a systemic immune-related proteome signature, we find that the relationships between proteins within this signature are uniquely associated with demographic, lifestyle, and clinical variables in a neurodegenerative disease-specific manner. Notably, this suggests that although the biological changes associated with APOE ε4 carriage are essential for neurodegeneration, broadly, interactions with underlying biological vulnerability and the environment may be key for driving the pathogenesis of the specific neurodegenerative disease.\n\nThere is evidence that the APOE ε4 genotype is a modern-day example of antagonistic pleiotropy. In younger adults, APOE ε4 is associated with increased survival and fertility in environments with high levels of infectious disease. For example, healthy individuals who are APOE ε4 heterozygotes exhibit heightened cytokine release, increased plasma TNF levels, a more pronounced hyperthermic response and an earlier onset of IL-6 production following immune challenge with TLR2/TLR4/TLR5 ligands or lipopolysaccharide. While this immune response protects younger APOE ε4 carriers from infectious diseases, prolonged states of inflammation and cytokine release are likely deleterious with age. Although this study identified a proteomic signature indicative of a pro-inflammatory phenotype, a limitation is the absence of direct measures of routine inflammatory markers such as C-reactive protein or cytokines. Future studies should incorporate these markers in prospectively designed cohorts to clarify their association with APOE ε4.\n\nTo date, the biological effects of APOE ε4 carriage have largely only been studied in the context of AD. A notable finding of our study is that the pro-inflammatory molecular phenotype associated with APOE ε4 extends to individuals with other neurodegenerative diseases, including FTD, PDD, PD and ALS. This raises two key considerations. First, our findings underscore the need to shift focus from the continued identification of genetic risk loci via genome-wide association studies toward functional characterization of established variants. Notably, the absence of a statistically significant association between a variant and a specific disease phenotype does not preclude biological relevance. Despite APOE ε4 being overrepresented in the AD cohort, we observe a consistent molecular signature associated with APOE ε4 across multiple neurodegenerative diseases, highlighting an underrecognized role for this variant beyond AD that may have been overlooked due to its historically strong link with AD risk. Second, our data support reconceptualizing APOE ε4 not only as a disease-specific risk factor but also as a broader susceptibility allele contributing to shared pathogenic mechanisms across neurodegenerative diseases. It remains unclear, however, why APOE ε4 is more strongly associated with AD in terms of prevalence despite exhibiting systemic biological effects across neurodegenerative diseases. One possibility is that interactions between APOE ε4 and additional age-related, environmental, or comorbid factors may selectively amplify neurodegenerative pathways characteristic of AD. Another possibility is that CNS-specific vulnerabilities or cellular contexts (for example, in hippocampal circuits or dopaminergic neurons) modulate how the APOE ε4 inflammatory phenotype manifests clinically. Thus, while APOE ε4 confers a shared biological susceptibility, disease expression likely depends on a combination of genetic background, cellular context(s), and lifetime exposures. Large-scale integrative efforts, such as the GNPC, which harmonize data across distinct disease cohorts into unified datasets, provide a powerful framework for advancing this line of inquiry. By enabling cross-disease comparisons, such efforts may help delineate modifiers that influence why some APOE ε4 carriers develop AD while others remain healthy or develop different neurodegenerative diseases. This has important implications for prognosis and risk stratification in midlife individuals who carry APOE ε4.\n\nA limitation of our study is the absence of validated biomarkers (for example, CSF p-tau217) to confirm clinical diagnoses, which reflects both the nature of the GNPC dataset and global heterogeneity in clinical practice. However, several features mitigate concerns regarding potential misdiagnosis. First, the APOE ε4 signature was derived from nonimpaired individuals. While it is possible that a minority of these nonimpaired individuals harbored asymptomatic pathology (for example, asymptomatic AD), the majority would be free of overt disease, reducing the likelihood of confounding results. Second, the consistent presence of the signature across all APOE ε4 carriers, irrespective of clinical diagnosis, supports its generalizability and suggests it reflects a broader APOE ε4-related biological phenotype rather than disease-specific changes. Finally, we validate our findings using postmortem brain proteomics and histopathology, where diagnostic certainty is highest. Here APOE ε4 status was not associated with hallmark pathologies, including amyloid-β, tau, TDP-43 or α-synuclein, across respective disease groups. This postmortem validation reinforces the robustness of our findings. Future studies would benefit from prospective cohorts incorporating validated CSF or plasma biomarkers to confirm and extend these observations.\n\nAn unexpected finding of our study was that plasma neurofilament light (NEFL) levels were lower in APOE ε4 carriers across neurodegenerative diseases, despite NEFL’s growing recognition as a biomarker of neurodegeneration. Prior studies have reported conflicting results— some found no association, another reported increased levels in APOE ε4 carriers, while others using the SomaScan and Simoa assays observed decreased levels, consistent with our findings. These discrepancies may reflect differences in sample size, with studies reporting decreased NEFL levels generally including larger cohorts (~600 to 5,000 participants, and 9,924 in our study). Alternatively, APOE ε4-related blood–brain barrier (BBB) or metabolic dysfunction may alter peripheral clearance of NEFL and affect its plasma or CSF concentration. These results raise important questions about the reliability of NEFL as a stand-alone biomarker and underscore the need for mechanistic studies and a shift toward precision biomarkers that integrate genetic and environmental context.\n\nIn our study, key peripheral inflammatory states in APOE ε4 carriers were mirrored in the CNS. Notably, brain proteomics performed using label-free MS orthogonally validated findings from SomaScan-based CSF and plasma analyses. While SomaScan aptamer technology offers high-throughput protein quantification, it is relatively insensitive to proteoform diversity, including post-translational modifications, a limitation when examining signaling pathways and protein networks where such modifications are functionally significant. In contrast, MS enables the detection of broader proteoforms, offering an independent assessment of protein abundance and pathway enrichment. The concordance of APOE ε4-associated protein signatures and enrichment patterns across plasma, CSF and brain proteomic datasets suggests that our findings are not artifacts of platform-specific biases but likely reflect underlying biology. Supporting this interpretation, we observed enrichment of APOE ε4-associated proteins in both hepatocytes and Kupffer cells in the CSF, but only in Kupffer cells and T cells in plasma. This pattern implies that plasma reflects chronic peripheral immune activation, whereas the CSF may capture liver-brain axis-mediated inflammatory signaling in APOE ε4 carriers. Further experimental studies are warranted to validate these mechanisms. Prospective cohort studies incorporating cross-platform, multi-tissue analyses from the same individuals will be essential to confirm and expand upon these observations.\n\nWhile the exact mechanisms underlying the mirroring of peripheral and central pro-inflammatory states remain unclear, they may involve interactions between pro-inflammatory peripheral immune cells and the BBB. A recent study of individuals with long COVID-19 demonstrated that hyperactive peripheral blood mononuclear cells adhere to the endothelial cells of the BBB, driving inflammation, degradation, and symptoms of brain fog. In support of this, cognitively healthy APOE ε4 carriers exhibit early markers of BBB dysfunction in the hippocampus and medial temporal lobe. As the BBB becomes increasingly compromised, it allows the infiltration of blood-derived proteins and pro-inflammatory immune cells into the brain, contributing to exacerbated neuroinflammation and neurodegeneration. In our study, we identify enriched pro-inflammatory immune cell subpopulations, including nonclassical and intermediate monocytes, memory CD8+ T cells, γδ T cells and NK cells. These immune cell types may represent peripheral blood mononuclear cells that interact with the BBB to promote neurodegeneration in APOE ε4 carriers. Given that APOE ε4 is linked to a shared molecular phenotype across neurodegenerative diseases, this hypothesis is consistent with current understanding. Healthy, nonimpaired APOE ε4 carriers have a systemic pro-inflammatory phenotype (and as we have shown here), early signs of BBB disruption, alterations in brain activity and connectivity, and sleep disturbances, all of which are known to be risk factors for neurodegenerative diseases, broadly. Further supporting this is the recent evidence that vaccinations protect against dementia, including the shingles vaccines Zostavax and Shingrix. Although none of these studies explicitly examined the interactive effects between vaccination status and APOE ε4 genotype, the fact that more than 60% of individuals with dementia are APOE ε4 carriers suggests that APOE ε4 may represent a critical modifier of the observed associations, warranting further investigation. Future studies in human disease-relevant models, such as patient stem cell-derived organoids, are needed to further elucidate these mechanisms.",
    "ori_text": "\nThe GNPC dataset represents a substantial advancement in neuro­degenerative disease research, by providing a real-world clinical pro­ teomic dataset that comprises over 35,000 (11,270 with APOE genotype) individuals across AD, FTD, PDD, PD, ALS and normal aging from across more than 20 clinical sites in the US, UK and Europe. This enabled us to ask whether the APOE ε4-associated proteomic signature is shared across multiple neurodegenerative diseases. Our results demonstrate that all APOE ε4 carriers, irrespective of neurodegenerative disease, have a unique proteome signature that extends across the plasma and CSF. Unlike prospectively designed cohorts, the GNPC dataset reflects real-world clinical heterogeneity, highlighting the robustness and generalizability of our findings. This signature is associated with pro-inflammatory immune dysregulation and an enrichment for circulating immune cells, including monocytes, memory CD8 and γδ T cells, Tregs and NK cells. This molecular phenotype extends to the brains of APOE ε4 carriers in a similar disease-independent manner and is not associated with the presence of any disease-specific brain pathology. Although all APOE ε4 carriers have a systemic immune-related proteome signature, we find that the relationships between proteins within this signature are uniquely associated with demographic, lifestyle, and clinical variables in a neurodegenerative disease-specific manner. Notably, this suggests that although the biological changes associated with APOE ε4 carriage are essential for neurodegeneration, broadly, interactions with underlying biological vulnerability and the environment may be key for driving the pathogenesis of the specific neurodegenerative disease.\n\nThere is evidence that the APOE ε4 genotype is a modern-day example of antagonistic pleiotropy. In younger adults, APOE ε4 is associated with increased survival and fertility in environments with high levels of infectious disease. For example, healthy individuals who are APOE ε4 heterozygotes exhibit heightened cytokine release, increased plasma TNF levels, a more pronounced hyperthermic response and an earlier onset of IL-6 production following immune challenge with TLR2/TLR4/TLR5 ligands or lipopolysaccharide. While this immune response protects younger APOE ε4 carriers from infectious diseases, prolonged states of inflammation and cytokine release are likely deleterious with age. Although this study identified a proteomic signature indicative of a pro-inflammatory phenotype, a limitation is the absence of direct measures of routine inflammatory markers such as C-reactive protein or cytokines. Future studies should incorporate these markers in prospectively designed cohorts to clarify their association with APOE ε4.\n\nTo date, the biological effects of APOE ε4 carriage have largely only been studied in the context of AD. A notable finding of our study is that the pro-inflammatory molecular phenotype associated with APOE ε4 extends to individuals with other neurodegenerative diseases, including FTD, PDD, PD and ALS. This raises two key considerations. First, our findings underscore the need to shift focus from the continued identification of genetic risk loci via genome-wide association studies toward functional characterization of established variants. Notably, the absence of a statistically significant association between a variant and a specific disease phenotype does not preclude biological relevance. Despite APOE ε4 being overrepresented in the AD cohort, we observe a consistent molecular signature associated with APOE ε4 across multiple neurodegenerative diseases, highlighting an underrecognized role for this variant beyond AD that may have been overlooked due to its historically strong link with AD risk. Second, our data support reconceptualizing APOE ε4 not only as a disease-specific risk factor but also as a broader susceptibility allele contributing to shared pathogenic mechanisms across neurodegenerative diseases. It remains unclear, however, why APOE ε4 is more strongly associated with AD in terms of prevalence despite exhibiting systemic biological effects across neurodegenerative diseases. One possibility is that interactions between APOE ε4 and additional age-related, environmental, or comorbid factors may selectively amplify neurodegenerative pathways characteristic of AD. Another possibility is that CNS-specific vulnerabilities or cellular contexts (for example, in hippocampal circuits or dopaminergic neurons) modulate how the APOE ε4 inflammatory phenotype manifests clinically. Thus, while APOE ε4 confers a shared biological susceptibility, disease expression likely depends on a combination of genetic background, cellular context(s), and lifetime exposures. Large-scale integrative efforts, such as the GNPC, which harmonize data across distinct disease cohorts into unified datasets, provide a powerful framework for advancing this line of inquiry. By enabling cross-disease comparisons, such efforts may help delineate modifiers that influence why some APOE ε4 carriers develop AD while others remain healthy or develop different neurodegenerative diseases. This has important implications for prognosis and risk stratification in midlife individuals who carry APOE ε4.\n\nA limitation of our study is the absence of validated biomarkers (for example, CSF p-tau217) to confirm clinical diagnoses, which reflects both the nature of the GNPC dataset and global heterogeneity in clinical practice. However, several features mitigate concerns regarding potential misdiagnosis. First, the APOE ε4 signature was derived from nonimpaired individuals. While it is possible that a minority of these nonimpaired individuals harbored asymptomatic pathology (for example, asymptomatic AD), the majority would be free of overt disease, reducing the likelihood of confounding results. Second, the consistent presence of the signature across all APOE ε4 carriers, irrespective of clinical diagnosis, supports its generalizability and suggests it reflects a broader APOE ε4-related biological phenotype rather than disease-specific changes. Finally, we validate our findings using postmortem brain proteomics and histopathology, where diagnostic certainty is highest. Here APOE ε4 status was not associated with hallmark pathologies, including amyloid-β, tau, TDP-43 or α-synuclein, across respective disease groups. This postmortem validation reinforces the robustness of our findings. Future studies would benefit from prospective cohorts incorporating validated CSF or plasma biomarkers to confirm and extend these observations.\n\nAn unexpected finding of our study was that plasma neurofilament light (NEFL) levels were lower in APOE ε4 carriers across neurodegenerative diseases, despite NEFL’s growing recognition as a biomarker of neurodegeneration. Prior studies have reported conflicting results— some found no association, another reported increased levels in APOE ε4 carriers, while others using the SomaScan and Simoa assays observed decreased levels, consistent with our findings. These discrepancies may reflect differences in sample size, with studies reporting decreased NEFL levels generally including larger cohorts (~600 to 5,000 participants, and 9,924 in our study). Alternatively, APOE ε4-related blood–brain barrier (BBB) or metabolic dysfunction may alter peripheral clearance of NEFL and affect its plasma or CSF concentration. These results raise important questions about the reliability of NEFL as a stand-alone biomarker and underscore the need for mechanistic studies and a shift toward precision biomarkers that integrate genetic and environmental context.\n\nIn our study, key peripheral inflammatory states in APOE ε4 carriers were mirrored in the CNS. Notably, brain proteomics performed using label-free MS orthogonally validated findings from SomaScan-based CSF and plasma analyses. While SomaScan aptamer technology offers high-throughput protein quantification, it is relatively insensitive to proteoform diversity, including post-translational modifications, a limitation when examining signaling pathways and protein networks where such modifications are functionally significant. In contrast, MS enables the detection of broader proteoforms, offering an independent assessment of protein abundance and pathway enrichment. The concordance of APOE ε4-associated protein signatures and enrichment patterns across plasma, CSF and brain proteomic datasets suggests that our findings are not artifacts of platform-specific biases but likely reflect underlying biology. Supporting this interpretation, we observed enrichment of APOE ε4-associated proteins in both hepatocytes and Kupffer cells in the CSF, but only in Kupffer cells and T cells in plasma. This pattern implies that plasma reflects chronic peripheral immune activation, whereas the CSF may capture liver-brain axis-mediated inflammatory signaling in APOE ε4 carriers. Further experimental studies are warranted to validate these mechanisms. Prospective cohort studies incorporating cross-platform, multi-tissue analyses from the same individuals will be essential to confirm and expand upon these observations.\n\nWhile the exact mechanisms underlying the mirroring of peripheral and central pro-inflammatory states remain unclear, they may involve interactions between pro-inflammatory peripheral immune cells and the BBB. A recent study of individuals with long COVID-19 demonstrated that hyperactive peripheral blood mononuclear cells adhere to the endothelial cells of the BBB, driving inflammation, degradation, and symptoms of brain fog. In support of this, cognitively healthy APOE ε4 carriers exhibit early markers of BBB dysfunction in the hippocampus and medial temporal lobe. As the BBB becomes increasingly compromised, it allows the infiltration of blood-derived proteins and pro-inflammatory immune cells into the brain, contributing to exacerbated neuroinflammation and neurodegeneration. In our study, we identify enriched pro-inflammatory immune cell subpopulations, including nonclassical and intermediate monocytes, memory CD8+ T cells, γδ T cells and NK cells. These immune cell types may represent peripheral blood mononuclear cells that interact with the BBB to promote neurodegeneration in APOE ε4 carriers. Given that APOE ε4 is linked to a shared molecular phenotype across neurodegenerative diseases, this hypothesis is consistent with current understanding. Healthy, nonimpaired APOE ε4 carriers have a systemic pro-inflammatory phenotype (and as we have shown here), early signs of BBB disruption, alterations in brain activity and connectivity, and sleep disturbances, all of which are known to be risk factors for neurodegenerative diseases, broadly. Further supporting this is the recent evidence that vaccinations protect against dementia, including the shingles vaccines Zostavax and Shingrix. Although none of these studies explicitly examined the interactive effects between vaccination status and APOE ε4 genotype, the fact that more than 60% of individuals with dementia are APOE ε4 carriers suggests that APOE ε4 may represent a critical modifier of the observed associations, warranting further investigation. Future studies in human disease-relevant models, such as patient stem cell-derived organoids, are needed to further elucidate these mechanisms.",
    "reference_list": "考点1：:“expression”根据语境翻译为“临床表现”更加合适\n考点2：“vulnerability”根据语境翻译为“易感性”更加合适\n考点3:“APOE ε4 carriage”推荐翻译为“APOE ε4基因携带者/APOE ε4基因携带状态”，勿翻译为“运载体” \n考点4:“prospectively designed cohorts”中的“prospectively”推荐翻译为“前瞻性”\n考点5:“disease-specific risk factor”推荐翻译为“疾病特异性风险因素”\n考点6:“postmortem validation”必须翻译为“尸检验证”，不能译为“死后验证”\n考点7:“proteoform diversity”推荐翻译为“蛋白质异构体多样性”\n考点8:“label-free MS”翻译为“无标记质谱”\n考点9:“orthogonally validated”推荐翻译为“交叉验证”\n考点10：“GNPC” 应该译为 “全球神经退行性疾病蛋白质组学联盟”，不能保留原文不译\n考点11：“individuals across AD, FTD, PDD, PD, ALS and normal aging”中“AD”应译为“阿尔茨海默病”或“阿尔茨海默病（AD）”，不能保留原文不译\n考点12：“individuals across AD, FTD, PDD, PD, ALS and normal aging”中“FTD”应译为“额颞叶痴呆”或“额颞叶痴呆（FTD）”，不能保留原文不译\n考点13：individuals across AD, FTD, PDD, PD, ALS and normal aging”中“PDD”应译为“帕金森病痴呆”或“帕金森病痴呆（PDD）”，不能保留原文不译\n考点14：individuals across AD, FTD, PDD, PD, ALS and normal aging”中“PD”应译为“帕金森病”或“帕金森病（PD）”，不能保留原文不译\n考点15：individuals across AD, FTD, PDD, PD, ALS and normal aging”中“ALS”应译为“肌萎缩侧索硬化症”或“肌萎缩侧索硬化症（ALS）”，不能保留原文不译",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "131"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nChina has reaffirmed its commitment to fostering a more open and investment-friendly economy with the release of a new action plan aimed at stabilizing and promoting foreign investment in 2025. In this article, we explore the key measures outlined in the plan and the broader implications for foreign investors.\n\nOn February 19, 2025, China introduced a comprehensive action plan to stabilize foreign investment (hereinafter referred to as the “action plan”), reaffirming its commitment to high-standard opening-up and advancing economic modernization. Approved during a State Council executive meeting, the action plan outlines key measures to attract and retain foreign investment by expanding market access, easing financial restrictions, and fostering a fair business environment. With a focus on sectors such as biotechnology, telecommunications, education, and healthcare, the initiative seeks to enhance foreign participation in China’s industrial and service sectors.\n\nThe move comes as China continues to be a major global investment hub, having established over 59,000 new foreign-invested enterprises (FIEs) in 2024 and maintaining an annual foreign investment inflow exceeding RMB 1 trillion (US$137.29 billion) for three consecutive years. In this article, we explore the key measures outlined in the plan, its impact on various sectors, and the broader implications for foreign investors.\n\nChina’s newly announced action plan reflects a concerted effort to enhance foreign investment, strengthen economic stability, and maintain momentum in its industrial development. At its core, the plan underscores China’s commitment to creating a more attractive and equitable business environment. A pivotal aspect of this strategy is the continuous evolution of the Invest in China brand, which will be refined each year through an organized roadmap that emphasizes targeted promotion and collaboration.\n\nIn light of the shifting global economic landscape, China has set out to address the diverse needs of international investors by tailoring its approach based on the unique characteristics of major investment sources. By building on bilateral investment promotion mechanisms and fostering closer cooperation between central and local governments, China is positioning itself as a reliable and strategic partner for foreign enterprises.\n\nA key focus of the action plan is reinforcing existing FIEs and encouraging reinvestment within the country. The government aims to optimize the business climate to ensure equal treatment for all enterprises, fostering an environment where companies are not only encouraged to invest but also to reinvest their profits domestically. To support this, revisions to the Catalogue of Encouraged Industries for Foreign Investment will direct foreign capital toward high-value sectors, including advanced manufacturing, modern services, and underdeveloped regions in central, western, and northeastern China. Additionally, efforts to enhance transparency in foreign enterprises’ reinvestment activities will ensure a more predictable and stable investment process.\n\nTo facilitate foreign mergers and acquisitions (M&A), the action plan also outlines steps to simplify regulations under the framework of the Foreign Investment Law. By streamlining M&A procedures, lowering barriers for cross-border equity swaps, and improving regulatory oversight, China aims to create a more investor-friendly landscape that supports long-term engagement and innovation.\n\nMoreover, the government is lifting restrictions on domestic loans for foreign enterprises, enabling them to leverage local financing for equity investments and regional expansion. Multinational corporations are also encouraged to establish regional headquarters in China, with regulatory adjustments aimed at easing foreign exchange management, personnel mobility, and data flow.\n\nThrough targeted efforts across strategic sectors such as biotechnology, animal husbandry, high-tech industries, and modern services, the action plan lays the foundation for deeper foreign involvement in China’s industrial modernization. These measures align with China’s broader objectives of fostering sustainable development and integrating international expertise into its key industries.\n\nFinally, to boost investor confidence, the plan includes initiatives aimed at enhancing transparency and communication about economic policies. Regular press conferences, expert briefings, and media outreach will serve as platforms to reinforce China’s openness to foreign investment and demonstrate its commitment to a stable, transparent, and competitive investment environment.\n\nExpansion of opening-up policies\nChina’s commitment to “opening up” remains a central pillar of its foreign investment promotion strategy. In 2024, the government introduced several key policy updates aimed at further improving market access for foreign enterprises:\n1. Foreign investment negative list – On August 19, 2024, Premier Li Qiang chaired a State Council executive meeting approving the Special Administrative Measures for Foreign Investment Access (Negative List) (2024 Edition). This marks the first revision since the previous edition was released in late 2021, signaling adjustments in market access restrictions for foreign investors.\n2. Encouraged catalogue – On December 20, China’s National Development and Reform Commission (NDRC) and the Ministry of Commerce (MOFCOM) issued the Catalogue of Encouraged Industries for Foreign Investment (Exposure Draft) (Draft FI Encouraged Catalogue), which expands the 2022 version. The 2024 draft includes 1,700 items—620 in the national catalogue and 1,080 in the regional catalogue, representing a 15 percent increase from the previous 1,474 items.\n3. Healthcare and telecommunications sector – On September 8, MOFCOM announced an expansion of pilot programs in the healthcare industry. The newly issued circular lifts restrictions on foreign-invested enterprises (FIEs) engaged in cell and gene therapy (CGT) within select free trade zones (FTZs) and allows wholly foreign-owned hospitals in designated cities.\n4. Telecommunications – In October, China launched a pilot program allowing 100 percent foreign ownership of data centers and value-added telecom services in Beijing, Shanghai, Hainan, and Shenzhen.\n\nThe 2025 Action Plan builds on these efforts and indicates a further expansion of pilot programs in healthcare and telecommunications. It also outlines research and planning for an orderly opening-up of the education and cultural industries, with implementation expected at an appropriate time. Additionally, China has reiterated its commitment to expanding market access in the services sector, which saw an added value of RMB 76.56 trillion (US$10.56 trillion) in 2024, growing by 5 percent year-on-year and accounting for 56.7 percent of GDP. The plan also places a strong emphasis on the biopharmaceutical industry, supporting qualified foreign-invested enterprises in pilot programs for segmented biopharmaceutical production. It pledges to accelerate the approval of provincial pilot projects and quality supervision plans while ensuring regulatory coordination. Further initiatives will focus on streamlining market entry for innovative drugs, optimizing bulk pharmaceutical procurement, and improving the predictability of medical device procurement policies.\n\nThese key sectors –healthcare, telecommunications, services, and biopharmaceuticals—are expected to present significant opportunities for foreign investors in 2025. As China continues to refine its foreign investment policies, businesses can expect a more accessible, predictable, and stable regulatory environment, fostering deeper international participation in the Chinese market.",
    "ori_text": "China has reaffirmed its commitment to fostering a more open and investment-friendly economy with the release of a new action plan aimed at stabilizing and promoting foreign investment in 2025. In this article, we explore the key measures outlined in the plan and the broader implications for foreign investors.\n\nOn February 19, 2025, China introduced a comprehensive action plan to stabilize foreign investment (hereinafter referred to as the “action plan”), reaffirming its commitment to high-standard opening-up and advancing economic modernization. Approved during a State Council executive meeting, the action plan outlines key measures to attract and retain foreign investment by expanding market access, easing financial restrictions, and fostering a fair business environment. With a focus on sectors such as biotechnology, telecommunications, education, and healthcare, the initiative seeks to enhance foreign participation in China’s industrial and service sectors.\n\nThe move comes as China continues to be a major global investment hub, having established over 59,000 new foreign-invested enterprises (FIEs) in 2024 and maintaining an annual foreign investment inflow exceeding RMB 1 trillion (US$137.29 billion) for three consecutive years. In this article, we explore the key measures outlined in the plan, its impact on various sectors, and the broader implications for foreign investors.\n\nChina’s newly announced action plan reflects a concerted effort to enhance foreign investment, strengthen economic stability, and maintain momentum in its industrial development. At its core, the plan underscores China’s commitment to creating a more attractive and equitable business environment. A pivotal aspect of this strategy is the continuous evolution of the Invest in China brand, which will be refined each year through an organized roadmap that emphasizes targeted promotion and collaboration.\n\nIn light of the shifting global economic landscape, China has set out to address the diverse needs of international investors by tailoring its approach based on the unique characteristics of major investment sources. By building on bilateral investment promotion mechanisms and fostering closer cooperation between central and local governments, China is positioning itself as a reliable and strategic partner for foreign enterprises.\n\nA key focus of the action plan is reinforcing existing FIEs and encouraging reinvestment within the country. The government aims to optimize the business climate to ensure equal treatment for all enterprises, fostering an environment where companies are not only encouraged to invest but also to reinvest their profits domestically. To support this, revisions to the Catalogue of Encouraged Industries for Foreign Investment will direct foreign capital toward high-value sectors, including advanced manufacturing, modern services, and underdeveloped regions in central, western, and northeastern China. Additionally, efforts to enhance transparency in foreign enterprises’ reinvestment activities will ensure a more predictable and stable investment process.\n\nTo facilitate foreign mergers and acquisitions (M&A), the action plan also outlines steps to simplify regulations under the framework of the Foreign Investment Law. By streamlining M&A procedures, lowering barriers for cross-border equity swaps, and improving regulatory oversight, China aims to create a more investor-friendly landscape that supports long-term engagement and innovation.\n\nMoreover, the government is lifting restrictions on domestic loans for foreign enterprises, enabling them to leverage local financing for equity investments and regional expansion. Multinational corporations are also encouraged to establish regional headquarters in China, with regulatory adjustments aimed at easing foreign exchange management, personnel mobility, and data flow.\n\nThrough targeted efforts across strategic sectors such as biotechnology, animal husbandry, high-tech industries, and modern services, the action plan lays the foundation for deeper foreign involvement in China’s industrial modernization. These measures align with China’s broader objectives of fostering sustainable development and integrating international expertise into its key industries.\n\nFinally, to boost investor confidence, the plan includes initiatives aimed at enhancing transparency and communication about economic policies. Regular press conferences, expert briefings, and media outreach will serve as platforms to reinforce China’s openness to foreign investment and demonstrate its commitment to a stable, transparent, and competitive investment environment.\n\nExpansion of opening-up policies\nChina’s commitment to “opening up” remains a central pillar of its foreign investment promotion strategy. In 2024, the government introduced several key policy updates aimed at further improving market access for foreign enterprises:\n1. Foreign investment negative list – On August 19, 2024, Premier Li Qiang chaired a State Council executive meeting approving the Special Administrative Measures for Foreign Investment Access (Negative List) (2024 Edition). This marks the first revision since the previous edition was released in late 2021, signaling adjustments in market access restrictions for foreign investors.\n2. Encouraged catalogue – On December 20, China’s National Development and Reform Commission (NDRC) and the Ministry of Commerce (MOFCOM) issued the Catalogue of Encouraged Industries for Foreign Investment (Exposure Draft) (Draft FI Encouraged Catalogue), which expands the 2022 version. The 2024 draft includes 1,700 items—620 in the national catalogue and 1,080 in the regional catalogue, representing a 15 percent increase from the previous 1,474 items.\n3. Healthcare and telecommunications sector – On September 8, MOFCOM announced an expansion of pilot programs in the healthcare industry. The newly issued circular lifts restrictions on foreign-invested enterprises (FIEs) engaged in cell and gene therapy (CGT) within select free trade zones (FTZs) and allows wholly foreign-owned hospitals in designated cities.\n4. Telecommunications – In October, China launched a pilot program allowing 100 percent foreign ownership of data centers and value-added telecom services in Beijing, Shanghai, Hainan, and Shenzhen.\n\nThe 2025 Action Plan builds on these efforts and indicates a further expansion of pilot programs in healthcare and telecommunications. It also outlines research and planning for an orderly opening-up of the education and cultural industries, with implementation expected at an appropriate time. Additionally, China has reiterated its commitment to expanding market access in the services sector, which saw an added value of RMB 76.56 trillion (US$10.56 trillion) in 2024, growing by 5 percent year-on-year and accounting for 56.7 percent of GDP. The plan also places a strong emphasis on the biopharmaceutical industry, supporting qualified foreign-invested enterprises in pilot programs for segmented biopharmaceutical production. It pledges to accelerate the approval of provincial pilot projects and quality supervision plans while ensuring regulatory coordination. Further initiatives will focus on streamlining market entry for innovative drugs, optimizing bulk pharmaceutical procurement, and improving the predictability of medical device procurement policies.\n\nThese key sectors –healthcare, telecommunications, services, and biopharmaceuticals—are expected to present significant opportunities for foreign investors in 2025. As China continues to refine its foreign investment policies, businesses can expect a more accessible, predictable, and stable regulatory environment, fostering deeper international participation in the Chinese market.",
    "reference_list": "考点1：State Council executive meeting应译为“国务院常务会议。\n考点2：market access音译为“市场准入”。\n考点3：Invest in China brand中的Invest in China是一个专有品牌名称，应译为“投资中国”品牌。\n考点4：leverage推荐译为“利用”。\n考点5：Exposure Draft应译为“征求意见稿”\n考点6：orderly opening-up应译为“有序开放”。\n考点7：bulk pharmaceutical procurement应译为“药品集中采购”，也可以译为“集采”。\n考点8：Foreign investment negative list应译为 外商投资准入负面清单。\n考点9：Special Administrative Measures for Foreign Investment Access (Negative List) (2024 Edition)应译为 外商投资准入特别管理措施（负面清单）（2024 年版） 。\n考点10：China’s National Development and Reform Commission (NDRC)应译为 中国国家发展和改革委员会\n考点11：Catalogue of Encouraged Industries for Foreign Investment (Exposure Draft)应译为 鼓励外商投资产业目录",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "38"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n量子计算理论建立在量子力学的叠加原理和纠缠现象基础之上，通过量子比特的相干操作实现了超越经典计算能力的信息处理范式。量子算法的设计利用量子并行性和量子干涉效应，在特定问题域中展现出指数级的计算优势，其中Shor算法对整数分解问题和Grover算法对无结构搜索问题的突破性进展标志着量子计算从理论走向实践的重要里程碑。量子门电路模型作为量子计算的标准计算模型，基于酉变换的可逆性原理构建了通用量子计算的理论框架。Pauli算子和Clifford群构成了量子纠错码的数学基础，而Gottesman-Knill定理证明了稳定子态的经典可模拟性。通用量子门集合的构造需要满足稠密性条件，其中Solovay-Kitaev定理保证了任意酉操作都可以通过有限门集合以任意精度逼近。\n量子纠错理论通过引入冗余度克服了量子相干性易受环境噪声破坏的根本挑战。量子纠错码的构造基于稳定子形式主义，通过对易关系的巧妙设计实现了量子信息的保护。表面码和拓扑码利用二维网格上的局域相互作用构建了具有阈值容错特性的量子存储系统，而色码则通过三维拓扑结构提供了更高的编码效率。绝热量子计算模型基于量子绝热定理，通过缓慢演化的哈密顿量引导系统从初始态到问题解态。量子退火算法利用横向磁场的调控实现了组合优化问题的求解，而变分量子算法则结合经典优化与量子资源，在近期含噪声中等规模量子设备上寻求量子优势。计算复杂性理论中的量子复杂性类别体系为理解量子计算能力提供了严格的数学框架。BQP复杂性类刻画了有界错误量子多项式时间可解的判定问题，而QMA类则是量子梅林 - 亚瑟类的简称，代表了量子非确定性多项式时间复杂性。量子交互证明系统和量子零知识证明扩展了经典密码学协议的安全性定义。量子近似优化算法通过参数化量子电路的变分训练解决了组合优化中的NP困难问题。最大割问题和图着色问题的量子启发式算法展现了在特定实例上的性能提升，而量子交替算子算法则为通用组合优化提供了系统性的量子方法。量子机器学习领域探索了量子计算与机器学习算法的深度融合。量子主成分分析算法利用量子奇异值分解实现了高维数据的降维处理，而量子支持向量机则通过量子核方法在指数维特征空间中进行分类。变分量子分类器和量子神经网络为近期量子设备上的机器学习应用提供了可行路径。量子模拟作为量子计算的重要应用方向，专注于利用可控量子系统模拟复杂量子多体系统的动力学演化。数字量子模拟通过Trotter-Suzuki分解将连续时间演化离散化为量子门序列，而模拟量子模拟则通过工程化的哈密顿量直接实现目标系统的物理映射。量子密码学基于量子力学的基本原理构建了信息论安全的密钥分发协议。BB84协议利用量子态的不可克隆定理和海森堡不确定性原理实现了无条件安全的密钥交换，而量子密钥分发的安全性证明依赖于纠缠提纯和隐私放大技术。量子计算的物理实现面临着量子相干时间有限和门操作保真度不足的技术挑战。超导约瑟夫森结量子比特通过能级工程和脉冲控制实现了高保真度的量子门操作，而离子阱量子计算机则利用激光冷却和囚禁技术维持了长相干时间的量子态。容错量子计算的实现需要将逻辑错误率压制到阈值以下，这要求物理量子比特的错误率满足严格的容错条件。量子错误纠正码的阈值定理表明，只要物理错误率低于特定阈值，通过增加编码冗余度可以将逻辑错误率任意降低。魔态蒸馏技术通过量子态的纯化过程为容错量子计算提供了高保真度的辅助资源态。量子优越性的演示需要在特定计算任务上展现量子设备相对于最优经典算法的计算优势。随机电路采样问题为量子优越性提供了理论基础，而玻色采样和IQP电路则构成了其他候选问题。量子优越性的验证面临着经典模拟算法不断改进的挑战，需要在问题规模和验证效率之间寻求平衡。变分量子特征求解器通过量子-经典混合算法求解哈密顿量的基态和激发态能谱。量子近似优化算法的性能分析揭示了量子优势与问题结构之间的深层联系，而量子交替算子算法的收敛性理论为算法设计提供了指导原则。量子计算中的去相干效应和环境噪声构成了实用量子算法设计的主要约束。开放量子系统的主方程描述了量子态在环境耦合下的非酉演化，而量子过程层析技术则提供了噪声特征化的实验手段。\n近期量子算法的研究集中于在含噪声中等规模量子设备上寻求实用量子优势。变分量子算法通过参数优化适应了硬件噪声特性，而量子错误缓解技术则通过后处理方法部分抑制了噪声影响。零噪声外推和概率错误消除为近期量子计算提供了实用的错误缓解策略。量子计算复杂性理论中的量子PCP猜想和量子哈密顿复杂性问题探索了量子系统中可验证性和难解性的根本界限。局域哈密顿量的基态能量问题被证明是QMA完全的，而量子满足性问题则为理解量子复杂性提供了重要范例。量子网络和分布式量子计算扩展了量子信息处理的空间范围。量子中继器通过纠缠交换克服了量子通信的距离限制，而量子互联网的愿景依赖于量子存储和量子路由技术的突破。分布式量子算法需要在通信复杂性和计算复杂性之间权衡，量子隐形传态和量子纠缠分发构成了分布式量子协议的基础操作。量子计算在材料科学和药物发现中的应用前景激发了量子模拟算法的深入研究。费米-哈伯德模型和分子电子结构计算为量子化学提供了天然的量子算法应用场景，而变分量子特征求解器在小分子体系中已经展现了与经典方法相当的计算精度。量子启发的经典算法从量子算法设计中汲取灵感，为经典计算机上的近似算法提供了新的思路。张量网络方法和矩阵乘积态技术在某些量子系统的经典模拟中取得了显著成功，而量子启发的优化算法则在组合优化和机器学习中找到了应用价值。",
    "ori_text": "\n\n量子计算理论建立在量子力学的叠加原理和纠缠现象基础之上，通过量子比特的相干操作实现了超越经典计算能力的信息处理范式。量子算法的设计利用量子并行性和量子干涉效应，在特定问题域中展现出指数级的计算优势，其中Shor算法对整数分解问题和Grover算法对无结构搜索问题的突破性进展标志着量子计算从理论走向实践的重要里程碑。量子门电路模型作为量子计算的标准计算模型，基于酉变换的可逆性原理构建了通用量子计算的理论框架。Pauli算子和Clifford群构成了量子纠错码的数学基础，而Gottesman-Knill定理证明了稳定子态的经典可模拟性。通用量子门集合的构造需要满足稠密性条件，其中Solovay-Kitaev定理保证了任意酉操作都可以通过有限门集合以任意精度逼近。\n量子纠错理论通过引入冗余度克服了量子相干性易受环境噪声破坏的根本挑战。量子纠错码的构造基于稳定子形式主义，通过对易关系的巧妙设计实现了量子信息的保护。表面码和拓扑码利用二维网格上的局域相互作用构建了具有阈值容错特性的量子存储系统，而色码则通过三维拓扑结构提供了更高的编码效率。绝热量子计算模型基于量子绝热定理，通过缓慢演化的哈密顿量引导系统从初始态到问题解态。量子退火算法利用横向磁场的调控实现了组合优化问题的求解，而变分量子算法则结合经典优化与量子资源，在近期含噪声中等规模量子设备上寻求量子优势。计算复杂性理论中的量子复杂性类别体系为理解量子计算能力提供了严格的数学框架。BQP复杂性类刻画了有界错误量子多项式时间可解的判定问题，而QMA类则是量子梅林 - 亚瑟类的简称，代表了量子非确定性多项式时间复杂性。量子交互证明系统和量子零知识证明扩展了经典密码学协议的安全性定义。量子近似优化算法通过参数化量子电路的变分训练解决了组合优化中的NP困难问题。最大割问题和图着色问题的量子启发式算法展现了在特定实例上的性能提升，而量子交替算子算法则为通用组合优化提供了系统性的量子方法。量子机器学习领域探索了量子计算与机器学习算法的深度融合。量子主成分分析算法利用量子奇异值分解实现了高维数据的降维处理，而量子支持向量机则通过量子核方法在指数维特征空间中进行分类。变分量子分类器和量子神经网络为近期量子设备上的机器学习应用提供了可行路径。量子模拟作为量子计算的重要应用方向，专注于利用可控量子系统模拟复杂量子多体系统的动力学演化。数字量子模拟通过Trotter-Suzuki分解将连续时间演化离散化为量子门序列，而模拟量子模拟则通过工程化的哈密顿量直接实现目标系统的物理映射。量子密码学基于量子力学的基本原理构建了信息论安全的密钥分发协议。BB84协议利用量子态的不可克隆定理和海森堡不确定性原理实现了无条件安全的密钥交换，而量子密钥分发的安全性证明依赖于纠缠提纯和隐私放大技术。量子计算的物理实现面临着量子相干时间有限和门操作保真度不足的技术挑战。超导约瑟夫森结量子比特通过能级工程和脉冲控制实现了高保真度的量子门操作，而离子阱量子计算机则利用激光冷却和囚禁技术维持了长相干时间的量子态。容错量子计算的实现需要将逻辑错误率压制到阈值以下，这要求物理量子比特的错误率满足严格的容错条件。量子错误纠正码的阈值定理表明，只要物理错误率低于特定阈值，通过增加编码冗余度可以将逻辑错误率任意降低。魔态蒸馏技术通过量子态的纯化过程为容错量子计算提供了高保真度的辅助资源态。量子优越性的演示需要在特定计算任务上展现量子设备相对于最优经典算法的计算优势。随机电路采样问题为量子优越性提供了理论基础，而玻色采样和IQP电路则构成了其他候选问题。量子优越性的验证面临着经典模拟算法不断改进的挑战，需要在问题规模和验证效率之间寻求平衡。变分量子特征求解器通过量子-经典混合算法求解哈密顿量的基态和激发态能谱。量子近似优化算法的性能分析揭示了量子优势与问题结构之间的深层联系，而量子交替算子算法的收敛性理论为算法设计提供了指导原则。量子计算中的去相干效应和环境噪声构成了实用量子算法设计的主要约束。开放量子系统的主方程描述了量子态在环境耦合下的非酉演化，而量子过程层析技术则提供了噪声特征化的实验手段。\n近期量子算法的研究集中于在含噪声中等规模量子设备上寻求实用量子优势。变分量子算法通过参数优化适应了硬件噪声特性，而量子错误缓解技术则通过后处理方法部分抑制了噪声影响。零噪声外推和概率错误消除为近期量子计算提供了实用的错误缓解策略。量子计算复杂性理论中的量子PCP猜想和量子哈密顿复杂性问题探索了量子系统中可验证性和难解性的根本界限。局域哈密顿量的基态能量问题被证明是QMA完全的，而量子满足性问题则为理解量子复杂性提供了重要范例。量子网络和分布式量子计算扩展了量子信息处理的空间范围。量子中继器通过纠缠交换克服了量子通信的距离限制，而量子互联网的愿景依赖于量子存储和量子路由技术的突破。分布式量子算法需要在通信复杂性和计算复杂性之间权衡，量子隐形传态和量子纠缠分发构成了分布式量子协议的基础操作。量子计算在材料科学和药物发现中的应用前景激发了量子模拟算法的深入研究。费米-哈伯德模型和分子电子结构计算为量子化学提供了天然的量子算法应用场景，而变分量子特征求解器在小分子体系中已经展现了与经典方法相当的计算精度。量子启发的经典算法从量子算法设计中汲取灵感，为经典计算机上的近似算法提供了新的思路。张量网络方法和矩阵乘积态技术在某些量子系统的经典模拟中取得了显著成功，而量子启发的优化算法则在组合优化和机器学习中找到了应用价值。",
    "reference_list": "考点1：“酉变换”推荐译为 Unitary Transformation，避免与“unitary operation”混用，全文统一。\n考点2：“量子纠错码”推荐译为 Quantum Error Correction Code，首次出现可注明缩写 QECC。\n考点3：“阈值容错”推荐译为 Fault-Tolerance Threshold避免仅译为“Threshold Fault Tolerance”\n考点4：“哈密顿量”推荐译为 Hamiltonian，泛指概念时用单数，指多个不同体系时用复数 Hamiltonians，全文统一。\n考点5：“问题解态”推荐译为 solution state，避免“problem-solving state”等过程化表达。\n考点6：量子梅林亚瑟类首次出现时译为 Quantum Merlin-Arthur，注明缩写 (QMA)，全文一致。\n考点7：量子近似优化算法首次出现时译为 Quantum Approximate Optimization Algorithm，注明缩写 (QAOA)，全文一致。\n考点8：量子密钥分发首次出现时译为 Quantum Key Distribution，注明缩写 (QKD)，全文一致。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "109"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nThe Atlantic meridional overturning circulation (AMOC) is a major tipping element in the climate system and a future collapse would have severe impacts on the climate in the North Atlantic region. In recent years weakening in circulation has been reported, but assessments by the Intergovernmental Panel on Climate Change (IPCC), based on the Climate Model Intercomparison Project (CMIP) model simulations suggest that a full collapse is unlikely within the 21st century. Tipping to an undesired state in the climate is, however, a growing concern with increasing greenhouse gas concentrations. Predictions based on observations rely on detecting early-warning signals, primarily an increase in variance (loss of resilience) and increased autocorrelation (critical slowing down), which have recently been reported for the AMOC. Here we provide statistical significance and data-driven estimators for the time of tipping. We estimate a collapse of the AMOC to occur around mid-century under the current scenario of future emissions.\nA forthcoming collapse of the Atlantic meridional overturning circulation (AMOC) is a major concern as it is one of the most important tipping elements in Earth’s climate system1–3. In recent years, model studies and paleoclimatic reconstructions indicate that the strongest abrupt climate fluctuations, the Dansgaard-Oeschger events4, are connected to the bimodal nature of the AMOC5,6. Numerous climate model studies show a hysteresis behavior, where changing a control parameter, typically the freshwater input into the Northern Atlantic, makes the AMOC bifurcate through a set of co-dimension one saddlenode bifurcations7–9. State-of-the-art Earth-system models can reproduce such a scenario, but the inter-model spread is large and the critical threshold is poorly constrained10,11. Based on the CMIP5 generation of models, the AR6 IPCC report quotes a collapse in the 21st century to be very unlikely (medium confidence)12. Among CMIP6 models, there is a larger spread in the AMOC response to warming scenarios, thus an increased uncertainty in the assessment of a future collapse13. There are, however, model biases toward overestimated stability of the AMOC, both from tuning to the historic climate record14, poor representation of the deep water formation15, salinity and glacial runoff16. When complex systems, such as the overturning circulation, undergo critical transitions by changing a control parameter λ through  a critical value λc, a structural change in the dynamics happens. The previously statistically stable state ceases to exist and the system moves to a different statistically stable state. The system undergoes a bifurcation, which for λ sufficiently close to λc can happen in a limited number of ways rather independent from the details in the governing dynamics17. Besides a decline of the AMOC before the critical transition, there are early-warning signals (EWSs), statistical quantities, which also change before the tipping happens. These are critical slowing down (increased autocorrelation) and, from the FluctuationDissipation Theorem, increased variance in the signal18–20. The latter is also termed “loss of resilience”, especially in the context of ecological collapse21. The two EWSs are statistical equilibrium concepts. Thus, using them as actual predictors of a forthcoming transition relies on the assumption of quasi-stationary dynamics. The AMOC has only been monitored continuously since 2004 through combined measurements from moored instruments, induced electrical currents in submarine cables and satellite surface measurements22. Over the period 2004–2012, a decline in the AMOC has been observed, but longer records are necessary to assess the significance. For that, careful fingerprinting techniques have been applied to longer records of sea surface temperature (SST), which, backed by a survey of a large ensemble of climate model simulations,have found the SST in the Subpolar gyre (SG) region of the North Atlantic (area marked with a black contour in Fig. 1a) to contain an optimal fingerprint of the strength of the AMOC23–25. Figure 1b shows the SG and the GM SSTs obtained from the Hadley Centre Sea Ice and Sea Surface Temperature data set (HadISST)26. Figure 1c shows the SG anomaly, and Fig. 1d shows the GM anomaly with a clear global warming trend in the last half of the record. The AMOC fingerprint for the period 1870–2020 is shown in Fig. 1e. This is the basis for the analysis. It has been reported11,27 that this and similar AMOC indices show significant trends in the mean, the variance and the autocorrelation, indicating early warning of a shutdown of the AMOC. However, a trend in the EWSs within a limited period of observation could be a random fluctuation within steady-state statistics. Thus, for a robust assessment of the shutdown, it is necessary to establish a statistical confidence level for the change above the natural fluctuations. This is not easily done given only one, the observed realization of the approach to the transition. Here we establish such a measure of the confidence for the variance and autocorrelation and demonstrate that variance is the more reliable of the two. A further contribution is an estimator of not only whether a transition is approaching but also the time when the critical transition is expected to occur. The strategy is to infer the evolution of the AMOC solely on observed changes in mean, variance and autocorrelation. The typical choice of control parameter is the flux of freshwater into the North Atlantic. River runoff, Greenland ice melt and export from the Arctic Ocean are not well constrained28; thus, we do not assume the control parameter known. Boers27 assumes the global mean temperature T to represent the control parameter. Although T has increased since ~1920 (Fig. 1d), the increase is not quite linear with time. All we assume here is that the AMOC is in an equilibrium state prior to a change toward the transition. The simplest uninformed assumption is that the change is sufficiently slow and that the control parameter approaches the (unknown) critical value linearly with time. This assumption is confirmed by a close fit of the estimated model to the observed AMOC fingerprint. Although we make no explicit assumptions, the primary driver of climate change, the logarithm of the atmospheric CO2 concentration, does, in fact, increase close to linearly with time in the industrial period29. Our results are robust without making specific assumptions regarding the driver of the AMOC. In this work, we show that a transition of the AMOC is most likely to occur around 2025-2095 (95% confidence interval).\nModeling and detecting the critical transition  Denote the observed AMOC fingerprint by x(t) (Fig. 1e). We model it by a stochastic process Xt, which, depending on a control parameter λ < 0, is at risk of undergoing a critical transition through a saddle-node bifurcation for λ = λc = 0. The system is initially in a statistically stable state, i.e., it follows some stationary distribution with constant λ = λ0. We are uninformed about the dynamics governing the evolution of Xt but can assume effective dynamics, which, with λ sufficiently close to the critical value λc = 0, can be described by the stochastic differential equation (SDE):dX t = ðAðX t mÞ2 + λÞdt + σdBt , ð1Þ  where m = μ ∣λ∣=A  p and μ is the stable fixed point of the drift, A is a time scale parameter, Bt is a Brownian motion and σ2 scales the variance. Disregarding the noise, this is the normal form of the codimension one saddle-node bifurcation17 (see “Methods”). The squareroot dependence of the stable state: μ m ∼  λc λ  p is the main signature of a saddle-node bifurcation. It is observed for the AMOC shutdown in ocean-only models as well as in coupled models, see Fig. 2, in strong support of Eq. (1) for the AMOC.At time t0, λ(t) begins to change linearly toward λc = λ(tc) = 0:  λðtÞ = λ0ð1 Θ1⁄2t t0 ðt t0Þ=τr Þ, ð2Þ  where Θ[t] is the Heaviside function and τr = tc − t0 > 0 is the ramping time up to time tc, where the transition eventually will occur. Time tc is denoted the tipping time; however, an actual tipping can happen earlier than tc due to a noise-induced tipping. As the transition is approached, the risk of noise-induced tipping (n-tipping) prior to tc is increasing and, at some point, making the EWSs irrelevant for predicting the tipping. The probability for n-tipping can, in the small noise limit, be calculated in closed form, Pðt,λÞ = 1 expð t=τnðλÞÞ, with mean waiting time  τnðλÞ = ðπ= ffi∣ffiλffiffi∣ffi  p Þ expð8∣λ∣3=2=3σ2Þ (see “Methods”). The mean and variance are calculated from the observations as the control parameter λ(t) is possibly changing. These EWSs are inherently equilibrium concepts and statistical; thus, a time window, Tw, of a certain size is required for a reliable estimate. As the transition is approached, the differences between the EWSs and the preramping values of the variance and autocorrelation (baseline) increase; thus, a shorter window Tw is required for detecting a difference. Conversely, close to the transition critical slowing down decreases the number of independent points within a window, thus calling for a larger window for reliable detection. Within a short enough window, [t − Tw/2, t + Tw/2], we may assume λ(t) to be constant and the noise small enough so that the process (1) for given λ is well approximated by a linear SDE, the Ornstein–Uhlenbeck process30. A Taylor expansion around the fixed point μ(λ) yields the approximation ... where ... and ... is the inverse correlation time. For fixed λ, the process is stationary, with mean μ, variance γ2 = σ2/2α and one-lag autocorrelation ρ = expð αΔtÞ with step size Δt = 1 month. As λ(t) increases, α decreases, and thus variance and autocorrelation increase. From μ, γ2 and ρ the parameters of Eq. (1) are determined: α = log ρ=Δt, σ2 = 2αγ2, A = α/2(μ − m) and  λ = ðσ2=4γ2Þ2=A. Closed form estimators for μ, γ2 and ρ are obtained from the observed time series within a running window by maximum likelihood estimation (MLE) (Supplementary text S1, see also ref. 31). The uncertainty is expressed through the variances of the estimators γ^2 and ^ρ obtained from the observations within a time window Tw. The hats indicate that they are estimators and thus stochastic variables with variances around the true values. Detection of an EWS at some chosen confidence level q (such as 95 or 99%) requires one of the estimates γ^2 or ^ρ for a given window to be statistically different from the baseline values γ^2  0 or ^ρ0, which depend on the window size as well as how different the EWSs are from their baseline values.",
    "ori_text": "\n\nThe Atlantic meridional overturning circulation (AMOC) is a major tipping element in the climate system and a future collapse would have severe impacts on the climate in the North Atlantic region. In recent years weakening in circulation has been reported, but assessments by the Intergovernmental Panel on Climate Change (IPCC), based on the Climate Model Intercomparison Project (CMIP) model simulations suggest that a full collapse is unlikely within the 21st century. Tipping to an undesired state in the climate is, however, a growing concern with increasing greenhouse gas concentrations. Predictions based on observations rely on detecting early-warning signals, primarily an increase in variance (loss of resilience) and increased autocorrelation (critical slowing down), which have recently been reported for the AMOC. Here we provide statistical significance and data-driven estimators for the time of tipping. We estimate a collapse of the AMOC to occur around mid-century under the current scenario of future emissions.\nA forthcoming collapse of the Atlantic meridional overturning circulation (AMOC) is a major concern as it is one of the most important tipping elements in Earth’s climate system1–3. In recent years, model studies and paleoclimatic reconstructions indicate that the strongest abrupt climate fluctuations, the Dansgaard-Oeschger events4, are connected to the bimodal nature of the AMOC5,6. Numerous climate model studies show a hysteresis behavior, where changing a control parameter, typically the freshwater input into the Northern Atlantic, makes the AMOC bifurcate through a set of co-dimension one saddlenode bifurcations7–9. State-of-the-art Earth-system models can reproduce such a scenario, but the inter-model spread is large and the critical threshold is poorly constrained10,11. Based on the CMIP5 generation of models, the AR6 IPCC report quotes a collapse in the 21st century to be very unlikely (medium confidence)12. Among CMIP6 models, there is a larger spread in the AMOC response to warming scenarios, thus an increased uncertainty in the assessment of a future collapse13. There are, however, model biases toward overestimated stability of the AMOC, both from tuning to the historic climate record14, poor representation of the deep water formation15, salinity and glacial runoff16. When complex systems, such as the overturning circulation, undergo critical transitions by changing a control parameter λ through  a critical value λc, a structural change in the dynamics happens. The previously statistically stable state ceases to exist and the system moves to a different statistically stable state. The system undergoes a bifurcation, which for λ sufficiently close to λc can happen in a limited number of ways rather independent from the details in the governing dynamics17. Besides a decline of the AMOC before the critical transition, there are early-warning signals (EWSs), statistical quantities, which also change before the tipping happens. These are critical slowing down (increased autocorrelation) and, from the FluctuationDissipation Theorem, increased variance in the signal18–20. The latter is also termed “loss of resilience”, especially in the context of ecological collapse21. The two EWSs are statistical equilibrium concepts. Thus, using them as actual predictors of a forthcoming transition relies on the assumption of quasi-stationary dynamics. The AMOC has only been monitored continuously since 2004 through combined measurements from moored instruments, induced electrical currents in submarine cables and satellite surface measurements22. Over the period 2004–2012, a decline in the AMOC has been observed, but longer records are necessary to assess the significance. For that, careful fingerprinting techniques have been applied to longer records of sea surface temperature (SST), which, backed by a survey of a large ensemble of climate model simulations,have found the SST in the Subpolar gyre (SG) region of the North Atlantic (area marked with a black contour in Fig. 1a) to contain an optimal fingerprint of the strength of the AMOC23–25. Figure 1b shows the SG and the GM SSTs obtained from the Hadley Centre Sea Ice and Sea Surface Temperature data set (HadISST)26. Figure 1c shows the SG anomaly, and Fig. 1d shows the GM anomaly with a clear global warming trend in the last half of the record. The AMOC fingerprint for the period 1870–2020 is shown in Fig. 1e. This is the basis for the analysis. It has been reported11,27 that this and similar AMOC indices show significant trends in the mean, the variance and the autocorrelation, indicating early warning of a shutdown of the AMOC. However, a trend in the EWSs within a limited period of observation could be a random fluctuation within steady-state statistics. Thus, for a robust assessment of the shutdown, it is necessary to establish a statistical confidence level for the change above the natural fluctuations. This is not easily done given only one, the observed realization of the approach to the transition. Here we establish such a measure of the confidence for the variance and autocorrelation and demonstrate that variance is the more reliable of the two. A further contribution is an estimator of not only whether a transition is approaching but also the time when the critical transition is expected to occur. The strategy is to infer the evolution of the AMOC solely on observed changes in mean, variance and autocorrelation. The typical choice of control parameter is the flux of freshwater into the North Atlantic. River runoff, Greenland ice melt and export from the Arctic Ocean are not well constrained28; thus, we do not assume the control parameter known. Boers27 assumes the global mean temperature T to represent the control parameter. Although T has increased since ~1920 (Fig. 1d), the increase is not quite linear with time. All we assume here is that the AMOC is in an equilibrium state prior to a change toward the transition. The simplest uninformed assumption is that the change is sufficiently slow and that the control parameter approaches the (unknown) critical value linearly with time. This assumption is confirmed by a close fit of the estimated model to the observed AMOC fingerprint. Although we make no explicit assumptions, the primary driver of climate change, the logarithm of the atmospheric CO2 concentration, does, in fact, increase close to linearly with time in the industrial period29. Our results are robust without making specific assumptions regarding the driver of the AMOC. In this work, we show that a transition of the AMOC is most likely to occur around 2025-2095 (95% confidence interval).\nModeling and detecting the critical transition  Denote the observed AMOC fingerprint by x(t) (Fig. 1e). We model it by a stochastic process Xt, which, depending on a control parameter λ < 0, is at risk of undergoing a critical transition through a saddle-node bifurcation for λ = λc = 0. The system is initially in a statistically stable state, i.e., it follows some stationary distribution with constant λ = λ0. We are uninformed about the dynamics governing the evolution of Xt but can assume effective dynamics, which, with λ sufficiently close to the critical value λc = 0, can be described by the stochastic differential equation (SDE):dX t = ðAðX t mÞ2 + λÞdt + σdBt , ð1Þ  where m = μ ∣λ∣=A  p and μ is the stable fixed point of the drift, A is a time scale parameter, Bt is a Brownian motion and σ2 scales the variance. Disregarding the noise, this is the normal form of the codimension one saddle-node bifurcation17 (see “Methods”). The squareroot dependence of the stable state: μ m ∼  λc λ  p is the main signature of a saddle-node bifurcation. It is observed for the AMOC shutdown in ocean-only models as well as in coupled models, see Fig. 2, in strong support of Eq. (1) for the AMOC.At time t0, λ(t) begins to change linearly toward λc = λ(tc) = 0:  λðtÞ = λ0ð1 Θ1⁄2t t0 ðt t0Þ=τr Þ, ð2Þ  where Θ[t] is the Heaviside function and τr = tc − t0 > 0 is the ramping time up to time tc, where the transition eventually will occur. Time tc is denoted the tipping time; however, an actual tipping can happen earlier than tc due to a noise-induced tipping. As the transition is approached, the risk of noise-induced tipping (n-tipping) prior to tc is increasing and, at some point, making the EWSs irrelevant for predicting the tipping. The probability for n-tipping can, in the small noise limit, be calculated in closed form, Pðt,λÞ = 1 expð t=τnðλÞÞ, with mean waiting time  τnðλÞ = ðπ= ffi∣ffiλffiffi∣ffi  p Þ expð8∣λ∣3=2=3σ2Þ (see “Methods”). The mean and variance are calculated from the observations as the control parameter λ(t) is possibly changing. These EWSs are inherently equilibrium concepts and statistical; thus, a time window, Tw, of a certain size is required for a reliable estimate. As the transition is approached, the differences between the EWSs and the preramping values of the variance and autocorrelation (baseline) increase; thus, a shorter window Tw is required for detecting a difference. Conversely, close to the transition critical slowing down decreases the number of independent points within a window, thus calling for a larger window for reliable detection. Within a short enough window, [t − Tw/2, t + Tw/2], we may assume λ(t) to be constant and the noise small enough so that the process (1) for given λ is well approximated by a linear SDE, the Ornstein–Uhlenbeck process30. A Taylor expansion around the fixed point μ(λ) yields the approximation ... where ... and ... is the inverse correlation time. For fixed λ, the process is stationary, with mean μ, variance γ2 = σ2/2α and one-lag autocorrelation ρ = expð αΔtÞ with step size Δt = 1 month. As λ(t) increases, α decreases, and thus variance and autocorrelation increase. From μ, γ2 and ρ the parameters of Eq. (1) are determined: α = log ρ=Δt, σ2 = 2αγ2, A = α/2(μ − m) and  λ = ðσ2=4γ2Þ2=A. Closed form estimators for μ, γ2 and ρ are obtained from the observed time series within a running window by maximum likelihood estimation (MLE) (Supplementary text S1, see also ref. 31). The uncertainty is expressed through the variances of the estimators γ^2 and ^ρ obtained from the observations within a time window Tw. The hats indicate that they are estimators and thus stochastic variables with variances around the true values. Detection of an EWS at some chosen confidence level q (such as 95 or 99%) requires one of the estimates γ^2 or ^ρ for a given window to be statistically different from the baseline values γ^2  0 or ^ρ0, which depend on the window size as well as how different the EWSs are from their baseline values.",
    "reference_list": "考点1：“Climate Model Intercomparison Project (CMIP)”推荐译为“气候模式对比计划”\n考点2：“tipping”推荐译为“颠覆”，而不应该翻译成专有名词中常见表述“临界的”\n考点3：“co-dimension one saddle node bifurcations”推荐译为“共维一鞍节点分叉点”\n考点4：“resilience”推荐译为“恢复力”\n考点5：“quasi-stationary”推荐译为“准稳态/平稳”\n考点6：“Heaviside function”推荐译为“赫维赛德函数”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "136"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n登高望远，穿云破雾\n推动“大金砖合作”高质量发展\n——在金砖国家领导人第十六次会晤上的讲话\n尊敬的普京总统，\n各位同事：\n 　　祝贺峰会成功召开，感谢普京总统及东道主俄罗斯的周到安排和热情接待。\n 　　我想借此机会再次欢迎新成员加入金砖大家庭。扩员是金砖发展史上的重要里程碑，也是国际格局演变的标志性事件。这次峰会我们又决定邀请多个国家成为金砖伙伴国。这是金砖发展过程中的又一个重要进展。中国人常讲：“君子处事，于义合者为利。”金砖国家走到一起，是基于共同追求，顺应世界和平和发展大势。我们要利用好这次峰会，保持好金砖发展势头，谋划好全局性、方向性、战略性问题，同心同德，勇毅前行，推动金砖国家集体再出发。\n 　　当前，世界进入新的动荡变革期，面临关键抉择。是任由世界动荡不安，还是推动其重回和平发展的正道？我想到俄罗斯作家车尔尼雪夫斯基的著作《怎么办？》，书中主人公的坚强意志和奋斗激情，正是当前我们所需要的精神力量。时代的风浪越大，我们越要勇立潮头，以坚韧不拔之志、敢为人先之勇、识变应变之谋，把金砖打造成促进“全球南方”团结合作的主要渠道、推动全球治理变革的先锋力量。\n 　　——我们要建设“和平金砖”，做共同安全的维护者。人类是不可分割的安全共同体。只有践行共同、综合、合作、可持续的安全观，才能走出一条普遍安全之路。乌克兰危机还在延宕。中国和巴西会同有关“全球南方”国家发起了乌克兰危机“和平之友”小组，旨在汇集更多致力于和平的声音。我们要坚持“战场不外溢、战事不升级、各方不拱火”三原则，推动局势尽快缓和。加沙地区的人道主义形势持续恶化，黎巴嫩战火又起，相关各方间的冲突还在进一步升级。我们要推动尽快停火、停止杀戮，为全面、公正、持久解决巴勒斯坦问题不懈努力。\n 　　——我们要建设“创新金砖”，做高质量发展的先行者。新一轮科技革命和产业变革迅猛发展。我们要紧跟时代步伐，培育新质生产力。中方新近成立中国－金砖国家人工智能发展与合作中心，愿同各方深化创新合作，释放人工智能能量。中方将建立金砖国家深海资源国际研究中心、金砖国家特殊经济区中国合作中心、金砖国家工业能力中国中心、金砖国家数字产业生态合作网络。欢迎各方积极参与，推动金砖合作提质升级。\n 　　——我们要建设“绿色金砖”，做可持续发展的践行者。绿色是这个时代的底色，金砖国家要主动融入全球绿色低碳转型洪流。中国电动汽车、锂电池、光伏产品等优质产能，为世界绿色发展提供了重要助力。中方愿发挥自身优势，同金砖国家拓展绿色产业、清洁能源以及绿色矿产合作，推动全产业链“绿色化”发展，充实合作“含绿量”，提升发展“含金量”。\n 　　——我们要建设“公正金砖”，做全球治理体系改革的引领者。国际力量对比正在深刻演变，但全球治理体系改革长期滞后。我们要践行真正的多边主义，坚持共商共建共享的全球治理观，以公平正义、开放包容为理念引领全球治理改革。我们要顺应“全球南方”崛起大势，积极回应各国加入金砖合作机制的呼声，推进扩员和设置伙伴国进程，提升发展中国家在全球治理中的代表性和发言权。\n 　　当前形势下，国际金融架构改革紧迫性突出。金砖国家要发挥引领作用，深化财金合作，促进金融基础设施互联互通，维护高水平金融安全，做大做强新开发银行，推动国际金融体系更好反映世界经济格局变化。\n 　　——我们要建设“人文金砖”，做文明和合共生的倡导者。金砖国家汇聚了深厚的历史和璀璨的文化。我们要积极倡导不同文明包容共存，加强治国理政经验交流，挖掘教育、体育、艺术等领域合作潜力，让不同文明交相辉映，照亮金砖前行之路。去年，我提出金砖数字教育合作倡议，很高兴看到这一机制已经落地。中方将实施金砖数字教育能力建设计划，未来5年在金砖国家设立10个海外学习中心，为1000名教育管理人员和师生提供培训机会，助力金砖人文交流走深走实。\n 　　各位同事！\n 　　中方愿同金砖各国一道，开创“大金砖合作”高质量发展新局面，携手更多“全球南方”国家共同推动构建人类命运共同体！\n 　　谢谢大家！",
    "ori_text": "\n\n登高望远，穿云破雾\n推动“大金砖合作”高质量发展\n——在金砖国家领导人第十六次会晤上的讲话\n尊敬的普京总统，\n各位同事：\n 　　祝贺峰会成功召开，感谢普京总统及东道主俄罗斯的周到安排和热情接待。\n 　　我想借此机会再次欢迎新成员加入金砖大家庭。扩员是金砖发展史上的重要里程碑，也是国际格局演变的标志性事件。这次峰会我们又决定邀请多个国家成为金砖伙伴国。这是金砖发展过程中的又一个重要进展。中国人常讲：“君子处事，于义合者为利。”金砖国家走到一起，是基于共同追求，顺应世界和平和发展大势。我们要利用好这次峰会，保持好金砖发展势头，谋划好全局性、方向性、战略性问题，同心同德，勇毅前行，推动金砖国家集体再出发。\n 　　当前，世界进入新的动荡变革期，面临关键抉择。是任由世界动荡不安，还是推动其重回和平发展的正道？我想到俄罗斯作家车尔尼雪夫斯基的著作《怎么办？》，书中主人公的坚强意志和奋斗激情，正是当前我们所需要的精神力量。时代的风浪越大，我们越要勇立潮头，以坚韧不拔之志、敢为人先之勇、识变应变之谋，把金砖打造成促进“全球南方”团结合作的主要渠道、推动全球治理变革的先锋力量。\n 　　——我们要建设“和平金砖”，做共同安全的维护者。人类是不可分割的安全共同体。只有践行共同、综合、合作、可持续的安全观，才能走出一条普遍安全之路。乌克兰危机还在延宕。中国和巴西会同有关“全球南方”国家发起了乌克兰危机“和平之友”小组，旨在汇集更多致力于和平的声音。我们要坚持“战场不外溢、战事不升级、各方不拱火”三原则，推动局势尽快缓和。加沙地区的人道主义形势持续恶化，黎巴嫩战火又起，相关各方间的冲突还在进一步升级。我们要推动尽快停火、停止杀戮，为全面、公正、持久解决巴勒斯坦问题不懈努力。\n 　　——我们要建设“创新金砖”，做高质量发展的先行者。新一轮科技革命和产业变革迅猛发展。我们要紧跟时代步伐，培育新质生产力。中方新近成立中国－金砖国家人工智能发展与合作中心，愿同各方深化创新合作，释放人工智能能量。中方将建立金砖国家深海资源国际研究中心、金砖国家特殊经济区中国合作中心、金砖国家工业能力中国中心、金砖国家数字产业生态合作网络。欢迎各方积极参与，推动金砖合作提质升级。\n 　　——我们要建设“绿色金砖”，做可持续发展的践行者。绿色是这个时代的底色，金砖国家要主动融入全球绿色低碳转型洪流。中国电动汽车、锂电池、光伏产品等优质产能，为世界绿色发展提供了重要助力。中方愿发挥自身优势，同金砖国家拓展绿色产业、清洁能源以及绿色矿产合作，推动全产业链“绿色化”发展，充实合作“含绿量”，提升发展“含金量”。\n 　　——我们要建设“公正金砖”，做全球治理体系改革的引领者。国际力量对比正在深刻演变，但全球治理体系改革长期滞后。我们要践行真正的多边主义，坚持共商共建共享的全球治理观，以公平正义、开放包容为理念引领全球治理改革。我们要顺应“全球南方”崛起大势，积极回应各国加入金砖合作机制的呼声，推进扩员和设置伙伴国进程，提升发展中国家在全球治理中的代表性和发言权。\n 　　当前形势下，国际金融架构改革紧迫性突出。金砖国家要发挥引领作用，深化财金合作，促进金融基础设施互联互通，维护高水平金融安全，做大做强新开发银行，推动国际金融体系更好反映世界经济格局变化。\n 　　——我们要建设“人文金砖”，做文明和合共生的倡导者。金砖国家汇聚了深厚的历史和璀璨的文化。我们要积极倡导不同文明包容共存，加强治国理政经验交流，挖掘教育、体育、艺术等领域合作潜力，让不同文明交相辉映，照亮金砖前行之路。去年，我提出金砖数字教育合作倡议，很高兴看到这一机制已经落地。中方将实施金砖数字教育能力建设计划，未来5年在金砖国家设立10个海外学习中心，为1000名教育管理人员和师生提供培训机会，助力金砖人文交流走深走实。\n 　　各位同事！\n 　　中方愿同金砖各国一道，开创“大金砖合作”高质量发展新局面，携手更多“全球南方”国家共同推动构建人类命运共同体！\n 　　谢谢大家！",
    "reference_list": "考点1：大金砖合作 必须译为：greater BRICS cooperation。避免使用 \"Great BRICS Cooperation\" 等可能引起歧义的表达，\"greater\" 能准确体现扩员后范围更广、规模更大的含义。\n考点2：君子处事，于义合者为利。 必须译为：A man of virtue regards righteousness as the greatest interest。避免额外添加“for mutual benefit”等非原文信息，以免偏离“合乎道义本身就是利益”的核心含义。\n考点3：和平金砖 推荐翻译为：a BRICS committed to peace。\n考点4：战场不外溢、战事不升级、各方不拱火 推荐翻译为：no expansion of the battlefields, no escalation of hostilities, and no fanning flames。避免将“外溢”简化为 “not expanding war”，应保留“spillover/expansion of the battlefield”的准确概念。\n考点5：创新金砖 推荐翻译为：a BRICS committed to innovation。\n考点6：绿色金砖 推荐翻译为：a BRICS committed to green development。\n考点7：公正金砖 推荐翻译为：a BRICS committed to justice。\n考点8：践行真正的多边主义 推荐翻译为：to champion true multilateralism。避免用 “follow” 替代 “champion/practice”，否则会削弱主动性和政治力度。\n考点9：坚持共商共建共享的全球治理观 推荐翻译为：to adhere to the vision of global governance characterized by extensive consultation, joint contribution, and shared benefits。避免将“共商共建共享”简化为“...for shared benefit”，需保留三者并列结构。\n考点10：人文金砖 推荐翻译为：a BRICS committed to closer people-to-people exchanges。避免使用 \"Humanistic BRICS\" 等在英文语境中偏向“人本主义”或“人文学科”的表达。\n考点11：开创……新局面 推荐翻译为：open a new chapter for / usher in a new era of，而非 create a new situation of，避免中式直译。\n考点12：再出发（政治话语） 推荐翻译为：embark on a new journey / launch a new chapter，避免 new departure 等不常用于政治语境的表达。\n考点13：绿色是这个时代的底色 推荐翻译为：Green development defines our era / Green is a defining feature of our times，避免直译为 fundamental color of this era。\n考点14：充实合作“含绿量”，提升发展“含金量” 推荐翻译为：increase the sustainability of cooperation and enhance the value/quality of development，避免逐字直译为 green content / gold content，丢失文字游戏与文化意象。\n考点15：转型洪流 推荐翻译为：the torrent of transition / a surging tide of transformation，而非简单的 global trend，以保留比喻的力量与气势。\n考点16：崛起大势 推荐翻译为：the irresistible rise / the prevailing tide of the rise，避免 general trend of the rise 这种情感色彩偏弱的表述。\n考点17：海外学习中心 推荐翻译为：overseas learning centers，避免额外增补未出现的修饰（如 for digital education cooperation）除非原文明确。\n考点18：师生 推荐翻译为：teachers and students，不应改为 practitioners，以免改变受益人群的范围和性质。\n考点19：引领者 推荐翻译为：leaders in / be the leader of，避免用 promote 替代，以免弱化领导角色的主动性与权威性。\n考点20：外溢（安全语境） 推荐翻译为：spillover of the battlefield，保留军事/冲突语境的准确含义，避免仅用 not expanding war。\n考点21：发展与合作（机构名称） 推荐翻译为：Development and Cooperation，避免添加原文无的 Research 等词汇。\n",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "114"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n**Abstract:** As we know, Hanfeizi is the most representative figure of the legist school. His ideas are best described in his book “Hanfeizi ”,in which he strongly advocated the importance of “law”, “means”, “force ” for an emperor to control his country. About one thousand years later, in Italy there was an politician named Machiavelli. In his famous book called “The Prince”, he adopted the same attitude with Hanfeizi towards how an emperor should rule his country. In this paper, the author tries to explore some similarities and some dissimilarities between the two great thinkers from the aspect of their background, their attitudes towards the nature and relationship of human beings and so on.  \n\n**I Similarities in their backgrounds**  \n\nHanfeizi (280BC_233BC) was born in the Spring and Autumn Period in Han state. At that time Han state was the most weakest state of the seven states. Hanfeizi ,who was much influenced by his teacher Xunzi and the Taoism, saw the political corruption in his country and put forward much useful advice to carry out reform.. Unfortunately the emperor of Han would not like to adopt his ideas and let his country wither away. However the emperor of Qinshihuang admired the talent of Hanfeizi and wanted to give him a position in Qin state. Although Qinshihuang finally killed Hanfeizi owing to listening to the unfaithful advice of Lisi., he ruled his country on the principles advocated by Hanfeizi. Until that time did the divived situation come to an end and the united central right come out.  \n\nMachiavelli was born in Florence, Italy at a time when the country was in political upheaval . Italy was divided between four dominant city-states, and each of these was continually at the mercy of the stronger foreign governments of Europe. Since 1434 Florence was ruled by the wealthy Medici family. Their rule was temporarily interrupted by a reform movement, begun in 1494, in which the young Machiavelli became an important diplomat. When the Medici family regained power in 1512 with the help of Spanish troops, Machiavelli was tortured and removed from public life. For the next 10 years he devoted himself to writing history, political philosophy, and even plays. He ultimately gained favor with the Medici family and was called back to public duty for the last two years of his life. Machiavelli's greatest work is The Prince, written in 1513 and published after his death in 1532. The work immediately provoked controversy and was soon condemned by Pope Clement VIII. Its main theme is that princes should retain absolute control of their territories, and they should use any means of expediency to accomplish this end, including deceit. Scholars struggle over interpreting Machiavelli's precise point. In several section Machiavelli praises Caesar Borgia, a Spanish aristocrat who became a notorious and much despised tyrant of the Romagna region of northern Italy. During Machiavelli's early years as a diplomat, he was in contact with Borgia and witnessed Borgia's rule first hand. Does Machiavelli hold up Borgia as the model prince? Some readers initially saw The Prince as a satire on absolute rulers such as Borgia, which showed the repugnance of arbitrary power (thereby implying the importance of liberty). However, this theory fell apart when, in 1810, a letter by Machiavelli was discovered in which he reveals that he wrote The Prince to endear himself to the ruling Medici family in Florence. To liberate Italy from the influence of foreign governments, Machiavelli explains that strong indigenous governments are important, even if they are absolutist.  \n\n**II Similarities in their attitudes reflected in their works**  \n\n1. On force\n\nFrom the experience Machiavelli learned that weak countries had no diplomatic relationship with other counties. In his work he put forward that the weakest thing in the world was the power that was exaggerated. He tried to persuade the emperor to make a strong army, which would become the solid foundation of any course. While Hanfeizi held the same opinion with Machiavelli, he said that the most important task for an emperor was to develop his country in many ways such as increasing the production of agriculture, establish clear encouragement and punishment laws, have a forceful army under his control.  \n\n2. On humans nature and their relationship  \n\nThough humanists of Machiavelli's time believed that an individual had much to offer to the well being of the state, Machiavelli was quick to mock human nature. Humanists believed that \"An individual only grows to maturity- both intellectually and morally- through participation' in the life of the state.\"\n\nMachiavelli generally distrusted citizens, stating that \"...in time of adversity, when the state is in need of it's citizens there are few to be found.” Machiavelli further went on to question the loyalty of the citizens and advised the Prince that \"...because men a wretched creatures who would not keep their word to you, you need keep your word to them.\"  \n\nThe same to Hanfeizi. Under the influence of his teacher Xunzi, Hanfeizi adhered to the principle that human nature was bad. And his developed his ideas to the enumerated kingdom which he thought was the heaven of the earth. He believed that human beings were driven by the greed for profit. We can see some trace in his famous saying: strict mother has kind children, while kind mother has brute children.\n\nBoth of them believed that the relationship among human beings was a kind of naked interest_oriented relationship. They make use of each other, not believe in others, and would try every means to reach ones aims.  \n\n3. On the image of emperor.  \n\nIn The Prince Niccolo Machiavelli presents a view of governing : state that is drastically different from that of humanists of his time. Machiavelli believes the ruling Prince should be the sole authority determining every aspect of the state and put in effect a policy, which would serve his best interests. These interests were gaining, maintaining, and expanding his political power. His understanding of human nature was a complete contradiction of what humanists believed and\n\ntaught. Machiavelli strongly promoted a secular society and felt morality was not necessary but in fact stood in the way of an effectively governed principality. Though in come cases Machiavelli's suggestions seem harsh and immoral one must remember that these views\n\nwere derived out of concern Italy's unstable political condition. If a prince can not be both feared and loved, Machiavelli suggests, it would be better for him to be feared bey the citizens within his own principality. He makes the generalization that men are, \"...ungrateful, fickle, liars, and deceivers, they shun danger and are greedy for profit; while you treat them well they are yours.\" He characterizes men as being self centered and not willing to act in the best interest of the state,\"[and when the prince] is in danger they turn against[him].\" Machiavelli reinforces the prince's need to be feared by stating: Machiavelli postulates that a prince must also deceive those whoattempt to flatter him.\n\nIn choosing wise men for his government and allowing those the freedom to speak the truth to him, and then only concerning matters on which he asks their opinion, and nothing else. But he should also question them toughly and listen to what they say; then he should make\nup his own mind.\n\nMachiavelli actively promoted a secular form of politics. He laid aside the Medievalli conception \"of the state as a necessary creation for humankinds spiritual, material, and social well-being.\" In such a state,\"a ruler was justified in his exercise of political power only if it contributed to the common good of the people he served, and the ethical side of a princes activity...ought to be based on Christian moral principles....\"\n\nMachiavelli believed a secular form of government to be a more realistic type. His views were to the benefit of the prince, in helping him maintain power rather than to serve to the well being of the citizens. Machiavelli promoted his belief by stating: The fact is that a man who wants to act virtuously in every way necessarily comes to grief among those who are not virtuous. Therefore,if a prince wants to maintain his rule he must learn not to be sovirtuous, and to make use of this or not according to need.\n\nHanfeizi also had the same attitude .He advocated his ideas about the “law”, ”mean”, ”force”. Many emperors in the Chinese history adopted his ideas in order to rule their countries. He believed that as an emperor ,one should know the dividing line of the encouragement and punishment and use these them wisely. The emperor should learn to get rid of the opponents and use law to rule the country so that all the citizen would know what they should do and what they should not.",
    "ori_text": "**Abstract:** As we know, Hanfeizi is the most representative figure of the legist school. His ideas are best described in his book “Hanfeizi ”,in which he strongly advocated the importance of “law”, “means”, “force ” for an emperor to control his country. About one thousand years later, in Italy there was an politician named Machiavelli. In his famous book called “The Prince”, he adopted the same attitude with Hanfeizi towards how an emperor should rule his country. In this paper, the author tries to explore some similarities and some dissimilarities between the two great thinkers from the aspect of their background, their attitudes towards the nature and relationship of human beings and so on.  \n\n**I Similarities in their backgrounds**  \n\nHanfeizi (280BC_233BC) was born in the Spring and Autumn Period in Han state. At that time Han state was the most weakest state of the seven states. Hanfeizi ,who was much influenced by his teacher Xunzi and the Taoism, saw the political corruption in his country and put forward much useful advice to carry out reform.. Unfortunately the emperor of Han would not like to adopt his ideas and let his country wither away. However the emperor of Qinshihuang admired the talent of Hanfeizi and wanted to give him a position in Qin state. Although Qinshihuang finally killed Hanfeizi owing to listening to the unfaithful advice of Lisi., he ruled his country on the principles advocated by Hanfeizi. Until that time did the divived situation come to an end and the united central right come out.  \n\nMachiavelli was born in Florence, Italy at a time when the country was in political upheaval . Italy was divided between four dominant city-states, and each of these was continually at the mercy of the stronger foreign governments of Europe. Since 1434 Florence was ruled by the wealthy Medici family. Their rule was temporarily interrupted by a reform movement, begun in 1494, in which the young Machiavelli became an important diplomat. When the Medici family regained power in 1512 with the help of Spanish troops, Machiavelli was tortured and removed from public life. For the next 10 years he devoted himself to writing history, political philosophy, and even plays. He ultimately gained favor with the Medici family and was called back to public duty for the last two years of his life. Machiavelli's greatest work is The Prince, written in 1513 and published after his death in 1532. The work immediately provoked controversy and was soon condemned by Pope Clement VIII. Its main theme is that princes should retain absolute control of their territories, and they should use any means of expediency to accomplish this end, including deceit. Scholars struggle over interpreting Machiavelli's precise point. In several section Machiavelli praises Caesar Borgia, a Spanish aristocrat who became a notorious and much despised tyrant of the Romagna region of northern Italy. During Machiavelli's early years as a diplomat, he was in contact with Borgia and witnessed Borgia's rule first hand. Does Machiavelli hold up Borgia as the model prince? Some readers initially saw The Prince as a satire on absolute rulers such as Borgia, which showed the repugnance of arbitrary power (thereby implying the importance of liberty). However, this theory fell apart when, in 1810, a letter by Machiavelli was discovered in which he reveals that he wrote The Prince to endear himself to the ruling Medici family in Florence. To liberate Italy from the influence of foreign governments, Machiavelli explains that strong indigenous governments are important, even if they are absolutist.  \n\n**II Similarities in their attitudes reflected in their works**  \n\n1. On force\n\nFrom the experience Machiavelli learned that weak countries had no diplomatic relationship with other counties. In his work he put forward that the weakest thing in the world was the power that was exaggerated. He tried to persuade the emperor to make a strong army, which would become the solid foundation of any course. While Hanfeizi held the same opinion with Machiavelli, he said that the most important task for an emperor was to develop his country in many ways such as increasing the production of agriculture, establish clear encouragement and punishment laws, have a forceful army under his control.  \n\n2. On humans nature and their relationship  \n\nThough humanists of Machiavelli's time believed that an individual had much to offer to the well being of the state, Machiavelli was quick to mock human nature. Humanists believed that \"An individual only grows to maturity- both intellectually and morally- through participation' in the life of the state.\"\n\nMachiavelli generally distrusted citizens, stating that \"...in time of adversity, when the state is in need of it's citizens there are few to be found.” Machiavelli further went on to question the loyalty of the citizens and advised the Prince that \"...because men a wretched creatures who would not keep their word to you, you need keep your word to them.\"  \n\nThe same to Hanfeizi. Under the influence of his teacher Xunzi, Hanfeizi adhered to the principle that human nature was bad. And his developed his ideas to the enumerated kingdom which he thought was the heaven of the earth. He believed that human beings were driven by the greed for profit. We can see some trace in his famous saying: strict mother has kind children, while kind mother has brute children.\n\nBoth of them believed that the relationship among human beings was a kind of naked interest_oriented relationship. They make use of each other, not believe in others, and would try every means to reach ones aims.  \n\n3. On the image of emperor.  \n\nIn The Prince Niccolo Machiavelli presents a view of governing : state that is drastically different from that of humanists of his time. Machiavelli believes the ruling Prince should be the sole authority determining every aspect of the state and put in effect a policy, which would serve his best interests. These interests were gaining, maintaining, and expanding his political power. His understanding of human nature was a complete contradiction of what humanists believed and\n\ntaught. Machiavelli strongly promoted a secular society and felt morality was not necessary but in fact stood in the way of an effectively governed principality. Though in come cases Machiavelli's suggestions seem harsh and immoral one must remember that these views\n\nwere derived out of concern Italy's unstable political condition. If a prince can not be both feared and loved, Machiavelli suggests, it would be better for him to be feared bey the citizens within his own principality. He makes the generalization that men are, \"...ungrateful, fickle, liars, and deceivers, they shun danger and are greedy for profit; while you treat them well they are yours.\" He characterizes men as being self centered and not willing to act in the best interest of the state,\"[and when the prince] is in danger they turn against[him].\" Machiavelli reinforces the prince's need to be feared by stating: Machiavelli postulates that a prince must also deceive those whoattempt to flatter him.\n\nIn choosing wise men for his government and allowing those the freedom to speak the truth to him, and then only concerning matters on which he asks their opinion, and nothing else. But he should also question them toughly and listen to what they say; then he should make\nup his own mind.\n\nMachiavelli actively promoted a secular form of politics. He laid aside the Medievalli conception \"of the state as a necessary creation for humankinds spiritual, material, and social well-being.\" In such a state,\"a ruler was justified in his exercise of political power only if it contributed to the common good of the people he served, and the ethical side of a princes activity...ought to be based on Christian moral principles....\"\n\nMachiavelli believed a secular form of government to be a more realistic type. His views were to the benefit of the prince, in helping him maintain power rather than to serve to the well being of the citizens. Machiavelli promoted his belief by stating: The fact is that a man who wants to act virtuously in every way necessarily comes to grief among those who are not virtuous. Therefore,if a prince wants to maintain his rule he must learn not to be sovirtuous, and to make use of this or not according to need.\n\nHanfeizi also had the same attitude .He advocated his ideas about the “law”, ”mean”, ”force”. Many emperors in the Chinese history adopted his ideas in order to rule their countries. He believed that as an emperor ,one should know the dividing line of the encouragement and punishment and use these them wisely. The emperor should learn to get rid of the opponents and use law to rule the country so that all the citizen would know what they should do and what they should not.",
    "reference_list": "考点1：\"Spring and Autum period\"必须译为“春秋战国”\n考点2：“strict mother has kind children, while kind mother has brute children”必须译为“严家无悍虏，而慈母有败子”\n考点3：“law” 指的是韩非子思想核心，必须译为 “法”\n考点4： “means” 指的是韩非子思想核心，必须译为“术”\n考点5：“force” 指的是韩非子思想核心，必须译为 “势”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "19"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\n\nIdentified Transportation Challenges\n1. Technical Capability and Real-Time Data Utilization\nSeveral studies highlight critical issues related to technical capability and real-time data utilization in smart transportation systems. The main issue is the integration of heterogeneous IoT data sources, which often creates data silos and interoperability problems that hamper seamless communication and decision-making [27,28,29,30,43]. Additionally, many legacy systems struggle to process dynamic, real-time data, resulting in suboptimal traffic management and extended response times [30,35,36,37,41,45,46]. Researchers further note a lack of robust predictive models, which undermines short-term traffic flow predictions and hinders efficient management of congestion in response to factors such as weather, road incidents, and special events [29,30,32,33,42,48,49].\nLimited integration of multimodal traffic data with situational context also impedes effective transportation planning, underscoring the need to incorporate contextual information (e.g., real-time traffic restrictions and urban planning changes) [33,41]. Data reliability and accuracy remain pressing concerns, with sensor anomalies necessitating rigorous validation to ensure data quality [34,38,39,46,47]. Finally, interoperability gaps across transportation subsystems (e.g., buses and subways) create operational inefficiencies and negatively affect commuter experiences [28,33,45].\n2. Traffic Congestion\nTraffic congestion remains a central challenge in urban environments, impairing economic efficiency, environmental sustainability, and public health. Primary contributors include escalating vehicular density—driven by urbanization and rising vehicle ownership—and infrastructure limitations that fail to accommodate growing travel demand [24,26,28,35]. Inadequate real-time data processing curtails proactive congestion management measures, such as adaptive traffic signals and dynamic routing, while inefficiencies in traffic management systems further exacerbate the problem [27,34,43]. Severe congestion at key locations and during peak hours highlights the challenges of an overburdened transportation network that lacks the flexibility to accommodate fluctuating demand [31,36]. Long queues at intersections and inadequate signal timing contribute to further delays and inefficient traffic flow management [36].\nCongestion also disrupts travel time reliability and impacts public transportation systems, particularly buses sharing mixed traffic lanes, leading to service irregularities and passenger dissatisfaction [42,44]. Beyond operational inefficiencies, the environmental impact of sustained congestion is significant, including higher fuel consumption and emissions that degrade air quality and contribute to respiratory ailments [38,48]. These findings stress the urgency of implementing measures that mitigate congestion and foster sustainable transportation alternatives.\n3. Public Transit and Multimodal Transportation Systems\nPublic transit and multimodal systems face interconnected challenges that restrict efficiency, accessibility, and overall effectiveness. Inequitable access is particularly acute in rural areas, where limited mobility options constrain access to essential services and exacerbate social inequalities [25]. This challenge is compounded by rising operational costs for demand-responsive transport systems and the difficulty in balancing multiple objectives, such as cost, coverage, and equity [25]. Operational inefficiencies, such as static timetables and unpredictably fluctuating traffic conditions, extend passenger wait times, reduce service reliability, and increase dissatisfaction [28]. Furthermore, a lack of integrated multimodal data hampers seamless transitions among various travel modes, while suboptimal passenger flow management during peak hours compounds congestion and service quality issues [33,45]. Consequently, planners seek integrated strategies to enhance network design, service frequency, and data sharing, ensuring that transit systems remain accessible, efficient, and adaptable to changing user demands [45].\n4. Traffic Safety and Accidental Risks\nTraffic safety and accidental risks remain substantial concerns in both conventional and increasingly connected or automated transport systems. Recurring traffic violations—such as drunk driving and red-light running—persist despite current enforcement, indicating an unmet need for integrating violation data into accident prevention measures [49]. The lack of advanced sensor deployment in accident-prone areas further limits the capacity to identify and address these violations proactively, leading to persistent safety risks [49]. Security threats in vehicular networks are another pressing concern, as increased connectivity in smart transportation systems introduces vulnerabilities to cyber intrusions and attacks, which can compromise vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications, posing substantial risks to road users and critical infrastructure [43]. The need to balance mobility with health restrictions during crises, such as pandemics, presents unique challenges. Restrictions, including curfews and changing alert levels, disrupt traffic flow and necessitate real-time adjustments to route planning, complicating efforts to ensure both public safety and transportation efficiency [39]. Additionally, in the era of autonomous vehicles (AVs), safety risks in mixed-traffic environments may arise due to the coexistence of autonomous and human-driven vehicles, leading to unpredictable interactions and potential conflicts caused by differing driving behaviors and decision-making processes [37]. AVs operate based on pre-programmed algorithms, whereas human drivers rely on intuition and experience, increasing the likelihood of accidents in complex urban environments [37].\n5. Environmental Impacts\nEnvironmental concerns tied to transportation systems pose major barriers to sustainable urban development. Persistent congestion intensifies emissions of harmful pollutants, such as nitrogen oxides and particulate matter, degrading air quality and urban livability [38]. Reliance on fossil fuels contributes significantly to greenhouse gas emissions, climate change, and economic burdens associated with fuel consumption [44]. Poorly optimized logistics and traffic management practices exacerbate these challenges by increasing both travel distances and fuel consumption [47].\nIn response, numerous studies highlight a shift toward green transportation solutions, including enhanced public transit, active travel modes (e.g., walking and cycling), and smart mobility technologies [44]. Such strategies aim to lower environmental footprints and foster sustainable urban growth [44].\n6. Transportation System Operation and Management\nEffective operation and management of transportation systems are essential for ensuring efficiency, reliability, and sustainability. Nonetheless, resource limitations, legacy systems, and growing complexity create substantial operational hurdles. Studies point to constrained resources and the difficulty of balancing cost, coverage, and equity objectives, particularly in densely populated urban settings [25]. Conventional traffic management strategies are increasingly inadequate for handling modern, complex urban mobility, particularly as vehicle density rises [26,35]. One major contributor to inefficiency is the inadequate processing of real-time traffic data, which hinders the ability to implement adaptive traffic control measures [35]. Traffic light operations, in particular, remain inefficient, failing to respond effectively to fluctuating traffic volumes and dynamic demand patterns [34].\nFurthermore, many systems are ill-equipped to incorporate real-time data and respond adaptively to fluctuating traffic conditions [36]. Traditional predictive models, which are typically designed for static or historical data, often prove ill-suited or exhibit inadequate performance when applied to dynamic, real-time traffic conditions. The complexity and unpredictability of streamed data can lead to delayed or suboptimal traffic flow management and inefficient resource utilization [44]. Freight operations add further intricacy, as route planning, resource allocation, and fleet management must account for cost, environmental impact, and service reliability [47]. Collectively, these findings illustrate the urgent need for data-driven, integrated strategies capable of addressing congestion, resource allocation, and technological interoperability challenges.",
    "ori_text": "Identified Transportation Challenges\n1. Technical Capability and Real-Time Data Utilization\nSeveral studies highlight critical issues related to technical capability and real-time data utilization in smart transportation systems. The main issue is the integration of heterogeneous IoT data sources, which often creates data silos and interoperability problems that hamper seamless communication and decision-making [27,28,29,30,43]. Additionally, many legacy systems struggle to process dynamic, real-time data, resulting in suboptimal traffic management and extended response times [30,35,36,37,41,45,46]. Researchers further note a lack of robust predictive models, which undermines short-term traffic flow predictions and hinders efficient management of congestion in response to factors such as weather, road incidents, and special events [29,30,32,33,42,48,49].\nLimited integration of multimodal traffic data with situational context also impedes effective transportation planning, underscoring the need to incorporate contextual information (e.g., real-time traffic restrictions and urban planning changes) [33,41]. Data reliability and accuracy remain pressing concerns, with sensor anomalies necessitating rigorous validation to ensure data quality [34,38,39,46,47]. Finally, interoperability gaps across transportation subsystems (e.g., buses and subways) create operational inefficiencies and negatively affect commuter experiences [28,33,45].\n2. Traffic Congestion\nTraffic congestion remains a central challenge in urban environments, impairing economic efficiency, environmental sustainability, and public health. Primary contributors include escalating vehicular density—driven by urbanization and rising vehicle ownership—and infrastructure limitations that fail to accommodate growing travel demand [24,26,28,35]. Inadequate real-time data processing curtails proactive congestion management measures, such as adaptive traffic signals and dynamic routing, while inefficiencies in traffic management systems further exacerbate the problem [27,34,43]. Severe congestion at key locations and during peak hours highlights the challenges of an overburdened transportation network that lacks the flexibility to accommodate fluctuating demand [31,36]. Long queues at intersections and inadequate signal timing contribute to further delays and inefficient traffic flow management [36].\nCongestion also disrupts travel time reliability and impacts public transportation systems, particularly buses sharing mixed traffic lanes, leading to service irregularities and passenger dissatisfaction [42,44]. Beyond operational inefficiencies, the environmental impact of sustained congestion is significant, including higher fuel consumption and emissions that degrade air quality and contribute to respiratory ailments [38,48]. These findings stress the urgency of implementing measures that mitigate congestion and foster sustainable transportation alternatives.\n3. Public Transit and Multimodal Transportation Systems\nPublic transit and multimodal systems face interconnected challenges that restrict efficiency, accessibility, and overall effectiveness. Inequitable access is particularly acute in rural areas, where limited mobility options constrain access to essential services and exacerbate social inequalities [25]. This challenge is compounded by rising operational costs for demand-responsive transport systems and the difficulty in balancing multiple objectives, such as cost, coverage, and equity [25]. Operational inefficiencies, such as static timetables and unpredictably fluctuating traffic conditions, extend passenger wait times, reduce service reliability, and increase dissatisfaction [28]. Furthermore, a lack of integrated multimodal data hampers seamless transitions among various travel modes, while suboptimal passenger flow management during peak hours compounds congestion and service quality issues [33,45]. Consequently, planners seek integrated strategies to enhance network design, service frequency, and data sharing, ensuring that transit systems remain accessible, efficient, and adaptable to changing user demands [45].\n4. Traffic Safety and Accidental Risks\nTraffic safety and accidental risks remain substantial concerns in both conventional and increasingly connected or automated transport systems. Recurring traffic violations—such as drunk driving and red-light running—persist despite current enforcement, indicating an unmet need for integrating violation data into accident prevention measures [49]. The lack of advanced sensor deployment in accident-prone areas further limits the capacity to identify and address these violations proactively, leading to persistent safety risks [49]. Security threats in vehicular networks are another pressing concern, as increased connectivity in smart transportation systems introduces vulnerabilities to cyber intrusions and attacks, which can compromise vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications, posing substantial risks to road users and critical infrastructure [43]. The need to balance mobility with health restrictions during crises, such as pandemics, presents unique challenges. Restrictions, including curfews and changing alert levels, disrupt traffic flow and necessitate real-time adjustments to route planning, complicating efforts to ensure both public safety and transportation efficiency [39]. Additionally, in the era of autonomous vehicles (AVs), safety risks in mixed-traffic environments may arise due to the coexistence of autonomous and human-driven vehicles, leading to unpredictable interactions and potential conflicts caused by differing driving behaviors and decision-making processes [37]. AVs operate based on pre-programmed algorithms, whereas human drivers rely on intuition and experience, increasing the likelihood of accidents in complex urban environments [37].\n5. Environmental Impacts\nEnvironmental concerns tied to transportation systems pose major barriers to sustainable urban development. Persistent congestion intensifies emissions of harmful pollutants, such as nitrogen oxides and particulate matter, degrading air quality and urban livability [38]. Reliance on fossil fuels contributes significantly to greenhouse gas emissions, climate change, and economic burdens associated with fuel consumption [44]. Poorly optimized logistics and traffic management practices exacerbate these challenges by increasing both travel distances and fuel consumption [47].\nIn response, numerous studies highlight a shift toward green transportation solutions, including enhanced public transit, active travel modes (e.g., walking and cycling), and smart mobility technologies [44]. Such strategies aim to lower environmental footprints and foster sustainable urban growth [44].\n6. Transportation System Operation and Management\nEffective operation and management of transportation systems are essential for ensuring efficiency, reliability, and sustainability. Nonetheless, resource limitations, legacy systems, and growing complexity create substantial operational hurdles. Studies point to constrained resources and the difficulty of balancing cost, coverage, and equity objectives, particularly in densely populated urban settings [25]. Conventional traffic management strategies are increasingly inadequate for handling modern, complex urban mobility, particularly as vehicle density rises [26,35]. One major contributor to inefficiency is the inadequate processing of real-time traffic data, which hinders the ability to implement adaptive traffic control measures [35]. Traffic light operations, in particular, remain inefficient, failing to respond effectively to fluctuating traffic volumes and dynamic demand patterns [34].\nFurthermore, many systems are ill-equipped to incorporate real-time data and respond adaptively to fluctuating traffic conditions [36]. Traditional predictive models, which are typically designed for static or historical data, often prove ill-suited or exhibit inadequate performance when applied to dynamic, real-time traffic conditions. The complexity and unpredictability of streamed data can lead to delayed or suboptimal traffic flow management and inefficient resource utilization [44]. Freight operations add further intricacy, as route planning, resource allocation, and fleet management must account for cost, environmental impact, and service reliability [47]. Collectively, these findings illustrate the urgent need for data-driven, integrated strategies capable of addressing congestion, resource allocation, and technological interoperability challenges.",
    "reference_list": "考点1：heterogeneous IoT data sources 需译为 异构物联网数据源，IoT不可不译。\n考点2：legacy systems 可译为 “传统系统”或“遗留系统”。\n考点3：multimodal traffic data 可译为 “多式联运交通数据” 或 “多模态交通数据”。\n考点4：Multimodal Transportation 需译为 多式联运。\n考点5：vehicle-to-vehicle (V2V) 需译为 车对车（V2V）。\n考点6：vehicle-to-infrastructure (V2I) 需译为 车对基础设施（V2I）。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "16"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n1. Introduction\nDigital technology has drastically changed the possibilities for the curation and display of cultural heritage collections (CHCs). The physical and conceptual boundaries of such collections continue to expand, creating new opportunities for audiences to access and to engage with artefacts and cultural heritage [1]. During cultural heritage collection digitalisation processes the nuances of past heritage contexts need to be considered to ensure that cultures and diverse social groups are presented in an inclusive manner [2]. Heritage institutions traditionally use methods such as cataloguing and labelling to describe artefacts and to communicate such histories and cultures to the public. The fact that many collections were established through ‘finds’, excavations, expeditions, and bought or seized by colonisers means that narratives related to colonisation and oppression are inevitably part of analogue cultural records even if they are not made explicit within them. Cultural heritage is increasingly negotiated as a past practice that is (re)constructed in the present [3] (p. 3), [4,5] (pp. 32, 165), [6] (pp. 4–8). Different dimensions of CHCs such as acquisition histories, museum history, ownership, location, the items themselves, and curatorial guidance are all intertwined in creating an interactive system between people and information [7]. Critical heritage studies examine the nexus of people, heritage, and societal power in its challenge to conventional heritage discourses [3] (p. 281), [8] (p. 4). Heritage is thus a process ‘understood as being produced through socio-political processes reflecting society’s power structures’ [9] (p. 569).\nIn digitising CHCs, the question-and-answer protocol of new technologies such as ChatGPT or the production of synthetic images with DALL-E, MidJourney, or Stable Diffusion immediately creates a situation in which human and machine exist in a cognitively productive relationship; the human describes and the machine renders. Generative AI, also known as GenAI or GAI, is an artificial intelligence technology that can generate text, images, or other data using generative models, often in response to prompts. It learns the patterns and structure of input training data to generate new data with similar characteristics. GenAI and the synthetic data it produces has been examined from a number of perspectives. The aesthetics of AI and its impact on visual cultural practices have been extensively discussed [10,11]. Understanding such computationally aided creativity, there is a need for a deeper investigation of the socio-material complexity in implementing GenAI for cultural dissemination [12,13].\nThe research question that underpins this paper is whether and how a machine can interpret and classify human memory and its artefacts in retrospect in an inclusive manner. In this, we recognise that compromises have to be reached between historical fidelity and inclusivity; we think that this requires careful annotation to explicate diverse positions over time regarding particular subject matters but also that it is paramount to make heritage collections relevant to contemporary audiences [14]. Given the inevitable presence of bias in CHCs and in their digitised versions [15,16] (pp. 607–640), [17] (pp. 815–825), this article aims to discuss the challenges that automation brings as well as provide solutions from beyond the cultural heritage sector. CHCs are normally quite diverse unless they are following some metadata standards as digitised historical collections are the result of legacy digitalisation. Further, there is a lack of interconnectivity/interoperability of digitised collections: not everything is online, or well annotated, or using the same software, and that may be picked via a GenAI or an aggregator such as, for example, Google Arts and Culture.\n3. Results and Discussion\n3.1. What Is Bias and How Does It Leak into Heritage Datasets?\nBias as a concept is accompanied by ideas of prejudice, unfairness, distortion, and violation, including a systematic distortion of a statistical result due to a factor not allowed for in its derivation [18]. Bias may be as simple as an excluding description related to issues of race and ethnicity, age, gender, LGBTQIA+ communities, and ability. The use of particular data such as post codes in the construction of algorithms can end up amplifying existing skewing such as where supposedly credit-worthy citizens reside, with detrimental impacts on those living elsewhere [19]. All CHCs involve selection, a form of bias in itself. Such selection is frequently accompanied by outdated descriptions of their artefacts that entail inclusion of some segments of society and exclusion of others, conforming to descriptions of a world very different from the contemporary. Dominant historical, national narratives, and organisational legacies dictate what may be included and articulated in a collection [3,20]. While technology can, at least in theory, revolutionise how we understand the human contexts that CHCs carry and CHCs’ ‘democratisation’ [1,21], practice proves otherwise with the risk of carrying through biases of a not-so-distant past to the present and hence the future [2,22,23]. As recently discussed in relation to newspaper archival collections, ‘bias exists prior to any sampling. . .unbiased data—even as an idea—is essentially ahistorical data’ [24] (p. 5).\nResearch into digital cultural data demonstrates how bias transitions from collections to datasets and then to platforms. AI can amplify bias and hinder effective AI implemen- tation due to a lack of well-annotated datasets and structured metadata in CHCs. Biases within museum collections can manifest in datasets, databases, and aggregators that in- creasingly employ AI technologies such as machine learning [16,25]. Bias in CHCs is then transferred, and it entails issues of digital cultural colonialism and otherness, reflecting tensions between contrasting structures such as European/western versus other, North versus South, and centre versus periphery [2,26–29]. This also extends to gender. Kizhner et al. (2021) examine how bias in the cultural heritage platform Google Arts and Culture is amplified with AI noting that the choices behind digitisation, publication, aggregation, and promotion often obscure institutional, social, and political circumscriptions. These perpetuate the status quo at scale [16]. Kizhner et al. advocate making these epistemic choices transparent, documented, and interpretable. Davis et al. (2021) succinctly state that algorithms are animated by data, data come from people, people make up society, and society is unequal. Davis et al. (2021) [30] discuss algorithmic reparation and intersection- ality as frameworks to combat structural inequalities reflected and amplified by machine learning outcomes.\nIn computer vision, too, biases related to digital cultural colonialism and dominant epistemologies persist, leading to biased knowledge representations [31,32]. To avoid merely replicating biases, AI technology must evolve to embrace complex, non-binary, and non-dominant interpretations. The contribution of humanities expertise in generative AI platforms is at best unclear. This can lead to biased interpretations and classifications. Critical perspectives from the humanities and social sciences play a vital role in highlighting these issues relevant to more inclusive and equitable AI development practices. These perspectives emphasise the need for ethical AI development (see [33]) that addresses racial and gender discrimination, among other socio-ethical concerns.\nBias, especially racial and gender bias, extends across both technical and epistemo- logical domains, with the gender binary serving as a deeply racialised tool of colonial control. The concept of auto-essentialisation, recently introduced [34], describes how automated technologies reinforce identity distinctions rooted in colonial practices. The concept of auto-essentialisation is explored through historical gender practices, particularly the establishment of the European gender binary via 19th- and 20th-century disciplines such as sexology, physiognomy, and phrenology. These historical practices are viewed as predecessors to today’s automated facial analysis technologies in computer vision. This connection underscores the necessity for a critical reassessment of AI/ML applications in image recognition, as they may represent modern iterations of longstanding technologically mediated ideologies [13,34].\nBias might be mitigated by the enhanced interconnectivity and interoperability of digitised collections through collections ‘speaking to’ each other and correcting misattri- butions, etc. This is particularly important where one deals with rare objects and small special collections, not least if they are located in countries such as Sweden with relatively few collections that cannot provide large datasets to train AI on and are therefore prone to acquire software off-the-peg and not necessarily trained on relevant data. However, calls for such interconnectivity and interoperability which require transnational cooperation are still recent and require political will (see e.g., [35]) and negotiated resource provision.\n3.2. GenAI: An Illustration of Biased Synthesis\nWasielewski (2023b) [36] examines the challenges faced by GenAI text-to-image gen- erators such as DALL·E and Stable Diffusion, focusing on their struggles with hand rep- resentation and object counting. While these tools have democratised AI-driven image creation, leading to a surge in creative outputs, they also exhibit significant limitations because they are mechanistic in their depiction of the objects, relying on pattern replication rather than contextual knowledge. This results in images that may appear superficially correct but lack nuanced understanding. The rise of generative AI models like ChatGPT and DALL-E has captured the public imagination; cultural and creative sectors increasingly turn to predictive models for analysing and categorising their materials [37].\nThe opportunities GenAI affords are significantly structured by the CH sector that underlies them. As Griffin et al. (2023) have shown in the context of Sweden, a geographi- cally large country with a small population (around 10.5 million) and a correspondingly small CH sector that is also quite fragmented, factors such as limited budgets, lack of AI expertise among CH staff, lack of professional mobility and of continuing professional training among CH staff, small collections, and no overarching national policy on the matter, can lead to scenarios where these factors are replayed in how AI is engaged with. This means that individual CHCs may acquire off-the-peg software solutions not trained on the data they are actually applied to or solutions that also lack interconnectivity and interoperability with software and systems in ‘sister’ CHCs, or they may simply not (be able to) afford themselves of what AI and GenAI have to offer, thus isolating those CHCs both nationally and internationally.\nThe interconnectivity and interoperability of heritage datasets significantly aid AI implementation in the cultural heritage sector by enhancing data access, integration, and analysis capabilities. These characteristics enable AI systems to cross-reference information across multiple collections and institutions, providing a more comprehensive view of cultural heritage. For instance, AI can link artifacts from various museums to reconstruct historical contexts or identify patterns across diverse collections. Interoperability also facilitates the standardisation of catalogue data, making it easier for AI to process and understand information from different sources. This standardisation improves searchability and compatibility with new technologies, as demonstrated by the National Museum of the Royal Navy and the University of Southampton’s pilot project on standardising catalogue data for image collections (see for example https://www.heritagefund.org.uk/about/ insight/research/artificial-intelligence-digital-heritage-leadership-briefing, accessed on 28 October 2024). Interoperable datasets provide AI systems with richer, more diverse training data, leading to improved accuracy and better generalisation across different types of cultural heritage materials and contexts. This enhanced performance is crucial for developing robust AI applications in the heritage sector. Furthermore, interconnectivity and interoperability support collaborative AI implementation by enabling knowledge sharing and facilitating multi-institutional projects (see [38] for practical solutions for enhancing interconnectivity).\nCultural heritage institutions can share expertise, resources, and best practices more easily when working with compatible datasets, potentially leading to groundbreaking discoveries or innovative applications. Many cultural heritage institutions face resource constraints when implementing AI. Interoperability helps address this challenge by al- lowing institutions to pool resources and share AI tools, expertise, and computational resources. This collaboration makes AI implementation more accessible to smaller organi- sations and reduces duplication of effort, as standardised, interoperable datasets prevent institutions from having to reinvent the wheel when implementing AI solutions. Inter- connected and interoperable datasets also enhance the discoverability and accessibility of cultural heritage materials through AI-powered tools. AI systems can leverage these datasets to provide more sophisticated search capabilities across multiple collections and in- stitutions, as well as offer more accurate and personalised recommendations to researchers and visitors. This improved functionality enhances user experience and engagement with cultural heritage materials.",
    "ori_text": "\n\n1. Introduction\nDigital technology has drastically changed the possibilities for the curation and display of cultural heritage collections (CHCs). The physical and conceptual boundaries of such collections continue to expand, creating new opportunities for audiences to access and to engage with artefacts and cultural heritage [1]. During cultural heritage collection digitalisation processes the nuances of past heritage contexts need to be considered to ensure that cultures and diverse social groups are presented in an inclusive manner [2]. Heritage institutions traditionally use methods such as cataloguing and labelling to describe artefacts and to communicate such histories and cultures to the public. The fact that many collections were established through ‘finds’, excavations, expeditions, and bought or seized by colonisers means that narratives related to colonisation and oppression are inevitably part of analogue cultural records even if they are not made explicit within them. Cultural heritage is increasingly negotiated as a past practice that is (re)constructed in the present [3] (p. 3), [4,5] (pp. 32, 165), [6] (pp. 4–8). Different dimensions of CHCs such as acquisition histories, museum history, ownership, location, the items themselves, and curatorial guidance are all intertwined in creating an interactive system between people and information [7]. Critical heritage studies examine the nexus of people, heritage, and societal power in its challenge to conventional heritage discourses [3] (p. 281), [8] (p. 4). Heritage is thus a process ‘understood as being produced through socio-political processes reflecting society’s power structures’ [9] (p. 569).\nIn digitising CHCs, the question-and-answer protocol of new technologies such as ChatGPT or the production of synthetic images with DALL-E, MidJourney, or Stable Diffusion immediately creates a situation in which human and machine exist in a cognitively productive relationship; the human describes and the machine renders. Generative AI, also known as GenAI or GAI, is an artificial intelligence technology that can generate text, images, or other data using generative models, often in response to prompts. It learns the patterns and structure of input training data to generate new data with similar characteristics. GenAI and the synthetic data it produces has been examined from a number of perspectives. The aesthetics of AI and its impact on visual cultural practices have been extensively discussed [10,11]. Understanding such computationally aided creativity, there is a need for a deeper investigation of the socio-material complexity in implementing GenAI for cultural dissemination [12,13].\nThe research question that underpins this paper is whether and how a machine can interpret and classify human memory and its artefacts in retrospect in an inclusive manner. In this, we recognise that compromises have to be reached between historical fidelity and inclusivity; we think that this requires careful annotation to explicate diverse positions over time regarding particular subject matters but also that it is paramount to make heritage collections relevant to contemporary audiences [14]. Given the inevitable presence of bias in CHCs and in their digitised versions [15,16] (pp. 607–640), [17] (pp. 815–825), this article aims to discuss the challenges that automation brings as well as provide solutions from beyond the cultural heritage sector. CHCs are normally quite diverse unless they are following some metadata standards as digitised historical collections are the result of legacy digitalisation. Further, there is a lack of interconnectivity/interoperability of digitised collections: not everything is online, or well annotated, or using the same software, and that may be picked via a GenAI or an aggregator such as, for example, Google Arts and Culture.\n3. Results and Discussion\n3.1. What Is Bias and How Does It Leak into Heritage Datasets?\nBias as a concept is accompanied by ideas of prejudice, unfairness, distortion, and violation, including a systematic distortion of a statistical result due to a factor not allowed for in its derivation [18]. Bias may be as simple as an excluding description related to issues of race and ethnicity, age, gender, LGBTQIA+ communities, and ability. The use of particular data such as post codes in the construction of algorithms can end up amplifying existing skewing such as where supposedly credit-worthy citizens reside, with detrimental impacts on those living elsewhere [19]. All CHCs involve selection, a form of bias in itself. Such selection is frequently accompanied by outdated descriptions of their artefacts that entail inclusion of some segments of society and exclusion of others, conforming to descriptions of a world very different from the contemporary. Dominant historical, national narratives, and organisational legacies dictate what may be included and articulated in a collection [3,20]. While technology can, at least in theory, revolutionise how we understand the human contexts that CHCs carry and CHCs’ ‘democratisation’ [1,21], practice proves otherwise with the risk of carrying through biases of a not-so-distant past to the present and hence the future [2,22,23]. As recently discussed in relation to newspaper archival collections, ‘bias exists prior to any sampling. . .unbiased data—even as an idea—is essentially ahistorical data’ [24] (p. 5).\nResearch into digital cultural data demonstrates how bias transitions from collections to datasets and then to platforms. AI can amplify bias and hinder effective AI implemen- tation due to a lack of well-annotated datasets and structured metadata in CHCs. Biases within museum collections can manifest in datasets, databases, and aggregators that in- creasingly employ AI technologies such as machine learning [16,25]. Bias in CHCs is then transferred, and it entails issues of digital cultural colonialism and otherness, reflecting tensions between contrasting structures such as European/western versus other, North versus South, and centre versus periphery [2,26–29]. This also extends to gender. Kizhner et al. (2021) examine how bias in the cultural heritage platform Google Arts and Culture is amplified with AI noting that the choices behind digitisation, publication, aggregation, and promotion often obscure institutional, social, and political circumscriptions. These perpetuate the status quo at scale [16]. Kizhner et al. advocate making these epistemic choices transparent, documented, and interpretable. Davis et al. (2021) succinctly state that algorithms are animated by data, data come from people, people make up society, and society is unequal. Davis et al. (2021) [30] discuss algorithmic reparation and intersection- ality as frameworks to combat structural inequalities reflected and amplified by machine learning outcomes.\nIn computer vision, too, biases related to digital cultural colonialism and dominant epistemologies persist, leading to biased knowledge representations [31,32]. To avoid merely replicating biases, AI technology must evolve to embrace complex, non-binary, and non-dominant interpretations. The contribution of humanities expertise in generative AI platforms is at best unclear. This can lead to biased interpretations and classifications. Critical perspectives from the humanities and social sciences play a vital role in highlighting these issues relevant to more inclusive and equitable AI development practices. These perspectives emphasise the need for ethical AI development (see [33]) that addresses racial and gender discrimination, among other socio-ethical concerns.\nBias, especially racial and gender bias, extends across both technical and epistemo- logical domains, with the gender binary serving as a deeply racialised tool of colonial control. The concept of auto-essentialisation, recently introduced [34], describes how automated technologies reinforce identity distinctions rooted in colonial practices. The concept of auto-essentialisation is explored through historical gender practices, particularly the establishment of the European gender binary via 19th- and 20th-century disciplines such as sexology, physiognomy, and phrenology. These historical practices are viewed as predecessors to today’s automated facial analysis technologies in computer vision. This connection underscores the necessity for a critical reassessment of AI/ML applications in image recognition, as they may represent modern iterations of longstanding technologically mediated ideologies [13,34].\nBias might be mitigated by the enhanced interconnectivity and interoperability of digitised collections through collections ‘speaking to’ each other and correcting misattri- butions, etc. This is particularly important where one deals with rare objects and small special collections, not least if they are located in countries such as Sweden with relatively few collections that cannot provide large datasets to train AI on and are therefore prone to acquire software off-the-peg and not necessarily trained on relevant data. However, calls for such interconnectivity and interoperability which require transnational cooperation are still recent and require political will (see e.g., [35]) and negotiated resource provision.\n3.2. GenAI: An Illustration of Biased Synthesis\nWasielewski (2023b) [36] examines the challenges faced by GenAI text-to-image gen- erators such as DALL·E and Stable Diffusion, focusing on their struggles with hand rep- resentation and object counting. While these tools have democratised AI-driven image creation, leading to a surge in creative outputs, they also exhibit significant limitations because they are mechanistic in their depiction of the objects, relying on pattern replication rather than contextual knowledge. This results in images that may appear superficially correct but lack nuanced understanding. The rise of generative AI models like ChatGPT and DALL-E has captured the public imagination; cultural and creative sectors increasingly turn to predictive models for analysing and categorising their materials [37].\nThe opportunities GenAI affords are significantly structured by the CH sector that underlies them. As Griffin et al. (2023) have shown in the context of Sweden, a geographi- cally large country with a small population (around 10.5 million) and a correspondingly small CH sector that is also quite fragmented, factors such as limited budgets, lack of AI expertise among CH staff, lack of professional mobility and of continuing professional training among CH staff, small collections, and no overarching national policy on the matter, can lead to scenarios where these factors are replayed in how AI is engaged with. This means that individual CHCs may acquire off-the-peg software solutions not trained on the data they are actually applied to or solutions that also lack interconnectivity and interoperability with software and systems in ‘sister’ CHCs, or they may simply not (be able to) afford themselves of what AI and GenAI have to offer, thus isolating those CHCs both nationally and internationally.\nThe interconnectivity and interoperability of heritage datasets significantly aid AI implementation in the cultural heritage sector by enhancing data access, integration, and analysis capabilities. These characteristics enable AI systems to cross-reference information across multiple collections and institutions, providing a more comprehensive view of cultural heritage. For instance, AI can link artifacts from various museums to reconstruct historical contexts or identify patterns across diverse collections. Interoperability also facilitates the standardisation of catalogue data, making it easier for AI to process and understand information from different sources. This standardisation improves searchability and compatibility with new technologies, as demonstrated by the National Museum of the Royal Navy and the University of Southampton’s pilot project on standardising catalogue data for image collections (see for example https://www.heritagefund.org.uk/about/ insight/research/artificial-intelligence-digital-heritage-leadership-briefing, accessed on 28 October 2024). Interoperable datasets provide AI systems with richer, more diverse training data, leading to improved accuracy and better generalisation across different types of cultural heritage materials and contexts. This enhanced performance is crucial for developing robust AI applications in the heritage sector. Furthermore, interconnectivity and interoperability support collaborative AI implementation by enabling knowledge sharing and facilitating multi-institutional projects (see [38] for practical solutions for enhancing interconnectivity).\nCultural heritage institutions can share expertise, resources, and best practices more easily when working with compatible datasets, potentially leading to groundbreaking discoveries or innovative applications. Many cultural heritage institutions face resource constraints when implementing AI. Interoperability helps address this challenge by al- lowing institutions to pool resources and share AI tools, expertise, and computational resources. This collaboration makes AI implementation more accessible to smaller organi- sations and reduces duplication of effort, as standardised, interoperable datasets prevent institutions from having to reinvent the wheel when implementing AI solutions. Inter- connected and interoperable datasets also enhance the discoverability and accessibility of cultural heritage materials through AI-powered tools. AI systems can leverage these datasets to provide more sophisticated search capabilities across multiple collections and in- stitutions, as well as offer more accurate and personalised recommendations to researchers and visitors. This improved functionality enhances user experience and engagement with cultural heritage materials.",
    "reference_list": "考点1. cultural heritage collections (CHCs)必须译为：文化遗产藏品\n考点2. expeditions推荐译为：探险\n考点3. gender binary必须译为：性别二元论\n考点4. auto-essentialisation必须译为：自动本质化\n考点5. ‘sister’ CHCs必须译为：姊妹文化遗产藏品\n考点6. Interoperable datasets推荐译为：互操性的数据集/可互操作的数据集\n考点7. reinvent the wheel推荐译为：重复性工作",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "147"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n沿着时间社会学长期以来专注时间体验的研究取向,本文以等待为线索,试图处理社会时间理论中主体性不足的困境。通过回溯等待这一时间体验的理论基础,本文考察了等待的双重属性,也即他者指涉的社会性和自我指涉的主体性,进而揭示出等待中希望的生产在桥接时间、自我与他人方面所具的社会意义。本文为社会时间框架下消极的主体正名,并建立了一种兼顾社会时间的社会性与主体性的分析路径。\n社会生活中的时间议题不胜枚举,其中“等待”作为体验时间和权力之间关系的一种特殊方式,直戳社会时间结构问题的症结,成为时间社会学的重要研究对象。相关研究揭示出等待在不同社会领域存在的困境及出路,但鲜少与经典社会学理论对话,或未叩击时间社会学的核心议题,使得我们仍要处理那些碎片化的社会时间理论及多元化的经验景象。实际上,一种关于等待的系统性阐析可以超越时间结构的批判性分析框架,在经典社会学建立的理论基础之上,应对时间社会学分析中主体性不足的境况。\n主体性不足首先体现在结构功能主义和马克思主义对时间的社会建构与支配分析的传统旨趣中。自涂尔干提出“时间作为一种社会范畴”开始,社会学家对时间的探索往往围绕着时间的社会建构特征展开,并将社会成员间共享的时间范畴视作社会生活秩序的基础。这种时间的功能主义探索虽然揭开了那些隐藏在自然时间背后的社会结构性力量,却又逐渐摒弃了能动的个体关于时间的鲜活体验。随着马克思主义学派对工作—时间理论的发展,工人在资本主义生产过程中的行动意志及所受剥削备受关注。一种“被支配的主体”在这种时间范畴的政治经济学批判中走上前台,从而弥合了结构功能主义学派中的主体性缺失状态。另一方面,马克思主义用商品化时间来理解工业化时间的倾向,使得社会时间的主体性研究将重心转向一种受经济、政治或文化法则支配下的消极主体,进而消减了主体的完整性。\n在社会时间研究深入的过程中,人们注意到现代制度体系不断制造着一种日常的、强制的或普遍的等待状态。等待经验中的消极主体逐渐成为时间建构与支配研究的重要切入点,并在经济、政治和文化领域得到检验。例如,顾客排队等待现象服务于商家谋取利润最大化的工具性动机,这实则损害了顾客的时间利益;监狱制度通过剥夺长期服刑囚犯的时间主权,促使他们主动屈服于无限期的等待状态;主流文化将“延迟满足”型等待与未来成就之实现关联起来,通过一种符号价值的塑造,实现青年人的自我管理与控制。不过,无论是沿着结构功能主义的时间建构视角,还是遵循马克思主义的政治经济学批判,等待都很容易被描绘为一种被强制接受且无法改变的状态。由此带来的结果之一便是等待研究中对于权力不平等议题的偏好。这类议题专注于勾勒等待者受时间秩序支配的形象,因而未能充分把握一种完整的主体性。随着互动论与现象学将社会时间与主体间复杂而多样的关系带回研究者视野中,社会成员利用时间来调整和组织自己生活的能动性也重新受到审视。\n换言之,关于“被支配的主体性”的批判性讨论忽略了存在于社会时间中的“能动的主体性”。同质性的社会时间被不同的主体以多种方式感知和体验着,人们在等待中通常不会空等,而会选择开展别的行动,以填补空等所导致的时间间隔或不确定性。由此可见,等待的消极性不等于等待者的消极性。等待的主体能够付诸一系列积极利用时间的实践,进而以自主的能动者的姿态来驾驭和理解个人时间,探索与建立社会意义。例如,有研究发现,长期失业者在其充满不确定性的待业期中会从一开始失去生活意义的状态转向努力控制生活轨迹。\n从社会时间研究中主体性的“缺失”到“被支配”的推进,再到一种“能动的主体”的出场,我们可以看到关于等待的研究不仅能够超越社会建构与秩序的分析框架,还能为时间、社会和主体之间复杂的相互作用提供宝贵的见解。通过关注行动者作为能动的主体所开展的时间实践,关于等待的研究可以为社会时间框架下的消极主体正名,进而为回答时间的社会性及主体性同在提供切入口。本文以等待的时间体验为线索回溯等待的社会理论基础,分析这种时间体验所。具有的社会性与主体性之双重属性以及如何发挥其社会性及主体性之双重价值,进而提供一种兼顾社会性建构与主体性存在的时间分析路径。",
    "ori_text": "\n\n沿着时间社会学长期以来专注时间体验的研究取向,本文以等待为线索,试图处理社会时间理论中主体性不足的困境。通过回溯等待这一时间体验的理论基础,本文考察了等待的双重属性,也即他者指涉的社会性和自我指涉的主体性,进而揭示出等待中希望的生产在桥接时间、自我与他人方面所具的社会意义。本文为社会时间框架下消极的主体正名,并建立了一种兼顾社会时间的社会性与主体性的分析路径。\n社会生活中的时间议题不胜枚举,其中“等待”作为体验时间和权力之间关系的一种特殊方式,直戳社会时间结构问题的症结,成为时间社会学的重要研究对象。相关研究揭示出等待在不同社会领域存在的困境及出路,但鲜少与经典社会学理论对话,或未叩击时间社会学的核心议题,使得我们仍要处理那些碎片化的社会时间理论及多元化的经验景象。实际上,一种关于等待的系统性阐析可以超越时间结构的批判性分析框架,在经典社会学建立的理论基础之上,应对时间社会学分析中主体性不足的境况。\n主体性不足首先体现在结构功能主义和马克思主义对时间的社会建构与支配分析的传统旨趣中。自涂尔干提出“时间作为一种社会范畴”开始,社会学家对时间的探索往往围绕着时间的社会建构特征展开,并将社会成员间共享的时间范畴视作社会生活秩序的基础。这种时间的功能主义探索虽然揭开了那些隐藏在自然时间背后的社会结构性力量,却又逐渐摒弃了能动的个体关于时间的鲜活体验。随着马克思主义学派对工作—时间理论的发展,工人在资本主义生产过程中的行动意志及所受剥削备受关注。一种“被支配的主体”在这种时间范畴的政治经济学批判中走上前台,从而弥合了结构功能主义学派中的主体性缺失状态。另一方面,马克思主义用商品化时间来理解工业化时间的倾向,使得社会时间的主体性研究将重心转向一种受经济、政治或文化法则支配下的消极主体,进而消减了主体的完整性。\n在社会时间研究深入的过程中,人们注意到现代制度体系不断制造着一种日常的、强制的或普遍的等待状态。等待经验中的消极主体逐渐成为时间建构与支配研究的重要切入点,并在经济、政治和文化领域得到检验。例如,顾客排队等待现象服务于商家谋取利润最大化的工具性动机,这实则损害了顾客的时间利益;监狱制度通过剥夺长期服刑囚犯的时间主权,促使他们主动屈服于无限期的等待状态;主流文化将“延迟满足”型等待与未来成就之实现关联起来,通过一种符号价值的塑造,实现青年人的自我管理与控制。不过,无论是沿着结构功能主义的时间建构视角,还是遵循马克思主义的政治经济学批判,等待都很容易被描绘为一种被强制接受且无法改变的状态。由此带来的结果之一便是等待研究中对于权力不平等议题的偏好。这类议题专注于勾勒等待者受时间秩序支配的形象,因而未能充分把握一种完整的主体性。随着互动论与现象学将社会时间与主体间复杂而多样的关系带回研究者视野中,社会成员利用时间来调整和组织自己生活的能动性也重新受到审视。\n换言之,关于“被支配的主体性”的批判性讨论忽略了存在于社会时间中的“能动的主体性”。同质性的社会时间被不同的主体以多种方式感知和体验着,人们在等待中通常不会空等,而会选择开展别的行动,以填补空等所导致的时间间隔或不确定性。由此可见,等待的消极性不等于等待者的消极性。等待的主体能够付诸一系列积极利用时间的实践,进而以自主的能动者的姿态来驾驭和理解个人时间,探索与建立社会意义。例如,有研究发现,长期失业者在其充满不确定性的待业期中会从一开始失去生活意义的状态转向努力控制生活轨迹。\n从社会时间研究中主体性的“缺失”到“被支配”的推进,再到一种“能动的主体”的出场,我们可以看到关于等待的研究不仅能够超越社会建构与秩序的分析框架,还能为时间、社会和主体之间复杂的相互作用提供宝贵的见解。通过关注行动者作为能动的主体所开展的时间实践,关于等待的研究可以为社会时间框架下的消极主体正名,进而为回答时间的社会性及主体性同在提供切入口。本文以等待的时间体验为线索回溯等待的社会理论基础,分析这种时间体验所。具有的社会性与主体性之双重属性以及如何发挥其社会性及主体性之双重价值,进而提供一种兼顾社会性建构与主体性存在的时间分析路径。",
    "reference_list": "考点1. “时间社会学”必须译为“Sociology of Time”\n考点2. “主体性不足”必须译为“Insufficient Subjectivity; Lack of Subjectivity”\n考点3. “他者指涉”必须译为“Other-reference”\n考点4. “自我指涉”必须译为“Self-reference”\n考点5. “消极的主体”必须译为“Negative Subject”\n考点6. “能动的主体（性）必须译为“Agentic Subject; Agentic Subjectivity”\n考点7. “被支配的主体”必须译为“Dominated Subject”。\n考点8. “线索”推荐译为“Lens; Analytical Thread”\n考点9. “困境”推荐译为“Dilemma; Predicament”\n考点10. “为……正名”推荐译为“To Vindicate”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "143"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n在沿海深厚软土地层中，由于其天然沉积成因复杂，形成了结构性显著、胶结性弱、微观孔隙形态高度多样的软黏性土体，其工程响应表现出显著的非线性、各向异性及时效性。当前城市基础设施向纵深发展趋势愈发显著，深基坑、地下空间及盾构隧道工程广泛侵入至30–60 m深度，常穿越多个承压含水层与扰动敏感软土层，故准确掌握软土在不同应力路径、加载速率与排水条件下的力学行为，成为高风险工程中亟待突破的技术瓶颈。\n本研究基于应力–应变–时间三维耦合视角，结合室内多路径三轴试验与微观结构观测，探讨深层软黏土在多种加载条件下的破坏机制与本构响应规律。试验采用GDS全自动三轴加载系统，设置恒应力比加载、应变控制加载及路径依赖加载等工况，分别开展了CU、CD与加载–卸载–再加载循环试验。试样取自上海浦东某典型地段第Ⅰ承压含水层上覆层，物理性质指标中天然含水率约为42%，液限约为52%，初始结构性明显。\n在试样制备阶段，通过真空饱和–背压饱和联合方案确保Skempton B值大于0.97。固结过程采用K0等向主固结路径模拟竖向加载条件；加载阶段控制速率为0.1 %/min，孔压及体应变数据每0.5 s采集一次，以捕捉瞬态响应。在非排水CU试验中观察到典型的剪切软化行为，最大主应力差达186 kPa后显著下降，强度包络曲线呈现非线性扩展趋势。部分样本表现出双峰型剪切响应，反映出内在结构破坏与颗粒重排的阶段性过程。\n结合剪胀角–应力比演化路径，发现该类土体在初始阶段表现为负剪胀，即体积压缩趋势明显，随加载持续出现临界状态剪胀角迅速增长的过渡过程，表明结构性破坏触发了粒间滑移与孔隙重构过程。应用DIC数字图像技术分析剪切带发展情况，发现剪切破坏并非单一面局部化，而呈现多裂缝共存、剪切面分支发展的复杂形态，尤其在加载–卸载–再加载循环试验中，剪切路径与之前不同，表现出明显的结构劣化记忆效应。\n在固结排水（CD）路径中，试样呈现较强的剪胀效应与残余强度平台，未发生明显峰值强度下降，显示出结构破坏模式受排水路径显著调控。为评估长期变形趋势，引入等时应变法，以不同持荷阶段（1 h、4 h、24 h）为基准，统计轴向与体积等时应变变化，并采用Burgers黏弹模型对长期蠕变数据进行拟合，获得瞬态黏滞参数η₁、稳态黏滞η₂及弹性模量E₁、E₂，发现软土黏弹参数与初始孔隙比呈幂律正相关关系。\n为进一步揭示微观机制，利用场发射扫描电子显微镜（FE-SEM）对试样剪切前后进行对比观察，结合X射线衍射分析（XRD）分析矿物组分演变，并辅以能谱分析（EDS）识别剪切面微区元素富集变化。结果表明，在剪切带区域，伊利石晶粒趋于定向排列，钙离子迁移导致絮凝结构松散化，反映出剪切诱导的物理–化学协同破坏机制。\n理论方面，本研究引入基于结构性演化的双屈服面模型，考虑加载历史下结构退化函数s(ε)，其演化由指数型函数控制，辅以非线性剪胀函数与加载方向因子。\n通过与Cam-Clay模型、ISSM模型（ISSM：Isotropic Structurally Sensitive Model）对比发现，传统模型无法准确再现应力路径切换下的剪胀行为突变、破坏延迟现象及循环加载的结构记忆效应，而本模型在路径相关性、多峰应力响应及剪切模量演化趋势拟合方面表现优异，具有良好的工程适应性。\n考虑深基坑降水导致的负孔压效应，通过轴对称渗透–剪切耦合试验装置模拟降水速率变化，结果揭示：在中高降水速率下，试样中部形成显著孔压梯度，导致有效应力突变，进而诱发剪切集中、结构坍塌及局部再固结过程。此现象在实际基坑监测中与沉降突变、内支撑反力异常响应高度吻合，显示模型理论具有现实指导意义。\n在理论分析基础上，为验证结构性本构模型在实际工程中的适用性，本文选取上海某深基坑工程作为验证场景。该工程基坑开挖深度达42.5 m，围护结构为地下连续墙+多道支撑体系，基坑底部穿越第Ⅰ与第Ⅱ承压含水层之间的软弱过渡层，层厚约9.5 m，孔隙比高达1.87。该区域地下水位变化频繁，软土结构性显著，对降水引起的有效应力扰动极为敏感。\n基于现场地勘资料与室内试验参数，构建二维有限元模型，采用应力–应变法分析基坑底部隆起、周边沉降与支撑内力响应。在模型中，软弱夹层赋予结构性演化模型，其余层按修正Mohr–Coulomb模型处理。通过参数反演校正过程，选取位移监测数据作为目标函数，以遗传算法优化剪切模量G₀、结构参数s₀、剪胀角ψ₀与屈服函数参数n的初始取值。拟合结果表明，结构性模型可有效反映现场观测中的非对称沉降、底鼓偏移及支撑反力滞后等现象。\n进一步在FLAC3D平台开展降水诱导下的三维多场耦合模拟，模拟内容包括：连续降水速率阶跃加载、不同排水边界控制、土体结构破坏演化及塑性区分布。模拟显示，降水速率超过1.5 m/d后，底部软弱层内部出现显著剪应变集中，最大塑性区沿墙底–软弱夹层交界处延伸，形成典型“壳型破坏模式”。同时，地层侧向移动引起中部支撑内力失衡，与实际施工期出现的轴力突增–突降过程高度吻合。\n为研究该类土体的长期沉降行为，本文构建基于Biot理论的固结–蠕变耦合分析框架，考虑超静孔压耗散与黏弹–塑性蠕变同步演化机制。引入改进型Log-time黏性函数描述等时变形，并设定沉降时程控制点（28 d、90 d、1 a、3 a、10 a）。预测结果表明，在含结构性的软土层中，沉降在3 a后仍呈缓慢增长态势，结构性破坏–再固结所引起的“二次沉降平台”在90–180天阶段最为显著，占总沉降量的32%以上。\n此外，软土区域常伴有基岩埋深大、剪切波速低的特点，导致地震作用下场地响应复杂，振动主频降低、波形延迟现象显著。为此，研究引入等效线性化方法，结合SH-wave输入条件与场地剖面参数，建立一维地震反应分析模型，选取北川地震、宝山地震等典型地震波作为输入。结果表明，结构性软土在高阶剪应变下强度退化显著，主频响应在1.2–2.3 Hz之间展宽，剪切模量下降达70%以上。\n场地响应中，孔压增长与微震放大存在明显同步性。通过动三轴试验观测发现，在循环加载第8–12周次内，孔压比r_u迅速上升至0.9以上，并伴随剪应变突跃，表明软土在动力荷载下存在结构性触发液化的风险。基于此，进一步提出动力下的应力路径控制模型，设置等幅–渐增加载序列并测定等效阻尼比、剪胀能耗指数、应力回滞面积，建立“动剪应变–孔压增长–能耗释放”三维特征面，揭示动力疲劳损伤机制。\n",
    "ori_text": "\n\n在沿海深厚软土地层中，由于其天然沉积成因复杂，形成了结构性显著、胶结性弱、微观孔隙形态高度多样的软黏性土体，其工程响应表现出显著的非线性、各向异性及时效性。当前城市基础设施向纵深发展趋势愈发显著，深基坑、地下空间及盾构隧道工程广泛侵入至30–60 m深度，常穿越多个承压含水层与扰动敏感软土层，故准确掌握软土在不同应力路径、加载速率与排水条件下的力学行为，成为高风险工程中亟待突破的技术瓶颈。\n本研究基于应力–应变–时间三维耦合视角，结合室内多路径三轴试验与微观结构观测，探讨深层软黏土在多种加载条件下的破坏机制与本构响应规律。试验采用GDS全自动三轴加载系统，设置恒应力比加载、应变控制加载及路径依赖加载等工况，分别开展了CU、CD与加载–卸载–再加载循环试验。试样取自上海浦东某典型地段第Ⅰ承压含水层上覆层，物理性质指标中天然含水率约为42%，液限约为52%，初始结构性明显。\n在试样制备阶段，通过真空饱和–背压饱和联合方案确保Skempton B值大于0.97。固结过程采用K0等向主固结路径模拟竖向加载条件；加载阶段控制速率为0.1 %/min，孔压及体应变数据每0.5 s采集一次，以捕捉瞬态响应。在非排水CU试验中观察到典型的剪切软化行为，最大主应力差达186 kPa后显著下降，强度包络曲线呈现非线性扩展趋势。部分样本表现出双峰型剪切响应，反映出内在结构破坏与颗粒重排的阶段性过程。\n结合剪胀角–应力比演化路径，发现该类土体在初始阶段表现为负剪胀，即体积压缩趋势明显，随加载持续出现临界状态剪胀角迅速增长的过渡过程，表明结构性破坏触发了粒间滑移与孔隙重构过程。应用DIC数字图像技术分析剪切带发展情况，发现剪切破坏并非单一面局部化，而呈现多裂缝共存、剪切面分支发展的复杂形态，尤其在加载–卸载–再加载循环试验中，剪切路径与之前不同，表现出明显的结构劣化记忆效应。\n在固结排水（CD）路径中，试样呈现较强的剪胀效应与残余强度平台，未发生明显峰值强度下降，显示出结构破坏模式受排水路径显著调控。为评估长期变形趋势，引入等时应变法，以不同持荷阶段（1 h、4 h、24 h）为基准，统计轴向与体积等时应变变化，并采用Burgers黏弹模型对长期蠕变数据进行拟合，获得瞬态黏滞参数η₁、稳态黏滞η₂及弹性模量E₁、E₂，发现软土黏弹参数与初始孔隙比呈幂律正相关关系。\n为进一步揭示微观机制，利用场发射扫描电子显微镜（FE-SEM）对试样剪切前后进行对比观察，结合X射线衍射分析（XRD）分析矿物组分演变，并辅以能谱分析（EDS）识别剪切面微区元素富集变化。结果表明，在剪切带区域，伊利石晶粒趋于定向排列，钙离子迁移导致絮凝结构松散化，反映出剪切诱导的物理–化学协同破坏机制。\n理论方面，本研究引入基于结构性演化的双屈服面模型，考虑加载历史下结构退化函数s(ε)，其演化由指数型函数控制，辅以非线性剪胀函数与加载方向因子。\n通过与Cam-Clay模型、ISSM模型（ISSM：Isotropic Structurally Sensitive Model）对比发现，传统模型无法准确再现应力路径切换下的剪胀行为突变、破坏延迟现象及循环加载的结构记忆效应，而本模型在路径相关性、多峰应力响应及剪切模量演化趋势拟合方面表现优异，具有良好的工程适应性。\n考虑深基坑降水导致的负孔压效应，通过轴对称渗透–剪切耦合试验装置模拟降水速率变化，结果揭示：在中高降水速率下，试样中部形成显著孔压梯度，导致有效应力突变，进而诱发剪切集中、结构坍塌及局部再固结过程。此现象在实际基坑监测中与沉降突变、内支撑反力异常响应高度吻合，显示模型理论具有现实指导意义。\n在理论分析基础上，为验证结构性本构模型在实际工程中的适用性，本文选取上海某深基坑工程作为验证场景。该工程基坑开挖深度达42.5 m，围护结构为地下连续墙+多道支撑体系，基坑底部穿越第Ⅰ与第Ⅱ承压含水层之间的软弱过渡层，层厚约9.5 m，孔隙比高达1.87。该区域地下水位变化频繁，软土结构性显著，对降水引起的有效应力扰动极为敏感。\n基于现场地勘资料与室内试验参数，构建二维有限元模型，采用应力–应变法分析基坑底部隆起、周边沉降与支撑内力响应。在模型中，软弱夹层赋予结构性演化模型，其余层按修正Mohr–Coulomb模型处理。通过参数反演校正过程，选取位移监测数据作为目标函数，以遗传算法优化剪切模量G₀、结构参数s₀、剪胀角ψ₀与屈服函数参数n的初始取值。拟合结果表明，结构性模型可有效反映现场观测中的非对称沉降、底鼓偏移及支撑反力滞后等现象。\n进一步在FLAC3D平台开展降水诱导下的三维多场耦合模拟，模拟内容包括：连续降水速率阶跃加载、不同排水边界控制、土体结构破坏演化及塑性区分布。模拟显示，降水速率超过1.5 m/d后，底部软弱层内部出现显著剪应变集中，最大塑性区沿墙底–软弱夹层交界处延伸，形成典型“壳型破坏模式”。同时，地层侧向移动引起中部支撑内力失衡，与实际施工期出现的轴力突增–突降过程高度吻合。\n为研究该类土体的长期沉降行为，本文构建基于Biot理论的固结–蠕变耦合分析框架，考虑超静孔压耗散与黏弹–塑性蠕变同步演化机制。引入改进型Log-time黏性函数描述等时变形，并设定沉降时程控制点（28 d、90 d、1 a、3 a、10 a）。预测结果表明，在含结构性的软土层中，沉降在3 a后仍呈缓慢增长态势，结构性破坏–再固结所引起的“二次沉降平台”在90–180天阶段最为显著，占总沉降量的32%以上。\n此外，软土区域常伴有基岩埋深大、剪切波速低的特点，导致地震作用下场地响应复杂，振动主频降低、波形延迟现象显著。为此，研究引入等效线性化方法，结合SH-wave输入条件与场地剖面参数，建立一维地震反应分析模型，选取北川地震、宝山地震等典型地震波作为输入。结果表明，结构性软土在高阶剪应变下强度退化显著，主频响应在1.2–2.3 Hz之间展宽，剪切模量下降达70%以上。\n场地响应中，孔压增长与微震放大存在明显同步性。通过动三轴试验观测发现，在循环加载第8–12周次内，孔压比r_u迅速上升至0.9以上，并伴随剪应变突跃，表明软土在动力荷载下存在结构性触发液化的风险。基于此，进一步提出动力下的应力路径控制模型，设置等幅–渐增加载序列并测定等效阻尼比、剪胀能耗指数、应力回滞面积，建立“动剪应变–孔压增长–能耗释放”三维特征面，揭示动力疲劳损伤机制。\n",
    "reference_list": "考点1：“软黏性土体”推荐翻译为 “soft clay”\n考点2：“深基坑”推荐翻译为 “deep foundation pit”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "162"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n理解传播技术作为一个技术/文化复合体如何对各种爱国主义或者民族主义的话语构型起至关重要的作用。而中国电竞作为一个“异质元素的集群”，其爱国主义有着独特的复杂性，不仅包括技术与文化，还包括政治、经济、资本、市场与个体等多元要素和主体，更加体现出一种多元互动的社会情境、权力博弈和文化景观，相应地，也指向更加复杂的话语接合实践。实际上，各种民族主义或者爱国主义都是文化和历史进程的产物，这些进程融入了权力关系、社会实践和意识形态斗争，同时也需要通过话语实践的不断肯定和争夺来维持。因此，民族主义或者爱国主义不是固化、静态或同质化的身份认同，而是一个异质性的领域，不同的参与者和话语在其中争夺合法性、权威和再现；这本质上是一种不断演进、协商和争夺意义与认同的话语“接合实践”。\n为此，本研究延续这一学术脉络并聚焦新兴的“电竞爱国主义”认同，利用话语接合的理论概念和方法论工具，考察中国电竞场域中爱国主义话语接合的可能形式、过程和意义，特别是其如何通过国家权力、行业资本、个人梦想的“三重接合”，相应地将政治理念、经济利益和自我认同，历史性、实践性、能动性地接合成一个复杂的、动态的甚至临时的“电竞爱国主义”认同。\n首先是国家权力要渗透、吸纳并规训电竞，将电竞同时作为一个“治理对象”和“发展主体”，并借由“为国争光”的爱国话语将年轻世代聚集的电竞场域打造成为一个新的爱国主义教育平台；其次是行业资本开始积极挪用上述国家话语，并联合其他利益相关者结成利益联盟，既合力推动电竞行业的快速野蛮生长，又以这种行业高速增长带来的经济合法性，争取和强化其行业的政治合法性；最后是电竞选手也会挪用这种爱国主义话语为自己的个人行为背书，甚至会将追求自我梦想（“冠军梦”）与国家梦想（“中国梦”）直接联接起来，寻求自我合法化、自我价值和自我认同。\n不过，不管是电竞行业还是电竞选手等对国家爱国主义话语的挪用以及相应的自我合理化和合法化，最终又都将接着被国家所吸纳，服务于地方经济发展、部门政策规划乃至国家文化走出去战略等，而这又将反过来被行业和选手等进一步挪用，继续服务于自我合理化和自我合法化，如此形成电竞爱国主义话语“三重接合”自我循环的内在动力。这种“三重接合”所体现出来的多元互动，使“电竞爱国主义”区别于以往的“粉丝民族主义”“嘻戏爱国主义”等，因此也对民族主义与爱国主义研究领域有所贡献。首先，以往民族主义研究多聚焦“官方”或“民间/民众”，一是作为“官方宣传”的精英建构论，即官方对民族主义的建构与利用，二是民众对民族主义的挪用与重组，“民众的网络正在向国家对民族主义的垄断发起挑战，民众在民族主义政治中正发挥着更大的作用”，而电竞爱国主义展现了爱国主义话语实践中官方与民众之外更多元的主体和行动者，特别是行业资本作为一个重要主体和行动者；其次，以往研究已经关注到自上而下的官方民族主义与自下而上的大众民族主义之间的互动关系，特别是新近粉丝民族主义等作为新兴大众民族主义的挑战性和抵抗性，而电竞爱国主义揭示了上述不同行动者之间更复杂和暧昧的相互关系和动态过程，特别是挑战了截然二分的“官方vs.民众”“自上而下vs.自下而上”，而是接合出一种“双向奔赴”“上下同心”的奇特关系；最后，电竞爱国主义警示我们，在国家与民众之外，在新媒体技术与民族主义互动关系之外，行业资本特别是裹挟着新媒体技术力量的行业资本作为民族主义及爱国主义场域中新兴而又强大的力量存在，有着强烈的合法性危机感和强大的能动性，从而在电竞爱国主义话语的三重接合循环中实质性地起到“车头”的主导性作用。以往研究让我们看到了国家与民众对民族主义及爱国主义的利用或挪用，电竞爱国主义却让我们进一步看到了资本作为新兴且强大的力量，借由对爱国主义话语的挪用，在主动策略性地接合国家、民众与行业的话语共识。但是，这并不意味着资本成为电竞爱国主义话语接合的主导力量。对这个接合过程，我们可以借用欧文·戈夫曼的拟剧理论术语作为隐喻来理解：资本固然在“后台”运筹，让选手在“前台”表演，并请民众在“舞台”前观赏，但国家始终是最强有力的“剧作家”，创作并限定了爱国主义的“剧本”，并使之内化成为资本、选手和民众的共同规范、准则、惯例和依据，即所有行动者共同的“框架”；包括资本在内的所有行动者在“框架”内或多或少有应变和创作的空间，但整体上是服从并服务于“剧本”和“剧作家”的。\n",
    "ori_text": "\n\n理解传播技术作为一个技术/文化复合体如何对各种爱国主义或者民族主义的话语构型起至关重要的作用。而中国电竞作为一个“异质元素的集群”，其爱国主义有着独特的复杂性，不仅包括技术与文化，还包括政治、经济、资本、市场与个体等多元要素和主体，更加体现出一种多元互动的社会情境、权力博弈和文化景观，相应地，也指向更加复杂的话语接合实践。实际上，各种民族主义或者爱国主义都是文化和历史进程的产物，这些进程融入了权力关系、社会实践和意识形态斗争，同时也需要通过话语实践的不断肯定和争夺来维持。因此，民族主义或者爱国主义不是固化、静态或同质化的身份认同，而是一个异质性的领域，不同的参与者和话语在其中争夺合法性、权威和再现；这本质上是一种不断演进、协商和争夺意义与认同的话语“接合实践”。\n为此，本研究延续这一学术脉络并聚焦新兴的“电竞爱国主义”认同，利用话语接合的理论概念和方法论工具，考察中国电竞场域中爱国主义话语接合的可能形式、过程和意义，特别是其如何通过国家权力、行业资本、个人梦想的“三重接合”，相应地将政治理念、经济利益和自我认同，历史性、实践性、能动性地接合成一个复杂的、动态的甚至临时的“电竞爱国主义”认同。\n首先是国家权力要渗透、吸纳并规训电竞，将电竞同时作为一个“治理对象”和“发展主体”，并借由“为国争光”的爱国话语将年轻世代聚集的电竞场域打造成为一个新的爱国主义教育平台；其次是行业资本开始积极挪用上述国家话语，并联合其他利益相关者结成利益联盟，既合力推动电竞行业的快速野蛮生长，又以这种行业高速增长带来的经济合法性，争取和强化其行业的政治合法性；最后是电竞选手也会挪用这种爱国主义话语为自己的个人行为背书，甚至会将追求自我梦想（“冠军梦”）与国家梦想（“中国梦”）直接联接起来，寻求自我合法化、自我价值和自我认同。\n不过，不管是电竞行业还是电竞选手等对国家爱国主义话语的挪用以及相应的自我合理化和合法化，最终又都将接着被国家所吸纳，服务于地方经济发展、部门政策规划乃至国家文化走出去战略等，而这又将反过来被行业和选手等进一步挪用，继续服务于自我合理化和自我合法化，如此形成电竞爱国主义话语“三重接合”自我循环的内在动力。这种“三重接合”所体现出来的多元互动，使“电竞爱国主义”区别于以往的“粉丝民族主义”“嘻戏爱国主义”等，因此也对民族主义与爱国主义研究领域有所贡献。首先，以往民族主义研究多聚焦“官方”或“民间/民众”，一是作为“官方宣传”的精英建构论，即官方对民族主义的建构与利用，二是民众对民族主义的挪用与重组，“民众的网络正在向国家对民族主义的垄断发起挑战，民众在民族主义政治中正发挥着更大的作用”，而电竞爱国主义展现了爱国主义话语实践中官方与民众之外更多元的主体和行动者，特别是行业资本作为一个重要主体和行动者；其次，以往研究已经关注到自上而下的官方民族主义与自下而上的大众民族主义之间的互动关系，特别是新近粉丝民族主义等作为新兴大众民族主义的挑战性和抵抗性，而电竞爱国主义揭示了上述不同行动者之间更复杂和暧昧的相互关系和动态过程，特别是挑战了截然二分的“官方vs.民众”“自上而下vs.自下而上”，而是接合出一种“双向奔赴”“上下同心”的奇特关系；最后，电竞爱国主义警示我们，在国家与民众之外，在新媒体技术与民族主义互动关系之外，行业资本特别是裹挟着新媒体技术力量的行业资本作为民族主义及爱国主义场域中新兴而又强大的力量存在，有着强烈的合法性危机感和强大的能动性，从而在电竞爱国主义话语的三重接合循环中实质性地起到“车头”的主导性作用。以往研究让我们看到了国家与民众对民族主义及爱国主义的利用或挪用，电竞爱国主义却让我们进一步看到了资本作为新兴且强大的力量，借由对爱国主义话语的挪用，在主动策略性地接合国家、民众与行业的话语共识。但是，这并不意味着资本成为电竞爱国主义话语接合的主导力量。对这个接合过程，我们可以借用欧文·戈夫曼的拟剧理论术语作为隐喻来理解：资本固然在“后台”运筹，让选手在“前台”表演，并请民众在“舞台”前观赏，但国家始终是最强有力的“剧作家”，创作并限定了爱国主义的“剧本”，并使之内化成为资本、选手和民众的共同规范、准则、惯例和依据，即所有行动者共同的“框架”；包括资本在内的所有行动者在“框架”内或多或少有应变和创作的空间，但整体上是服从并服务于“剧本”和“剧作家”的。\n",
    "reference_list": "考点1. “权力博弈”推荐译为“power games”或者“power dynamics”，选取一种即可，保持译文一致性\n考点2. “粉丝民族主义”应该译为“fandom nationalism”，已成为主流翻译\n考点3. “嬉戏民族主义”应该译为“playful patriotism”，已成为主流翻译",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "199"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n16 of the best things to do in London\nFast-paced, fabulous and fun, London is packed with world-class things to see and experience. You probably already have a checklist of London sights to visit, but don't forget to pause and soak up the vibe of a city that has been at the forefront of world culture for at least two millennia.\nWhether you're a first-time visitor or coming back for more, London serves up so many options that it can be hard to know where to start. It's easy to fill days or even weeks taking advantage of free entry at the city's top art galleries and museums, learning about the rich and complex history, and seeing live bands and captivating West End shows.\nIf you have the time – and budget – almost anything is possible in London. To help you whittle down the options, here are the top experiences in London that you won't want to miss.\n1. Stroll the sights of the South Bank\nA great way to get your bearings and take in a slew of sights at the same time is to take a west-to-east walk along the Thames, through the cultural quarter known as the South Bank. Getting off the Tube at Westminster will deposit you right by Big Ben, the legendary bell atop the clocktower of the Houses of Parliament. From there, cross Westminster Bridge for stellar views back toward the seat of British democracy.\nOnce on the Queen's Walk, as this pathway is known, stroll east with the river to your left. Although it’s inescapably touristy, a rotation on the London Eye is a must for any first-time visitor to the capital. This futuristic Ferris wheel takes 30 minutes to complete a full turn, reaching 135m (443ft) at its highest point, and providing spectacular views of iconic landmarks from its glass capsules. Book tickets in advance to avoid the lines.\nThe Southbank Centre offers up a roll call of top-draw icons and entertainment; it's a great place to go if you're traveling with kids, with lots of free activities and events in summer. Once you leave the Brutalist concrete architecture of the Southbank Centre behind, you'll find other eclectic London sights, including Shakespeare’s Globe Theatre, the Tate Modern art gallery (with views across the river to St Paul’s Cathedral), and the Shard, Britain's tallest building. As you walk, look across the river towards the City of London, and try to pick out its curiously nicknamed skyscrapers – such as the Gherkin, the Cheesegrater and the Walkie-Talkie. When hunger calls, take a snack break at legendary Borough Market close to London Bridge, where there are pubs, restaurants, dairies, bakers and more than 100 gourmet food stalls.  \nLocal tip: Ice-cream sellers on Westminster Bridge are known for overcharging tourists, so resist the urge to buy anything here. Also, don't engage in any of the cup and ball gambling games – these are illegal scams and you will not win, no matter how easy it looks.\n2. Be wowed by contemporary art at Tate Modern\nA vast shrine to modern and contemporary art, the much-loved Tate Modern enjoys a triumphant position right on the River Thames. Housed in the former Bankside Power Station, the gallery is a vigorous statement of modernity, architectural renewal and accessibility. Enter via Holland St to experience the vast Turbine Hall, which used to house the power station’s electricity generators, and is now home to large-scale art installations. Upstairs exhibition spaces are pushing the conceptual envelope, too, with interesting temporary shows, installations and performance art.\nLocal tip: Level 10, the viewing platform atop the Blavatnik Building, has been the subject of some controversy regarding privacy because it's possible to look into the adjacent apartment buildings. There are many signs politely requesting no photography on the south side (and not as much to see there anyway). There are also great views from the coffee shop and bar in the main building. If the tide is out, try mudlarking – an evocative term for looking for historic junk on the exposed mud at low tide – right in front of the gallery.\n3. Step back in time at the Tower of London\nA world of English eccentricity enclosed within the sturdy walls of an imposing 11th-century fortress, the Tower of London is the perfect place to start a visit to London. As well as taking visitors on a remarkable architectural and historical journey, the castle is home to the world's largest diamond (the controversial Cullinan diamond, part of the famous Crown Jewels), as well as a dazzling array of armor and weaponry. A palpable sense of history and heritage will greet you at every turn.\nPlanning tip: It’s well worth getting to the Tower early – you'll need at least half a day to explore the sprawling chambers, courtyards and jail cells, and hear about its gruesome history. Arrive as the doors are unlocked and head straight to the Crown Jewels to avoid a long wait in line. To learn more about the Tower's back story, join a Yeoman Warder’s tour for a fascinating and personal introduction to the life and grisly times of this fortress-palace.\n4. Explore London’s Black history\nLondon’s Black history is rich and fascinating and stretches back across centuries. All over London, you'll sense a growing enthusiasm for acknowledging, owning and celebrating this once-overlooked part of the capital's story. Begin your journey by joining one of the 16 walking tours in central London run by Black History Walks, then head down to the Docklands to learn about the capital’s involvement in the transatlantic slave trade at the Museum of London Docklands before meandering south to marvel at the vast Black archives at Brixton’s Black Cultural Archives. Next, indulge in some delicious Caribbean cuisine and take in many of the city’s best Black artists at 198 Contemporary Arts and Learning.\nPlanning tip: Notting Hill Carnival, held over the August Bank Holiday weekend, is a colossal street party celebrating Black, Caribbean and African cultures. Join the dancing, parties and parades that fill the neighborhoods around Ladbroke Grove. The official website publishes routes and events in advance.\n5. Imagine the royal weddings of yesteryear at Westminster Abbey\nWestminster Abbey has been the heart of the country’s royal and religious life for centuries. This Gothic wonder was founded more than a thousand years ago and today it displays a mix of architectural styles, with the bulk of its structure dating back to the 13th century. As a result, almost every nook and cranny has a story attached to it.\nLondon's great abbey has served as the venue for many showstopper funerals and weddings – 30 monarchs are buried here, and 16 royal weddings have been hosted here, the most recent being that of Prince William and Catherine Middleton in 2011. Among the highlights, you will find the oldest door in the UK, the collection of memorials to great poets and writers known as Poets’ Corner, the Coronation Chair, 14th-century cloisters, a 900-year-old garden, royal tombs and much, much more.\nPlanning tip: Be warned that the crowds are almost as solid as the abbey’s unshakeable stonework, so aim to join the line first thing in the morning.\n6. Delve into Muslim London\nLondon was once the capital of an empire that ruled over more than half the world’s Muslims, so it should come as no surprise that the city is home to a wide range of Muslim communities and rich in Islamic heritage. Start with the amazing Islamic collections in the Victoria & Albert Museum’s Jameel Gallery or the British Museum’s Albukhary Gallery – between them, these former imperial institutes hold over 115,000 Islamic items.\nTo learn where Arabic was taught in 17th century London, take an eye-opening Muslim History Tour, then treat yourself to some of the capital’s most delicious Muslim cuisine. Try a fiery curry along East London’s Brick Lane (or great Punjabi-style kebabs nearby at Tayyabs), head north to Green Lanes for London’s most authentic Anatolian dishes, or go west along Edgware Rd for varied Middle Eastern cuisine.\n7. Tour through history and science at South Kensington's museums\nA trio of world-class museums lie within yards of each other in the well-to-do neighborhood of South Kensington, their grand edifices proving an equal draw to the glories within. With seven floors of interactive, educational and eye-opening exhibits, the spellbinding collection of models, machines and inventions at the Science Museum mesmerizes adults and children in equal measure.\nYou could spend days in the huge Victoria & Albert Museum, which houses the world’s leading collection of decorative art objects, and still be astounded at its variety and depth. With its animatronic Tyrannosaurus rex, riveting displays about planet Earth, the research-oriented Darwin Centre and architecture straight out of a Gothic fairy tale, the Natural History Museum is an astonishing melding of science and imagination. Start in the iconic Hintze Hall, where the skeleton of a blue whale dives down from the ceiling.\nPlanning tip: To see a more unusual side to the museums, and mingle with some Londoners, check in advance to see if any “Lates” are running; the museums periodically open their doors into the evening for special events with music and food. There are even occasional sleepover events called Dino Snores at the Natural History Museum.",
    "ori_text": "16 of the best things to do in London\nFast-paced, fabulous and fun, London is packed with world-class things to see and experience. You probably already have a checklist of London sights to visit, but don't forget to pause and soak up the vibe of a city that has been at the forefront of world culture for at least two millennia.\nWhether you're a first-time visitor or coming back for more, London serves up so many options that it can be hard to know where to start. It's easy to fill days or even weeks taking advantage of free entry at the city's top art galleries and museums, learning about the rich and complex history, and seeing live bands and captivating West End shows.\nIf you have the time – and budget – almost anything is possible in London. To help you whittle down the options, here are the top experiences in London that you won't want to miss.\n1. Stroll the sights of the South Bank\nA great way to get your bearings and take in a slew of sights at the same time is to take a west-to-east walk along the Thames, through the cultural quarter known as the South Bank. Getting off the Tube at Westminster will deposit you right by Big Ben, the legendary bell atop the clocktower of the Houses of Parliament. From there, cross Westminster Bridge for stellar views back toward the seat of British democracy.\nOnce on the Queen's Walk, as this pathway is known, stroll east with the river to your left. Although it’s inescapably touristy, a rotation on the London Eye is a must for any first-time visitor to the capital. This futuristic Ferris wheel takes 30 minutes to complete a full turn, reaching 135m (443ft) at its highest point, and providing spectacular views of iconic landmarks from its glass capsules. Book tickets in advance to avoid the lines.\nThe Southbank Centre offers up a roll call of top-draw icons and entertainment; it's a great place to go if you're traveling with kids, with lots of free activities and events in summer. Once you leave the Brutalist concrete architecture of the Southbank Centre behind, you'll find other eclectic London sights, including Shakespeare’s Globe Theatre, the Tate Modern art gallery (with views across the river to St Paul’s Cathedral), and the Shard, Britain's tallest building. As you walk, look across the river towards the City of London, and try to pick out its curiously nicknamed skyscrapers – such as the Gherkin, the Cheesegrater and the Walkie-Talkie. When hunger calls, take a snack break at legendary Borough Market close to London Bridge, where there are pubs, restaurants, dairies, bakers and more than 100 gourmet food stalls.  \nLocal tip: Ice-cream sellers on Westminster Bridge are known for overcharging tourists, so resist the urge to buy anything here. Also, don't engage in any of the cup and ball gambling games – these are illegal scams and you will not win, no matter how easy it looks.\n2. Be wowed by contemporary art at Tate Modern\nA vast shrine to modern and contemporary art, the much-loved Tate Modern enjoys a triumphant position right on the River Thames. Housed in the former Bankside Power Station, the gallery is a vigorous statement of modernity, architectural renewal and accessibility. Enter via Holland St to experience the vast Turbine Hall, which used to house the power station’s electricity generators, and is now home to large-scale art installations. Upstairs exhibition spaces are pushing the conceptual envelope, too, with interesting temporary shows, installations and performance art.\nLocal tip: Level 10, the viewing platform atop the Blavatnik Building, has been the subject of some controversy regarding privacy because it's possible to look into the adjacent apartment buildings. There are many signs politely requesting no photography on the south side (and not as much to see there anyway). There are also great views from the coffee shop and bar in the main building. If the tide is out, try mudlarking – an evocative term for looking for historic junk on the exposed mud at low tide – right in front of the gallery.\n3. Step back in time at the Tower of London\nA world of English eccentricity enclosed within the sturdy walls of an imposing 11th-century fortress, the Tower of London is the perfect place to start a visit to London. As well as taking visitors on a remarkable architectural and historical journey, the castle is home to the world's largest diamond (the controversial Cullinan diamond, part of the famous Crown Jewels), as well as a dazzling array of armor and weaponry. A palpable sense of history and heritage will greet you at every turn.\nPlanning tip: It’s well worth getting to the Tower early – you'll need at least half a day to explore the sprawling chambers, courtyards and jail cells, and hear about its gruesome history. Arrive as the doors are unlocked and head straight to the Crown Jewels to avoid a long wait in line. To learn more about the Tower's back story, join a Yeoman Warder’s tour for a fascinating and personal introduction to the life and grisly times of this fortress-palace.\n4. Explore London’s Black history\nLondon’s Black history is rich and fascinating and stretches back across centuries. All over London, you'll sense a growing enthusiasm for acknowledging, owning and celebrating this once-overlooked part of the capital's story. Begin your journey by joining one of the 16 walking tours in central London run by Black History Walks, then head down to the Docklands to learn about the capital’s involvement in the transatlantic slave trade at the Museum of London Docklands before meandering south to marvel at the vast Black archives at Brixton’s Black Cultural Archives. Next, indulge in some delicious Caribbean cuisine and take in many of the city’s best Black artists at 198 Contemporary Arts and Learning.\nPlanning tip: Notting Hill Carnival, held over the August Bank Holiday weekend, is a colossal street party celebrating Black, Caribbean and African cultures. Join the dancing, parties and parades that fill the neighborhoods around Ladbroke Grove. The official website publishes routes and events in advance.\n5. Imagine the royal weddings of yesteryear at Westminster Abbey\nWestminster Abbey has been the heart of the country’s royal and religious life for centuries. This Gothic wonder was founded more than a thousand years ago and today it displays a mix of architectural styles, with the bulk of its structure dating back to the 13th century. As a result, almost every nook and cranny has a story attached to it.\nLondon's great abbey has served as the venue for many showstopper funerals and weddings – 30 monarchs are buried here, and 16 royal weddings have been hosted here, the most recent being that of Prince William and Catherine Middleton in 2011. Among the highlights, you will find the oldest door in the UK, the collection of memorials to great poets and writers known as Poets’ Corner, the Coronation Chair, 14th-century cloisters, a 900-year-old garden, royal tombs and much, much more.\nPlanning tip: Be warned that the crowds are almost as solid as the abbey’s unshakeable stonework, so aim to join the line first thing in the morning.\n6. Delve into Muslim London\nLondon was once the capital of an empire that ruled over more than half the world’s Muslims, so it should come as no surprise that the city is home to a wide range of Muslim communities and rich in Islamic heritage. Start with the amazing Islamic collections in the Victoria & Albert Museum’s Jameel Gallery or the British Museum’s Albukhary Gallery – between them, these former imperial institutes hold over 115,000 Islamic items.\nTo learn where Arabic was taught in 17th century London, take an eye-opening Muslim History Tour, then treat yourself to some of the capital’s most delicious Muslim cuisine. Try a fiery curry along East London’s Brick Lane (or great Punjabi-style kebabs nearby at Tayyabs), head north to Green Lanes for London’s most authentic Anatolian dishes, or go west along Edgware Rd for varied Middle Eastern cuisine.\n7. Tour through history and science at South Kensington's museums\nA trio of world-class museums lie within yards of each other in the well-to-do neighborhood of South Kensington, their grand edifices proving an equal draw to the glories within. With seven floors of interactive, educational and eye-opening exhibits, the spellbinding collection of models, machines and inventions at the Science Museum mesmerizes adults and children in equal measure.\nYou could spend days in the huge Victoria & Albert Museum, which houses the world’s leading collection of decorative art objects, and still be astounded at its variety and depth. With its animatronic Tyrannosaurus rex, riveting displays about planet Earth, the research-oriented Darwin Centre and architecture straight out of a Gothic fairy tale, the Natural History Museum is an astonishing melding of science and imagination. Start in the iconic Hintze Hall, where the skeleton of a blue whale dives down from the ceiling.\nPlanning tip: To see a more unusual side to the museums, and mingle with some Londoners, check in advance to see if any “Lates” are running; the museums periodically open their doors into the evening for special events with music and food. There are even occasional sleepover events called Dino Snores at the Natural History Museum.",
    "reference_list": "考点1：Houses of Parliament 应译为 英国国会大厦\n考点2：Westminster Bridge 应译为 威斯敏斯特桥\n考点3：Queen's Walk 应译为 女王步道\n考点4：London Eye 应译为 伦敦眼\n考点5：Southbank Centre 应译为 南岸艺术中心\n考点6：Shakespeare’s Globe Theatre 应译为 莎士比亚环球剧场\n考点7：Tate Modern 应译为 泰特现代美术馆\n考点8：St Paul’s Cathedral 应译为 圣保罗大教堂\n考点9：The Shard 应译为 碎片大厦/伦敦碎片塔\n考点10：City of London 应译为 伦敦金融城/伦敦城\n考点11：the Gherkin 应译为 小黄瓜大厦\n考点12：the Cheesegrater 应译为 刨丝器大厦\n考点13：the Walkie-Talkie 应译为 对讲机大厦\n考点14：Borough Market 应译为 博罗市场\n考点15：London Bridge 应译为 伦敦桥\n考点16：Tate Modern’s Turbine Hall 应译为 泰特现代美术馆涡轮大厅\n考点17：Bankside Power Station 应译为 岸边发电站\n考点18：Blavatnik Building 应译为 布拉瓦特尼克楼\n考点19：mudlarking 应译为 淘泥寻宝/河泥拾遗\n考点20：Tower of London 应译为 伦敦塔\n考点21：Cullinan diamond 应译为 库里南钻石\n考点22：Crown Jewels 应译为 英国王室珠宝/御宝\n考点23：Yeoman Warder 应译为 伦敦塔哨兵/伦敦塔守卫\n考点24：London’s Black history 应译为 伦敦黑人历史\n考点25：Black History Walks 应译为 黑人历史徒步之旅\n考点26：Museum of London Docklands 应译为 伦敦码头区博物馆\n考点27：Brixton’s Black Cultural Archives 应译为 布里克斯顿黑人文化档案馆\n考点28：198 Contemporary Arts and Learning 应译为 198当代艺术与学习中心\n考点29：Notting Hill Carnival 应译为 诺丁山狂欢节\n考点30：Ladbroke Grove 应译为 拉德布鲁克格罗夫\n考点31：Westminster Abbey 应译为 威斯敏斯特大教堂/威斯敏斯特修道院\n考点32：Poets’ Corner 应译为 诗人角\n考点33：Coronation Chair 应译为 加冕椅\n考点34：Victoria & Albert Museum 应译为 维多利亚与艾尔伯特博物馆\n考点35：Jameel Gallery 应译为 贾米尔展厅\n考点36：British Museum’s Albukhary Gallery 应译为 大英博物馆阿尔布哈里展厅\n考点37：Brick Lane 应译为 砖巷\n考点38：Tayyabs 应译为 塔亚布餐厅\n考点39：Green Lanes 应译为 格林巷\n考点40：Edgware Rd 应译为 埃奇韦尔路\n考点41：South Kensington 应译为 南肯辛顿\n考点42：Science Museum 应译为 科学博物馆\n考点43：Natural History Museum 应译为 自然历史博物馆\n考点44：Darwin Centre 应译为 达尔文中心\n考点45：Hintze Hall 应译为 欣策大厅\n考点46：Dino Snores 应译为 恐龙夜宿/恐龙夜眠活动",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "广告营销",
    "prompt_id": "75"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n7月8日，国家发展改革委（简称“发改委”）表示，日前新增下达100亿元中央预算内投资，开展以工代赈加力扩围促进重点群体就业增收行动，支持26个省（区、市)和新疆生产建设兵团实施1975个项目，预计发放劳务报酬45.9亿元，助力31万名重点群体稳就业促增收。\n以工代赈是指政府投资建设基础设施工程，受赈济者参加工程建设获得劳务报酬，以此取代直接赈济的一项扶持政策，也是中央政治局会议部署的稳就业稳经济政策工具之一。\n发改委每年下达以工代赈中央专项资金，并推动国家重点项目、农业农村基础设施项目实施以工代赈。截至2025年6月底，发改委联合财政部共下达2025年度以工代赈中央投资295亿元，支持地方实施以工代赈项目近6000个，预计吸纳带动70余万名困难群众就地就近就业，将发放劳务报酬超过110亿元，有效拓宽群众就业增收渠道。\n发改委表示，下一步将立足当前就业形势，积极主动作为，督促指导地方推动已下达投资的以工代赈项目全部开工建设，抓实抓牢重点群体务工组织和劳务报酬发放等关键环节，同步做好项目常态化滚动式储备，推动以工代赈切实发挥稳就业、促增收的逆周期调节作用。\n突出纾困解难、可感可及和一举多得\n当前，以工代赈着力挖掘务工岗位扩大就业容量，突出“纾困解难”。本批1975个以工代赈项目瞄准返乡回流重点群体集中、务工需求大的地区，围绕城乡融合发展和农业农村领域中小型基础设施建设，充分挖掘工程建设、服务保障、项目管理和建后管护等各环节务工岗位，预计吸纳带动31万名重点群体就近就业，包括脱贫人口及防返贫致贫监测对象、返乡农民工、其他农村劳动力等群体。\n此外，以工代赈着力提高劳务报酬占中央投资比例，突出“可感可及”。本批投资将项目劳务报酬占中央投资的比例提高至不低于40%，优先实施人工用量大、材料成本低、机械使用少的村道巷道硬化、乡村生产道路改造、小型排灌沟渠疏浚、生态护坡护坝等劳动密集型工程。与此同时，推动地方落实以工代赈项目可不招标的要求，鼓励“村民自建”“乡建公司承建”等灵活发包方式，创新“乡镇政府+村级合作社（村民项目理事会、乡建公司）+群众”的劳务组织模式，提高乡村两级基层组织动员能力，增加群众更多实际务工收入。本批100亿元投资将发放劳务报酬45.9亿元，占比达45.9%。\n另外，以工代赈着力改善群众身边的生产生活条件，突出“一举多得”。本批投资拟支持硬化各类村道巷道、改造县城或乡镇连接村庄的小型道路共9640公里，疏浚小型排灌沟渠3762余公里，整治农田9180余亩，铺设供排水管网2110公里，修建农村简易桥涵、山坪塘和蓄水池等4842座。这些“小而美”的项目既能有效改善村容村貌和人居环境，又能提升农村产业发展配套基础设施条件，覆盖了一般政府投资支持不到的“末梢”，补上了部分建设领域的“盲点”和“死角”，打通了城乡基础设施“最后一公里”。\n加力扩围提标实施以工代赈，促进重点群体就业增收\n近日，发改委联合有关部门印发了《以工代赈加力扩围促进重点群体就业增收行动方案》（简称“《行动方案》”），通过这项增量政策，进一步加大对困难群体帮扶力度。\n发改委政策研究室副主任李超表示，近期以工代赈的新举措和工作进展可以用“加力”“扩围”“提标”三个关键词概括。\n此次《行动方案》要新增安排一批中央预算内投资项目，对重点群体较为集中的地区予以支持。受益对象要扩围，支持项目也扩围。另外，《行动方案》将以工代赈劳务报酬占中央对项目投入资金的比重由30%以上提高至40%以上，尽可能增加群众务工收入。发改委已经完成重点群体摸底、项目谋划申报等前期工作，正在抓紧组织开展项目审查，有序推进投资计划下达工作。\n下一步，发改委将推动各地最大程度挖掘以工代赈项目用工岗位规模，最大力度吸纳当地困难群众参与建设，最大幅度提高劳务报酬占中央投资的比例，多种方式开展培训提高务工群众技能，充分发挥以工代赈中“赈”的实效。",
    "ori_text": "7月8日，国家发展改革委（简称“发改委”）表示，日前新增下达100亿元中央预算内投资，开展以工代赈加力扩围促进重点群体就业增收行动，支持26个省（区、市)和新疆生产建设兵团实施1975个项目，预计发放劳务报酬45.9亿元，助力31万名重点群体稳就业促增收。\n以工代赈是指政府投资建设基础设施工程，受赈济者参加工程建设获得劳务报酬，以此取代直接赈济的一项扶持政策，也是中央政治局会议部署的稳就业稳经济政策工具之一。\n发改委每年下达以工代赈中央专项资金，并推动国家重点项目、农业农村基础设施项目实施以工代赈。截至2025年6月底，发改委联合财政部共下达2025年度以工代赈中央投资295亿元，支持地方实施以工代赈项目近6000个，预计吸纳带动70余万名困难群众就地就近就业，将发放劳务报酬超过110亿元，有效拓宽群众就业增收渠道。\n发改委表示，下一步将立足当前就业形势，积极主动作为，督促指导地方推动已下达投资的以工代赈项目全部开工建设，抓实抓牢重点群体务工组织和劳务报酬发放等关键环节，同步做好项目常态化滚动式储备，推动以工代赈切实发挥稳就业、促增收的逆周期调节作用。\n突出纾困解难、可感可及和一举多得\n当前，以工代赈着力挖掘务工岗位扩大就业容量，突出“纾困解难”。本批1975个以工代赈项目瞄准返乡回流重点群体集中、务工需求大的地区，围绕城乡融合发展和农业农村领域中小型基础设施建设，充分挖掘工程建设、服务保障、项目管理和建后管护等各环节务工岗位，预计吸纳带动31万名重点群体就近就业，包括脱贫人口及防返贫致贫监测对象、返乡农民工、其他农村劳动力等群体。\n此外，以工代赈着力提高劳务报酬占中央投资比例，突出“可感可及”。本批投资将项目劳务报酬占中央投资的比例提高至不低于40%，优先实施人工用量大、材料成本低、机械使用少的村道巷道硬化、乡村生产道路改造、小型排灌沟渠疏浚、生态护坡护坝等劳动密集型工程。与此同时，推动地方落实以工代赈项目可不招标的要求，鼓励“村民自建”“乡建公司承建”等灵活发包方式，创新“乡镇政府+村级合作社（村民项目理事会、乡建公司）+群众”的劳务组织模式，提高乡村两级基层组织动员能力，增加群众更多实际务工收入。本批100亿元投资将发放劳务报酬45.9亿元，占比达45.9%。\n另外，以工代赈着力改善群众身边的生产生活条件，突出“一举多得”。本批投资拟支持硬化各类村道巷道、改造县城或乡镇连接村庄的小型道路共9640公里，疏浚小型排灌沟渠3762余公里，整治农田9180余亩，铺设供排水管网2110公里，修建农村简易桥涵、山坪塘和蓄水池等4842座。这些“小而美”的项目既能有效改善村容村貌和人居环境，又能提升农村产业发展配套基础设施条件，覆盖了一般政府投资支持不到的“末梢”，补上了部分建设领域的“盲点”和“死角”，打通了城乡基础设施“最后一公里”。\n加力扩围提标实施以工代赈，促进重点群体就业增收\n近日，发改委联合有关部门印发了《以工代赈加力扩围促进重点群体就业增收行动方案》（简称“《行动方案》”），通过这项增量政策，进一步加大对困难群体帮扶力度。\n发改委政策研究室副主任李超表示，近期以工代赈的新举措和工作进展可以用“加力”“扩围”“提标”三个关键词概括。\n此次《行动方案》要新增安排一批中央预算内投资项目，对重点群体较为集中的地区予以支持。受益对象要扩围，支持项目也扩围。另外，《行动方案》将以工代赈劳务报酬占中央对项目投入资金的比重由30%以上提高至40%以上，尽可能增加群众务工收入。发改委已经完成重点群体摸底、项目谋划申报等前期工作，正在抓紧组织开展项目审查，有序推进投资计划下达工作。\n下一步，发改委将推动各地最大程度挖掘以工代赈项目用工岗位规模，最大力度吸纳当地困难群众参与建设，最大幅度提高劳务报酬占中央投资的比例，多种方式开展培训提高务工群众技能，充分发挥以工代赈中“赈”的实效。",
    "reference_list": "考点1：“加力扩围”应译为“to strengthen efforts and expand the scope”，“加力”指加大力度，“扩围”指扩大范围。 \n考点2：“中央政治局”应译为“Political Bureau of the Central Committee of the CPC ”，中国特有的政府机构名称。\n考点3：“逆周期调节”应译为“counter-cyclical adjustment ”，中国特色表达。\n考点4：“可感可及”中的“可及”应译为“accessibility”。\n考点5：“小而美”应译为“small yet smart”，不可译为“small but beautiful”。\n考点6：“加力扩围提标”中的“提标”应译为“raising standards”，不可译为“upgrade”\n考点7：“摸底”应译为“preliminary survey”。\n考点8：“乡镇政府+村级合作社+群众”译文需避免保留“+”，建议把“+”意译为“connecting / linking... with / collaboration between”这种能体现出协作关系的表达",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "49"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n《烬琉璃》\n第一幕：琉璃碎\n【场景 1：鎏金夜宴】\n水晶吊灯的光斑洒在宴会厅，镜头定格在苏璃身上。她身着绯红琉璃裙，银剪修剪缎带，金粉滑落。屏风阴影里，林浩将文件塞进白薇薇的墨绿色手袋，文件封面透出 “核心工艺图谱”。苏璃腰间刻着 “璃” 字的琉璃佩轻晃，林浩手表秒针停在 10:17—— 与工作室监控切断时间吻合。\n\n【场景 2：骤雨破局】\n暴雨夜，苏璃冲进工作室，设计台散落撕碎的草图，中央是断裂的琉璃佩，断面嵌着半颗珍珠。投影幕布播放监控：林浩用万能钥匙开门，白薇薇拷贝硬盘，两人碰掉琉璃佩。\n蒙太奇镜头：\n\n苏璃捧起断佩，指腹划过刻痕，血珠染红碎片。\n财经新闻字幕闪烁：“苏氏工艺破产”“核心技术被收购”。\n垃圾桶里，绯红琉璃裙揉成一团，金线凤凰如滴血残羽。\n\n第二幕：淬火录\n【场景 1：废窑重生】\n三年后，废弃窑厂内，苏璃将碎琉璃投入熔炉，火苗映红手臂疤痕。她夹起通红琉璃浸入冷水，裂纹成荆棘图案。左侧屏幕中，林浩展示 “涅槃系列”，设计与苏璃草稿一致；右侧工作台上，她将荆棘琉璃嵌入钛金属框架，底座刻 “烬” 字。\n\n【场景 2：暗棋落子】\n国际设计周后台，白薇薇试戴缺左翅的凤凰项链。苏璃混在工人中，穿 “暗夜琉璃” 工服，袖口露红绳 —— 当年裙摆丝线。她将微型芯片贴在展台雕花里。\n\n第三幕：烬凤鸣\n【场景 1：展台惊雷】\n聚光灯下，白薇薇走秀时，背景屏切换影像：\n\n林浩与境外买家交割文件，桌上放着苏璃的断佩。\n白薇薇用 PS 篡改设计时间戳，屏保是苏璃获奖照。\n苏璃将刻有 “苏氏工艺” 的琉璃碎片熔入新作。\n白薇薇胸前吊坠缺翅处透出仿琉璃气泡。苏璃身着熔岩石色工装走出，举起钛合金框架 —— 内嵌重生凤凰，左翅琉璃剔透，右翅钛金属冷冽，裂纹如火焰纹路。\n\n【场景 2：琉璃新生】\n半年后，公益工坊内，苏璃教孩子用碎琉璃拼凤凰壁画，每片羽毛刻捐赠者名字。她围裙口袋露出国际工艺保护协会邀请函，落款正是夺回商标权之日。\n\n【核心意象贯穿】\n\n琉璃佩：从温润到断裂，再到镶嵌于凤凰心脏，隐喻苏璃从天真匠人到遭遇背叛，最终在废墟中重建自我的蜕变。\n荆棘与凤凰：荆棘是复仇的锋芒，亦是重生的铠甲；凤凰涅槃则直接呼应 “烬琉璃” 的主题，展现大女主在灰烬中重燃的力量。\n色彩叙事：绯红（毁灭）→ 熔岩石色（蛰伏与淬炼）→ 彩虹光（新生），以视觉符号串联起苏璃从低谷到逆袭的情感轨迹，全程无对白却通过道具、场景与动作完成强情节叙事。",
    "ori_text": "《烬琉璃》\n第一幕：琉璃碎\n【场景 1：鎏金夜宴】\n水晶吊灯的光斑洒在宴会厅，镜头定格在苏璃身上。她身着绯红琉璃裙，银剪修剪缎带，金粉滑落。屏风阴影里，林浩将文件塞进白薇薇的墨绿色手袋，文件封面透出 “核心工艺图谱”。苏璃腰间刻着 “璃” 字的琉璃佩轻晃，林浩手表秒针停在 10:17—— 与工作室监控切断时间吻合。\n\n【场景 2：骤雨破局】\n暴雨夜，苏璃冲进工作室，设计台散落撕碎的草图，中央是断裂的琉璃佩，断面嵌着半颗珍珠。投影幕布播放监控：林浩用万能钥匙开门，白薇薇拷贝硬盘，两人碰掉琉璃佩。\n蒙太奇镜头：\n\n苏璃捧起断佩，指腹划过刻痕，血珠染红碎片。\n财经新闻字幕闪烁：“苏氏工艺破产”“核心技术被收购”。\n垃圾桶里，绯红琉璃裙揉成一团，金线凤凰如滴血残羽。\n\n第二幕：淬火录\n【场景 1：废窑重生】\n三年后，废弃窑厂内，苏璃将碎琉璃投入熔炉，火苗映红手臂疤痕。她夹起通红琉璃浸入冷水，裂纹成荆棘图案。左侧屏幕中，林浩展示 “涅槃系列”，设计与苏璃草稿一致；右侧工作台上，她将荆棘琉璃嵌入钛金属框架，底座刻 “烬” 字。\n\n【场景 2：暗棋落子】\n国际设计周后台，白薇薇试戴缺左翅的凤凰项链。苏璃混在工人中，穿 “暗夜琉璃” 工服，袖口露红绳 —— 当年裙摆丝线。她将微型芯片贴在展台雕花里。\n\n第三幕：烬凤鸣\n【场景 1：展台惊雷】\n聚光灯下，白薇薇走秀时，背景屏切换影像：\n\n林浩与境外买家交割文件，桌上放着苏璃的断佩。\n白薇薇用 PS 篡改设计时间戳，屏保是苏璃获奖照。\n苏璃将刻有 “苏氏工艺” 的琉璃碎片熔入新作。\n白薇薇胸前吊坠缺翅处透出仿琉璃气泡。苏璃身着熔岩石色工装走出，举起钛合金框架 —— 内嵌重生凤凰，左翅琉璃剔透，右翅钛金属冷冽，裂纹如火焰纹路。\n\n【场景 2：琉璃新生】\n半年后，公益工坊内，苏璃教孩子用碎琉璃拼凤凰壁画，每片羽毛刻捐赠者名字。她围裙口袋露出国际工艺保护协会邀请函，落款正是夺回商标权之日。\n\n【核心意象贯穿】\n\n琉璃佩：从温润到断裂，再到镶嵌于凤凰心脏，隐喻苏璃从天真匠人到遭遇背叛，最终在废墟中重建自我的蜕变。\n荆棘与凤凰：荆棘是复仇的锋芒，亦是重生的铠甲；凤凰涅槃则直接呼应 “烬琉璃” 的主题，展现大女主在灰烬中重燃的力量。\n色彩叙事：绯红（毁灭）→ 熔岩石色（蛰伏与淬炼）→ 彩虹光（新生），以视觉符号串联起苏璃从低谷到逆袭的情感轨迹，全程无对白却通过道具、场景与动作完成强情节叙事。",
    "reference_list": "考点1：“琉璃”推荐译为“liuli (a type of Chinese colored glaze)”或“Chinese colored glaze”，不可直译为“glass”或“crystal”，应保留文化特性\n考点2：“绯红琉璃裙”推荐译为“crimson liuli gown”，不可译为“red glass dress”，应保留“绯红”中的东方古典审美\n考点3：“断佩”推荐译为“broken pendant”或“fractured talisman”，不可译为“broken necklace”\n考点4：“涅槃系列”推荐译为“Nirvana Collection”或“Phoenix Rebirth Series”，不可译为“Rebirth Line”，应保留“涅槃”背后的佛教文化语义\n考点5：“荆棘图案”推荐译为“thorn motif”，应呈现“荆棘”象征的苦难与坚韧\n考点6：“烬”推荐译为“embers”或“ashes”，应保留其“余烬中的希望”语义\n考点7：“暗夜琉璃”推荐译为“Nocturne Liuli”或“Dark Liuli Uniform”\n考点8：“裂纹如火焰纹路”推荐译为“cracks resembling flame patterns”\n考点9：“金线凤凰如滴血残羽”推荐译为“gold-threaded phoenix resembling a bloodstained feather”，不可译为“gold phoenix like bloody feathers”，避免误解成暴力图像",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "小说",
    "prompt_id": "26"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nI.THE PRISON DOOR\nA throng of bearded men, in sad-coloured garments and grey steeple-crowned hats, intermixed with women, some wearing hoods, and others bareheaded, was assembled in front of a wooden edifice, the door of which was heavily timbered with oak, and studded with iron spikes.\nThe founders of a new colony, whatever Utopia of human virtue and happiness they might originally project, have invariably recognised it among their earliest practical necessities to allot a portion of the virgin soil as a cemetery, and another portion as the site of a prison. In accordance with this rule it may safely be assumed that the forefathers of Boston had built the first prison-house somewhere in the vicinity of Cornhill, almost as seasonably as they marked out the first burial-ground, on Isaac Johnson’s lot, and round about his grave, which subsequently became the nucleus of all the congregated sepulchres in the old churchyard of King’s Chapel. Certain it is that, some fifteen or twenty years after the settlement of the town, the wooden jail was already marked with weather-stains and other indications of age, which gave a yet darker aspect to its beetle-browed and gloomy front. The rust on the ponderous iron-work of its oaken door looked more antique than anything else in the New World. Like all that pertains to crime, it seemed never to have known a youthful era. Before this ugly edifice, and between it and the wheel-track of the street, was a grass-plot, much overgrown with burdock, pig-weed, apple-pern, and such unsightly vegetation, which evidently found something congenial in the soil that had so early borne the black flower of civilised society, a prison. But on one side of the portal, and rooted almost at the threshold, was a wild rose-bush, covered, in this month of June, with its delicate gems, which might be imagined to offer their fragrance and fragile beauty to the prisoner as he went in, and to the condemned criminal as he came forth to his doom, in token that the deep heart of Nature could pity and be kind to him.\nThis rose-bush, by a strange chance, has been kept alive in history; but whether it had merely survived out of the stern old wilderness, so long after the fall of the gigantic pines and oaks that originally overshadowed it, or whether, as there is fair authority for believing, it had sprung up under the footsteps of the sainted Ann Hutchinson as she entered the prison-door, we shall not take upon us to determine. Finding it so directly on the threshold of our narrative, which is now about to issue from that inauspicious portal, we could hardly do otherwise than pluck one of its flowers, and present it to the reader. It may serve, let us hope, to symbolise some sweet moral blossom that may be found along the track, or relieve the darkening close of a tale of human frailty and sorrow.\nII.THE MARKET-PLACE\nThe grass-plot before the jail, in Prison Lane, on a certain summer morning, not less than two centuries ago, was occupied by a pretty large number of the inhabitants of Boston, all with their eyes intently fastened on the iron-clamped oaken door. Amongst any other population, or at a later period in the history of New England, the grim rigidity that petrified the bearded physiognomies of these good people would have augured some awful business in hand. It could have betokened nothing short of the anticipated execution of some noted culprit, on whom the sentence of a legal tribunal had but confirmed the verdict of public sentiment. But, in that early severity of the Puritan character, an inference of this kind could not so indubitably be drawn. It might be that a sluggish bond-servant, or an undutiful child, whom his parents had given over to the civil authority, was to be corrected at the whipping-post. It might be that an Antinomian, a Quaker, or other heterodox religionist, was to be scourged out of the town, or an idle or vagrant Indian, whom the white man’s firewater had made riotous about the streets, was to be driven with stripes into the shadow of the forest. It might be, too, that a witch, like old Mistress Hibbins, the bitter-tempered widow of the magistrate, was to die upon the gallows. In either case, there was very much the same solemnity of demeanour on the part of the spectators, as befitted a people among whom religion and law were almost identical, and in whose character both were so thoroughly interfused, that the mildest and severest acts of public discipline were alike made venerable and awful. Meagre, indeed, and cold, was the sympathy that a transgressor might look for, from such bystanders, at the scaffold. On the other hand, a penalty which, in our days, would infer a degree of mocking infamy and ridicule, might then be invested with almost as stern a dignity as the punishment of death itself.\nIt was a circumstance to be noted on the summer morning when our story begins its course, that the women, of whom there were several in the crowd, appeared to take a peculiar interest in whatever penal infliction might be expected to ensue. The age had not so much refinement, that any sense of impropriety restrained the wearers of petticoat and farthingale from stepping forth into the public ways, and wedging their not unsubstantial persons, if occasion were, into the throng nearest to the scaffold at an execution. Morally, as well as materially, there was a coarser fibre in those wives and maidens of old English birth and breeding than in their fair descendants, separated from them by a series of six or seven generations; for, throughout that chain of ancestry, every successive mother had transmitted to her child a fainter bloom, a more delicate and briefer beauty, and a slighter physical frame, if not character of less force and solidity than her own. The women who were now standing about the prison-door stood within less than half a century of the period when the man-like Elizabeth had been the not altogether unsuitable representative of the sex. They were her countrywomen: and the beef and ale of their native land, with a moral diet not a whit more refined, entered largely into their composition. The bright morning sun, therefore, shone on broad shoulders and well-developed busts, and on round and ruddy cheeks, that had ripened in the far-off island, and had hardly yet grown paler or thinner in the atmosphere of New England. There was, moreover, a boldness and rotundity of speech among these matrons, as most of them seemed to be, that would startle us at the present day, whether in respect to its purport or its volume of tone.",
    "ori_text": "I.THE PRISON DOOR\nA throng of bearded men, in sad-coloured garments and grey steeple-crowned hats, intermixed with women, some wearing hoods, and others bareheaded, was assembled in front of a wooden edifice, the door of which was heavily timbered with oak, and studded with iron spikes.\nThe founders of a new colony, whatever Utopia of human virtue and happiness they might originally project, have invariably recognised it among their earliest practical necessities to allot a portion of the virgin soil as a cemetery, and another portion as the site of a prison. In accordance with this rule it may safely be assumed that the forefathers of Boston had built the first prison-house somewhere in the vicinity of Cornhill, almost as seasonably as they marked out the first burial-ground, on Isaac Johnson’s lot, and round about his grave, which subsequently became the nucleus of all the congregated sepulchres in the old churchyard of King’s Chapel. Certain it is that, some fifteen or twenty years after the settlement of the town, the wooden jail was already marked with weather-stains and other indications of age, which gave a yet darker aspect to its beetle-browed and gloomy front. The rust on the ponderous iron-work of its oaken door looked more antique than anything else in the New World. Like all that pertains to crime, it seemed never to have known a youthful era. Before this ugly edifice, and between it and the wheel-track of the street, was a grass-plot, much overgrown with burdock, pig-weed, apple-pern, and such unsightly vegetation, which evidently found something congenial in the soil that had so early borne the black flower of civilised society, a prison. But on one side of the portal, and rooted almost at the threshold, was a wild rose-bush, covered, in this month of June, with its delicate gems, which might be imagined to offer their fragrance and fragile beauty to the prisoner as he went in, and to the condemned criminal as he came forth to his doom, in token that the deep heart of Nature could pity and be kind to him.\nThis rose-bush, by a strange chance, has been kept alive in history; but whether it had merely survived out of the stern old wilderness, so long after the fall of the gigantic pines and oaks that originally overshadowed it, or whether, as there is fair authority for believing, it had sprung up under the footsteps of the sainted Ann Hutchinson as she entered the prison-door, we shall not take upon us to determine. Finding it so directly on the threshold of our narrative, which is now about to issue from that inauspicious portal, we could hardly do otherwise than pluck one of its flowers, and present it to the reader. It may serve, let us hope, to symbolise some sweet moral blossom that may be found along the track, or relieve the darkening close of a tale of human frailty and sorrow.\nII.THE MARKET-PLACE\nThe grass-plot before the jail, in Prison Lane, on a certain summer morning, not less than two centuries ago, was occupied by a pretty large number of the inhabitants of Boston, all with their eyes intently fastened on the iron-clamped oaken door. Amongst any other population, or at a later period in the history of New England, the grim rigidity that petrified the bearded physiognomies of these good people would have augured some awful business in hand. It could have betokened nothing short of the anticipated execution of some noted culprit, on whom the sentence of a legal tribunal had but confirmed the verdict of public sentiment. But, in that early severity of the Puritan character, an inference of this kind could not so indubitably be drawn. It might be that a sluggish bond-servant, or an undutiful child, whom his parents had given over to the civil authority, was to be corrected at the whipping-post. It might be that an Antinomian, a Quaker, or other heterodox religionist, was to be scourged out of the town, or an idle or vagrant Indian, whom the white man’s firewater had made riotous about the streets, was to be driven with stripes into the shadow of the forest. It might be, too, that a witch, like old Mistress Hibbins, the bitter-tempered widow of the magistrate, was to die upon the gallows. In either case, there was very much the same solemnity of demeanour on the part of the spectators, as befitted a people among whom religion and law were almost identical, and in whose character both were so thoroughly interfused, that the mildest and severest acts of public discipline were alike made venerable and awful. Meagre, indeed, and cold, was the sympathy that a transgressor might look for, from such bystanders, at the scaffold. On the other hand, a penalty which, in our days, would infer a degree of mocking infamy and ridicule, might then be invested with almost as stern a dignity as the punishment of death itself.\nIt was a circumstance to be noted on the summer morning when our story begins its course, that the women, of whom there were several in the crowd, appeared to take a peculiar interest in whatever penal infliction might be expected to ensue. The age had not so much refinement, that any sense of impropriety restrained the wearers of petticoat and farthingale from stepping forth into the public ways, and wedging their not unsubstantial persons, if occasion were, into the throng nearest to the scaffold at an execution. Morally, as well as materially, there was a coarser fibre in those wives and maidens of old English birth and breeding than in their fair descendants, separated from them by a series of six or seven generations; for, throughout that chain of ancestry, every successive mother had transmitted to her child a fainter bloom, a more delicate and briefer beauty, and a slighter physical frame, if not character of less force and solidity than her own. The women who were now standing about the prison-door stood within less than half a century of the period when the man-like Elizabeth had been the not altogether unsuitable representative of the sex. They were her countrywomen: and the beef and ale of their native land, with a moral diet not a whit more refined, entered largely into their composition. The bright morning sun, therefore, shone on broad shoulders and well-developed busts, and on round and ruddy cheeks, that had ripened in the far-off island, and had hardly yet grown paler or thinner in the atmosphere of New England. There was, moreover, a boldness and rotundity of speech among these matrons, as most of them seemed to be, that would startle us at the present day, whether in respect to its purport or its volume of tone.",
    "reference_list": "考点1：“sad-coloured garments”应该译为“色泽暗淡的衣服”。\n考点2： “steeple-crowned hats”应译为“尖顶高帽”。\n考点3：“apple-pern”应当译为“杂草、毒草“之类的衰败意象 \n考点4： “beetle-browed”应译为“如眉骨般突出的”。\n考点5： “unsightly vegetation”应译为“刺眼的植被”。\n考点6： “pity and be kind to him”中的“pity”应译为“怜惜”。\n考点7： “sainted Ann Hutchinson”应译为“圣人安·哈钦森”。\n考点8： “awful business”应译为“肮脏的交易”。\n考点9： “Antinomian”应译为“惟信仰论者”。\n考点10：“Quaker”应译为“公谊会教徒”。\n考点11：“fainter bloom”应译为“更暗淡的容光”。\n考点12：“briefer beauty”应译为“更短的花期”。",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "小说",
    "prompt_id": "58"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n今年港股IPO尤为火爆，2025年上半年港交所新受理的IPO申请达到168家，远超去年全年。同时赴港上市的企业中不乏宁德时代、恒瑞医药、海天味业等行业龙头，最近挖掘机龙头三一重工的港股IPO也有新进展。\n格隆汇获悉，近日，三一重工股份有限公司（简称“三一重工”）境外发行上市备案有新进展。监管要求公司补充说明对控股股东认定结果不一致的原因及认定标准，并就控股股东的认定情况出具明确结论性意见；公司部分募集资金拟用于扩大海外制造能力，说明具体项目情况及项目所在的国别或地区等。\n三一重工 (SS:600031)曾于今年5月递表港交所，中信证券为其独家保荐人。作为国内最大的工程机械企业，2024年其收入超783亿元。但在行业周期等影响下，近几年三一重工的收入存在波动，且公司海外营收占比较大，面临关税、贸易保护政策等风险。\n近几年三一重工的股价也大幅波动，在2021年达到48.51元/股的高峰后，呈震荡下跌走势，今天下午收盘为19.07元/股，市值超1616亿元。如今工程机械市场情况如何？不妨通过三一重工来一探究竟。\n三一重工冲击“A+H”上市，近三年累计派息超70亿\n三一重工总部位于北京市昌平区，其历史可追溯至1989年，当时公司创始人梁稳根与唐修国、毛中吾、袁金华共同创立了公司前身涟源市焊接材料厂。\n1994年公司在湖南成立，从其前身分立并改组为一家专注于工程机械制造业务的有限责任公司，并于2000年改制为股份有限公司，2003年在上海证券交易所主板上市。\n招股书显示，截至2025年5月14日，控股股东集团（包括三一集团、梁稳根、唐修国、向文波、毛中吾、袁金华、易小刚、周福贵及北京三一重机）共同持有三一重工约33.73%股份。\n三一重工创始人梁稳根及其子梁在中均担任公司非执行董事。\n梁稳根今年68岁，1983年获得中南矿冶学院（现为中南大学）金属材料及热处理工程学士学位，在机械行业拥有超过40年经验。梁稳根自2000年10月起担任三一集团董事，2001年4月起担任三一重机有限公司董事，2016年8月起担任湖南三一工学院股份有限公司董事。\n梁在中今年40岁，2006年获得华威大学计算机与管理科学学士学位，并于2014年获得哈佛大学肯尼迪政府学院公共管理硕士学位。梁在中2006年加入公司，曾担任子公司三一汽车制造有限公司制造部调度员，还曾在三一集团财务部担任多个管理职务，并担任过湖南三湘银行股份有限公司董事长。\n三一重工董事长向文波今年62岁，1988年获得大连理工大学材料工程学硕士学位，1991年加入公司前身，并于2000年共同创立三一集团，此后在集团担任执行总裁、市场营销部总经理、总经理等多项职务。\n副董事长兼总裁俞宏福今年62岁，1984年获得南京建筑工程学院（现南京工业大学）工程机械学士学位，2010年获得中欧国际工商学院工商管理硕士学位。2006年加入集团，先后担任生产管理部主任、小型挖掘机事业部总经理等职务。\n值得注意的是，据2024年年度报告，向文波、俞宏福、易小刚等高管均存在减持公司股份的情形。同时，三一重工一边大手笔分红，一边赴港上市募资的行为也备受市场关注。\n2022年、2023年、2024年（简称“报告期”），三一重工分别向股东宣派或支付现金股息约38亿元、13.5亿元、18.6亿元，三年累计派息超70亿元。\n本次赴港IPO，三一重工拟募资用于进一步发展全球销售及服务网络，以提高全球品牌知名度、市场渗透率和服务效率；增强研发能力；扩大海外制造能力和优化生产效率；营运资金和一般公司用途。\n尽管公司募资用途中提到要增强研发能力，但实际上近两年公司的研发人员数量却大幅下降。年报显示，2022年至2024年末，三一重工在职员工数量从约2.6万名降至2.5万名；其中，研发人员从7466 名降至 5867 名，减少近1600人。",
    "ori_text": "今年港股IPO尤为火爆，2025年上半年港交所新受理的IPO申请达到168家，远超去年全年。同时赴港上市的企业中不乏宁德时代、恒瑞医药、海天味业等行业龙头，最近挖掘机龙头三一重工的港股IPO也有新进展。\n格隆汇获悉，近日，三一重工股份有限公司（简称“三一重工”）境外发行上市备案有新进展。监管要求公司补充说明对控股股东认定结果不一致的原因及认定标准，并就控股股东的认定情况出具明确结论性意见；公司部分募集资金拟用于扩大海外制造能力，说明具体项目情况及项目所在的国别或地区等。\n三一重工 (SS:600031)曾于今年5月递表港交所，中信证券为其独家保荐人。作为国内最大的工程机械企业，2024年其收入超783亿元。但在行业周期等影响下，近几年三一重工的收入存在波动，且公司海外营收占比较大，面临关税、贸易保护政策等风险。\n近几年三一重工的股价也大幅波动，在2021年达到48.51元/股的高峰后，呈震荡下跌走势，今天下午收盘为19.07元/股，市值超1616亿元。如今工程机械市场情况如何？不妨通过三一重工来一探究竟。\n三一重工冲击“A+H”上市，近三年累计派息超70亿\n三一重工总部位于北京市昌平区，其历史可追溯至1989年，当时公司创始人梁稳根与唐修国、毛中吾、袁金华共同创立了公司前身涟源市焊接材料厂。\n1994年公司在湖南成立，从其前身分立并改组为一家专注于工程机械制造业务的有限责任公司，并于2000年改制为股份有限公司，2003年在上海证券交易所主板上市。\n招股书显示，截至2025年5月14日，控股股东集团（包括三一集团、梁稳根、唐修国、向文波、毛中吾、袁金华、易小刚、周福贵及北京三一重机）共同持有三一重工约33.73%股份。\n三一重工创始人梁稳根及其子梁在中均担任公司非执行董事。\n梁稳根今年68岁，1983年获得中南矿冶学院（现为中南大学）金属材料及热处理工程学士学位，在机械行业拥有超过40年经验。梁稳根自2000年10月起担任三一集团董事，2001年4月起担任三一重机有限公司董事，2016年8月起担任湖南三一工学院股份有限公司董事。\n梁在中今年40岁，2006年获得华威大学计算机与管理科学学士学位，并于2014年获得哈佛大学肯尼迪政府学院公共管理硕士学位。梁在中2006年加入公司，曾担任子公司三一汽车制造有限公司制造部调度员，还曾在三一集团财务部担任多个管理职务，并担任过湖南三湘银行股份有限公司董事长。\n三一重工董事长向文波今年62岁，1988年获得大连理工大学材料工程学硕士学位，1991年加入公司前身，并于2000年共同创立三一集团，此后在集团担任执行总裁、市场营销部总经理、总经理等多项职务。\n副董事长兼总裁俞宏福今年62岁，1984年获得南京建筑工程学院（现南京工业大学）工程机械学士学位，2010年获得中欧国际工商学院工商管理硕士学位。2006年加入集团，先后担任生产管理部主任、小型挖掘机事业部总经理等职务。\n值得注意的是，据2024年年度报告，向文波、俞宏福、易小刚等高管均存在减持公司股份的情形。同时，三一重工一边大手笔分红，一边赴港上市募资的行为也备受市场关注。\n2022年、2023年、2024年（简称“报告期”），三一重工分别向股东宣派或支付现金股息约38亿元、13.5亿元、18.6亿元，三年累计派息超70亿元。\n本次赴港IPO，三一重工拟募资用于进一步发展全球销售及服务网络，以提高全球品牌知名度、市场渗透率和服务效率；增强研发能力；扩大海外制造能力和优化生产效率；营运资金和一般公司用途。\n尽管公司募资用途中提到要增强研发能力，但实际上近两年公司的研发人员数量却大幅下降。年报显示，2022年至2024年末，三一重工在职员工数量从约2.6万名降至2.5万名；其中，研发人员从7466 名降至 5867 名，减少近1600人。",
    "reference_list": "考点1： \"海天味业\"应译为“ Foshan Haitian Flavouring and Food Company Ltd.” \n考点2：\"一探究竟\"应译为“figure out”\n考点3： “三一重工”应译为“SANY Heavy Industry”\n考点4： “恒瑞医药”应译为“Hengrui Pharmaceuticals”\n考点5：“湖南三一工学院”应译为“Hunan SANY Industrial Vocational and Technical College”\n考点6： “哈佛大学肯尼迪政府学院”应译为“John F.Kennedy School of Government”，简称“Harvard Kennedy School”，缩写HKS；\n考点7：“南京工业大学”应译为“Nanjing Tech University”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "64"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nThe popularity of short drama videos is a common expectation of content, platform, and user sides\n\n- The plot is short and compact, with a strong sense of rhythm. There are many exciting and turning points every minute, and the scene and interaction are excellent.\n- Short drama content is high-quality PGC content for the platform recommended by the algorithm, which increases the user’s stay time on the platform, and the platform will support traffic.\n- Currently, the global market is blank and has a great sense of freshness.\n\nThe popularity of short dramas, the retention demand of platforms, and the blank market overseas will contribute to the vigorous development of the overseas short drama market.\n\nIn this article, we will delve into various aspects of short drama content going global, including video making, and show you how to use domestic content and video localization tools to gain traffic overseas. I believe this method will bring you new ideas and elevate your content and fans to a new level. The following is the most comprehensive analysis of short drama production strategies going global. We hope you can become a master as soon as possible!\n\n🔥 The secret of content production of short dramas\n\nBy observing more effective short drama accounts, we can see that the account types, content production methods, and publishing rules of “Overseas Short Drama” are very effective and replicable. Specifically, find short dramas with explosive plots, operate accounts according to the drama dimension, strengthen localized content production, and maintain a high publishing frequency.\n\nThrough this storytelling structure, each short drama account can reach tens of thousands or even hundreds of thousands of subscribers in a few weeks or months. Let’s carefully dismantle each part of the machine fee.\n\n1. Find short dramas with explosive plots\nTo attract the attention of the audience on TikTok, you need to master the art of popular short videos. The average attention span used on platforms such as TikTok is only 1–4 seconds, so it becomes more challenging to stand out. The first rule of going global with short dramas is “explosive plot”. To attract your audience and get the viewing time you need, you must start with “content explosion”. Reelshort short dramas with hundreds of thousands of fans have similar strategies.\n\n1. What is an explosive plot?\n\nGenerally speaking, dramas that combine popular elements such as revenge, time travel, sadomasochism, and sweet pets will become popular if there are also pornographic or violent ones. These plots vary from region to region. For example, female short dramas with love as the main theme are common in various regions. Specifically, in Europe and America, the male protagonists are mostly CEOs, heirs of wealthy families, powerful alphas, werewolves, and vampires, while the female protagonists are mostly independent female protagonists who are self-reliant, because female audiences in Europe and America prefer this set, and instead have the complex of crying and sadomasochism to be deleted. Popular themes in South East Asia are mostly scenes of bitter love, mother-in-law and daughter-in-law wars, while Brazil and other South American regions prefer gangsters.\n\n2. Where can I find a short play with an explosive plot?\n\nChinese mainland’s short drama content has high competitiveness worldwide, and is in a leading position in terms of production level, theme type, and audience. Therefore, if you want to create a short drama account on TikTok, it is a very wise choice to learn about and obtain the latest short dramas from Chinese mainland platforms such as Douyin, Kuaishou, WeChat Channels, and publish them overseas.\n\nWhen choosing domestic short drama works, the following factors can be considered:\n- Theme types: You can choose themes that meet the preferences of overseas audiences, such as romance, comedy, suspense, science fiction, etc.\n- Production level: The production level of short dramas should be high, with clear visuals, smooth plots, and natural acting skills of actors.\n- Audience: You can choose short dramas with certain popularity, which can more easily attract the attention of overseas users.\n\nBy following these guidelines, you can effectively obtain content from the short drama market in the Chinese mainland, successfully publish it to your account on TikTok after being processed by Localization. As for the content posted overseas, we can also see through the screenshots below that they are very attractive, and many users are constantly seeking the next installment: next please, next part, next, next pls …\n\n2. Operate accounts by episode dimension\nOperating a TikTok account according to the dimension of the series has many benefits, which are similar to the usual IP character design we create, which can bring high fan conversion and continuous content viewing.\n- It can form a stable fan base. TV series have a certain continuity and completeness, and viewers can form a recognition and favorable impression of the account by watching TV series, thus becoming a stable fan base.\n- It can improve the stickiness of the account. TV series can generate sustained viewing interest from the audience, thereby increasing the active level and stickiness of the account.\n- It can reduce operating costs. Operating accounts according to the TV series set dimension can reduce the workload of operators and reduce operating costs.\n\nIt is highly recommended that when TikTok operates an account, publish the content of the short drama neatly and orderly according to the series of the short drama.\n\n3. Strengthen localized content production\nGlobalization of content must be preceded by localization of content：\n\n1. Cultural adaptability: When choosing short plays, consider their cross-cultural transmissibility. Although some short plays may be very popular in the Chinese mainland, it does not mean that they will be equally popular in other cultural environments. Choose stories that have universal appeal and are easy to understand.\n2. Language and subtitles: Considering the TikTok international audience, adding subtitles in English or other languages to the short play will help expand its audience.\n3. Music and dubbing: Due to the different music copyright situation in some countries, the same, distributed to TikTok in each country needs to be reconsidered the music copyright and localization dubbing.\n\nAccurate live dubbing is time-consuming and laborious. In addition to hiring someone to do the dubbing separately, it is also necessary to adjust the dubbing, screen, and subtitles in the later stage to achieve alignment of audio and video subtitles. In practice in the industry and most of the TikTok short drama cases we have seen, it is basically composed of “subtitling” + “translating subtitles” + “music”, and live dubbing is relatively rare. Many top short drama companies in the industry use GhostCut automatic subtitling and automatic translation functions are very effective, low-cost, and the lowest cost is only a few cents per minute. The following are the specific subtitling and translation effects.",
    "ori_text": "The popularity of short drama videos is a common expectation of content, platform, and user sides\n\n- The plot is short and compact, with a strong sense of rhythm. There are many exciting and turning points every minute, and the scene and interaction are excellent.\n- Short drama content is high-quality PGC content for the platform recommended by the algorithm, which increases the user’s stay time on the platform, and the platform will support traffic.\n- Currently, the global market is blank and has a great sense of freshness.\n\nThe popularity of short dramas, the retention demand of platforms, and the blank market overseas will contribute to the vigorous development of the overseas short drama market.\n\nIn this article, we will delve into various aspects of short drama content going global, including video making, and show you how to use domestic content and video localization tools to gain traffic overseas. I believe this method will bring you new ideas and elevate your content and fans to a new level. The following is the most comprehensive analysis of short drama production strategies going global. We hope you can become a master as soon as possible!\n\n🔥 The secret of content production of short dramas\n\nBy observing more effective short drama accounts, we can see that the account types, content production methods, and publishing rules of “Overseas Short Drama” are very effective and replicable. Specifically, find short dramas with explosive plots, operate accounts according to the drama dimension, strengthen localized content production, and maintain a high publishing frequency.\n\nThrough this storytelling structure, each short drama account can reach tens of thousands or even hundreds of thousands of subscribers in a few weeks or months. Let’s carefully dismantle each part of the machine fee.\n\n1. Find short dramas with explosive plots\nTo attract the attention of the audience on TikTok, you need to master the art of popular short videos. The average attention span used on platforms such as TikTok is only 1–4 seconds, so it becomes more challenging to stand out. The first rule of going global with short dramas is “explosive plot”. To attract your audience and get the viewing time you need, you must start with “content explosion”. Reelshort short dramas with hundreds of thousands of fans have similar strategies.\n\n1. What is an explosive plot?\n\nGenerally speaking, dramas that combine popular elements such as revenge, time travel, sadomasochism, and sweet pets will become popular if there are also pornographic or violent ones. These plots vary from region to region. For example, female short dramas with love as the main theme are common in various regions. Specifically, in Europe and America, the male protagonists are mostly CEOs, heirs of wealthy families, powerful alphas, werewolves, and vampires, while the female protagonists are mostly independent female protagonists who are self-reliant, because female audiences in Europe and America prefer this set, and instead have the complex of crying and sadomasochism to be deleted. Popular themes in South East Asia are mostly scenes of bitter love, mother-in-law and daughter-in-law wars, while Brazil and other South American regions prefer gangsters.\n\n2. Where can I find a short play with an explosive plot?\n\nChinese mainland’s short drama content has high competitiveness worldwide, and is in a leading position in terms of production level, theme type, and audience. Therefore, if you want to create a short drama account on TikTok, it is a very wise choice to learn about and obtain the latest short dramas from Chinese mainland platforms such as Douyin, Kuaishou, WeChat Channels, and publish them overseas.\n\nWhen choosing domestic short drama works, the following factors can be considered:\n- Theme types: You can choose themes that meet the preferences of overseas audiences, such as romance, comedy, suspense, science fiction, etc.\n- Production level: The production level of short dramas should be high, with clear visuals, smooth plots, and natural acting skills of actors.\n- Audience: You can choose short dramas with certain popularity, which can more easily attract the attention of overseas users.\n\nBy following these guidelines, you can effectively obtain content from the short drama market in the Chinese mainland, successfully publish it to your account on TikTok after being processed by Localization. As for the content posted overseas, we can also see through the screenshots below that they are very attractive, and many users are constantly seeking the next installment: next please, next part, next, next pls …\n\n2. Operate accounts by episode dimension\nOperating a TikTok account according to the dimension of the series has many benefits, which are similar to the usual IP character design we create, which can bring high fan conversion and continuous content viewing.\n- It can form a stable fan base. TV series have a certain continuity and completeness, and viewers can form a recognition and favorable impression of the account by watching TV series, thus becoming a stable fan base.\n- It can improve the stickiness of the account. TV series can generate sustained viewing interest from the audience, thereby increasing the active level and stickiness of the account.\n- It can reduce operating costs. Operating accounts according to the TV series set dimension can reduce the workload of operators and reduce operating costs.\n\nIt is highly recommended that when TikTok operates an account, publish the content of the short drama neatly and orderly according to the series of the short drama.\n\n3. Strengthen localized content production\nGlobalization of content must be preceded by localization of content：\n\n1. Cultural adaptability: When choosing short plays, consider their cross-cultural transmissibility. Although some short plays may be very popular in the Chinese mainland, it does not mean that they will be equally popular in other cultural environments. Choose stories that have universal appeal and are easy to understand.\n2. Language and subtitles: Considering the TikTok international audience, adding subtitles in English or other languages to the short play will help expand its audience.\n3. Music and dubbing: Due to the different music copyright situation in some countries, the same, distributed to TikTok in each country needs to be reconsidered the music copyright and localization dubbing.\n\nAccurate live dubbing is time-consuming and laborious. In addition to hiring someone to do the dubbing separately, it is also necessary to adjust the dubbing, screen, and subtitles in the later stage to achieve alignment of audio and video subtitles. In practice in the industry and most of the TikTok short drama cases we have seen, it is basically composed of “subtitling” + “translating subtitles” + “music”, and live dubbing is relatively rare. Many top short drama companies in the industry use GhostCut automatic subtitling and automatic translation functions are very effective, low-cost, and the lowest cost is only a few cents per minute. The following are the specific subtitling and translation effects.",
    "reference_list": "考点1：“PGC content”推荐译为“专业生产内容”，专业术语。\n考点2：“a great sense of freshness”不可直译为“很强的新鲜感”，推荐译为“强烈的新奇感”或“极具吸引力的新意”，更符合市场语境和行文语气。\n考点3：“elevate your content and fans to a new level”推荐译为“提升内容质量和用户量级”或“实现内容与粉丝的双重跃升”，不可生硬直译为“提升内容和粉丝”。\n考点4：“explosive plot”推荐译为“爆款剧情”或“引爆剧情”，不可译为“爆炸性情节”，后者易误导为暴力内容。\n考点5：“CEO, heirs of wealthy families, powerful alphas, werewolves, and vampires”必须统译为“霸总、豪门、强势Alpha、狼人、吸血鬼”等流行人设，体现海外市场偏好，避免逐个直译导致割裂。\n考点6：“the complex of crying and sadomasochism to be deleted”中的“complex”推荐译为“情结”或“偏好”。\n考点7：“bitter love, mother-in-law and daughter-in-law wars”必须译为“虐恋情深、婆媳大战”，属固定题材用语，避免逐字翻译失去语义色彩。\n考点8：“content stickiness”推荐译为“内容粘性”或“用户粘性”，属平台运营常用术语，需统一用词。\n考点9：“globalization of content must be preceded by localization of content”推荐译为“内容出海需先本地化”，为常见表达结构。\n考点10：“cross-cultural transmissibility”推荐译为“跨文化传播力”或“文化适应性”，不可译为“传染性”或“可传播性”。\n考点11：“alignment of audio and video subtitles”推荐译为“音画字幕同步”，不可译为“对齐音频和视频字幕”，生硬机械。\n考点12：“GhostCut”应保留专有名词形式，后续可加注释“（一款自动字幕与翻译工具）”。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "互联网",
    "prompt_id": "20"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nThe Secret to Coca-Cola’s Global Marketing Power: Crisp Creativity\n\nAs every marketer knows, it’s difficult to keep consumers interested when preferences, attitudes and expectations are always changing. Now imagine juggling all that for over 100 years.\nThat’s exactly what the Coca-Cola Company has been doing since its start all the way back in 1886. At the time, its bubbly beverage was just five cents a glass and its slogan was “Drink Coca-Cola.” \nNothing wrong with keeping it simple, right?\nMaybe not — but the creativity cup wasn’t empty. As business boomed, so did the Coca-Cola slogans, showing off marketing strategies built to sell the mouthwatering customer experience. Here are just a few examples:\n- 1905: “Coca-Cola Revives and Sustains”\n- 1922: “Thirst Knows No Season”\n- 1927: “Pure as Sunlight” and “Around the Corner from Everywhere”\n- 1939: “Whoever You Are, Whatever You Do, Wherever You May Be, When You Think of Refreshment Think of Ice Cold Coca‑Cola”\n- 1952: “What You Want is a Coke”\n- 1979: “Have a Coke and a Smile”\n- 1989: “Official Soft Drink of Summer”\n- 2009: “Open Happiness”\n- 2016: “Taste the Feeling”\n\nSee how those slogans change over time? They’re shifting to align with an ever-changing consumer preference — and yet, they’re always positioning the Coca-Cola Company as sunny, cheerful, warm and energetic. A consistent image builds brand identity, but if you want brand loyalty, you need consumers to trust that you’ll stick to your values as the years go by.\nAnd that, dear marketers, is where our story really begins. Because the secret to Coca-Cola’s marketing strategy has never been just one catchy phrase or product strategy; instead, it’s about finding crisp, refreshing ways to tell a decades-old story.\nSo, how have they managed it?\n\nA Taste of Success: 4 Famous Coca-Cola Marketing Campaigns\nAs it turns out, my little snow globe was only one marketing channel for the unstoppable Coca-Cola brand. Its campaigns have taken tons of incredible forms throughout the years, including these four favorites:\n1. The Coca-Cola Santas\nAlthough Santa Claus has been enjoying the crisp taste of Coca-Cola in holiday ads since the 1920s, he didn’t get his iconic look until 1931. It was all thanks to illustrator Haddon Sundblom, who took inspiration from “‘Twas the Night Before Christmas” to create a warm, friendly character.\nWarm and friendly. Sounds a lot like what Coca-Cola was doing with its slogans, right?\nUnsurprisingly, it worked. The world fell in love with this iteration of Saint Nick, and Coca-Cola put that “nose like a cherry” on billboards, store displays, calendars and more. \n2. Bonus: The Bears\nWhile they might have crossed paths when grabbing a Coke, the iconic polar bears of snow globe fame weren’t actually part of the Santa Claus campaigns. They debuted in 1993 as part of a new technical approach in Coca-Cola’s marketing — including computer animation. The bears were called “fun” and “playful,” representing yet another new interpretation of familiar values.\n3. A Brilliant Bottle\nI know — bottle design isn’t really digital marketing or content marketing. But stay with me on this one.\nIn 1912, the Coca-Cola Company realized it didn’t have a significant way to protect its brand identity. It needed packaging it could patent. So, the company asked glass companies to develop a “bottle so distinct that you would recognize it by feel in the dark or lying broken on the ground.” \nWhy? Lead Coca-Cola attorney Harold Hirsch said it best: “We are not building Coca‑Cola alone for today. We are building Coca‑Cola forever.”\nSee what I mean about brand positioning and consistency?\nBy 1915, the company had secured its bottle and its patent. Now, the bottle is part of Coca-Cola’s marketing campaigns, held by Santas and polar bears alike — and it’s a reminder that marketing is about more than words on a screen.\n4. Sharing Your Soft Drink\nI have mixed feelings about the “Share a Coke” campaign, I really do.\nAnd that’s not because it’s anything short of brilliant. It is. I’ll just never be over the fact that I couldn’t find my name on one of those iconic bottles. \nA moment of silence for the Ashlees of the world.\nThe folks behind the campaign said they built it to talk to the Coca-Cola target audience (minus me) “at eye level,” which is an interesting perspective on matching your marketing tone to your consumers’ expectations. In this case, it was all about a friendly, informal, social approach — one that stuck to the brand’s values and encouraged people to buy and share their favorite soft drink at the same time.\n“I’d Like to Buy the World a Coke”\nWhen creative director Bill Backer found himself suffering through a flight delay with his fellow grounded passengers, he realized the once-furious folks were now laughing at their woes over a Coke. He told the rest of his team he’d like to do the same thing for the whole world — but they protested, wondering if it would make more sense to buy the world homes instead.\nSo they did both.\nThe “I’d Like to Buy the World a Coke” campaign started as a commercial celebrating the desire to help one another. It turned into a song that helped do that very thing, with the Coca-Cola Company donating $80,000 in royalties to UNICEF.\nYears later, Google got into the marketing mix with “Project Re:Brief” — a modernization of the original campaign. This time, people could purchase Coca-Cola products on their smartphones, record messages and send them to strangers all over the world through innovative vending machines.\nIn many ways, this is a culmination of everything we’ve seen from Coca-Cola. It was the familiar story of warmth and friendliness told in new ways — but it took those values to the next level by turning them into a tangible, interactive customer experience.\n\nTake Inspiration From the Coca-Cola Playbook\nEven if you’re more of a Pepsi person, there’s always something to learn from the Coca-Cola brand. From its humble five-cent beginnings to campaigns that change lives (and my own holiday traditions), this company isn’t just in your glass anymore; it’s a major force in the marketing world — and it has a lot to say.\nIf you’re looking for ways to evolve with changing market dynamics, talk to a shifting consumer base and still maintain the spark that makes your company unique, it might be time to grab a Coke.",
    "ori_text": "The Secret to Coca-Cola’s Global Marketing Power: Crisp Creativity\n\nAs every marketer knows, it’s difficult to keep consumers interested when preferences, attitudes and expectations are always changing. Now imagine juggling all that for over 100 years.\nThat’s exactly what the Coca-Cola Company has been doing since its start all the way back in 1886. At the time, its bubbly beverage was just five cents a glass and its slogan was “Drink Coca-Cola.” \nNothing wrong with keeping it simple, right?\nMaybe not — but the creativity cup wasn’t empty. As business boomed, so did the Coca-Cola slogans, showing off marketing strategies built to sell the mouthwatering customer experience. Here are just a few examples:\n- 1905: “Coca-Cola Revives and Sustains”\n- 1922: “Thirst Knows No Season”\n- 1927: “Pure as Sunlight” and “Around the Corner from Everywhere”\n- 1939: “Whoever You Are, Whatever You Do, Wherever You May Be, When You Think of Refreshment Think of Ice Cold Coca‑Cola”\n- 1952: “What You Want is a Coke”\n- 1979: “Have a Coke and a Smile”\n- 1989: “Official Soft Drink of Summer”\n- 2009: “Open Happiness”\n- 2016: “Taste the Feeling”\n\nSee how those slogans change over time? They’re shifting to align with an ever-changing consumer preference — and yet, they’re always positioning the Coca-Cola Company as sunny, cheerful, warm and energetic. A consistent image builds brand identity, but if you want brand loyalty, you need consumers to trust that you’ll stick to your values as the years go by.\nAnd that, dear marketers, is where our story really begins. Because the secret to Coca-Cola’s marketing strategy has never been just one catchy phrase or product strategy; instead, it’s about finding crisp, refreshing ways to tell a decades-old story.\nSo, how have they managed it?\n\nA Taste of Success: 4 Famous Coca-Cola Marketing Campaigns\nAs it turns out, my little snow globe was only one marketing channel for the unstoppable Coca-Cola brand. Its campaigns have taken tons of incredible forms throughout the years, including these four favorites:\n1. The Coca-Cola Santas\nAlthough Santa Claus has been enjoying the crisp taste of Coca-Cola in holiday ads since the 1920s, he didn’t get his iconic look until 1931. It was all thanks to illustrator Haddon Sundblom, who took inspiration from “‘Twas the Night Before Christmas” to create a warm, friendly character.\nWarm and friendly. Sounds a lot like what Coca-Cola was doing with its slogans, right?\nUnsurprisingly, it worked. The world fell in love with this iteration of Saint Nick, and Coca-Cola put that “nose like a cherry” on billboards, store displays, calendars and more. \n2. Bonus: The Bears\nWhile they might have crossed paths when grabbing a Coke, the iconic polar bears of snow globe fame weren’t actually part of the Santa Claus campaigns. They debuted in 1993 as part of a new technical approach in Coca-Cola’s marketing — including computer animation. The bears were called “fun” and “playful,” representing yet another new interpretation of familiar values.\n3. A Brilliant Bottle\nI know — bottle design isn’t really digital marketing or content marketing. But stay with me on this one.\nIn 1912, the Coca-Cola Company realized it didn’t have a significant way to protect its brand identity. It needed packaging it could patent. So, the company asked glass companies to develop a “bottle so distinct that you would recognize it by feel in the dark or lying broken on the ground.” \nWhy? Lead Coca-Cola attorney Harold Hirsch said it best: “We are not building Coca‑Cola alone for today. We are building Coca‑Cola forever.”\nSee what I mean about brand positioning and consistency?\nBy 1915, the company had secured its bottle and its patent. Now, the bottle is part of Coca-Cola’s marketing campaigns, held by Santas and polar bears alike — and it’s a reminder that marketing is about more than words on a screen.\n4. Sharing Your Soft Drink\nI have mixed feelings about the “Share a Coke” campaign, I really do.\nAnd that’s not because it’s anything short of brilliant. It is. I’ll just never be over the fact that I couldn’t find my name on one of those iconic bottles. \nA moment of silence for the Ashlees of the world.\nThe folks behind the campaign said they built it to talk to the Coca-Cola target audience (minus me) “at eye level,” which is an interesting perspective on matching your marketing tone to your consumers’ expectations. In this case, it was all about a friendly, informal, social approach — one that stuck to the brand’s values and encouraged people to buy and share their favorite soft drink at the same time.\n“I’d Like to Buy the World a Coke”\nWhen creative director Bill Backer found himself suffering through a flight delay with his fellow grounded passengers, he realized the once-furious folks were now laughing at their woes over a Coke. He told the rest of his team he’d like to do the same thing for the whole world — but they protested, wondering if it would make more sense to buy the world homes instead.\nSo they did both.\nThe “I’d Like to Buy the World a Coke” campaign started as a commercial celebrating the desire to help one another. It turned into a song that helped do that very thing, with the Coca-Cola Company donating $80,000 in royalties to UNICEF.\nYears later, Google got into the marketing mix with “Project Re:Brief” — a modernization of the original campaign. This time, people could purchase Coca-Cola products on their smartphones, record messages and send them to strangers all over the world through innovative vending machines.\nIn many ways, this is a culmination of everything we’ve seen from Coca-Cola. It was the familiar story of warmth and friendliness told in new ways — but it took those values to the next level by turning them into a tangible, interactive customer experience.\n\nTake Inspiration From the Coca-Cola Playbook\nEven if you’re more of a Pepsi person, there’s always something to learn from the Coca-Cola brand. From its humble five-cent beginnings to campaigns that change lives (and my own holiday traditions), this company isn’t just in your glass anymore; it’s a major force in the marketing world — and it has a lot to say.\nIf you’re looking for ways to evolve with changing market dynamics, talk to a shifting consumer base and still maintain the spark that makes your company unique, it might be time to grab a Coke.",
    "reference_list": "考点1：“Crisp Creativity”应译为“鲜活爽脆的创意/让创意保持鲜活”。\n考点2：”the creativity cup wasn’t empty”采用了隐喻的手法，推荐译为“创意的源泉并未枯竭”。\n考点3：”brand identity”是市场营销中的核心术语，区别于brand image（品牌形象），指品牌希望在消费者心中建立的形象和认知，应该译为“品牌识别”。\n考点4：”Pepsi person”推荐译为“百事粉”。\n考点5：“crossed paths”需结合语境理解，推荐译为“曾（在广告中）同框出现”。\n考点6：”at eye level”应译为“以平等的姿态”。\n考点7：‘’A Brilliant Bottle”应译为“ 绝妙的瓶身设计”",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "广告营销",
    "prompt_id": "32"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n在高地温与动水扰动共同作用的岩体注浆过程中，浆液的扩散行为不仅受控于材料本身的流变特性，还与围岩孔隙结构、渗流状态和热-流-固耦合过程密切相关。由于注浆区位于高温水循环发育带，地层中含水层与微裂隙网络交错分布，在高温梯度与高水压联合驱动下，浆液的流动呈现非线性穿透与波动扩散特征，明显不同于常温条件下的达西型渗流模式。\n注浆材料方面，传统水泥基材料在高温环境下易出现早凝、抗冲散性下降及与围岩界面结合力弱化等问题，难以满足热扰动隧洞或深部裂隙封堵的工程需求。近年来，基于硫铝酸盐水泥（CSA）与地聚物的复合体系显示出在高地温注浆工程中的潜在优势，表现为良好的热稳定性、低黏度下的快速凝结能力及优异的抗冲散性。试验结果表明，随着环境温度升高至90℃以上，CSA-地聚物复合浆液在剪切速率超过50 s⁻¹后仍保持适度的塑性流动性，其初始凝结时间控制在15分钟以内，而在动水条件下的抗分散半径显著小于普通水泥浆液。\n从反应机制角度分析，CSA-地聚物复合注浆材料的强度来源主要包括三种路径：（1）CSA组分在高温水环境中快速水化，形成大量的钙矾石（ettringite）与铝酸钙水合物（C-A-H）；（2）地聚物体系在激发剂（如氢氧化钠、硅酸钠）作用下发生溶出-聚合反应，生成以N-A-S-H为主的凝胶相，并在高温作用下形成三维交联结构；（3）二者之间发生协同水化或共聚反应，形成含钠-钙-铝硅四元复合胶体，提升浆体的致密性与热稳定性。\n尤其在高地温条件下，硅铝源溶解速率明显加快，有助于早期强度形成；同时，水化放热过程的热峰前移、强度增长速率提升，需特别控制反应速率与放热曲线，避免浆体快速失水导致开裂。测试表明，浆液在90℃热浴中养护6小时后，其等效28天抗压强度可达到常温下养护3天的水平。\n在材料-环境交互过程中，浆液与高温水体接触会导致体系内自由水加速逸散、浆体离子浓度快速变化，进而影响凝胶结构的形成与空间网络的构建。这一过程中的界面演化表现为：早期形成的钙矾石与水铝石类水化产物在高温下易产生相变或晶型重构，从而影响浆岩界面层的致密度和剪切结合力。此外，高温环境还促进离子迁移速率，造成溶胶-凝胶相转化区的边界模糊，进而影响后期浆体力学性能的均质性。\n注浆体在固化过程中的热传导行为也是决定其最终工程性能的关键因素之一。实际观测发现，CSA-地聚物浆体的导热系数在40–120℃区间呈非线性变化趋势，主要受其孔隙结构、毛细水蒸发速率以及水化产物热物性差异影响。微观分析显示，随着高温作用时间延长，浆体内部出现明显的微裂隙重构现象，导致热响应不均并产生局部热应力集中，可能引发注浆区的局部失稳。\n从界面破坏试验来看，高温-动水复合作用下，浆岩结合面表现出明显的黏聚力退化与界面粗糙度劣化趋势，破坏模式逐步由剪切黏结转向界面滑移。多轴加载试验进一步揭示，在不同温度梯度与水流剪切应力耦合作用下，浆体层内发生黏弹性-塑性转变，其应力-应变关系不再线性，需引入变形时效与温度响应项进行多参数修正。\n为提升注浆体在复杂环境下的适应性，一种新型多尺度增强方法被提出，采用纳米硅灰、聚乙烯醇纤维与碳纳米管协同掺杂策略，可显著提升浆体的抗冲散临界流速、界面黏结强度及后期干湿循环下的体积稳定性。该体系在高温循环20次后仍保持超过85%的未扰动抗压强度，并在模拟动水渗透试验中表现出低于10⁻⁷ cm/s的长期渗透系数，有效满足封堵型注浆工程的稳定性要求。\n为了系统评估注浆材料在热-水-应力条件下的适应性与可靠性，需建立多维度测试方法体系。常用测试方法包括但不限于：\n流变性能测试：采用旋转流变仪（如HAAKE RheoStress）在不同温度和剪切速率下测定黏度-剪切应力关系曲线，提取屈服应力与表观黏度；\n抗冲散性测试：利用动水槽或旋转剪切装置（参考中国工程建设标准CECS 513）模拟不同水流速下的流失行为，测定抗分散起始流速与流失质量比；\n界面黏结测试：通过直剪仪或劈拉试验评估浆体与岩体/混凝土界面结合强度，分析剪切滑移段能量释放情况；\n微观结构分析：结合XRD、SEM、MIP及CT等方法，揭示浆体水化产物类型、孔隙结构演化及热损伤微裂隙分布；\n热性能测试：采用热常数分析仪（如Hot Disk法）测定浆体不同龄期下的导热系数、比热容等参数；\n模拟服役试验：构建封闭高温–流动水–应力三维模拟腔，开展长期渗透–温升–剪切循环加载实验，评价材料稳定性和性能劣化趋势。\n在服役适应性方面，复合浆体还需满足以下要求：（1）在多次热循环中维持体积稳定性，避免微裂隙扩展或孔隙结构坍塌；（2）在长时间动水冲蚀下保持界面稳定性与渗透性控制；（3）在复杂水化路径影响下依然具备良好的反应完整性与后期强度增长潜力。\n特别是在深部隧洞、边坡支护或储能库区等典型高温水域，封堵型注浆材料应体现“快凝–抗流失–稳性能–可调控”的综合特征。材料配方可通过以下策略进一步优化：（1）引入晶种辅助水化，控制初期析晶行为；（2）掺加有机-无机复合缓凝剂调节热促反应速率；（3）通过界面活性剂或功能颗粒强化浆岩界面结合区；（4）优化粒径分布与颗粒级配以提升浆液稳定性与微结构密实度。\n此外，服役性能模拟还应考虑注浆体老化行为，如高温下碳酸化、溶解蚀变及界面再析晶等问题。通过长期暴露试验及CT动态跟踪，可揭示材料在复杂服役条件下的失效机制，从而为工程参数选取与配方优化提供科学支撑。\n整体来看，高地温动水环境下的注浆材料需综合考虑流变稳定性、界面黏结性、热稳定性与微观结构演化机制，其设计不再仅限于材料物性层面，更应从系统耦合过程、界面相互作用及服役行为预测等多维度进行优化设计。",
    "ori_text": "\n\n在高地温与动水扰动共同作用的岩体注浆过程中，浆液的扩散行为不仅受控于材料本身的流变特性，还与围岩孔隙结构、渗流状态和热-流-固耦合过程密切相关。由于注浆区位于高温水循环发育带，地层中含水层与微裂隙网络交错分布，在高温梯度与高水压联合驱动下，浆液的流动呈现非线性穿透与波动扩散特征，明显不同于常温条件下的达西型渗流模式。\n注浆材料方面，传统水泥基材料在高温环境下易出现早凝、抗冲散性下降及与围岩界面结合力弱化等问题，难以满足热扰动隧洞或深部裂隙封堵的工程需求。近年来，基于硫铝酸盐水泥（CSA）与地聚物的复合体系显示出在高地温注浆工程中的潜在优势，表现为良好的热稳定性、低黏度下的快速凝结能力及优异的抗冲散性。试验结果表明，随着环境温度升高至90℃以上，CSA-地聚物复合浆液在剪切速率超过50 s⁻¹后仍保持适度的塑性流动性，其初始凝结时间控制在15分钟以内，而在动水条件下的抗分散半径显著小于普通水泥浆液。\n从反应机制角度分析，CSA-地聚物复合注浆材料的强度来源主要包括三种路径：（1）CSA组分在高温水环境中快速水化，形成大量的钙矾石（ettringite）与铝酸钙水合物（C-A-H）；（2）地聚物体系在激发剂（如氢氧化钠、硅酸钠）作用下发生溶出-聚合反应，生成以N-A-S-H为主的凝胶相，并在高温作用下形成三维交联结构；（3）二者之间发生协同水化或共聚反应，形成含钠-钙-铝硅四元复合胶体，提升浆体的致密性与热稳定性。\n尤其在高地温条件下，硅铝源溶解速率明显加快，有助于早期强度形成；同时，水化放热过程的热峰前移、强度增长速率提升，需特别控制反应速率与放热曲线，避免浆体快速失水导致开裂。测试表明，浆液在90℃热浴中养护6小时后，其等效28天抗压强度可达到常温下养护3天的水平。\n在材料-环境交互过程中，浆液与高温水体接触会导致体系内自由水加速逸散、浆体离子浓度快速变化，进而影响凝胶结构的形成与空间网络的构建。这一过程中的界面演化表现为：早期形成的钙矾石与水铝石类水化产物在高温下易产生相变或晶型重构，从而影响浆岩界面层的致密度和剪切结合力。此外，高温环境还促进离子迁移速率，造成溶胶-凝胶相转化区的边界模糊，进而影响后期浆体力学性能的均质性。\n注浆体在固化过程中的热传导行为也是决定其最终工程性能的关键因素之一。实际观测发现，CSA-地聚物浆体的导热系数在40–120℃区间呈非线性变化趋势，主要受其孔隙结构、毛细水蒸发速率以及水化产物热物性差异影响。微观分析显示，随着高温作用时间延长，浆体内部出现明显的微裂隙重构现象，导致热响应不均并产生局部热应力集中，可能引发注浆区的局部失稳。\n从界面破坏试验来看，高温-动水复合作用下，浆岩结合面表现出明显的黏聚力退化与界面粗糙度劣化趋势，破坏模式逐步由剪切黏结转向界面滑移。多轴加载试验进一步揭示，在不同温度梯度与水流剪切应力耦合作用下，浆体层内发生黏弹性-塑性转变，其应力-应变关系不再线性，需引入变形时效与温度响应项进行多参数修正。\n为提升注浆体在复杂环境下的适应性，一种新型多尺度增强方法被提出，采用纳米硅灰、聚乙烯醇纤维与碳纳米管协同掺杂策略，可显著提升浆体的抗冲散临界流速、界面黏结强度及后期干湿循环下的体积稳定性。该体系在高温循环20次后仍保持超过85%的未扰动抗压强度，并在模拟动水渗透试验中表现出低于10⁻⁷ cm/s的长期渗透系数，有效满足封堵型注浆工程的稳定性要求。\n为了系统评估注浆材料在热-水-应力条件下的适应性与可靠性，需建立多维度测试方法体系。常用测试方法包括但不限于：\n流变性能测试：采用旋转流变仪（如HAAKE RheoStress）在不同温度和剪切速率下测定黏度-剪切应力关系曲线，提取屈服应力与表观黏度；\n抗冲散性测试：利用动水槽或旋转剪切装置（参考中国工程建设标准CECS 513）模拟不同水流速下的流失行为，测定抗分散起始流速与流失质量比；\n界面黏结测试：通过直剪仪或劈拉试验评估浆体与岩体/混凝土界面结合强度，分析剪切滑移段能量释放情况；\n微观结构分析：结合XRD、SEM、MIP及CT等方法，揭示浆体水化产物类型、孔隙结构演化及热损伤微裂隙分布；\n热性能测试：采用热常数分析仪（如Hot Disk法）测定浆体不同龄期下的导热系数、比热容等参数；\n模拟服役试验：构建封闭高温–流动水–应力三维模拟腔，开展长期渗透–温升–剪切循环加载实验，评价材料稳定性和性能劣化趋势。\n在服役适应性方面，复合浆体还需满足以下要求：（1）在多次热循环中维持体积稳定性，避免微裂隙扩展或孔隙结构坍塌；（2）在长时间动水冲蚀下保持界面稳定性与渗透性控制；（3）在复杂水化路径影响下依然具备良好的反应完整性与后期强度增长潜力。\n特别是在深部隧洞、边坡支护或储能库区等典型高温水域，封堵型注浆材料应体现“快凝–抗流失–稳性能–可调控”的综合特征。材料配方可通过以下策略进一步优化：（1）引入晶种辅助水化，控制初期析晶行为；（2）掺加有机-无机复合缓凝剂调节热促反应速率；（3）通过界面活性剂或功能颗粒强化浆岩界面结合区；（4）优化粒径分布与颗粒级配以提升浆液稳定性与微结构密实度。\n此外，服役性能模拟还应考虑注浆体老化行为，如高温下碳酸化、溶解蚀变及界面再析晶等问题。通过长期暴露试验及CT动态跟踪，可揭示材料在复杂服役条件下的失效机制，从而为工程参数选取与配方优化提供科学支撑。\n整体来看，高地温动水环境下的注浆材料需综合考虑流变稳定性、界面黏结性、热稳定性与微观结构演化机制，其设计不再仅限于材料物性层面，更应从系统耦合过程、界面相互作用及服役行为预测等多维度进行优化设计。",
    "reference_list": "考点1：“热-流-固耦合过程” 应该翻译为 “thermal–hydraulic–mechanical (THM) coupling process”或者“thermo-hydro-mechanical (THM) coupling process””\n考点2：“热峰” 只能翻译为 “thermal peak ”或“exothermic peak”，不能翻译为“heat peak”，因为这表示的是热能外放的过程，译文二者取其一即可，保持译文一致性\n考点3：“系统耦合过程” 应该翻译为 “thermal–hydraulic–mechanical coupling process” 或 “thermo-hydro-mechanical coupling process”，因为这是对前文的一个总结性说法，应该还原成原本含义。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "157"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n三、地方高校“新工科专业建设的经验——以浙江为例 \n这一轮“新工科”建设，为地方院校整合教育资源、加强特色办学和提高办学质量提供了机遇。如浙江省教育厅真正落实了“新工科”背景下的产业需求导向，开辟了政产学研合作协同育人的建设途径，全面推进了新时代浙江省高校工科教育改革及创新，为全国“新工科”建设提供了浙江样本和浙江元素。\n “浙八味”是一个中医药领域的概念，是指白术、白芍、浙贝母、杭白菊、元胡、玄参、笕麦冬、温郁金等八味浙江地区出产的中药材。2017年6月1日，浙江省本科高校专业认证暨新工科建设研讨会上发布了《浙江省新工科建设行动八条方案》(以下简称“新浙八味”)，包括建设行业特色学院、建设工科优势特色专业、建设工科核心课程和通识课程、实施工科院系与行业企业人员互聘“双千计划”、实施产学合作协同育人项目、建设一批协同创新中心、建设一批大学生学科竞赛品牌、培育若干新工科建设示范点等八条指导性的政策目标。“新浙八味”的提出，为浙江省高校的“新工科”建设提供了行动指南。三年来，不少浙江高校已在“新工科”专业建设和人才培养方面取得了宝贵的实践经验。\n 1.z大学：以学科交叉为特色，开设“新工科”课程群 z大学是浙江省的一所重点综合性大学，在传统工科专业上具有深厚的历史积累，其“新工科”建设对于浙江省高校具有示范作用。Z大学以美国斯坦福大学为学习对象，斯坦福和硅谷的关系与Z大学和杭州的关系较为相似，Z大学也提出“新工科”专业建设要与杭州和浙江的发展相结合，相得益彰。陆国栋(2017)介绍过z大学在新工科建设方面的五大探索，包括3个双学位班、贯通本研的工程师学院、激发师生激情的学生评价模式改革以及校企协同的“千生计划”等。\n 在专业建设方面，z大学根据新时代科技发展的最新趋势，创新“新工科”建设的理念，以学科交叉为特色，开创了“机器人+人工智能”“金融+数学”“计算机+大数据”等三个双学位班。自2016年以后，已招收本科生300多人，培养模式得到学生、家长、企业和专家的高度认同。在新专业开设上，Z大学比较谨慎，但在开设新课程上却是步伐很大。例如，该校的计算机学院开始上区块链、大数据、物联网的课程，但并非独立设置专业，而是通过加强新课程，让学生受到更多的训练。Z大学接下来计划开设区块链、大数据、云计算、人工智能等一大批课程群，能够把本科和研究生打通。同时，也会发挥各工科类学院和产业界结合的优势，邀请一批优秀的产业界专家来校授课。 \n2.H大学：围绕核心优势，开设复合型“新工科”专业 H大学是浙江省一所以电子科技为特色的省属重点大学。该校申报的《浙江省地方高校多学科交叉的复合型新工科专业建设与实践》为教育部发布的612个首批“新工科”研究与实践项目之一。面对以“互联网+”为主导的新兴信息产业转型，而H大学工科专业里70%的专业与产业相关， 因此“新工科”专业建设既是机遇也是挑战。面对传统IT专业升级换代、传统工科专业智能化、非工科专业信息化等三大问题，H大学着力强化IT专业的特色。首先，H大学考虑在未来两年内，计划要停招11个本科专业，其中，包括信息工程等。由于H大学在IT领域里专业很多，有些专业名称很相似，例如，电子科学与技术、电子信息科学与技术、电子信息工程，在实际人才培养过程中定位并不是很清晰，因此有必要进行裁撤或合并。其次，高校现在面向的很多行业需求单靠一个学科是无法满足的，所以H大学现在申请的“新工科”专业都是复合型专业。H大学正在升级尝试的一个复合型专业是“会计+计算机”，也叫“云会计”，培养的“云会计”人才只需要面对用户、根据需求设计财务规则即可，能够优化传统的财务人员工作流程和提升工作效率。除了“云会计”以外，H大学还新开设了智能科学与技术专业，该专业主要的应用领域是机器人，这个专业仅靠H大学自动化学院无法办成，因此H大学成立了交叉教学组织，可以通过这个组织吸引计算机、电子、机械等多个学院来为智能科学与技术专业的发展提供资源支撑。",
    "ori_text": "三、地方高校“新工科专业建设的经验——以浙江为例 \n这一轮“新工科”建设，为地方院校整合教育资源、加强特色办学和提高办学质量提供了机遇。如浙江省教育厅真正落实了“新工科”背景下的产业需求导向，开辟了政产学研合作协同育人的建设途径，全面推进了新时代浙江省高校工科教育改革及创新，为全国“新工科”建设提供了浙江样本和浙江元素。\n “浙八味”是一个中医药领域的概念，是指白术、白芍、浙贝母、杭白菊、元胡、玄参、笕麦冬、温郁金等八味浙江地区出产的中药材。2017年6月1日，浙江省本科高校专业认证暨新工科建设研讨会上发布了《浙江省新工科建设行动八条方案》(以下简称“新浙八味”)，包括建设行业特色学院、建设工科优势特色专业、建设工科核心课程和通识课程、实施工科院系与行业企业人员互聘“双千计划”、实施产学合作协同育人项目、建设一批协同创新中心、建设一批大学生学科竞赛品牌、培育若干新工科建设示范点等八条指导性的政策目标。“新浙八味”的提出，为浙江省高校的“新工科”建设提供了行动指南。三年来，不少浙江高校已在“新工科”专业建设和人才培养方面取得了宝贵的实践经验。\n 1.z大学：以学科交叉为特色，开设“新工科”课程群 z大学是浙江省的一所重点综合性大学，在传统工科专业上具有深厚的历史积累，其“新工科”建设对于浙江省高校具有示范作用。Z大学以美国斯坦福大学为学习对象，斯坦福和硅谷的关系与Z大学和杭州的关系较为相似，Z大学也提出“新工科”专业建设要与杭州和浙江的发展相结合，相得益彰。陆国栋(2017)介绍过z大学在新工科建设方面的五大探索，包括3个双学位班、贯通本研的工程师学院、激发师生激情的学生评价模式改革以及校企协同的“千生计划”等。\n 在专业建设方面，z大学根据新时代科技发展的最新趋势，创新“新工科”建设的理念，以学科交叉为特色，开创了“机器人+人工智能”“金融+数学”“计算机+大数据”等三个双学位班。自2016年以后，已招收本科生300多人，培养模式得到学生、家长、企业和专家的高度认同。在新专业开设上，Z大学比较谨慎，但在开设新课程上却是步伐很大。例如，该校的计算机学院开始上区块链、大数据、物联网的课程，但并非独立设置专业，而是通过加强新课程，让学生受到更多的训练。Z大学接下来计划开设区块链、大数据、云计算、人工智能等一大批课程群，能够把本科和研究生打通。同时，也会发挥各工科类学院和产业界结合的优势，邀请一批优秀的产业界专家来校授课。 \n2.H大学：围绕核心优势，开设复合型“新工科”专业 H大学是浙江省一所以电子科技为特色的省属重点大学。该校申报的《浙江省地方高校多学科交叉的复合型新工科专业建设与实践》为教育部发布的612个首批“新工科”研究与实践项目之一。面对以“互联网+”为主导的新兴信息产业转型，而H大学工科专业里70%的专业与产业相关， 因此“新工科”专业建设既是机遇也是挑战。面对传统IT专业升级换代、传统工科专业智能化、非工科专业信息化等三大问题，H大学着力强化IT专业的特色。首先，H大学考虑在未来两年内，计划要停招11个本科专业，其中，包括信息工程等。由于H大学在IT领域里专业很多，有些专业名称很相似，例如，电子科学与技术、电子信息科学与技术、电子信息工程，在实际人才培养过程中定位并不是很清晰，因此有必要进行裁撤或合并。其次，高校现在面向的很多行业需求单靠一个学科是无法满足的，所以H大学现在申请的“新工科”专业都是复合型专业。H大学正在升级尝试的一个复合型专业是“会计+计算机”，也叫“云会计”，培养的“云会计”人才只需要面对用户、根据需求设计财务规则即可，能够优化传统的财务人员工作流程和提升工作效率。除了“云会计”以外，H大学还新开设了智能科学与技术专业，该专业主要的应用领域是机器人，这个专业仅靠H大学自动化学院无法办成，因此H大学成立了交叉教学组织，可以通过这个组织吸引计算机、电子、机械等多个学院来为智能科学与技术专业的发展提供资源支撑。",
    "reference_list": "考点 1：\"新工科\" 应译为 \"emerging engineering disciplines\"\n考点 2：\"地方高校\" 应译为 \"local universities\"\n考点 3：\"政产学研合作协同育人\" 应译为 \"government-industry-academia-research collaborative education\"\n考点 4：\"浙八味\" 应译为 \"Eight Zhejiang Flavors\"\n考点 5：\"浙江省本科高校专业认证暨新工科建设研讨会\" 应译为 \"Zhejiang Undergraduate Program Accreditation and Emerging Engineering Disciplines Construction Seminar\"\n考点 6：\"浙江省新工科建设行动八条方案\" 应译为 \"Eight-Point Action Plan for Zhejiang Emerging Engineering Disciplines Construction\"\n考点 7：\"新浙八味\" 应译为 \"New Eight Zhejiang Flavors\"\n考点 8：\"行业特色学院\" 应译为 \"industry-specific colleges\"\n考点 9：\"工科优势特色专业\" 应译为 \"advantageous engineering programs\"\n考点 10：\"工科核心课程\" 应译为 \"core engineering courses\"\n考点 11：\"双千计划\" 应译为 \"Dual Thousand Talents Program\"\n考点 12：\"产学合作协同育人项目\" 应译为 \"industry-academia collaborative education projects\"\n考点 13：\"协同创新中心\" 应译为 \"collaborative innovation centers\"\n考点 13：\"大学生学科竞赛品牌\" 应译为 \"student discipline competition brands\"\n考点 14：\"新工科建设示范点\" 应译为 \"demonstration sites for emerging engineering disciplines\"\n考点 15：\"Z 大学\" 应译为 \"Z University\"\n考点 16：\"工程师学院\" 应译为 \"School of Engineering\"\n考点 17：\"复合型专业\" 应译为 \"compound/interdisciplinary programs\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "83"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n病因\n\n心肌血流量减少而使心肌缺氧是心绞痛的主要病因，导致心肌血流减少的最常见原因是冠状动脉疾病。\n发病原因\n血液中的脂质成分沉积在冠状动脉血管壁上，形成动脉粥样硬化斑块，是导致动脉管腔狭窄、心肌供血供氧不足是心绞痛的主要病因。\n诱发因素\n稳定型心绞痛\n稳定型心绞痛通常由体力劳动引发。在爬楼梯，运动或走路时，心脏需要更多血液，而血管动脉粥样硬化变窄时，心肌无法获得足够的血液，因此发生心绞痛。除了身体活动外，其他因素如情绪波动、寒冷和暴饮暴食等也会使心率增快，心肌耗氧增多，引发心绞痛。\n不稳定型心绞痛\n大多数没有明显诱因，即使在休息时也可发生。少部分有诱因，如感染、甲亢等导致心肌耗氧量增加，低血压导致冠状动脉血流量减少，贫血和低氧血症导致血液携氧能力下降。\n变异型心绞痛\n由冠状动脉痉挛引起的，表现为冠状动脉暂时性变窄，从而减少心脏血流量，导致胸痛。吸烟、喝酒和吸毒均为重要诱发因素。\n\n症状\n心绞痛以发作性疼痛为主要临床表现，多表现为胸部压榨性疼痛，主要位于胸骨后，可放射至心前区、上肢、下颌咽喉部，也有些患者仅表现为胸闷。\n典型症状\n加拿大心血管病学会（CCS）把心绞痛严重度分为四级。\nⅠ级：一般体力活动（如步行和登楼）不受限，仅在强、快或持续用力时发生心绞痛。\nⅡ级：一般体力活动轻度受限。快步、饭后、寒冷、精神刺激或醒后数小时内发生心绞痛。一般情况下平地步行200m以上或登楼一层以上受限。\nⅢ级：一般体力活动明显受限，一般情况下平地步行200m内或登楼一层引起心绞痛。\nⅣ级：轻微活动或休息时即可发生心绞痛。\n根据不同的疾病类型又表现出不同的疾病症状。\n稳定型心绞痛\n患者常在体力活动或情绪激动时，出现压迫、发闷或紧缩性胸痛，主要在胸骨后，可波及整个心前区，可伴烧灼感，持续数分钟，休息或舌下含服硝酸甘油等硝酸酯类药物后能在几分钟内缓解。\n不稳定型心绞痛\n患者胸部不适的部位及性质与稳定型心绞痛相似，但通常程度更重，持续时间更长，可达半小时至一小时，胸痛可在安静或睡眠中发生，休息或舌下含服硝酸甘油后症状缓解不明显。\n变异型心绞痛\n主要表现为安静状态下的心前区疼痛，无活动或情绪激动等诱因，可伴心律失常及晕厥。\n伴随症状\n发作时可伴有胸闷、出汗、恶心、呕吐、心悸或呼吸困难等症状。\n就医\n\n对于疑似心绞痛发作的患者，如果症状持续几分钟不缓解，在休息或舌下含服硝酸甘油后疼痛也不消失，应立即拨打急救电话寻求帮助。除非救护车无法到达，否则不要自行驾车前往医院。等待救护车到来期间采取卧位或半卧位休息。\n医生可根据患者病史、体格检查、心电图、超声心动图、CT等相关检查，对患者病情初步判断，并制定相关的治疗方案。\n发作典型者：根据发作特点和体征，结合年龄和高危因素，在排除其他原因所致的心绞痛后，一般即可确诊。心电图无改变的患者可考虑做运动负荷试验。\n发作不典型者：要观察硝酸甘油的疗效和发作时心电图的改变进行诊断。如仍不能确诊，可多次复查心电图、心电图负荷试验或24小时动态心电图连续监测，如心电图出现阳性变化或负荷试验诱发心绞痛时亦可确诊。\n就诊科室\n急诊科、胸痛门诊（中心）、心内科、心外科。\n相关检查\n心电图检查\n心电图是诊断心肌缺血的最常用的无创性检查，静息时心电图在正常范围内的患者，不能排除心肌缺血，可考虑进行动态心电图记录和（或）运动负荷试验。\n心电图负荷试验\n亦称心电图运动负荷试验，是通过一定量的运动增加心脏负荷，观察心电图变化以及有无心绞痛发作。运动方式主要有迎着转动的平板就地踏步和踏车。\n心电图连续动态监测\n连续记录24小时或更长时间心电活动的全过程，包括休息、活动、进餐、工作、学习和睡眠等不同情况下的心电图资料。\n超声心动图\n医生可以根据超声心动图来发现与心绞痛相关的问题，包括心肌区域是否因长时间缺血而受损。\n胸部X光片\n该检查拍摄心脏和肺部的图像。这是为了寻找可能解释心绞痛症状的其他原因，并检查是否有扩大的心脏和肺淤血等。检查时应除去有金属性物质的衣物、饰品，拍摄时要处于深吸气的静止状态。\n核素心肌显像及负荷试验\n核压力测试有助于测量静息和压力期间心肌的血流量。它类似于常规压力测试，但在核应力测试期间，放射性物质被注入血液中。心脏供血不足的部位会在图像上显示为灌注缺损，可明确静息和运动时有无心肌缺血。检查前根据医生意见调整平时所服药物，测试前避免饮水进食，检查前24小时避免进食任何含有咖啡因的东西。\n血液指标检查\n包括肌钙蛋白、心肌酶等，因为这些指标在心肌坏死时都会发生相应变化。\n冠状动脉增强CT\n这是一种无创性检查，主要判断患者是否存在冠状动脉狭窄。主要适用于症状不典型的可疑冠心病的患者。检查前正常休息和饮食，检查过程中因造影剂注入体内可能会有全身发热的感觉，不要紧张和惊慌，以免干扰检查结果。心功能正常的患者，检查后应大量饮水，有助于将造影剂排出体外。\n冠状动脉造影\n该检查为有创性检查，可以准确反映冠状动脉狭窄的程度和部位，目前是诊断冠状动脉病变并指导治疗方案选择的黄金标准。做该项检查后，心功能正常者应大量饮水，帮助将造影剂排出体外。\n\n",
    "ori_text": "\n\n病因\n\n心肌血流量减少而使心肌缺氧是心绞痛的主要病因，导致心肌血流减少的最常见原因是冠状动脉疾病。\n发病原因\n血液中的脂质成分沉积在冠状动脉血管壁上，形成动脉粥样硬化斑块，是导致动脉管腔狭窄、心肌供血供氧不足是心绞痛的主要病因。\n诱发因素\n稳定型心绞痛\n稳定型心绞痛通常由体力劳动引发。在爬楼梯，运动或走路时，心脏需要更多血液，而血管动脉粥样硬化变窄时，心肌无法获得足够的血液，因此发生心绞痛。除了身体活动外，其他因素如情绪波动、寒冷和暴饮暴食等也会使心率增快，心肌耗氧增多，引发心绞痛。\n不稳定型心绞痛\n大多数没有明显诱因，即使在休息时也可发生。少部分有诱因，如感染、甲亢等导致心肌耗氧量增加，低血压导致冠状动脉血流量减少，贫血和低氧血症导致血液携氧能力下降。\n变异型心绞痛\n由冠状动脉痉挛引起的，表现为冠状动脉暂时性变窄，从而减少心脏血流量，导致胸痛。吸烟、喝酒和吸毒均为重要诱发因素。\n\n症状\n心绞痛以发作性疼痛为主要临床表现，多表现为胸部压榨性疼痛，主要位于胸骨后，可放射至心前区、上肢、下颌咽喉部，也有些患者仅表现为胸闷。\n典型症状\n加拿大心血管病学会（CCS）把心绞痛严重度分为四级。\nⅠ级：一般体力活动（如步行和登楼）不受限，仅在强、快或持续用力时发生心绞痛。\nⅡ级：一般体力活动轻度受限。快步、饭后、寒冷、精神刺激或醒后数小时内发生心绞痛。一般情况下平地步行200m以上或登楼一层以上受限。\nⅢ级：一般体力活动明显受限，一般情况下平地步行200m内或登楼一层引起心绞痛。\nⅣ级：轻微活动或休息时即可发生心绞痛。\n根据不同的疾病类型又表现出不同的疾病症状。\n稳定型心绞痛\n患者常在体力活动或情绪激动时，出现压迫、发闷或紧缩性胸痛，主要在胸骨后，可波及整个心前区，可伴烧灼感，持续数分钟，休息或舌下含服硝酸甘油等硝酸酯类药物后能在几分钟内缓解。\n不稳定型心绞痛\n患者胸部不适的部位及性质与稳定型心绞痛相似，但通常程度更重，持续时间更长，可达半小时至一小时，胸痛可在安静或睡眠中发生，休息或舌下含服硝酸甘油后症状缓解不明显。\n变异型心绞痛\n主要表现为安静状态下的心前区疼痛，无活动或情绪激动等诱因，可伴心律失常及晕厥。\n伴随症状\n发作时可伴有胸闷、出汗、恶心、呕吐、心悸或呼吸困难等症状。\n就医\n\n对于疑似心绞痛发作的患者，如果症状持续几分钟不缓解，在休息或舌下含服硝酸甘油后疼痛也不消失，应立即拨打急救电话寻求帮助。除非救护车无法到达，否则不要自行驾车前往医院。等待救护车到来期间采取卧位或半卧位休息。\n医生可根据患者病史、体格检查、心电图、超声心动图、CT等相关检查，对患者病情初步判断，并制定相关的治疗方案。\n发作典型者：根据发作特点和体征，结合年龄和高危因素，在排除其他原因所致的心绞痛后，一般即可确诊。心电图无改变的患者可考虑做运动负荷试验。\n发作不典型者：要观察硝酸甘油的疗效和发作时心电图的改变进行诊断。如仍不能确诊，可多次复查心电图、心电图负荷试验或24小时动态心电图连续监测，如心电图出现阳性变化或负荷试验诱发心绞痛时亦可确诊。\n就诊科室\n急诊科、胸痛门诊（中心）、心内科、心外科。\n相关检查\n心电图检查\n心电图是诊断心肌缺血的最常用的无创性检查，静息时心电图在正常范围内的患者，不能排除心肌缺血，可考虑进行动态心电图记录和（或）运动负荷试验。\n心电图负荷试验\n亦称心电图运动负荷试验，是通过一定量的运动增加心脏负荷，观察心电图变化以及有无心绞痛发作。运动方式主要有迎着转动的平板就地踏步和踏车。\n心电图连续动态监测\n连续记录24小时或更长时间心电活动的全过程，包括休息、活动、进餐、工作、学习和睡眠等不同情况下的心电图资料。\n超声心动图\n医生可以根据超声心动图来发现与心绞痛相关的问题，包括心肌区域是否因长时间缺血而受损。\n胸部X光片\n该检查拍摄心脏和肺部的图像。这是为了寻找可能解释心绞痛症状的其他原因，并检查是否有扩大的心脏和肺淤血等。检查时应除去有金属性物质的衣物、饰品，拍摄时要处于深吸气的静止状态。\n核素心肌显像及负荷试验\n核压力测试有助于测量静息和压力期间心肌的血流量。它类似于常规压力测试，但在核应力测试期间，放射性物质被注入血液中。心脏供血不足的部位会在图像上显示为灌注缺损，可明确静息和运动时有无心肌缺血。检查前根据医生意见调整平时所服药物，测试前避免饮水进食，检查前24小时避免进食任何含有咖啡因的东西。\n血液指标检查\n包括肌钙蛋白、心肌酶等，因为这些指标在心肌坏死时都会发生相应变化。\n冠状动脉增强CT\n这是一种无创性检查，主要判断患者是否存在冠状动脉狭窄。主要适用于症状不典型的可疑冠心病的患者。检查前正常休息和饮食，检查过程中因造影剂注入体内可能会有全身发热的感觉，不要紧张和惊慌，以免干扰检查结果。心功能正常的患者，检查后应大量饮水，有助于将造影剂排出体外。\n冠状动脉造影\n该检查为有创性检查，可以准确反映冠状动脉狭窄的程度和部位，目前是诊断冠状动脉病变并指导治疗方案选择的黄金标准。做该项检查后，心功能正常者应大量饮水，帮助将造影剂排出体外。\n\n",
    "reference_list": "考点1：“冠状动脉疾病”必须译为 Coronary Artery Disease，常用缩写 CAD，首次出现时应给出全称与缩写，全文统一。\n考点2：“稳定型心绞痛”必须译为 Stable Angina Pectoris。\n考点3：“不稳定型心绞痛”必须译为 Unstable Angina Pectoris。\n考点4：“变异型心绞痛”必须译为 Variant Angina 或 Prinzmetal’s Angina。\n考点5：“胸骨后疼痛”推荐译为 Retrosternal Pain。\n考点6：“舌下含服硝酸甘油”推荐译为 Sublingual Nitroglycerin Administration。\n考点7：“心电图负荷试验”推荐译为 Exercise Stress Test 或 Electrocardiographic Stress Test。\n考点8：“动态心电图”推荐译为 Ambulatory Electrocardiogram 或 Holter Monitoring。\n考点9：“核素心肌显像”推荐译为 Nuclear Myocardial Perfusion Imaging 或 Nuclear Cardiac Scan。\n考点10：核素心肌显像 必须译为 Nuclear Myocardial Perfusion Imaging，不能遗漏 “perfusion”。\n考点11：活动耐量限制的表述应准确传达触发条件，如 “walking more than 200m is limited” 应改为 “limitation occurs when walking more than 200m”。\n考点12：少数情况应译为 “A Minority of Cases Are…” 或 “In a Minority of Cases, …”，避免直接用 “Minority” 作主语。\n考点13：医学影像中避免使用 “shooting”，推荐译为 “during exposure” 或 “while the image is being taken”。\n考点14：跑步机运动应译为 Walking on a Treadmill，避免使用错误构造如 “rotating treadmill”。\n考点15：胸片拍摄体位的表达应符合临床指令习惯，推荐译为 “hold breath after deep inhalation”。",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "食品健康",
    "prompt_id": "111"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nIn an era characterized by rapid digitization and the proliferation of online communication platforms, vast amounts of textual data are generated daily. While the proliferation of online communication provides rich insights, extracting meaning from vast textual data remains resource intensive. Latent content analysis, which involves decoding the underlying meanings, sentiments, and nuances in text, is crucial for understanding social dynamics, informing policy decisions, and guiding business strategies. Automating this process could significantly enhance our ability to respond to societal needs promptly and effectively.\nThe societal implications of effectively analyzing textual content are profound. Sentiment analysis can reveal public opinion on policies or products, influencing governmental decisions and corporate strategies. Understanding political leanings aids in assessing electoral landscapes and fostering democratic engagement. Detecting emotional intensity and sarcasm in communication is vital for mental health monitoring, customer service, and even national security. Large Language Models (LLMs) offer the potential to perform these analyses at scale, reducing reliance on extensive human labor and accelerating the time to insight.\nThe field of automated content analysis has evolved significantly over the past few decades. Early computational approaches relied on manual coding schemes applied to small datasets. The advent of machine learning introduced algorithms capable of handling larger datasets with increased efficiency. Traditional models, such as Naïve Bayes and Support Vector Machines, were used for tasks like sentiment classification but often struggled with contextual understanding.\nThe introduction of deep learning architectures marked a transformative period in natural language processing (NLP). Models utilizing word embeddings captured semantic relationships between words. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks improved the modeling of sequential data. These advancements enhanced performance in sentiment analysis and emotion detection tasks.\nRecent research has also explored integrating multi-modal data (e.g., text with images or audio) to enhance sentiment and effect detection, a challenge that LLMs may benefit from addressing. Thareja addressed the challenges posed by extreme emotional sentiments on social media platforms like Twitter, which can impact users’ mental well-being. Introducing Tweet-SentiNet, a multi-modal framework utilizing both image and text embeddings, the study demonstrated improved sentiment analysis by effectively filtering content with extreme sentiments. Similarly, Li et al. proposed a multi-modal sentiment analysis model based on image and text fusion using a cross-attention mechanism. By extracting features using advanced techniques like ALBert for text and DenseNet121 for images, and then fusing them with cross-attention, their model outperformed baseline models on public datasets, achieving accuracy and F1 scores of over 85%. Akhtar et al. explored a deep multi-task contextual attention framework for multi-modal affect analysis. Recognizing that emotions and sentiments are interdependent, they leveraged the associations among neighboring utterances and their multi-modal information.\nRecent approaches broaden the scope of stance detection by integrating knowledge graphs, which help capture political or ideological context in more structured ways. Likewise, boundary-aware frameworks for few‐shot tasks have shown promise in enriching entity‐level interpretations.\nDespite these improvements, models have been found to still face challenges in interpreting complex linguistic features such as sarcasm and nuanced emotions. Sarcasm detection, for instance, requires an understanding of contextual cues and sometimes external knowledge beyond the text itself, leading researchers to explore context-aware and multi-modal approaches to enhance detection accuracy. Baruah et al. investigated the impact of conversational context on sarcasm detection using deep-learning (BERT, BiLSTM) NLP models and ML classifier (SVM). They found that incorporating the last utterance in a dialogue significantly improved classifier performance on Twitter datasets, achieving an F-score of 0.743 with BERT. Exploring the distinction between intended and perceived sarcasm, Oprea and Magdy introduced the iSarcasm dataset, which consists of tweets labeled for sarcasm directly by their authors emphasizing the need for datasets that reflect the intended use of sarcasm to improve detection systems.\nThe introduction of the Transformer architecture and pre-trained language models such as BERT and RoBERTa significantly advanced NLP capabilities. These models utilized attention mechanisms to capture long-range dependencies in text, leading to state-of-the-art results in various tasks.\nBeyond Transformer architectures, emerging methods provide complementary solutions. For example, knowledge-graph‐based architectures can improve stance detection tasks, and boundary‐aware LLM designs are increasingly valuable for few‐shot named entity recognition. Integrating both constituency and dependency parse information has proven beneficial for relation extraction.\nLarge Language Models (LLMs) like GPT-2 and GPT-3 expanded these capabilities by increasing model size and training data. GPT-3, with 175 billion parameters, demonstrated remarkable proficiency in zero-shot and few-shot learning scenarios, performing well on tasks it was not explicitly trained for.\nRecent studies have explored LLMs in sentiment analysis and related tasks. Chang & Bergen investigated the use of GPT-3 for sentiment classification and found that it performed competitively with fine-tuned models on specific datasets. Similarly, Floridi and Chiriatti discussed the potential of GPT-3 in understanding and generating human-like text, highlighting its applicability in content analysis.\nThe incorporation of context-aware mechanisms, consideration of intended versus perceived meanings, and the use of multi-modal data represent critical steps toward improving model performance in complex NLP tasks. The development of domain-specific models like PoliBERTweet highlights the potential benefits of customizing language models to better capture specific content areas, such as political discourse. The integration of symbolic reasoning with deep learning in SenticNet 6 further highlights the importance of combining different AI approaches to enhance understanding and interpretation of subtle linguistic features.\nHowever, challenges remain regarding the ethical and practical implications of relying on LLMs. Concerns include model bias, the interpretability of results, and the tendency of LLMs to produce plausible but incorrect or biased outputs. Additionally, studies have shown that while LLMs excel in language tasks, their performance in detecting sarcasm and nuanced emotions is inconsistent.\nThe consistency of LLMs over time is another area of interest. Although not updated by service providers, models that are prompted on different instances, may produce different outputs on the same input, raising questions about consistency in longitudinal studies. LLMs can be sensitive to input phrasing, leading to different interpretations based on slight changes in wording.\nHuman annotators have long been the gold standard in content analysis due to their ability to understand context, cultural references, and subtle language cues. Inter-rater reliability metrics such as Krippendorff’s alpha are used to assess consistency among human coders. Comparing LLM performance against human benchmarks is essential to evaluate their viability as substitutes or supplements in content analysis tasks.\nWhile Large Language Models (LLMs) have demonstrated impressive capabilities, there is a notable lack of comprehensive evaluations comparing their performance to human annotators across multiple dimensions of latent content analysis. Existing studies often focus on single tasks or lack extensive statistical analysis of reliability and quality. Additionally, the consistency of LLMs over time and their inter-rater reliability in capturing complex linguistic features remain underexplored. To address these gaps this study formulates the following research questions:\nRQ1: How reliably do LLMs compare to human annotators across multiple dimensions of latent content analysis?\nAlthough the field of content analysis has advanced from manual coding schemes, through machine learning introduced algorithms capable of handling larger datasets with increased efficiency, and finally peaked with deep learning architectures, research is still needed especially in interpreting complex linguistic features such as sarcasm and nuanced emotions. On the other hand, other studies show that machines underperform in comparison to humans in certain tasks. One big gap in these studies is the lack of comparison with human annotations – to compare how LLMs and humans annotate complex linguistic features and whether humans are better at these tasks.\nPrevious studies have focused on specific aspects of content analysis, such as sentiment classification and sarcasm detection, but there is limited research on how the level of reliability between LLMs and humans varies across different dimensions. This is another gap to be addressed in this study.\nRQ2: Are LLMs consistent over time when analyzing textual content?\nConsistency over time is another underaddressed issue. Models used in different instances can create different outputs in different instances. LLM outputs can vary due to minor prompt modifications, raising concerns about time consistency.\nRQ3: To what extent do LLMs provide analysis that is comparable to human analysis in terms of quality?\nHuman annotators have long been the gold standard in content analysis due to their ability to understand context, cultural references, and subtle language cues. However, the ability of LLMs to learn from the context is being examined, as well as their ability to produce human-like texts is rising, with an aim to replace human annotators with LLMs. Even though these studies are rising in numbers, quality check studies comparing humans and LLMs are still lacking, and this is another gap to be addressed in this study.\nRQ4: How do inter-rater reliability and comparability vary across different LLM models?\nPrevious studies examined some LLM models’ success in annotation, but usually in one or two tasks, and usually using one or two models in this study we aim to close this gap by including multiple models and multiple tasks, and examine all their inter-rater reliability and consistency. Given the rapid development and diversity of LLM architectures—each trained on varying datasets and employing different model sizes—it’s crucial to understand whether these differences translate into variations in content analysis outcomes.\nTo evaluate the inter-rater reliability and quality of large language models (LLMs) in latent content analysis, we conducted a comparative study involving both humans and eight types of LLMs that each responded to presented queries to evaluate content by assigning values to statements. Our objective was to benchmark the performance of LLMs and humans across four key dimensions: sentiment, political leaning, emotional intensity, and sarcasm detection by performing (a) within (internal consistency) and (b) between analyses (comparison of performance).\nThe ethical approval was acquired from the Ethics Committee prior to this research. All methods were carried out in accordance with relevant guidelines and regulations.",
    "ori_text": "\n\nIn an era characterized by rapid digitization and the proliferation of online communication platforms, vast amounts of textual data are generated daily. While the proliferation of online communication provides rich insights, extracting meaning from vast textual data remains resource intensive. Latent content analysis, which involves decoding the underlying meanings, sentiments, and nuances in text, is crucial for understanding social dynamics, informing policy decisions, and guiding business strategies. Automating this process could significantly enhance our ability to respond to societal needs promptly and effectively.\nThe societal implications of effectively analyzing textual content are profound. Sentiment analysis can reveal public opinion on policies or products, influencing governmental decisions and corporate strategies. Understanding political leanings aids in assessing electoral landscapes and fostering democratic engagement. Detecting emotional intensity and sarcasm in communication is vital for mental health monitoring, customer service, and even national security. Large Language Models (LLMs) offer the potential to perform these analyses at scale, reducing reliance on extensive human labor and accelerating the time to insight.\nThe field of automated content analysis has evolved significantly over the past few decades. Early computational approaches relied on manual coding schemes applied to small datasets. The advent of machine learning introduced algorithms capable of handling larger datasets with increased efficiency. Traditional models, such as Naïve Bayes and Support Vector Machines, were used for tasks like sentiment classification but often struggled with contextual understanding.\nThe introduction of deep learning architectures marked a transformative period in natural language processing (NLP). Models utilizing word embeddings captured semantic relationships between words. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks improved the modeling of sequential data. These advancements enhanced performance in sentiment analysis and emotion detection tasks.\nRecent research has also explored integrating multi-modal data (e.g., text with images or audio) to enhance sentiment and effect detection, a challenge that LLMs may benefit from addressing. Thareja addressed the challenges posed by extreme emotional sentiments on social media platforms like Twitter, which can impact users’ mental well-being. Introducing Tweet-SentiNet, a multi-modal framework utilizing both image and text embeddings, the study demonstrated improved sentiment analysis by effectively filtering content with extreme sentiments. Similarly, Li et al. proposed a multi-modal sentiment analysis model based on image and text fusion using a cross-attention mechanism. By extracting features using advanced techniques like ALBert for text and DenseNet121 for images, and then fusing them with cross-attention, their model outperformed baseline models on public datasets, achieving accuracy and F1 scores of over 85%. Akhtar et al. explored a deep multi-task contextual attention framework for multi-modal affect analysis. Recognizing that emotions and sentiments are interdependent, they leveraged the associations among neighboring utterances and their multi-modal information.\nRecent approaches broaden the scope of stance detection by integrating knowledge graphs, which help capture political or ideological context in more structured ways. Likewise, boundary-aware frameworks for few‐shot tasks have shown promise in enriching entity‐level interpretations.\nDespite these improvements, models have been found to still face challenges in interpreting complex linguistic features such as sarcasm and nuanced emotions. Sarcasm detection, for instance, requires an understanding of contextual cues and sometimes external knowledge beyond the text itself, leading researchers to explore context-aware and multi-modal approaches to enhance detection accuracy. Baruah et al. investigated the impact of conversational context on sarcasm detection using deep-learning (BERT, BiLSTM) NLP models and ML classifier (SVM). They found that incorporating the last utterance in a dialogue significantly improved classifier performance on Twitter datasets, achieving an F-score of 0.743 with BERT. Exploring the distinction between intended and perceived sarcasm, Oprea and Magdy introduced the iSarcasm dataset, which consists of tweets labeled for sarcasm directly by their authors emphasizing the need for datasets that reflect the intended use of sarcasm to improve detection systems.\nThe introduction of the Transformer architecture and pre-trained language models such as BERT and RoBERTa significantly advanced NLP capabilities. These models utilized attention mechanisms to capture long-range dependencies in text, leading to state-of-the-art results in various tasks.\nBeyond Transformer architectures, emerging methods provide complementary solutions. For example, knowledge-graph‐based architectures can improve stance detection tasks, and boundary‐aware LLM designs are increasingly valuable for few‐shot named entity recognition. Integrating both constituency and dependency parse information has proven beneficial for relation extraction.\nLarge Language Models (LLMs) like GPT-2 and GPT-3 expanded these capabilities by increasing model size and training data. GPT-3, with 175 billion parameters, demonstrated remarkable proficiency in zero-shot and few-shot learning scenarios, performing well on tasks it was not explicitly trained for.\nRecent studies have explored LLMs in sentiment analysis and related tasks. Chang & Bergen investigated the use of GPT-3 for sentiment classification and found that it performed competitively with fine-tuned models on specific datasets. Similarly, Floridi and Chiriatti discussed the potential of GPT-3 in understanding and generating human-like text, highlighting its applicability in content analysis.\nThe incorporation of context-aware mechanisms, consideration of intended versus perceived meanings, and the use of multi-modal data represent critical steps toward improving model performance in complex NLP tasks. The development of domain-specific models like PoliBERTweet highlights the potential benefits of customizing language models to better capture specific content areas, such as political discourse. The integration of symbolic reasoning with deep learning in SenticNet 6 further highlights the importance of combining different AI approaches to enhance understanding and interpretation of subtle linguistic features.\nHowever, challenges remain regarding the ethical and practical implications of relying on LLMs. Concerns include model bias, the interpretability of results, and the tendency of LLMs to produce plausible but incorrect or biased outputs. Additionally, studies have shown that while LLMs excel in language tasks, their performance in detecting sarcasm and nuanced emotions is inconsistent.\nThe consistency of LLMs over time is another area of interest. Although not updated by service providers, models that are prompted on different instances, may produce different outputs on the same input, raising questions about consistency in longitudinal studies. LLMs can be sensitive to input phrasing, leading to different interpretations based on slight changes in wording.\nHuman annotators have long been the gold standard in content analysis due to their ability to understand context, cultural references, and subtle language cues. Inter-rater reliability metrics such as Krippendorff’s alpha are used to assess consistency among human coders. Comparing LLM performance against human benchmarks is essential to evaluate their viability as substitutes or supplements in content analysis tasks.\nWhile Large Language Models (LLMs) have demonstrated impressive capabilities, there is a notable lack of comprehensive evaluations comparing their performance to human annotators across multiple dimensions of latent content analysis. Existing studies often focus on single tasks or lack extensive statistical analysis of reliability and quality. Additionally, the consistency of LLMs over time and their inter-rater reliability in capturing complex linguistic features remain underexplored. To address these gaps this study formulates the following research questions:\nRQ1: How reliably do LLMs compare to human annotators across multiple dimensions of latent content analysis?\nAlthough the field of content analysis has advanced from manual coding schemes, through machine learning introduced algorithms capable of handling larger datasets with increased efficiency, and finally peaked with deep learning architectures, research is still needed especially in interpreting complex linguistic features such as sarcasm and nuanced emotions. On the other hand, other studies show that machines underperform in comparison to humans in certain tasks. One big gap in these studies is the lack of comparison with human annotations – to compare how LLMs and humans annotate complex linguistic features and whether humans are better at these tasks.\nPrevious studies have focused on specific aspects of content analysis, such as sentiment classification and sarcasm detection, but there is limited research on how the level of reliability between LLMs and humans varies across different dimensions. This is another gap to be addressed in this study.\nRQ2: Are LLMs consistent over time when analyzing textual content?\nConsistency over time is another underaddressed issue. Models used in different instances can create different outputs in different instances. LLM outputs can vary due to minor prompt modifications, raising concerns about time consistency.\nRQ3: To what extent do LLMs provide analysis that is comparable to human analysis in terms of quality?\nHuman annotators have long been the gold standard in content analysis due to their ability to understand context, cultural references, and subtle language cues. However, the ability of LLMs to learn from the context is being examined, as well as their ability to produce human-like texts is rising, with an aim to replace human annotators with LLMs. Even though these studies are rising in numbers, quality check studies comparing humans and LLMs are still lacking, and this is another gap to be addressed in this study.\nRQ4: How do inter-rater reliability and comparability vary across different LLM models?\nPrevious studies examined some LLM models’ success in annotation, but usually in one or two tasks, and usually using one or two models in this study we aim to close this gap by including multiple models and multiple tasks, and examine all their inter-rater reliability and consistency. Given the rapid development and diversity of LLM architectures—each trained on varying datasets and employing different model sizes—it’s crucial to understand whether these differences translate into variations in content analysis outcomes.\nTo evaluate the inter-rater reliability and quality of large language models (LLMs) in latent content analysis, we conducted a comparative study involving both humans and eight types of LLMs that each responded to presented queries to evaluate content by assigning values to statements. Our objective was to benchmark the performance of LLMs and humans across four key dimensions: sentiment, political leaning, emotional intensity, and sarcasm detection by performing (a) within (internal consistency) and (b) between analyses (comparison of performance).\nThe ethical approval was acquired from the Ethics Committee prior to this research. All methods were carried out in accordance with relevant guidelines and regulations.",
    "reference_list": "考点1：“resource intensive”推荐译为“资源密集型”\n考点2：“societal needs”推荐译为“社会需要/需求”\n考点3：“insight”推荐译为“了解/见解”\n考点4：“benefit”推荐译为“受益于”\n考点5：“inconsistent”推荐译为“时好时坏的”或“不稳定的”\n考点6：\"constituency parse\"推荐译为“组块分析”/“成分句法分析”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "130"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nTalent competitiveness refers to the ability of a country or a region to cultivate, attract, and utilize talent resources for its economic and social development, as demonstrated by its talent strategy, policy, and deployment, thereby contributing to the development of the region or the country [1]. National competitiveness is influenced by higher education and scientific research systems, both of which depend on talent competitiveness. Countries around the world have introduced several talent policies to promote national development. In 2022, the UK’s Research and Innovation Agency (RIA) formulated its Strategy 2022–2027: Changing the Future Together, focusing on building a system of excellence in research and innovation to achieve the goal of becoming a global science and technology powerhouse and an innovation-driven nation [2]. In 2023, the U.S. Federal Government introduced its STEM education plan for the period 2023–2028, which was laid out in four areas including education, social engagement, workforce development, and research & innovation capability, as the key support for the U.S. to maintain its global leadership in science and technology [3]. In China, another major economy in the world, the synergistic development of science, education, and talent is seen as fundamental and strategic for the comprehensive construction of a modern socialist country [4]. In both the West and the East, talent search has been recognized as the most important task over decades [5].\nThe European Institute of Business Administration (hereinafter, INSEAD), established in 1957, is headquartered in Fontainebleau, France, with additional campuses in locations including Singapore and Abu Dhabi. INSEAD’s educational mission is to develop future business leaders with a global perspective, a strong sense of responsibility, and the capacity to drive meaningful impact. The institution offers a diverse portfolio of academic programs, including the MBA program, designed to cultivate senior leadership talent; the Executive MBA (EMBA) program, targeting mid- to senior-level managers; and the PhD program, which focuses on rigorous academic research. In addition to its degree offerings, INSEAD engages in specialized research initiatives led by expert teams that integrate resources from multiple sources to conduct focused academic investigations and produce comprehensive database reports. One such initiative is the Global Talent Competitiveness Index (hereinafter, GTCI) project, which is discussed in detail in the following section.\nTo assess and monitor the landscape of global talent cultivation, INSEAD has taken the lead in launching the GTCI. The GTCI index focuses on the ability of countries or economies to cultivate, attract and retain talent, and has received extensive attention from academics for its comprehensiveness, international comparability, dynamic monitoring capability, and policy guidance. Seminal studies have examined the effectiveness of the GTCI. By analyzing the role of talent in the economic development of various countries and economies, researchers suggest that the GTCI could be used as a competitiveness measurement standard [6] as it assesses a country’s talent competitiveness from a comprehensive and objective perspective [7].\nPioneering research has used the GTCI data to conduct international comparisons. After an in-depth analysis of the G20 countries’ performance in talent competitiveness, researchers found that developed countries are particularly strong in talent competitiveness [8]. Some scholars have also examined the migration status of 25 countries and found a positive correlation between a country’s migration status and its GTCI performance, highlighting the importance of talent competitiveness in driving a country’s development [9]. Moreover, several studies have utilized the GTCI data for dynamic monitoring and analysis: using the European innovation scoreboard, scholars have analyzed the changes in Poland’s GTCI data between 2013 and 2018 and pointed out the challenges for talent management and innovation [10]. These capabilities provide important research insights for policymakers, business leaders, and academic researchers worldwide.\nExtending the aforementioned literature, this study takes GTCI as the key data source and selects G20 countries as the main objects of analysis. In the past, the established literature from the fields of political economy [11], development studies [12], and public policy [13] has carefully sketched the issue of China’s talent competitiveness. However, few studies have compared the talent competitiveness of China with a representative coalition of countries such as the G20, resulting in a lack of international comparative perspective. At the end of the 20th century and the beginning of the 21st century, Chinese scholars had already begun to pay attention to the issue of talent competitiveness and to build China’s assessment system in the foreground [14]. However, as of 2024, there is still no substantial breakthrough drawn on such a comprehensive database as the GTCI database.\nAs of now, the scholarly discussions on the issue of talent competitiveness in Chinese academia focus on two aspects: (a) analyzing talent competition between regions and (b) providing vague suggestions for policy-making without detailed solutions. This is caused by China’s rapid development in the 21st century, which leaves regional competition being the focus of public policy research while talent competitiveness is an accessory. At the same time, there is a research gap between economic advancement and educational development: globalized economic development requires China to have a more developed talent competitiveness system, but the mainstream examination-based education system is not conducive to such development.\nThus, in studies focusing solely on China’s talent competitiveness, there are three research gaps that can be summarized. First, due to the lack of national-level datasets, most of the existing studies are based on individual provinces in China and are not generalizable enough. Second, current Chinese-language research in talent competitiveness mainly focuses on local policy slogans, with relatively broad arguments and a lack of empirical data support. Third, relevant studies in English language still have not proposed a set of systematic, comprehensive evaluation frameworks to measure the competitiveness of talents across the world, which hinders academics from deep diving into talent policies.\nAdditionally, there is an unmet need of highly skilled professionals in China, partly due to the disadvantage of its education system. China’s low attractiveness to talent has also led to a large number of Chinese overseas students being reluctant to return to China and foreign talent being reluctant to enter China [15]. The lack of a scientific evaluation system is not conducive to the updating of talent competitiveness policies at the national level, thus leading to a vicious circle of local talent competitiveness policies.\nGiven this, this research proposes and adopts an original analysis matrix as a multi-dimensional and multi-indicator framework (which we name PEST-embedded SWOT matrix), for assessing talent competitiveness. By comparatively analyzing the performance of different countries in terms of talent competitiveness, this investigation aims to accurately grasp China’s position and posture in the global talent competition, thereby putting forward targeted improvement paths and policy recommendations in terms of talent cultivation, attraction, and utilization. We aimed to conduct a comprehensive literature analysis and introduce an analytical matrix to extract the indicators embedded in the GTCI data that influence China’s talent competitiveness. These indicators are compared with those of G20 countries to explore the underlying reasons for observed changes. Through this comparative analysis, we seek to identify the key factors shaping China’s talent competitiveness and examine the political, economic, social, and technological deficiencies contributing to these challenges. This research will provide valuable insights into strategies for enhancing China’s talent competitiveness. Furthermore, we will lay the groundwork for developing a national talent competitiveness assessment system tailored to China’s specific context. In subsequent research, the current absence of a standardized and unified evaluation framework is expected to become increasingly evident.\nBuilding upon this research, we aim to develop a standardized and unified talent competitiveness assessment system for China. Ideally, this system will adopt a dual structure, comprising a nationally unified framework as the core, complemented by region-specific subsystems that reflect local cultural and contextual variations. This ambitious initiative represents the practical application of preceding theoretical research. However, achieving this objective necessitates a solid foundation of theoretical inquiry grounded in current realities, drawing upon the well-established GTCI talent competitiveness evaluation model. Accordingly, this study employs a SWOT-PEST analytical matrix (political, economic, social, and technological) to systematically examine the key factors shaping China’s present talent competitiveness landscape.\n ",
    "ori_text": "Talent competitiveness refers to the ability of a country or a region to cultivate, attract, and utilize talent resources for its economic and social development, as demonstrated by its talent strategy, policy, and deployment, thereby contributing to the development of the region or the country [1]. National competitiveness is influenced by higher education and scientific research systems, both of which depend on talent competitiveness. Countries around the world have introduced several talent policies to promote national development. In 2022, the UK’s Research and Innovation Agency (RIA) formulated its Strategy 2022–2027: Changing the Future Together, focusing on building a system of excellence in research and innovation to achieve the goal of becoming a global science and technology powerhouse and an innovation-driven nation [2]. In 2023, the U.S. Federal Government introduced its STEM education plan for the period 2023–2028, which was laid out in four areas including education, social engagement, workforce development, and research & innovation capability, as the key support for the U.S. to maintain its global leadership in science and technology [3]. In China, another major economy in the world, the synergistic development of science, education, and talent is seen as fundamental and strategic for the comprehensive construction of a modern socialist country [4]. In both the West and the East, talent search has been recognized as the most important task over decades [5].\nThe European Institute of Business Administration (hereinafter, INSEAD), established in 1957, is headquartered in Fontainebleau, France, with additional campuses in locations including Singapore and Abu Dhabi. INSEAD’s educational mission is to develop future business leaders with a global perspective, a strong sense of responsibility, and the capacity to drive meaningful impact. The institution offers a diverse portfolio of academic programs, including the MBA program, designed to cultivate senior leadership talent; the Executive MBA (EMBA) program, targeting mid- to senior-level managers; and the PhD program, which focuses on rigorous academic research. In addition to its degree offerings, INSEAD engages in specialized research initiatives led by expert teams that integrate resources from multiple sources to conduct focused academic investigations and produce comprehensive database reports. One such initiative is the Global Talent Competitiveness Index (hereinafter, GTCI) project, which is discussed in detail in the following section.\nTo assess and monitor the landscape of global talent cultivation, INSEAD has taken the lead in launching the GTCI. The GTCI index focuses on the ability of countries or economies to cultivate, attract and retain talent, and has received extensive attention from academics for its comprehensiveness, international comparability, dynamic monitoring capability, and policy guidance. Seminal studies have examined the effectiveness of the GTCI. By analyzing the role of talent in the economic development of various countries and economies, researchers suggest that the GTCI could be used as a competitiveness measurement standard [6] as it assesses a country’s talent competitiveness from a comprehensive and objective perspective [7].\nPioneering research has used the GTCI data to conduct international comparisons. After an in-depth analysis of the G20 countries’ performance in talent competitiveness, researchers found that developed countries are particularly strong in talent competitiveness [8]. Some scholars have also examined the migration status of 25 countries and found a positive correlation between a country’s migration status and its GTCI performance, highlighting the importance of talent competitiveness in driving a country’s development [9]. Moreover, several studies have utilized the GTCI data for dynamic monitoring and analysis: using the European innovation scoreboard, scholars have analyzed the changes in Poland’s GTCI data between 2013 and 2018 and pointed out the challenges for talent management and innovation [10]. These capabilities provide important research insights for policymakers, business leaders, and academic researchers worldwide.\nExtending the aforementioned literature, this study takes GTCI as the key data source and selects G20 countries as the main objects of analysis. In the past, the established literature from the fields of political economy [11], development studies [12], and public policy [13] has carefully sketched the issue of China’s talent competitiveness. However, few studies have compared the talent competitiveness of China with a representative coalition of countries such as the G20, resulting in a lack of international comparative perspective. At the end of the 20th century and the beginning of the 21st century, Chinese scholars had already begun to pay attention to the issue of talent competitiveness and to build China’s assessment system in the foreground [14]. However, as of 2024, there is still no substantial breakthrough drawn on such a comprehensive database as the GTCI database.\nAs of now, the scholarly discussions on the issue of talent competitiveness in Chinese academia focus on two aspects: (a) analyzing talent competition between regions and (b) providing vague suggestions for policy-making without detailed solutions. This is caused by China’s rapid development in the 21st century, which leaves regional competition being the focus of public policy research while talent competitiveness is an accessory. At the same time, there is a research gap between economic advancement and educational development: globalized economic development requires China to have a more developed talent competitiveness system, but the mainstream examination-based education system is not conducive to such development.\nThus, in studies focusing solely on China’s talent competitiveness, there are three research gaps that can be summarized. First, due to the lack of national-level datasets, most of the existing studies are based on individual provinces in China and are not generalizable enough. Second, current Chinese-language research in talent competitiveness mainly focuses on local policy slogans, with relatively broad arguments and a lack of empirical data support. Third, relevant studies in English language still have not proposed a set of systematic, comprehensive evaluation frameworks to measure the competitiveness of talents across the world, which hinders academics from deep diving into talent policies.\nAdditionally, there is an unmet need of highly skilled professionals in China, partly due to the disadvantage of its education system. China’s low attractiveness to talent has also led to a large number of Chinese overseas students being reluctant to return to China and foreign talent being reluctant to enter China [15]. The lack of a scientific evaluation system is not conducive to the updating of talent competitiveness policies at the national level, thus leading to a vicious circle of local talent competitiveness policies.\nGiven this, this research proposes and adopts an original analysis matrix as a multi-dimensional and multi-indicator framework (which we name PEST-embedded SWOT matrix), for assessing talent competitiveness. By comparatively analyzing the performance of different countries in terms of talent competitiveness, this investigation aims to accurately grasp China’s position and posture in the global talent competition, thereby putting forward targeted improvement paths and policy recommendations in terms of talent cultivation, attraction, and utilization. We aimed to conduct a comprehensive literature analysis and introduce an analytical matrix to extract the indicators embedded in the GTCI data that influence China’s talent competitiveness. These indicators are compared with those of G20 countries to explore the underlying reasons for observed changes. Through this comparative analysis, we seek to identify the key factors shaping China’s talent competitiveness and examine the political, economic, social, and technological deficiencies contributing to these challenges. This research will provide valuable insights into strategies for enhancing China’s talent competitiveness. Furthermore, we will lay the groundwork for developing a national talent competitiveness assessment system tailored to China’s specific context. In subsequent research, the current absence of a standardized and unified evaluation framework is expected to become increasingly evident.\nBuilding upon this research, we aim to develop a standardized and unified talent competitiveness assessment system for China. Ideally, this system will adopt a dual structure, comprising a nationally unified framework as the core, complemented by region-specific subsystems that reflect local cultural and contextual variations. This ambitious initiative represents the practical application of preceding theoretical research. However, achieving this objective necessitates a solid foundation of theoretical inquiry grounded in current realities, drawing upon the well-established GTCI talent competitiveness evaluation model. Accordingly, this study employs a SWOT-PEST analytical matrix (political, economic, social, and technological) to systematically examine the key factors shaping China’s present talent competitiveness landscape.\n ",
    "reference_list": "考点1： \"talent search \"应译为 \"招才引智 / 人才寻觅”\n考点2： \"drive meaningful impact \"应译为 “推动产生深远影响 / 创造有意义的价值”\n考点3： \"Seminal studies \"应译为 “开创性研究 / 奠基性研究”\n考点4：\" Pioneering research\" 应译为 \"先驱性研究 / 开创性研究\"\n考点5：\" in the foreground \"应译为\" 前瞻性地 / 率先\"\n考点6：\" research gap \"应译为 研究空白\n考点7： grounded in current realities 应译为 立足于当前现实 / 植根于现实情况",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "92"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n　There is a vast hidden workforce behind AI（April 10, 2025）\nWhen DEEPSEEK, a hotshot Chinese firm, released its cheap large language model late last year it overturned long-standing assumptions about what it will take to build the next generation of artificial intelligence (AI). This will matter to whoever comes out on top in the epic global battle for AI supremacy. Developers are now reconsidering how much hardware, energy and data are needed. Yet another, less discussed, input in machine intelligence is in flux too: the workforce.　\nTo the layman, AI is all robots, machines and models. It is a technology that kills jobs. In fact, there are millions of workers involved in producing AI models. Much of their work has involved tasks like tagging objects in images of roads in order to train self-driving cars and labelling words in the audio recordings used to train speech-recognition systems. Technically, annotators give data the contextual information computers need to work out the statistical associations between components of a dataset and their meaning to human beings. In fact, anyone who has completed a captcha test, selecting photos containing zebra crossings, may have inadvertently helped train an AI.\nAnnotators have long been compared to parents, teaching models and helping them make sense of the world. But the latest models don’t need their guidance in the same way. As the technology grows up, are its teachers becoming redundant?Data annotation is not new. Fei Fei Li, an American computer scientist known as “the godmother of AI”, is credited with firing the industry’s starting gun in the mid-2000s when she created ImageNet, the largest image dataset at the time. Ms Li realised that if she paid college students to categorise the images, which was then how most researchers did things, the task would take 90 years. Instead, she hired workers around the world using Mechanical Turk, an online gig-work platform run by Amazon. She got some 3.2m images organised into a dataset in two and a half years. Soon other AI labs were outsourcing annotation work this way, too.\nA debate in the industry has been about the treatment of the workers behind AI. Firms are reluctant to share information on wages. But American annotators generally consider $10-20 per hour to be decent pay on online platforms. Those in poor countries often get $4-8 per hour. Many must use monitoring tools that track their computer activity and are penalised for being slow. Scale AI has been hit with several lawsuits over its employment practices. The firm denies wrongdoing and says: “We plan to defend ourselves vigorously.”The bigger issue, though, is that basic annotation work is drying up. In part, this was inevitable. If AI was once a toddler who needed a parent to point things out and to help it make sense of the world around it, the technology has grown into an adolescent who needs occasional specialist guidance and advice. AI labs increasingly use pre-labelled data from other AI labs, which use algorithms to apply labels to datasets.\nThe most recent wave of AI models has changed data work more dramatically. Since 2022, when OpenAI first let the public play with its ChatGPT chatbot, there has been a rush of interest in large language models. Data from Pitchbook, a research firm, suggest that global venture-capital funding for AI startups jumped by more than 50% in 2024 to $131.5bn, even as funding for other startups fell. Much of it is going into newer techniques for developing AI, which do not need data annotated in the same way. Iva Gumnishka at Humans in the Loop, a social enterprise, says firms doing low-skilled annotation for older computer-vision and natural-language-processing clients are being “left behind”.\nThere is still demand for annotators, but their work has changed. As businesses start to deploy AI, they are building smaller specialised models and looking for highly educated annotators to help. It has become fairly common for adverts for annotation jobs to require a PhD or skills in coding and science. Now that researchers are trying to make AI more multilingual, demand for annotators who speak languages other than English is growing, too. Sushovan Das, a dentist working on medical-AI projects at iMerit, reckons that annotation work will never disappear. “This world is constantly evolving,” he says. “So the AI needs to be improved time and again.”\nIf AI developers had their way they would not need this sort of human input at all. Studies suggest that as much as 80% of the time that goes into the development of AI is spent on data work. Naveen Rao at Databricks, an AI firm, says he would like models to teach themselves, just as he would like his own children to do. “I want to build self-efficacious humans,” he says. “I want them to have their own curiosity and figure out how to solve problems. I don’t want to spoon-feed them every step of the way.”There is a lot of excitement about unsupervised learning, which involves feeding models unlabelled data, and reinforcement learning, which uses trial and error to improve decision-making. AI firms, including Google DeepMind, have trained machines to win at games like Go and chess by millions of contests against themselves and tracking which strategies work, without any human input at all. But that self-taught approach doesn’t work outside the realms of maths and science, at least for the moment.\nTech nerds everywhere have been blown away by how cheap and efficient DeepSeek’s model is. But they are less impressed by DeepSeek’s attempt to train AI using feedback generated by computers rather than humans. The model struggled to answer open-ended questions, producing gobbledygook in a mixture of languages. Mr Bradley, like many techies, reckons that more people will need to get involved in training AI, not fewer. Diversity in the workforce matters. When ChatGPT was released a few years ago, people noticed that it overused the word “delve”. The word became seen as “AI-ese”, a telltale sign that the text was written by a bot. In fact, annotators in Africa had been hired to train the model and the word “delve” is more commonly used in African English than it is in American or British English. In the same way as workers’ skills and knowledge are transferred to models, their vocabulary is, too. As it turns out, it takes more than just a village to raise a child.",
    "ori_text": "　There is a vast hidden workforce behind AI（April 10, 2025）\nWhen DEEPSEEK, a hotshot Chinese firm, released its cheap large language model late last year it overturned long-standing assumptions about what it will take to build the next generation of artificial intelligence (AI). This will matter to whoever comes out on top in the epic global battle for AI supremacy. Developers are now reconsidering how much hardware, energy and data are needed. Yet another, less discussed, input in machine intelligence is in flux too: the workforce.　\nTo the layman, AI is all robots, machines and models. It is a technology that kills jobs. In fact, there are millions of workers involved in producing AI models. Much of their work has involved tasks like tagging objects in images of roads in order to train self-driving cars and labelling words in the audio recordings used to train speech-recognition systems. Technically, annotators give data the contextual information computers need to work out the statistical associations between components of a dataset and their meaning to human beings. In fact, anyone who has completed a captcha test, selecting photos containing zebra crossings, may have inadvertently helped train an AI.\nAnnotators have long been compared to parents, teaching models and helping them make sense of the world. But the latest models don’t need their guidance in the same way. As the technology grows up, are its teachers becoming redundant?Data annotation is not new. Fei Fei Li, an American computer scientist known as “the godmother of AI”, is credited with firing the industry’s starting gun in the mid-2000s when she created ImageNet, the largest image dataset at the time. Ms Li realised that if she paid college students to categorise the images, which was then how most researchers did things, the task would take 90 years. Instead, she hired workers around the world using Mechanical Turk, an online gig-work platform run by Amazon. She got some 3.2m images organised into a dataset in two and a half years. Soon other AI labs were outsourcing annotation work this way, too.\nA debate in the industry has been about the treatment of the workers behind AI. Firms are reluctant to share information on wages. But American annotators generally consider $10-20 per hour to be decent pay on online platforms. Those in poor countries often get $4-8 per hour. Many must use monitoring tools that track their computer activity and are penalised for being slow. Scale AI has been hit with several lawsuits over its employment practices. The firm denies wrongdoing and says: “We plan to defend ourselves vigorously.”The bigger issue, though, is that basic annotation work is drying up. In part, this was inevitable. If AI was once a toddler who needed a parent to point things out and to help it make sense of the world around it, the technology has grown into an adolescent who needs occasional specialist guidance and advice. AI labs increasingly use pre-labelled data from other AI labs, which use algorithms to apply labels to datasets.\nThe most recent wave of AI models has changed data work more dramatically. Since 2022, when OpenAI first let the public play with its ChatGPT chatbot, there has been a rush of interest in large language models. Data from Pitchbook, a research firm, suggest that global venture-capital funding for AI startups jumped by more than 50% in 2024 to $131.5bn, even as funding for other startups fell. Much of it is going into newer techniques for developing AI, which do not need data annotated in the same way. Iva Gumnishka at Humans in the Loop, a social enterprise, says firms doing low-skilled annotation for older computer-vision and natural-language-processing clients are being “left behind”.\nThere is still demand for annotators, but their work has changed. As businesses start to deploy AI, they are building smaller specialised models and looking for highly educated annotators to help. It has become fairly common for adverts for annotation jobs to require a PhD or skills in coding and science. Now that researchers are trying to make AI more multilingual, demand for annotators who speak languages other than English is growing, too. Sushovan Das, a dentist working on medical-AI projects at iMerit, reckons that annotation work will never disappear. “This world is constantly evolving,” he says. “So the AI needs to be improved time and again.”\nIf AI developers had their way they would not need this sort of human input at all. Studies suggest that as much as 80% of the time that goes into the development of AI is spent on data work. Naveen Rao at Databricks, an AI firm, says he would like models to teach themselves, just as he would like his own children to do. “I want to build self-efficacious humans,” he says. “I want them to have their own curiosity and figure out how to solve problems. I don’t want to spoon-feed them every step of the way.”There is a lot of excitement about unsupervised learning, which involves feeding models unlabelled data, and reinforcement learning, which uses trial and error to improve decision-making. AI firms, including Google DeepMind, have trained machines to win at games like Go and chess by millions of contests against themselves and tracking which strategies work, without any human input at all. But that self-taught approach doesn’t work outside the realms of maths and science, at least for the moment.\nTech nerds everywhere have been blown away by how cheap and efficient DeepSeek’s model is. But they are less impressed by DeepSeek’s attempt to train AI using feedback generated by computers rather than humans. The model struggled to answer open-ended questions, producing gobbledygook in a mixture of languages. Mr Bradley, like many techies, reckons that more people will need to get involved in training AI, not fewer. Diversity in the workforce matters. When ChatGPT was released a few years ago, people noticed that it overused the word “delve”. The word became seen as “AI-ese”, a telltale sign that the text was written by a bot. In fact, annotators in Africa had been hired to train the model and the word “delve” is more commonly used in African English than it is in American or British English. In the same way as workers’ skills and knowledge are transferred to models, their vocabulary is, too. As it turns out, it takes more than just a village to raise a child.",
    "reference_list": "考点 1：【hidden workforce 】应译为 【隐形劳动力】\n考点 2：【multilingual AI】 应译为 【多语言人工智能】\n考点 3：【venture-capital funding】 应译为【 风险投资资金】",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "82"
  },
  {
    "prompt": "翻译，中文翻译成英文，不要输出译文以外的内容。以下是你本次的任务：\n\n在俄罗斯文化中，莫斯科和彼得堡已经超出城市的地理范畴，作为一种文化符号成为对立的两极：俄罗斯传统文化与西方文化，民族性与现代性，俄罗斯与欧洲，弥赛亚与敌基督等，从而构成了一直以来困扰俄罗斯的关于道路选择和民族身份认证等一系列重大的俄罗斯思想问题。\n\n在“莫斯科神话”的编码中，很大一部分与它的地理形态和构成相关。编年史记载，莫斯科坐落在一片天然形成的如巨型大碗的洼地之中，周围有12座不高的山峦环绕。但据历史学家确认，莫斯科是由七座神奇的山丘组成。它们是波罗维茨、斯列坚斯科、特维尔、三头山、列弗尔托夫、沃罗比约夫和传奇的施维夫。如此一来，围绕着莫斯科到底是由7座山丘还是12座山丘组成就形成了一系列复杂的说法。其中，俄罗斯星相学就将莫斯科划归为金牛座的属性。这不仅是因为这座城市的奠基日（1147年3月28日，史上记载为1147年4月5日）恰好落在黄道带（Зодиак）的金牛座上（有人注意到在古克里姆林宫的三角形里有个牛头，即金牛座的象征），更因为第一罗马和第二罗马的创建日期也是金牛座属性：即罗马建于公元前754年4月22日，而康斯坦丁堡则建于公元330年5月11日。按照当代俄罗斯星相学家巴维尔·格罗巴的观点，莫斯科的不可替代性和宇宙性即由此构成。因为它是按照“七座山丘一条河”的原则建造的，它是一座“永恒之城”。在东正教秘传中，数字7永远被认为是一个具有魔法的数字，它意味着秘密、尚未认识的东西和无法解释的东西。\n\n莫斯科如此的地貌和城市结构，我们可以借尤里·洛特曼的“城市符号学”理论加以阐释：“当一座城市在与周遭的世界中的关系中，就像一座坐落在尘世中心的教堂一般，那么，它首先表现出一种被理想化的宇宙模式来。”这样的城市，通常，“被置于‘大地的中心’。……耶路撒冷、罗马、莫斯科在不同的（城市）文本中正是作为某些世界的中心来看待的。它可以同时既作为天国城市的模型，又作为周边世界的圣地。”这样的城市也被称为“同心城市”。“通常，城市的同心状态在符号学的空间里，是与处在高山之上（群山上）的城市形象相联系的。那样的城市表现为地与天的中介，在它周围集结着一些有关起源、发生嬗变的神话，它具有开始，但没有结束——这是‘永恒之城’。”\n\n除此之外，莫斯科的大火也成为“莫斯科神话”中较为重要的构成元素。莫斯科曾遭受过无数次“火”的历练。历史上比较重要的记载共有四次。1812年的那场大火促成了这座城市的诸多骄傲。战争与大火的破坏，不仅使莫斯科成为“多灾多难”之城的象征，也使它成为俄罗斯最受宠爱的城市。俄罗斯热爱并怜惜着莫斯科，因为从莫斯科身上俄罗斯认出了自己。\n\n如此一来，俄罗斯文学“莫斯科文本”最基本的神话原型通常分为两类：一是有关起源的神话：即莫斯科起源于“七座山丘”或“十二座山丘”的神话和莫斯科作为“向心的”“被护佑的城市”神话。二是关于末日论的神话：即莫斯科的“大火”。“火”的意象在莫斯科文本中往往衍生出两个向度的神话阐释：即莫斯科既是“浴火重生”的“凤凰城”，又是象征“毁灭”的“大墓地”。俄罗斯“白银时代”的研究者们在言涉“莫斯科-彼得堡”的城市哲学时，最早提及了莫斯科城的“凤凰之名”：“在与罗马争夺优先权的斗争中，莫斯科逐渐书写了新的神话，它就是凤凰城”，“从灰烬中得到重生的旧首都吸引了全世界的目光。”这里喻指大火后的莫斯科像凤凰涅槃一样在烈火中重生。“凤凰城”因此而得名。有的文学家认为，莫斯科之所以重要，不仅是因为莫斯科是俄罗斯传统的象征，更重要的是，它与浴火的凤凰有关。它代表着俄罗斯民族源源不断的生命力和重振雄风的可能。\n\n“大墓地”一词出自恰达耶夫的《哲学书简》。在其中，恰达耶夫特别强调说“大墓地指的是莫斯科”。作为俄罗斯思想界西欧派的杰出代表，恰达耶夫将充满着宗法制陈腐之气的莫斯科喻为死亡之城。在第一封信中，恰达耶夫对俄罗斯进行了强烈的谴责：“首先是野蛮的不开化，然后是愚蠢的愚昧，接下来是残暴的，凌辱的异族统治……它除了残暴以外没有兴起过任何东西，除了奴役以外没有温暖过任何东西……我们仅仅生活在界限非常狭隘的现在，没有过去和未来，置身于僵死的停滞。”在恰达耶夫看来，俄罗斯真是一无是处了。俄罗斯构成了人类“精神世界的一处空白”，俄罗斯人“徒有基督徒的虚名”，甚至连俄罗斯人勇敢的天性，也被恰达耶夫视为一种“恶习”。“残暴的、凌辱异族的统治，这一统治方式后来又为我们本民族的当权者所继承。” 《哲学书简》遂成为斯拉夫派和西欧派争论的导火索。在西欧派看来，莫斯科所代表的保守，“维护那些与俄罗斯的历史落后性联接在一起的民族生活的特征”，它“担心欧洲的技术机械、工业的发展”，它认为“与欧洲在形式上的相似的新社会可能戕害俄罗斯精神的独特性，让俄罗斯失去个性”，在这种陈腐保守的民族主义氛围里，莫斯科没有一丝生气，是一座“大墓地”，是“死寂的原子”，是“保守的庞然大物”。\n\n然而，在苏维埃政权的最初年代，“莫斯科神话”发生了本质的变形。当然，这主要与新政权对作家心灵的意识形态高压有关，与将首都重又转向莫斯科有关。从20年代开始，莫斯科神话又显现出两种形态：旧莫斯科被讽刺性地重新提起，当代莫斯科则被理解为乌托邦。在20年代，安德烈·别雷创作了有关革命前的莫斯科三部曲《莫斯科》，这个称谓无可避免地使人把那部他创作于1911年的《彼得堡》联系在一起。在这部小说里，所有过往构成“莫斯科神话”的东西都被颠倒了过来。取代“神圣”的莫斯科的是“万恶的、该死的莫斯科”“站在地狱之上的莫斯科”；取代“家常的莫斯科”的是“小市民的”“鄙俗的”“肮脏的莫斯科”；取代“自然的、生气盎然、蓬勃壮大”的莫斯科的是“衰老的”“病恹恹的”莫斯科。莫斯科仿佛是一个“肿瘤”：“莫斯科……是被自己不幸命运的丝袜捆绑了千年的老太婆”，它“突出来的瘤子，纠缠成密不透风的网络。”在这里，被祛神话化了的旧的、革命前的莫斯科，又被莫斯科的现代神话、莫斯科的科学技术乌托邦、莫斯科的科学幻想所补足。20年代的莫斯科神话往往与那些年的两个口号密切相关：即“要进行世界革命”和“要搞电气化！”这两个思想要求文学的世界性激情，而作家们的创作甚至超出了这个社会订货。他们不仅把莫斯科描绘成全世界的，而且是全宇宙的。莫斯科的现代化不仅闪烁着英雄主义色彩，而且是一种梦想的设计。最能体现这种设计的是在二三十年代有关莫斯科的诗歌里对于地铁的赞颂。\n\n高度发达的工业化，正是20年代莫斯科“魔幻”乌托邦的通常语境。然而，与此同时，还存在另一种与意识形态相对抗的象征符号性的魔幻。这种魔幻使20年代的“莫斯科文本”往往具有两种固定的情节：一是被无产阶级大众所掌握的科学发明，二是集体劳动的思想体制。第一种情节在布尔加科夫的反乌托邦小说《孽卵》和《狗心》之中被典型地运用。\n\n“莫斯科神话”在布尔加科夫的最后一部长篇小说《大师与玛格丽特》中发生了决定性的逆转。在这里，莫斯科不再是耶路撒冷的模板，而是根本的对立。然而，在这一对立中，被特别强调的不是对新世界的期待，而是旧世界的衰朽。小说写道：在莫斯科“太阳被击成粉末”。城市毁灭了，仿佛变成了彼得堡一般的“虚空”。莫斯科神话和彼得堡神话就此合拢在一起：两座城市在精神上都是空虚的。",
    "ori_text": "在俄罗斯文化中，莫斯科和彼得堡已经超出城市的地理范畴，作为一种文化符号成为对立的两极：俄罗斯传统文化与西方文化，民族性与现代性，俄罗斯与欧洲，弥赛亚与敌基督等，从而构成了一直以来困扰俄罗斯的关于道路选择和民族身份认证等一系列重大的俄罗斯思想问题。\n\n在“莫斯科神话”的编码中，很大一部分与它的地理形态和构成相关。编年史记载，莫斯科坐落在一片天然形成的如巨型大碗的洼地之中，周围有12座不高的山峦环绕。但据历史学家确认，莫斯科是由七座神奇的山丘组成。它们是波罗维茨、斯列坚斯科、特维尔、三头山、列弗尔托夫、沃罗比约夫和传奇的施维夫。如此一来，围绕着莫斯科到底是由7座山丘还是12座山丘组成就形成了一系列复杂的说法。其中，俄罗斯星相学就将莫斯科划归为金牛座的属性。这不仅是因为这座城市的奠基日（1147年3月28日，史上记载为1147年4月5日）恰好落在黄道带（Зодиак）的金牛座上（有人注意到在古克里姆林宫的三角形里有个牛头，即金牛座的象征），更因为第一罗马和第二罗马的创建日期也是金牛座属性：即罗马建于公元前754年4月22日，而康斯坦丁堡则建于公元330年5月11日。按照当代俄罗斯星相学家巴维尔·格罗巴的观点，莫斯科的不可替代性和宇宙性即由此构成。因为它是按照“七座山丘一条河”的原则建造的，它是一座“永恒之城”。在东正教秘传中，数字7永远被认为是一个具有魔法的数字，它意味着秘密、尚未认识的东西和无法解释的东西。\n\n莫斯科如此的地貌和城市结构，我们可以借尤里·洛特曼的“城市符号学”理论加以阐释：“当一座城市在与周遭的世界中的关系中，就像一座坐落在尘世中心的教堂一般，那么，它首先表现出一种被理想化的宇宙模式来。”这样的城市，通常，“被置于‘大地的中心’。……耶路撒冷、罗马、莫斯科在不同的（城市）文本中正是作为某些世界的中心来看待的。它可以同时既作为天国城市的模型，又作为周边世界的圣地。”这样的城市也被称为“同心城市”。“通常，城市的同心状态在符号学的空间里，是与处在高山之上（群山上）的城市形象相联系的。那样的城市表现为地与天的中介，在它周围集结着一些有关起源、发生嬗变的神话，它具有开始，但没有结束——这是‘永恒之城’。”\n\n除此之外，莫斯科的大火也成为“莫斯科神话”中较为重要的构成元素。莫斯科曾遭受过无数次“火”的历练。历史上比较重要的记载共有四次。1812年的那场大火促成了这座城市的诸多骄傲。战争与大火的破坏，不仅使莫斯科成为“多灾多难”之城的象征，也使它成为俄罗斯最受宠爱的城市。俄罗斯热爱并怜惜着莫斯科，因为从莫斯科身上俄罗斯认出了自己。\n\n如此一来，俄罗斯文学“莫斯科文本”最基本的神话原型通常分为两类：一是有关起源的神话：即莫斯科起源于“七座山丘”或“十二座山丘”的神话和莫斯科作为“向心的”“被护佑的城市”神话。二是关于末日论的神话：即莫斯科的“大火”。“火”的意象在莫斯科文本中往往衍生出两个向度的神话阐释：即莫斯科既是“浴火重生”的“凤凰城”，又是象征“毁灭”的“大墓地”。俄罗斯“白银时代”的研究者们在言涉“莫斯科-彼得堡”的城市哲学时，最早提及了莫斯科城的“凤凰之名”：“在与罗马争夺优先权的斗争中，莫斯科逐渐书写了新的神话，它就是凤凰城”，“从灰烬中得到重生的旧首都吸引了全世界的目光。”这里喻指大火后的莫斯科像凤凰涅槃一样在烈火中重生。“凤凰城”因此而得名。有的文学家认为，莫斯科之所以重要，不仅是因为莫斯科是俄罗斯传统的象征，更重要的是，它与浴火的凤凰有关。它代表着俄罗斯民族源源不断的生命力和重振雄风的可能。\n\n“大墓地”一词出自恰达耶夫的《哲学书简》。在其中，恰达耶夫特别强调说“大墓地指的是莫斯科”。作为俄罗斯思想界西欧派的杰出代表，恰达耶夫将充满着宗法制陈腐之气的莫斯科喻为死亡之城。在第一封信中，恰达耶夫对俄罗斯进行了强烈的谴责：“首先是野蛮的不开化，然后是愚蠢的愚昧，接下来是残暴的，凌辱的异族统治……它除了残暴以外没有兴起过任何东西，除了奴役以外没有温暖过任何东西……我们仅仅生活在界限非常狭隘的现在，没有过去和未来，置身于僵死的停滞。”在恰达耶夫看来，俄罗斯真是一无是处了。俄罗斯构成了人类“精神世界的一处空白”，俄罗斯人“徒有基督徒的虚名”，甚至连俄罗斯人勇敢的天性，也被恰达耶夫视为一种“恶习”。“残暴的、凌辱异族的统治，这一统治方式后来又为我们本民族的当权者所继承。” 《哲学书简》遂成为斯拉夫派和西欧派争论的导火索。在西欧派看来，莫斯科所代表的保守，“维护那些与俄罗斯的历史落后性联接在一起的民族生活的特征”，它“担心欧洲的技术机械、工业的发展”，它认为“与欧洲在形式上的相似的新社会可能戕害俄罗斯精神的独特性，让俄罗斯失去个性”，在这种陈腐保守的民族主义氛围里，莫斯科没有一丝生气，是一座“大墓地”，是“死寂的原子”，是“保守的庞然大物”。\n\n然而，在苏维埃政权的最初年代，“莫斯科神话”发生了本质的变形。当然，这主要与新政权对作家心灵的意识形态高压有关，与将首都重又转向莫斯科有关。从20年代开始，莫斯科神话又显现出两种形态：旧莫斯科被讽刺性地重新提起，当代莫斯科则被理解为乌托邦。在20年代，安德烈·别雷创作了有关革命前的莫斯科三部曲《莫斯科》，这个称谓无可避免地使人把那部他创作于1911年的《彼得堡》联系在一起。在这部小说里，所有过往构成“莫斯科神话”的东西都被颠倒了过来。取代“神圣”的莫斯科的是“万恶的、该死的莫斯科”“站在地狱之上的莫斯科”；取代“家常的莫斯科”的是“小市民的”“鄙俗的”“肮脏的莫斯科”；取代“自然的、生气盎然、蓬勃壮大”的莫斯科的是“衰老的”“病恹恹的”莫斯科。莫斯科仿佛是一个“肿瘤”：“莫斯科……是被自己不幸命运的丝袜捆绑了千年的老太婆”，它“突出来的瘤子，纠缠成密不透风的网络。”在这里，被祛神话化了的旧的、革命前的莫斯科，又被莫斯科的现代神话、莫斯科的科学技术乌托邦、莫斯科的科学幻想所补足。20年代的莫斯科神话往往与那些年的两个口号密切相关：即“要进行世界革命”和“要搞电气化！”这两个思想要求文学的世界性激情，而作家们的创作甚至超出了这个社会订货。他们不仅把莫斯科描绘成全世界的，而且是全宇宙的。莫斯科的现代化不仅闪烁着英雄主义色彩，而且是一种梦想的设计。最能体现这种设计的是在二三十年代有关莫斯科的诗歌里对于地铁的赞颂。\n\n高度发达的工业化，正是20年代莫斯科“魔幻”乌托邦的通常语境。然而，与此同时，还存在另一种与意识形态相对抗的象征符号性的魔幻。这种魔幻使20年代的“莫斯科文本”往往具有两种固定的情节：一是被无产阶级大众所掌握的科学发明，二是集体劳动的思想体制。第一种情节在布尔加科夫的反乌托邦小说《孽卵》和《狗心》之中被典型地运用。\n\n“莫斯科神话”在布尔加科夫的最后一部长篇小说《大师与玛格丽特》中发生了决定性的逆转。在这里，莫斯科不再是耶路撒冷的模板，而是根本的对立。然而，在这一对立中，被特别强调的不是对新世界的期待，而是旧世界的衰朽。小说写道：在莫斯科“太阳被击成粉末”。城市毁灭了，仿佛变成了彼得堡一般的“虚空”。莫斯科神话和彼得堡神话就此合拢在一起：两座城市在精神上都是空虚的。",
    "reference_list": "考点1 ：“城市符号学”推荐译为”urban semiotics‘’\n考点2：“民族身份认证”推荐译为“national identity recognition”\n考点3：\"白银时代\"推荐译为”Silver Age”\n考点4：”大墓地”推荐译为”great cemetery”\n考点5：“家常的莫斯科”推荐译为“ordinary Moscow”\n考点6：“莫斯科如此的地貌和城市结构，我们可以借尤里·洛特曼的‘城市符号学‘理论加以阐释”推荐译为“Such topography and urban structure of Moscow can be interpreted using Yuri Lotman’s theory of ‘urban semiotics’.”\n考点7：“东正教秘传”推荐译为”Eastern Orthodox esotericism“\n考点18：“凤凰涅槃”推荐译为“phoenix reborn from the ashes”\n考点9：”波罗维茨、斯列坚斯科、特维尔、三头山、列弗尔托夫、沃罗比约夫”推荐译为”Borovitsky Hill, Sretensky Hill, Tverskoy Hill, Tryokhgornaya Hill, Lefortovo Hill, Sparrow Hills”\n考点10：“人类精神世界的一处空白”推荐译为“a blank spot in the spiritual world of humanity”\n考点11：“要搞电气化！”推荐译为“Electrification!”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "103"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nTitle: Psychological Barriers and Outcomes of Extension Requests in the Workplace: An Empirical Study‌\n\n‌Abstract‌\nThis study investigates the psychological factors influencing employees' decisions to request deadline extensions in professional settings, with a focus on self-presentation concerns, perceived negative evaluations, and organizational policies. Using a mixed-methods approach involving surveys and behavioral experiments, data were collected from 500 employees across diverse industries. Results indicate that concerns about self-image act as significant barriers to extension requests, while employees who proactively seek extensions demonstrate higher work quality. Gender differences reveal distinct interpersonal concerns affecting willingness to request extensions. The presence of formal extension policies significantly enhances request rates, suggesting actionable interventions for organizations. These findings underscore the need for psychological support mechanisms in workplace environments to mitigate cognitive biases and improve productivity.\n\n‌1. Introduction‌\nDeadline management is a critical aspect of workplace psychology, where employees often face pressures related to task completion and performance evaluations. Extension requests—formal appeals for additional time—represent a common yet understudied behavior in organizational psychology. Previous research has highlighted psychological barriers such as fear of negative judgment and self-presentation anxieties, which can deter employees from seeking necessary accommodations. The broader field of psychology emphasizes that cognitive distortions, including overestimation of negative outcomes, are pervasive in decision-making processes. For instance, studies on personality disorders reveal how maladaptive thought patterns exacerbate interpersonal conflicts, paralleling workplace dynamics where employees misjudge supervisors' reactions.8 This study integrates these insights to examine how psychological factors influence extension requests and their correlation with work outcomes. Theoretical frameworks from cognitive psychology and organizational behavior guide this inquiry, with hypotheses centered on gender disparities and policy impacts.\n\n‌2. Method‌\n‌2.1 Participants‌\nA total of 500 full-time employees (46% male, 54% female; mean age = 34.2 years, SD = 8.5) were recruited from technology, healthcare, and education sectors. Participants represented varied organizational roles, including entry-level staff (40%), middle management (35%), and senior executives (25%). Inclusion criteria required at least one year of employment to ensure familiarity with workplace protocols. Compensation included monetary incentives and confidentiality assurances.\n‌2.2 Design and Procedure‌\nA sequential mixed-methods design was employed, comprising:\n‌- Survey Phase‌: Participants completed an online questionnaire assessing self-presentation concerns (e.g., \"I worry that requesting an extension will make me seem incompetent\"), perceived supervisor reactions, and past extension behaviors. Scales used a 7-point Likert format, validated in prior cognitive psychology research for reliability (Cronbach’s α = 0.85).\n- ‌Experimental Phase‌: A subgroup of 200 participants engaged in a simulated task scenario involving urgent vs. non-urgent deadlines. Behavioral data on request timing, task quality, and post-request anxiety were recorded. Scenarios were counterbalanced to control for order effects.\n- Data collection occurred over three months, with ethics approval obtained from an institutional review board. All instruments adhered to APA guidelines for psychological assessments.\n‌2.3 Measures‌\nKey variables included:\n‌- Self-Presentation Concerns‌: Measured via the Workplace Anxiety Scale (WAS), adapted from studies on cognitive biases.\n‌- Work Quality‌: Evaluated using supervisor ratings on a 10-point scale for tasks completed with vs. without extensions.\n‌- Perceived Negative Evaluations‌: Captured through vignette-based questions derived from social psychology frameworks.\n- ‌Organizational Policies‌: Assessed by examining company handbooks and participant reports on formal extension protocols.\n\n‌3. Results‌\n‌3.1 Quantitative Findings‌\nResults from regression analyses revealed that self-presentation concerns were the strongest predictor of avoidance behaviors (β = 0.42, p < .001), accounting for 65% of variance in extension request reluctance. Employees who requested extensions exhibited 23% higher work quality scores (M = 8.2, SD = 1.1) compared to non-requesters (M = 6.7, SD = 1.5), supporting the hypothesis that proactive requests correlate with superior outcomes. Gender differences emerged significantly (p = .02), with women reporting higher interpersonal concerns (e.g., fear of burdening others) rather than self-competence doubts, aligning with trends in health psychology research on gendered communication patterns.\n‌3.2 Qualitative Insights‌\nThematic analysis of open-ended responses identified recurring themes:\n- Overestimation of negative supervisor evaluations was common across genders, with 78% of participants inflating perceived criticism.\n- In non-urgent task scenarios, supervisors prioritized quality over speed, reducing negative feedback when extensions were requested.\n- Formal organizational policies (e.g., clear request guidelines) boosted request willingness by 40%, mitigating psychological barriers through structured support.\n\n‌4. Discussion‌\nThis study demonstrates that psychological barriers to extension requests stem primarily from cognitive distortions, such as overestimating negative judgments, which align with broader findings in mental health research. The positive association between extension requests and work quality underscores that employees seeking accommodations engage in more deliberate task execution, challenging assumptions that extensions indicate poor performance. Gender-specific concerns highlight the need for tailored interventions, as women's reluctance is driven more by interpersonal dynamics than self-doubt—a nuance consistent with recent APA reports on workplace psychology trends.\nThe role of organizational policies emerges as a key moderator, reinforcing that formal structures reduce ambiguity and anxiety, thereby fostering psychological safety. Compared to prior studies on educational psychology, where deadline extensions are common, workplace contexts amplify barriers due to hierarchical dynamics. Limitations include reliance on self-reported data and sector-specific sampling, which may limit generalizability. Future research should explore cross-cultural variations and longitudinal designs to track behavioral changes over time.\n\n‌5. Conclusion‌\nEmployees' decisions to request deadline extensions are significantly influenced by psychological factors, including self-presentation fears and cognitive biases, with notable gender differences in underlying concerns. Organizations can enhance productivity and well-being by implementing formal extension policies and psychological support programs. This study contributes to workplace psychology by providing empirical evidence for interventions that address cognitive distortions, ultimately promoting healthier work environments.\n\n‌6. Extending the Research: Policy Interventions and Cognitive Mechanisms‌\nBuilding on the foundational findings of our study, this section explores actionable strategies for organizations and theoretical contributions to workplace psychology.\n6.1 Organizational Policy Design\nThe study’s results underscore that formal extension policies reduce psychological barriers by 40%, but their design requires nuance. Effective policies should:\n- Clarify Eligibility Criteria: Transparent guidelines (e.g., \"Extensions permitted for tasks exceeding 8 hours of work\") mitigate ambiguity-induced anxiety. A 2024 meta-analysis confirms that rule clarity decreases perceived request \"stigma\" by 31%.\n- Decentralize Approval Authority: Allowing team leads (vs. senior managers) to approve requests reduces hierarchical intimidation, particularly for junior employees.\n- Normalize Extensions as Productivity Tools: Case studies from tech firms show that framing extensions as \"quality optimization periods\" (e.g., Google’s \"20% time\" model) increases utilization without penalizing performance metrics.\n6.2 Cognitive-Behavioral Interventions\nEmployees’ overestimation of negative evaluations mirrors clinical findings in social anxiety research. Adapting therapeutic techniques could yield workplace benefits:\n- Reframing Exercises: Training sessions teaching employees to challenge cognitive distortions (e.g., \"My supervisor will think I’m lazy\") reduced avoidance behaviors by 22% in a pilot study.\n- Graded Exposure: Gradually increasing exposure to extension requests (e.g., starting with low-stakes tasks) builds confidence, akin to exposure therapy for phobias.\n- Feedback Loops: Anonymous peer data sharing (e.g., \"70% of your team requested extensions last quarter\") corrects pluralistic ignorance, where employees falsely assume they are outliers.\n6.3 Cross-Cultural and Longitudinal Gaps\nWhile this study focused on Western corporate contexts, Hofstede’s cultural dimensions theory suggests collectivist cultures (e.g., Japan) may exhibit heightened group harmony concerns, further deterring requests. Future research should:\n- Compare extension behaviors in high-power-distance vs. egalitarian cultures.\n- Track long-term effects of policy changes using controlled trials (e.g., A/B testing different policy formats across office branches).\n6.4 Theoretical Contributions\nThis work bridges gaps between clinical psychology and organizational behavior by:\n- Extending Cognitive Distortion Models: Demonstrating how workplace-specific distortions (e.g., \"extension = failure\") parallel maladaptive beliefs in anxiety disorders.\n- Redefining Procrastination: Proactive extension requests may represent strategic delay rather than avoidance, challenging traditional procrastination frameworks.",
    "ori_text": "Title: Psychological Barriers and Outcomes of Extension Requests in the Workplace: An Empirical Study‌\n\n‌Abstract‌\nThis study investigates the psychological factors influencing employees' decisions to request deadline extensions in professional settings, with a focus on self-presentation concerns, perceived negative evaluations, and organizational policies. Using a mixed-methods approach involving surveys and behavioral experiments, data were collected from 500 employees across diverse industries. Results indicate that concerns about self-image act as significant barriers to extension requests, while employees who proactively seek extensions demonstrate higher work quality. Gender differences reveal distinct interpersonal concerns affecting willingness to request extensions. The presence of formal extension policies significantly enhances request rates, suggesting actionable interventions for organizations. These findings underscore the need for psychological support mechanisms in workplace environments to mitigate cognitive biases and improve productivity.\n\n‌1. Introduction‌\nDeadline management is a critical aspect of workplace psychology, where employees often face pressures related to task completion and performance evaluations. Extension requests—formal appeals for additional time—represent a common yet understudied behavior in organizational psychology. Previous research has highlighted psychological barriers such as fear of negative judgment and self-presentation anxieties, which can deter employees from seeking necessary accommodations. The broader field of psychology emphasizes that cognitive distortions, including overestimation of negative outcomes, are pervasive in decision-making processes. For instance, studies on personality disorders reveal how maladaptive thought patterns exacerbate interpersonal conflicts, paralleling workplace dynamics where employees misjudge supervisors' reactions.8 This study integrates these insights to examine how psychological factors influence extension requests and their correlation with work outcomes. Theoretical frameworks from cognitive psychology and organizational behavior guide this inquiry, with hypotheses centered on gender disparities and policy impacts.\n\n‌2. Method‌\n‌2.1 Participants‌\nA total of 500 full-time employees (46% male, 54% female; mean age = 34.2 years, SD = 8.5) were recruited from technology, healthcare, and education sectors. Participants represented varied organizational roles, including entry-level staff (40%), middle management (35%), and senior executives (25%). Inclusion criteria required at least one year of employment to ensure familiarity with workplace protocols. Compensation included monetary incentives and confidentiality assurances.\n‌2.2 Design and Procedure‌\nA sequential mixed-methods design was employed, comprising:\n‌- Survey Phase‌: Participants completed an online questionnaire assessing self-presentation concerns (e.g., \"I worry that requesting an extension will make me seem incompetent\"), perceived supervisor reactions, and past extension behaviors. Scales used a 7-point Likert format, validated in prior cognitive psychology research for reliability (Cronbach’s α = 0.85).\n- ‌Experimental Phase‌: A subgroup of 200 participants engaged in a simulated task scenario involving urgent vs. non-urgent deadlines. Behavioral data on request timing, task quality, and post-request anxiety were recorded. Scenarios were counterbalanced to control for order effects.\n- Data collection occurred over three months, with ethics approval obtained from an institutional review board. All instruments adhered to APA guidelines for psychological assessments.\n‌2.3 Measures‌\nKey variables included:\n‌- Self-Presentation Concerns‌: Measured via the Workplace Anxiety Scale (WAS), adapted from studies on cognitive biases.\n‌- Work Quality‌: Evaluated using supervisor ratings on a 10-point scale for tasks completed with vs. without extensions.\n‌- Perceived Negative Evaluations‌: Captured through vignette-based questions derived from social psychology frameworks.\n- ‌Organizational Policies‌: Assessed by examining company handbooks and participant reports on formal extension protocols.\n\n‌3. Results‌\n‌3.1 Quantitative Findings‌\nResults from regression analyses revealed that self-presentation concerns were the strongest predictor of avoidance behaviors (β = 0.42, p < .001), accounting for 65% of variance in extension request reluctance. Employees who requested extensions exhibited 23% higher work quality scores (M = 8.2, SD = 1.1) compared to non-requesters (M = 6.7, SD = 1.5), supporting the hypothesis that proactive requests correlate with superior outcomes. Gender differences emerged significantly (p = .02), with women reporting higher interpersonal concerns (e.g., fear of burdening others) rather than self-competence doubts, aligning with trends in health psychology research on gendered communication patterns.\n‌3.2 Qualitative Insights‌\nThematic analysis of open-ended responses identified recurring themes:\n- Overestimation of negative supervisor evaluations was common across genders, with 78% of participants inflating perceived criticism.\n- In non-urgent task scenarios, supervisors prioritized quality over speed, reducing negative feedback when extensions were requested.\n- Formal organizational policies (e.g., clear request guidelines) boosted request willingness by 40%, mitigating psychological barriers through structured support.\n\n‌4. Discussion‌\nThis study demonstrates that psychological barriers to extension requests stem primarily from cognitive distortions, such as overestimating negative judgments, which align with broader findings in mental health research. The positive association between extension requests and work quality underscores that employees seeking accommodations engage in more deliberate task execution, challenging assumptions that extensions indicate poor performance. Gender-specific concerns highlight the need for tailored interventions, as women's reluctance is driven more by interpersonal dynamics than self-doubt—a nuance consistent with recent APA reports on workplace psychology trends.\nThe role of organizational policies emerges as a key moderator, reinforcing that formal structures reduce ambiguity and anxiety, thereby fostering psychological safety. Compared to prior studies on educational psychology, where deadline extensions are common, workplace contexts amplify barriers due to hierarchical dynamics. Limitations include reliance on self-reported data and sector-specific sampling, which may limit generalizability. Future research should explore cross-cultural variations and longitudinal designs to track behavioral changes over time.\n\n‌5. Conclusion‌\nEmployees' decisions to request deadline extensions are significantly influenced by psychological factors, including self-presentation fears and cognitive biases, with notable gender differences in underlying concerns. Organizations can enhance productivity and well-being by implementing formal extension policies and psychological support programs. This study contributes to workplace psychology by providing empirical evidence for interventions that address cognitive distortions, ultimately promoting healthier work environments.\n\n‌6. Extending the Research: Policy Interventions and Cognitive Mechanisms‌\nBuilding on the foundational findings of our study, this section explores actionable strategies for organizations and theoretical contributions to workplace psychology.\n6.1 Organizational Policy Design\nThe study’s results underscore that formal extension policies reduce psychological barriers by 40%, but their design requires nuance. Effective policies should:\n- Clarify Eligibility Criteria: Transparent guidelines (e.g., \"Extensions permitted for tasks exceeding 8 hours of work\") mitigate ambiguity-induced anxiety. A 2024 meta-analysis confirms that rule clarity decreases perceived request \"stigma\" by 31%.\n- Decentralize Approval Authority: Allowing team leads (vs. senior managers) to approve requests reduces hierarchical intimidation, particularly for junior employees.\n- Normalize Extensions as Productivity Tools: Case studies from tech firms show that framing extensions as \"quality optimization periods\" (e.g., Google’s \"20% time\" model) increases utilization without penalizing performance metrics.\n6.2 Cognitive-Behavioral Interventions\nEmployees’ overestimation of negative evaluations mirrors clinical findings in social anxiety research. Adapting therapeutic techniques could yield workplace benefits:\n- Reframing Exercises: Training sessions teaching employees to challenge cognitive distortions (e.g., \"My supervisor will think I’m lazy\") reduced avoidance behaviors by 22% in a pilot study.\n- Graded Exposure: Gradually increasing exposure to extension requests (e.g., starting with low-stakes tasks) builds confidence, akin to exposure therapy for phobias.\n- Feedback Loops: Anonymous peer data sharing (e.g., \"70% of your team requested extensions last quarter\") corrects pluralistic ignorance, where employees falsely assume they are outliers.\n6.3 Cross-Cultural and Longitudinal Gaps\nWhile this study focused on Western corporate contexts, Hofstede’s cultural dimensions theory suggests collectivist cultures (e.g., Japan) may exhibit heightened group harmony concerns, further deterring requests. Future research should:\n- Compare extension behaviors in high-power-distance vs. egalitarian cultures.\n- Track long-term effects of policy changes using controlled trials (e.g., A/B testing different policy formats across office branches).\n6.4 Theoretical Contributions\nThis work bridges gaps between clinical psychology and organizational behavior by:\n- Extending Cognitive Distortion Models: Demonstrating how workplace-specific distortions (e.g., \"extension = failure\") parallel maladaptive beliefs in anxiety disorders.\n- Redefining Procrastination: Proactive extension requests may represent strategic delay rather than avoidance, challenging traditional procrastination frameworks.",
    "reference_list": "考点1：”self-presentation concerns“应该译为“自我呈现顾虑”，是社会心理学的专业术语。\n考点2：”mixed-methods approach”应译为“混合方法研究”。\n考点3：“ognitive biases”不应译为“认知偏见”。\n考点4：”Cronbach’s α“应译为“克朗巴赫系数”，是统计学的专业术语。\n考点5：”Graded Exposure“应译为“分级暴露”。\n考点6：”with ethics approval obtained from an institutional review board”应翻译为”机构审查委员会的伦理批准“",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "35"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n2025年6月9日上午，江苏省选考化学、地理的考生完成了高考“成人礼”。在考场外，一位妈妈手捧顶流玩偶Labubu花束的身影格外引人注目，她的这一暖心举动，为紧张的高考增添了一抹别样的色彩。\n\n这位妈妈透露，女儿一直很喜欢Labubu，然而上学期间由于学业繁重，没怎么让她去购买。如今高考结束，她特意带着Labubu花束来迎接女儿，就是希望女儿能够开开心心的。在妈妈心中，高考只是人生中的一场考试，女儿永远是最棒的，她期待着女儿未来能做自己喜欢的事，成为想成为的人。这份深沉的爱与满满的仪式感，让人动容。\n\nLabubu的爆火并非偶然。从设计层面来看，它打破了传统玩具甜美的范式，走丑萌路线，尖耳朵、圆眼睛以及带有尖牙的露齿笑容，将可爱与神秘的气息巧妙融合，满足了年轻一代追求个性化表达的需求。在营销方面，泡泡玛特借助盲盒机制，通过推出限量版、隐藏版来制造稀缺性，极大地刺激了消费者的购买欲望。再加上明星效应和社交媒体的广泛传播，Labubu想不火都难。此外，它还推出各地特色限定款，如新加坡限定版鱼尾狮Labubu，精准适配了不同地区的本土化审美需求。\n\n近年来，高考考场外家长们的应援方式可谓花样百出。从传统的横幅、鲜花和拥抱，到如今的“烧烤花”“985现金花束”等，这些独特的应援背后，折射出当代家长的教育智慧和对孩子深深的爱。“烧烤花”承载着孩子备考期间对美食的念想，传递着父母无声的承诺：无论结果如何，生活本味永远值得期待；“985现金花束”则寄托了家长期盼孩子金榜题名、直抵顶尖学府的热望。\n\n教育专家指出，高考压力往往源于对“完美结局”的过度追求，家长应该学会“科学助攻”，用更理性、更贴心的方式支持孩子。比如，有的家长用Excel表格梳理考试日程，用便签纸记录孩子情绪波动，通过模拟填报志愿系统提前演练决策过程，这种“润物细无声”的支持，远比考场外的鲜花横幅更有力量。在漫漫人生长河中，总有一些时刻，宛如熠熠星辰，照亮我们前行的道路，成为生命中难以磨灭的珍贵记忆。对于无数中国学子而言，高考，无疑就是这样一个至关重要的时刻。它不仅仅是一场知识的检验，更是一场盛大的人生“成人礼”，承载着青春的梦想、奋斗的汗水，以及家庭的殷切期望。\n\n回到这位带Labubu花束的妈妈身上，她关注到了孩子的喜好和情绪，让孩子知道，高考不是终点，家人的爱与支持才是最坚实的后盾。这也给众多家长提了个醒，比起成绩，孩子的快乐和内心需求同样重要。高考只是人生的一个阶段，未来还有更多的可能性等待着孩子们去探索。希望每一位考生都能在家人的关爱和支持下，勇敢地迈向新的征程，实现自己的梦想。",
    "ori_text": "2025年6月9日上午，江苏省选考化学、地理的考生完成了高考“成人礼”。在考场外，一位妈妈手捧顶流玩偶Labubu花束的身影格外引人注目，她的这一暖心举动，为紧张的高考增添了一抹别样的色彩。\n\n这位妈妈透露，女儿一直很喜欢Labubu，然而上学期间由于学业繁重，没怎么让她去购买。如今高考结束，她特意带着Labubu花束来迎接女儿，就是希望女儿能够开开心心的。在妈妈心中，高考只是人生中的一场考试，女儿永远是最棒的，她期待着女儿未来能做自己喜欢的事，成为想成为的人。这份深沉的爱与满满的仪式感，让人动容。\n\nLabubu的爆火并非偶然。从设计层面来看，它打破了传统玩具甜美的范式，走丑萌路线，尖耳朵、圆眼睛以及带有尖牙的露齿笑容，将可爱与神秘的气息巧妙融合，满足了年轻一代追求个性化表达的需求。在营销方面，泡泡玛特借助盲盒机制，通过推出限量版、隐藏版来制造稀缺性，极大地刺激了消费者的购买欲望。再加上明星效应和社交媒体的广泛传播，Labubu想不火都难。此外，它还推出各地特色限定款，如新加坡限定版鱼尾狮Labubu，精准适配了不同地区的本土化审美需求。\n\n近年来，高考考场外家长们的应援方式可谓花样百出。从传统的横幅、鲜花和拥抱，到如今的“烧烤花”“985现金花束”等，这些独特的应援背后，折射出当代家长的教育智慧和对孩子深深的爱。“烧烤花”承载着孩子备考期间对美食的念想，传递着父母无声的承诺：无论结果如何，生活本味永远值得期待；“985现金花束”则寄托了家长期盼孩子金榜题名、直抵顶尖学府的热望。\n\n教育专家指出，高考压力往往源于对“完美结局”的过度追求，家长应该学会“科学助攻”，用更理性、更贴心的方式支持孩子。比如，有的家长用Excel表格梳理考试日程，用便签纸记录孩子情绪波动，通过模拟填报志愿系统提前演练决策过程，这种“润物细无声”的支持，远比考场外的鲜花横幅更有力量。在漫漫人生长河中，总有一些时刻，宛如熠熠星辰，照亮我们前行的道路，成为生命中难以磨灭的珍贵记忆。对于无数中国学子而言，高考，无疑就是这样一个至关重要的时刻。它不仅仅是一场知识的检验，更是一场盛大的人生“成人礼”，承载着青春的梦想、奋斗的汗水，以及家庭的殷切期望。\n\n回到这位带Labubu花束的妈妈身上，她关注到了孩子的喜好和情绪，让孩子知道，高考不是终点，家人的爱与支持才是最坚实的后盾。这也给众多家长提了个醒，比起成绩，孩子的快乐和内心需求同样重要。高考只是人生的一个阶段，未来还有更多的可能性等待着孩子们去探索。希望每一位考生都能在家人的关爱和支持下，勇敢地迈向新的征程，实现自己的梦想。",
    "reference_list": "考点1：顶尖 可译为 top-tier 或 elite 或其它正确词汇。\n考点2：烧烤花 需译为 barbecue bouquet，不可译为 barbecue flowers，此处是花束的意思。\n考点3：985现金花束 可译为 985 cash bouquet。\n考点4：对于“高考”的译法，全文应保持一致，不能既用college entrance examination，又用gaokao。",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "3"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nTHE RIGHT TO BE FORGOTTENJeffrey Rosen*At the end of January, the European Commissioner for Justice, Fundamen- tal Rights, and Citizenship, Viviane Reding, announced the European Commission’s proposal to create a sweeping new privacy right—the “right to be forgotten.” The right, which has been hotly debated in Europe for the past few years, has finally been codified as part of a broad new proposed data protection regulation. Although Reding depicted the new right as a modest expansion of existing data privacy rights, in fact it represents the biggest threat to free speech on the Internet in the coming decade. The right to be forgotten could make Facebook and Google, for example, liable for up to two percent of their global income if they fail to remove photos that people post about themselves and later regret, even if the photos have been widely distributed already. Unless the right is defined more precisely when it is promulgated over the next year or so, it could precipitate a dramatic clash between European and American conceptions of the proper balance between privacy and free speech, leading to a far less open Internet.In theory, the right to be forgotten addresses an urgent problem in the digital age: it is very hard to escape your past on the Internet now that every photo, status update, and tweet lives forever in the cloud. But Europeans and Americans have diametrically opposed approaches to the problem. In Europe, the intellectual roots of the right to be forgotten can be found in French law, which recognizes le droit à l’oubli—or the “right of oblivion”—a right that allows a convicted criminal who has served his time and been rehabilitated to object to the publication of the facts of his conviction and incarceration. In America, by contrast, publication of someone’s criminal history is protected by the First Amendment, leading Wikipedia to resist the efforts by two Germans convicted of murdering a famous actor to remove their criminal history from the actor’s Wikipedia page.European regulators believe that all citizens face the difficulty of escaping their past now that the Internet records everything and forgets nothing—a difficulty that used to be limited to convicted criminals. When Commissioner Reding announced the new right to be forgotten on January 22, she noted the particular risk to teenagers who might reveal compromising information that they would later come to regret. She then articulated the core provision of the “right to be forgotten”: “If an individual no longer wants his personal data to be processed or stored by a data controller, and if there is no legitimate reason for keeping it, the data should be removed from their system.” In endorsing the new right, Reding downplayed its effect on free speech. “It is clear that the right to be forgotten cannot amount to a right of the total erasure of history,” she said.3 And relying on Reding’s speeches, press accounts of the newly proposed right to be forgotten have been similarly reassuring about its effect on free speech. In a post at the Atlantic.com, Why Journalists Shouldn’t Fear Europe’s ‘Right to be Forgotten,’ John Hendel writes that although the original proposals a year ago “would have potentially given people the ability to cull any digital reference—from the public record, journalism, or social networks—they deemed irrelevant and unflattering,” Reding had proposed a narrower definition of data that people have the right to remove: namely “personal data [people] have given out themselves.”4 According to Hendel “[t]his provision is key. The overhaul insists that Internet users control the data they put online, not the references in media or anywhere else.” But Hendel seems not to have parsed the regulations that were actually proposed three days later on January 25. They are not limited to personal data that people “have given out themselves”; instead, they create a new right to delete personal data, defined broadly as “any information relating to a data subject.”6 For this reason, they arguably create a legally enforceable right to demand the deletion of any photos or data that I post myself, even after they’ve gone viral, not to mention unflattering photos that include me or information about me that others post, whether or not it is true. In a widely cited blog post last March, Peter Fleischer, chief privacy counsel of Google, notes that the right to be forgotten, as discussed in Europe, often covers three separate categories, each of which proposes progressively greater threats to free speech.7 And the right to be forgotten, as proposed at the end of January, arguably applies in all three of Fleischer’s categories.The first category is the least controversial: “If I post something online, do I have the right to delete it again?” This involves cases where I post a photo on Facebook and later think better of it and want to take it down. Since Facebook and other social networking sites already allow me to do this, creating a legally enforceable right here is mostly symbolic and entirely unobjectionable. As proposed, the European right to be forgotten would also usefully put pressure on Facebook to abide by its own stated privacy policies by allowing users to confirm that photos and other data have been deleted from its archives after they are removed from public display. But the right to delete data becomes far more controversial when it involves Fleischer’s second category: “If I post something, and someone else copies it and re-posts it on their own site, do I have the right to delete it?” Imagine a teenager regrets posting a picture of herself with a bottle of beer on her own site and after deleting it, later discovers that several of her friends have copied and reposted the picture on their own sites. If she asks them to take down the pictures, and her friends refuse or cannot be found, should Facebook be forced to delete the picture from her friends’ albums without the owners’ consent based solely on the teenager’s objection? According to the proposed European Right to Forget, the default answer is almost certainly yes. According to the regulation, when someone demands the erasure of personal data, an Internet Service Provider “shall carry out the erasure without delay,” unless the retention of the data is “necessary” for exercising “the right of freedom of expression,” as defined by member states in their local laws.",
    "ori_text": "THE RIGHT TO BE FORGOTTENJeffrey Rosen*At the end of January, the European Commissioner for Justice, Fundamen- tal Rights, and Citizenship, Viviane Reding, announced the European Commission’s proposal to create a sweeping new privacy right—the “right to be forgotten.” The right, which has been hotly debated in Europe for the past few years, has finally been codified as part of a broad new proposed data protection regulation. Although Reding depicted the new right as a modest expansion of existing data privacy rights, in fact it represents the biggest threat to free speech on the Internet in the coming decade. The right to be forgotten could make Facebook and Google, for example, liable for up to two percent of their global income if they fail to remove photos that people post about themselves and later regret, even if the photos have been widely distributed already. Unless the right is defined more precisely when it is promulgated over the next year or so, it could precipitate a dramatic clash between European and American conceptions of the proper balance between privacy and free speech, leading to a far less open Internet.In theory, the right to be forgotten addresses an urgent problem in the digital age: it is very hard to escape your past on the Internet now that every photo, status update, and tweet lives forever in the cloud. But Europeans and Americans have diametrically opposed approaches to the problem. In Europe, the intellectual roots of the right to be forgotten can be found in French law, which recognizes le droit à l’oubli—or the “right of oblivion”—a right that allows a convicted criminal who has served his time and been rehabilitated to object to the publication of the facts of his conviction and incarceration. In America, by contrast, publication of someone’s criminal history is protected by the First Amendment, leading Wikipedia to resist the efforts by two Germans convicted of murdering a famous actor to remove their criminal history from the actor’s Wikipedia page.European regulators believe that all citizens face the difficulty of escaping their past now that the Internet records everything and forgets nothing—a difficulty that used to be limited to convicted criminals. When Commissioner Reding announced the new right to be forgotten on January 22, she noted the particular risk to teenagers who might reveal compromising information that they would later come to regret. She then articulated the core provision of the “right to be forgotten”: “If an individual no longer wants his personal data to be processed or stored by a data controller, and if there is no legitimate reason for keeping it, the data should be removed from their system.” In endorsing the new right, Reding downplayed its effect on free speech. “It is clear that the right to be forgotten cannot amount to a right of the total erasure of history,” she said.3 And relying on Reding’s speeches, press accounts of the newly proposed right to be forgotten have been similarly reassuring about its effect on free speech. In a post at the Atlantic.com, Why Journalists Shouldn’t Fear Europe’s ‘Right to be Forgotten,’ John Hendel writes that although the original proposals a year ago “would have potentially given people the ability to cull any digital reference—from the public record, journalism, or social networks—they deemed irrelevant and unflattering,” Reding had proposed a narrower definition of data that people have the right to remove: namely “personal data [people] have given out themselves.”4 According to Hendel “[t]his provision is key. The overhaul insists that Internet users control the data they put online, not the references in media or anywhere else.” But Hendel seems not to have parsed the regulations that were actually proposed three days later on January 25. They are not limited to personal data that people “have given out themselves”; instead, they create a new right to delete personal data, defined broadly as “any information relating to a data subject.”6 For this reason, they arguably create a legally enforceable right to demand the deletion of any photos or data that I post myself, even after they’ve gone viral, not to mention unflattering photos that include me or information about me that others post, whether or not it is true. In a widely cited blog post last March, Peter Fleischer, chief privacy counsel of Google, notes that the right to be forgotten, as discussed in Europe, often covers three separate categories, each of which proposes progressively greater threats to free speech.7 And the right to be forgotten, as proposed at the end of January, arguably applies in all three of Fleischer’s categories.The first category is the least controversial: “If I post something online, do I have the right to delete it again?” This involves cases where I post a photo on Facebook and later think better of it and want to take it down. Since Facebook and other social networking sites already allow me to do this, creating a legally enforceable right here is mostly symbolic and entirely unobjectionable. As proposed, the European right to be forgotten would also usefully put pressure on Facebook to abide by its own stated privacy policies by allowing users to confirm that photos and other data have been deleted from its archives after they are removed from public display. But the right to delete data becomes far more controversial when it involves Fleischer’s second category: “If I post something, and someone else copies it and re-posts it on their own site, do I have the right to delete it?” Imagine a teenager regrets posting a picture of herself with a bottle of beer on her own site and after deleting it, later discovers that several of her friends have copied and reposted the picture on their own sites. If she asks them to take down the pictures, and her friends refuse or cannot be found, should Facebook be forced to delete the picture from her friends’ albums without the owners’ consent based solely on the teenager’s objection? According to the proposed European Right to Forget, the default answer is almost certainly yes. According to the regulation, when someone demands the erasure of personal data, an Internet Service Provider “shall carry out the erasure without delay,” unless the retention of the data is “necessary” for exercising “the right of freedom of expression,” as defined by member states in their local laws.",
    "reference_list": "考点1：“codified”应译为“编入法典”\n考点2：“First Amendment”应译为“第一修正案”\n考点3：“think better of it”应译为“改变了主意”\n考点4：“legally enforceable right”应译为“具有法律强制执行力的权利“",
    "Primary_Domain": "垂类场景",
    "Secondary_Domain": "法律",
    "prompt_id": "46"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\n\nToni Morrison, born Chloe Anthony Wofford in 1931, was the second of four children. Her father, a shipyard welder and a gifted storyteller, and her mother, a religious woman skilled at singing church songs, moved from the South to Ohio, hoping to raise their children in an environment more welcoming to Black people. Although they had moved to the North, the Woffords maintained a family atmosphere where the oral traditions of Southern Black culture remained highly influential. Undoubtedly, this family atmosphere, filled with songs, stories, and women’s gossip, had a profound impact on her creative writing. A significant aspect of Morrison's literary endeavor has been to craft a distinct voice for Black Americans, one that draws its strength from the oral art forms of Afro-American culture.\n\nExamples of this oral tradition are found throughout Morrison’s novels, where music is used as a tool to express the joys and soothe the sorrows of Black people. This Africanist musical language was often inaccessible to a white audience. By grounding her literary craftsmanship in Black musical traditions, she consciously distances herself from mainstream Anglo-American writers. Through her multi-layered lyrical narration, interweaving stories with music, myth, and other oral forms, Morrison offers readers vivid portrayals of the African-American experience—their love, loneliness, struggles, quests, traditions, and history. The characters and places she created, the scenes she imagined, and her explorations of humanity and bittersweet love all constitute an oeuvre unparalleled in contemporary American literature.\n\nMorrison’s ability to intricately draw on these traditions stems from her rich personal experience. In a 1992 interview, she stated that she considers herself lucky to have learned two languages: “one from books and the other from the storytelling at large family gatherings that always took place when someone came up from the South.” This childhood experience is reflected in her unique writing style, which masterfully combines modern literary forms with ancient modes of discourse.\n\nMusic, in particular, held a special power for Morrison. Raised in a music-rich environment, she was surrounded by a family of musicians, including her mother and grandparents. She recalled waking up to her mother’s voice each morning, learning to understand its subtle nuances—its tone, volume, and timbre—which conveyed whether her mother was happy, sad, or angry. In her childhood world, the sound of music often spoke more powerfully than the words themselves.\n\nThough immersed in this environment, Morrison was a listener rather than a performer. Claiming no natural gift for music, she recalled with frustration being sent with her sister to learn piano from a book. This theme of a complex relationship with music—both as a source of cultural heritage and a marker of social status—is powerfully explored in her novel Song of Solomon.\n\nThe novel presents characters whose identities are deeply tied to their acceptance or rejection of their musical heritage. For instance, Macon Dead II, who has become well-off and successful, strives to climb the social ladder. As a result, he rejects his sister, Pilate, because of her low social status and her deep connection to their family’s folk traditions. By all accounts, Pilate is a peculiar old woman who makes a living selling bootleg whiskey and lives without modern conveniences. Yet, she is the keeper of the family’s history, which she preserves in the songs she sings—a responsibility she believes was dictated to her by her father’s ghost. Despite his snobbery, Macon cannot resist the temptation of sneaking around Pilate’s house, listening to the three women inside singing by candlelight. He is caught in a dilemma, torn between the restrictive sophistication required for upward mobility and the free, soul-soothing musical expressions emanating from his sister’s home.\n\nUltimately, Macon chooses to reject Pilate and her music, thereby detaching himself from his family's history and roots. It is his son, Milkman, who embarks on a journey to seek his own identity, a journey that involves reconnecting with the very traditions his father spurned. This quest for self-discovery is intertwined with a mysterious song that holds the key to his family’s past.\n\nThe song first appears in the novel on the night of Milkman’s birth. As a man in blue wings attempts suicide, Pilate stands on the hospital steps and begins to sing “in a powerful contralto.” The song, considered the novel's most valuable treasure, is sung by children and elders, evolving as it is passed down. It interweaves the myth of a flying African slave with the history of the Dead family. This act of storytelling through music embeds Afro-American mythology into the family's oral tradition, ensuring it is handed down from generation to generation.\n\nWhen asked about the \"flying African\" myth, Morrison explained that while she found references to it in slave narratives, she could not find hard data on its origins. She believed this was precisely its power. Myth, she argued, is “the way people learn narrative. Myth is the first information there is, and it conveys far more than what is explicitly stated.” It is clear that Morrison has faith in the ability of myth to communicate profound, nonspecific knowledge. In Song of Solomon, she gives voice to music to unearth this mythic core, providing a framework for the novel’s central themes of history, identity, and freedom.",
    "ori_text": "Toni Morrison, born Chloe Anthony Wofford in 1931, was the second of four children. Her father, a shipyard welder and a gifted storyteller, and her mother, a religious woman skilled at singing church songs, moved from the South to Ohio, hoping to raise their children in an environment more welcoming to Black people. Although they had moved to the North, the Woffords maintained a family atmosphere where the oral traditions of Southern Black culture remained highly influential. Undoubtedly, this family atmosphere, filled with songs, stories, and women’s gossip, had a profound impact on her creative writing. A significant aspect of Morrison's literary endeavor has been to craft a distinct voice for Black Americans, one that draws its strength from the oral art forms of Afro-American culture.\n\nExamples of this oral tradition are found throughout Morrison’s novels, where music is used as a tool to express the joys and soothe the sorrows of Black people. This Africanist musical language was often inaccessible to a white audience. By grounding her literary craftsmanship in Black musical traditions, she consciously distances herself from mainstream Anglo-American writers. Through her multi-layered lyrical narration, interweaving stories with music, myth, and other oral forms, Morrison offers readers vivid portrayals of the African-American experience—their love, loneliness, struggles, quests, traditions, and history. The characters and places she created, the scenes she imagined, and her explorations of humanity and bittersweet love all constitute an oeuvre unparalleled in contemporary American literature.\n\nMorrison’s ability to intricately draw on these traditions stems from her rich personal experience. In a 1992 interview, she stated that she considers herself lucky to have learned two languages: “one from books and the other from the storytelling at large family gatherings that always took place when someone came up from the South.” This childhood experience is reflected in her unique writing style, which masterfully combines modern literary forms with ancient modes of discourse.\n\nMusic, in particular, held a special power for Morrison. Raised in a music-rich environment, she was surrounded by a family of musicians, including her mother and grandparents. She recalled waking up to her mother’s voice each morning, learning to understand its subtle nuances—its tone, volume, and timbre—which conveyed whether her mother was happy, sad, or angry. In her childhood world, the sound of music often spoke more powerfully than the words themselves.\n\nThough immersed in this environment, Morrison was a listener rather than a performer. Claiming no natural gift for music, she recalled with frustration being sent with her sister to learn piano from a book. This theme of a complex relationship with music—both as a source of cultural heritage and a marker of social status—is powerfully explored in her novel Song of Solomon.\n\nThe novel presents characters whose identities are deeply tied to their acceptance or rejection of their musical heritage. For instance, Macon Dead II, who has become well-off and successful, strives to climb the social ladder. As a result, he rejects his sister, Pilate, because of her low social status and her deep connection to their family’s folk traditions. By all accounts, Pilate is a peculiar old woman who makes a living selling bootleg whiskey and lives without modern conveniences. Yet, she is the keeper of the family’s history, which she preserves in the songs she sings—a responsibility she believes was dictated to her by her father’s ghost. Despite his snobbery, Macon cannot resist the temptation of sneaking around Pilate’s house, listening to the three women inside singing by candlelight. He is caught in a dilemma, torn between the restrictive sophistication required for upward mobility and the free, soul-soothing musical expressions emanating from his sister’s home.\n\nUltimately, Macon chooses to reject Pilate and her music, thereby detaching himself from his family's history and roots. It is his son, Milkman, who embarks on a journey to seek his own identity, a journey that involves reconnecting with the very traditions his father spurned. This quest for self-discovery is intertwined with a mysterious song that holds the key to his family’s past.\n\nThe song first appears in the novel on the night of Milkman’s birth. As a man in blue wings attempts suicide, Pilate stands on the hospital steps and begins to sing “in a powerful contralto.” The song, considered the novel's most valuable treasure, is sung by children and elders, evolving as it is passed down. It interweaves the myth of a flying African slave with the history of the Dead family. This act of storytelling through music embeds Afro-American mythology into the family's oral tradition, ensuring it is handed down from generation to generation.\n\nWhen asked about the \"flying African\" myth, Morrison explained that while she found references to it in slave narratives, she could not find hard data on its origins. She believed this was precisely its power. Myth, she argued, is “the way people learn narrative. Myth is the first information there is, and it conveys far more than what is explicitly stated.” It is clear that Morrison has faith in the ability of myth to communicate profound, nonspecific knowledge. In Song of Solomon, she gives voice to music to unearth this mythic core, providing a framework for the novel’s central themes of history, identity, and freedom.",
    "reference_list": "考点1：“church songs”推荐译为“颂歌”或“圣歌”\n考点2：“women’s gossip”推荐译为“女性絮语”或“女性八卦”\n考点3：“oral tradition”推荐译为“口头传统”\n考点4：“flying African”推荐译为“黑人会飞”\n考点5：“Milkman”推荐译为“奶娃”\n考点6：“bootleg whiskey”推荐译为“私酿酒”或“私酿威士忌”，不能译为“私酒”\n考点7：“his sister”需翻译成“他妹妹”，翻译成“他姐姐”错误",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "人文科学",
    "prompt_id": "15"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n3.1测绘地理信息技术在矿产勘探中的应用\n\n　　在矿产作业中，有效的矿产勘探施工一方面能够提升后续施工的效率，节约施工中不必要的人力、物力成本；另一方面也能够提高后续施工作业的安全性，通过准确的数据来保障工作人员的人身安全和企业的财产安全。在传统的矿产勘探工作中，勘探工作主要以人力为主，以相应的机械设备为辅助。这一种勘探方式不仅无法做到精准分析相应的地理数据，更有可能对矿产附近的水土环境进行破坏，造成难以弥补的损失。\n\n　　除此之外，人工作业也存在着安全弊端。在部分水土流失严重的地区进行人工作业还有可能发生滑坡等危险，不利于矿产勘探工作的顺利开展。在信息技术不断发展的过程中，地质勘查工作必然会应用到测绘地理信息技术，它能够通过相应的数据采集设备将矿产的深度以及矿产所处的地质图层进行数据收集，将收集到的数据传输到计算机系统中，通过相应的信息技术转化为工程人员能够看懂的数据分析报告和三维效果图，对矿产能否开发及开发的危险进行系统性分析。\n\n　　同传统的矿产勘探工作相比，测绘地理信息技术具有以下几方面的优势：①地理测绘信息技术以信息技术取代传统的人工测绘，极大地降低了企业的人力成本支出，提升了企业的经济效率；②人工成本的减少也能够增加矿场勘测人员的人身安全性，保障施工人员的安全；③随着信息技术的不断发展，测绘地理信息技术也能够不断更新更加准确的地理数据信息，为后续施工方案的制定及矿产的开发奠定良好的数据基础。\n\n3.2测绘地理信息技术在工程测绘中的应用\n\n　　在施工工程前期的工作准备中，地质勘探工作是保障工程测绘有效性的重要工作内容之一。而传统的地质信息数据收集需要考虑到天气环境、土壤土质等多种因素的影响，需要耗费企业大量的人力、物力成本进行多次测量。但是在测绘地理信息技术应用的过程中，该技术能够有效降低施工企业的成本，提升施工企业测绘工作的有效性及数据精的准性。在工程测绘中，测绘地理信息技术的应用主要有以下几个方面：①以测绘技术代替传统的人工多次测量能够通过矢量的方式来保存勘察地区的地理信息数据，并将相关数据上传到计算机系统中进行数据分析。这样一方面能够提升数据勘测的精准性，另一方面也能够加强数据的保存以及分析，通过先进的计算机系统来保障数据分析的精准性，为后续的施工图纸、施工方案制定打下坚实的基础。②测绘地理信息技术也能够提高数据的精准性。测绘地理信息技术在测量时需要应用到许多精密的仪器以及先进的设备技术。这些设备技术是目前地质勘测领域所能做到的数据误差最小、数据精准度最高的技术设备。因此同传统的工程测绘工作相比，该项技术的测绘成果要更加精准，能够保证数据的精准性。③在工程测绘中，测绘地理信息技术能够将收集到的地质信息等相关地理信息上传到计算机系统中，并由计算机系统进行三维建模处理，对不同的数据进行系统分析，给出相应的三维效果图，为后续的施工奠定良好的基础。这样能够帮助专业人员以更加直观的方式了解到该地区的地质信息。除了工程测绘外，三维效果图还被广泛地应用在交通作业、地质信息收集等场景，它以更加直观、更加便于人们理解、更加精准等的优点成为了人们施工作业中的常见技术之一。",
    "ori_text": "3.1测绘地理信息技术在矿产勘探中的应用\n\n　　在矿产作业中，有效的矿产勘探施工一方面能够提升后续施工的效率，节约施工中不必要的人力、物力成本；另一方面也能够提高后续施工作业的安全性，通过准确的数据来保障工作人员的人身安全和企业的财产安全。在传统的矿产勘探工作中，勘探工作主要以人力为主，以相应的机械设备为辅助。这一种勘探方式不仅无法做到精准分析相应的地理数据，更有可能对矿产附近的水土环境进行破坏，造成难以弥补的损失。\n\n　　除此之外，人工作业也存在着安全弊端。在部分水土流失严重的地区进行人工作业还有可能发生滑坡等危险，不利于矿产勘探工作的顺利开展。在信息技术不断发展的过程中，地质勘查工作必然会应用到测绘地理信息技术，它能够通过相应的数据采集设备将矿产的深度以及矿产所处的地质图层进行数据收集，将收集到的数据传输到计算机系统中，通过相应的信息技术转化为工程人员能够看懂的数据分析报告和三维效果图，对矿产能否开发及开发的危险进行系统性分析。\n\n　　同传统的矿产勘探工作相比，测绘地理信息技术具有以下几方面的优势：①地理测绘信息技术以信息技术取代传统的人工测绘，极大地降低了企业的人力成本支出，提升了企业的经济效率；②人工成本的减少也能够增加矿场勘测人员的人身安全性，保障施工人员的安全；③随着信息技术的不断发展，测绘地理信息技术也能够不断更新更加准确的地理数据信息，为后续施工方案的制定及矿产的开发奠定良好的数据基础。\n\n3.2测绘地理信息技术在工程测绘中的应用\n\n　　在施工工程前期的工作准备中，地质勘探工作是保障工程测绘有效性的重要工作内容之一。而传统的地质信息数据收集需要考虑到天气环境、土壤土质等多种因素的影响，需要耗费企业大量的人力、物力成本进行多次测量。但是在测绘地理信息技术应用的过程中，该技术能够有效降低施工企业的成本，提升施工企业测绘工作的有效性及数据精的准性。在工程测绘中，测绘地理信息技术的应用主要有以下几个方面：①以测绘技术代替传统的人工多次测量能够通过矢量的方式来保存勘察地区的地理信息数据，并将相关数据上传到计算机系统中进行数据分析。这样一方面能够提升数据勘测的精准性，另一方面也能够加强数据的保存以及分析，通过先进的计算机系统来保障数据分析的精准性，为后续的施工图纸、施工方案制定打下坚实的基础。②测绘地理信息技术也能够提高数据的精准性。测绘地理信息技术在测量时需要应用到许多精密的仪器以及先进的设备技术。这些设备技术是目前地质勘测领域所能做到的数据误差最小、数据精准度最高的技术设备。因此同传统的工程测绘工作相比，该项技术的测绘成果要更加精准，能够保证数据的精准性。③在工程测绘中，测绘地理信息技术能够将收集到的地质信息等相关地理信息上传到计算机系统中，并由计算机系统进行三维建模处理，对不同的数据进行系统分析，给出相应的三维效果图，为后续的施工奠定良好的基础。这样能够帮助专业人员以更加直观的方式了解到该地区的地质信息。除了工程测绘外，三维效果图还被广泛地应用在交通作业、地质信息收集等场景，它以更加直观、更加便于人们理解、更加精准等的优点成为了人们施工作业中的常见技术之一。",
    "reference_list": "考点1：“测绘地理信息技术”推荐译为“Surveying and Geographic Information Technology”\n考点2：“矿产勘探”推荐译为“mineral exploration”\n考点3：“人工作业”推荐译为“manual operation”\n考点4：“滑坡”需要译为“landslide”\n考点5：“地质图层”推荐译为“geological stratification”\n考点6：“人力成本支出”推荐译为“labor costs”\n考点7：“有效性”推荐译为“validity”\n考点8：“多次测量”推荐译为“repetitive measurements”\n考点9：“水土环境”推荐译为“local ecosystem”\n考点10：“三维效果图”推荐译为“3D models”，不能译为“3D renderings”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "10"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\nMemorandum No.5 \nPreventive Service\nAntung Custom House \nto The Chief Secretary, Inspectorate General of Custom\n\nI find the position here more clearly defined than I had expected. It can be stated in a few lines.\nFrom Japanese territory on the Corea side of the Yalu River, and across that river: the water of one half of which is claimed expressly, the other half also by suggestion, by the Japanese; and so to the Japanese settlement of the South Manchurian Railway zone at Antung, - Chinese soil but again entirely under Japanese control, - dutiable goods have, since the imposing of the new tariff this year, been increasingly smuggled by boat.\nOnce landed within the settlement limits the cargo is safe, either for consumption within Antung settlement or to be put on the railway – also under Japanese control – where it can then be conveyed without Customs intervention into Manchuria and discharged duty free at any point.\nThe Chinese customs function in Antung under the following limitations. They exercise adequate control, over the direct import by railway, at the first station after the river crossing. They maintain little more than a face-value footing on a narrow depth, undefined, along the water front. Within the settlement they are unsupported by Chinese authority; Chinese police being entirely excluded from operating. (Even the Chinese post office may not function in the settlement.) Japanese police and the settlement authorities are less than lukewarm in their supports. The public generally barely concedes us the prerogatives of a Government office. Corean and other low-class roughs openly defy, and when occasion demands maltreat out officers, rushing goods through, by boat or sledge, by sheer force.\nSmuggling is non-existent outside the settlement limits. There is no problem there at present. It may be taken that the goal of the smuggled cargoes is for the most part the railway: for distribution, in whole or broken into smaller packages, up country.\nThe problem before the Customs is: whether, by means, say, of armed patrol vessels in the river, to maintain the check that our own Government cannot, and the Japanese will not, provide ashore; or whether, by increased staffing or by means of new stations, to attempt to cover the ground support to the Japanese authorities. The only alternative must be that of a withdrawal to, or the forming of an additional barrier at, some region behind this virtual bridgehead against the Chinese Customs. This last is not practicable on several grounds; moreover, while accounting for cargo leaving there for inland would not deal – as the Customs existing first station on the line does not deal – with smuggled cargoes remaining in the settlement for consumption there.\nTo take the first: strong measures are impracticable for the following reasons:\nThe entire breadth of the river is, in reality, claimed by the Japanese. Were it decided to police the waterfront by means of floating craft – a method that would at best only account for eight months in the year, the remaining months being icebound – the first use of armed force would probably be given the prominence of an “incident”. Apart from this, too, such floating guard would be largely wasted. Goods on their way across from the other side are still within their right. Our duty-collecting stations are on the shore. Until they have attempted to pass these they are within the law.\nBy shore patrols still less would the Japanese permit the use of arms; and in a conflict with smugglers our officers would be, and have already been, treated equally with the smugglers as breaking the peace.\nI do not recommend any steps in the direction of force to meet the situation in the Antung district nor do I think that even another motor boat would appreciably assist such a situation.\nSmuggling by boat or sledge across the river in order to avoid the Customs at the first station on the railway has existed since the opening of the place in 1907. It did not under the old tariff amount to a serious matter for the revenue and the cases brought forward to the Inspectorate rose largely from clandestine movements of rice and salt. With the higher tariff Shingishu (Hsin Wiju) on the Corean side began to be made a depot for cargo destined to be ferried across the river to Antung.\nThe idea of using force being put on one side and the status of the Japanese Railway zone Settlement being what it is, the Customs can only press the Authorities there for what improvement it can secure intreatment. This was done upon the introduction of the higher tariff and there seems reason to see in the Japanese official attitude some realization that greater support must be lent to the Chinese Customs. This is the line that was followed by the late Commissioner, Mr. Fukumoto and his line of action is now being followed up by the present Commissioner, Mr. Bessell.\nJapanese administration on the two sides of the river falls under two distinct authorities, both as to Government and Railway management. On the Shingishu side is the Japanese “Department” of Chosen; on the Antung side is the South Manchurian Railway under the Kwangtung Government, the headquarters of which is situated at Port Arthur.\nEarly in the year Mr. Fukumoto made representations to the Japanese Consul at Antung and as a result two definite steps were effected:\n(a) Japanese merchants were instructed by the authorities at Seoul (Keicho) through the Commissioner of Japanese Customs at Shingishu : “to avail themselves of the railway” when importing goods across the river into Antung.\n(b) the Kwangtung Government at Port Arthur instructed the Consul at Antung that police in the settlement were to “assist the Customs by sending patrols along the foreshore to direct smugglers to report and pay the proper duties”; and by further issuing “a severe warning to suspected smugglers to abandon their practices in future.”\nRegarding the first of these: Mr. Inouye, Commissioner of Japanese Customs at Shingishu tells me that this order is absolutely obeyed. Goods, he said, are no longer stored in the warehouses on the riverside there by the cargo brokers, of whom there are five, licensed by the Customs. And the hundred Corean coolies who used to work the cargo there (and no doubt across the river) have now gone over to Antung to seek work on that side: - “There, probably,” Mr. Inouye added, “to turn their abilities to smuggling against the Japanese side of the water!\nAnd Mr. Bessell says that since the above orders were promulgated the Antung Customs receipts have risen appreciably and show directly the effect of the new rule as far as Shingishu side is concerned.\nMr. Usami, Japanese Consul at Antung, states that he thinks that this riverine smuggling will be “practically put an end to” by the new orders. This is as it may be of course. But no doubt something has been accomplished and this is the line that we must continue to follow, pressing fore the full carrying out of the Japanese promises. That the Customs must rest content with these measures granted by the Japanese; measures which, by the lapse of time may tend to be less thoroughly carried out, or, in their turn, may come to be countered by the smuggling fraternity, is to be deplored; but in the circumstances of our establishment at Antung and of China’s inability to secure a stronger position for us, there seems no present alternative.\nI believe, however, that no little can be done to “clinch” these arrangements officially in higher places, by a visit to the Governor General at Seoul and, thereafter, to the Governor General at Port Arthur, and this I propose to do in the course of the next week.\nThen there are certain further steps that can be taken by the Customs; these are:\n(a) the opening, already proposed, of a station of the Customs at Liutaokou.\n(b) that we should avail ourselves of our right, already established under noted exchanged at the signing of the Customs Railway Agreement of 1919, signed by the Inspector General of Customs and Ijuin, Japanese Minister (River Yalu Frontier Trade Agreement, 1913: pp 775/9, Vol. II, Treaties , Conventions, etc., No: 3. Miscellaneous Serious: No. 30.); and open a Chinese Customs Office on the Corean side of the Yalu.\nWith regard to (a) : The opening of a station at Liutaokou, which is the spot to which this smuggling across the river is carried out, may be said to be a necessary measure if only for the reason that trade is developing towards that end of the settlement; while it will deprive those landing in that neighbourhood with dutiable cargo of their present not altogether unfounded excuse, namely, that it is a mile and a half further up-stream to get to the Customs. The details of carrying this out should be easy of accomplishment with the help of the officials.\nWith reference to (b): we come here to something rather more important, requiring, as it would, some negotiation with the Corean Government before it could be effected.\nIt would give us the advantage of a lookout established upon the farther side of the river. Now that we know definite instructions have been reveived by the Japanese Customs there to discourage the shipping of cargo across the river our presence on the spot would assist in keeping them up to the mark. Duty on such exports as may leave there would be collected by such an office; but its principla use would be as a watch on river traffic.\nNo very great amount of smuggling can occur except of goods that have been brought there by the railway. And this involves temporary storage there; for the Japanese Customs which is in a strong position and keeps a firm hand over shippers no less than importers, permits no export without full formality. With closer relations with the Japanese Customs on the Corean side there should result a mutual assistance that does not spring from the present proximity of the two Customs’ working at the railway station.\nThe Japanese duties are far higher than ours; and the Shingishu Customs maintains a system of patrol along 25 miles of the Corean bank of the River, the upkeep of which, exclusive of buildings, is Yen 330000 per annum. The assistance that the Chinese Customs could render, therefore, must at least equal what we should be asking of them. It is in the direction of such mutual working that we should try to move. Smuggling will never be entirely eradicable by any system in a district poor, full of the turbulent characters associated with frontiers, and lending itself particularly, as regards ground, to clandestine operations. But smuggling in any wholesale form could not flourish greatly with the two Customs’ acting under a fair degree of understanding and good relations.\nI propose, therefore, to discuss the question of opening such an office with the Corean Authorities in a few days.\nThere is one last proposition that I believe should be considered:\n(c) the borrowing of a police guard from the Antung settlement authorities for the protection of Customs officers.\nSince Chinese police may not operate and armed Customs officers are regarded askance in the Settlement, the Antung authorities might, by arrangement, detail a certain makes of police in uniform for a permanent guard to the Customs. These guards would be paid for by us through the Police Department. They would not function as Custom officers; but where rough treatment at the hands of Coreans or others was apprehended they would be detailed under our orders for duty; that duty being only the protection of our officers acting as any Customs officer is expected to act, and must be free to act. I suggest that about twelve such police would be sufficient. They would be under the orders of their own Police Chief except – as above noted – regarding the details of actual post for the time being.\nI have discussed this suggestion with the Japanese Consul and he will look into the arguments for and against it with his Chief of police; regarding it, of course, as merely a tentative suggestion and not as definite arrangement. I propose to go into this question on the same basis with the Governor General – or whoever may discuss these questions with me – when I reach Port Arthur. \nEverything considered I do not regard the question of smuggling at Antung as so grave a one as I had expected to find it. This does not mean that it is not recognized that there has been a deplorable loss to the revenue under the circumstances that have obtained. But I think this has been the result of the hiatus in Customs powers here of the early part of this year and is not a question impossible to deal with. The increase this spring in the tariff caught Customs methods napping at Antung as it has done elsewhere. In seeking the obvious changes in practice called for by the new demands upon us ground has had to be crossed that was in a high degree delicate and demanded a full measure of time and discussion.\nWhen it is said that the status of the Railway Settlement of Antung is hopelessly inequitable to China everything has been said. It is not justifiable to ascribe to individuals, nor even to local and subordinate administrations, the faults in a system so perverse and difficult to handle. The required adjustments in procedure take time to bring about. But Mr. Fukumoto’s appeal through the local Consul appears to have received at the hands of the Various authorities who had to be consulted, quite a fair reception and response, and orders were in the course of time given which have already commenced to show satisfactory results. The further proposals for the consideration of the Inspector General now being forwarded will serve further to prevent loss of revenue on any large scale. All that will then be called for will be some extra activity and watchfulness on our part to see that the new safeguards – such as they are – are at least given their full chance.\nI will report in a later memorandum upon the outcome of my interviews with the Authorities at Seoul and Port Arthur.",
    "ori_text": "\n\nMemorandum No.5 \nPreventive Service\nAntung Custom House \nto The Chief Secretary, Inspectorate General of Custom\n\nI find the position here more clearly defined than I had expected. It can be stated in a few lines.\nFrom Japanese territory on the Corea side of the Yalu River, and across that river: the water of one half of which is claimed expressly, the other half also by suggestion, by the Japanese; and so to the Japanese settlement of the South Manchurian Railway zone at Antung, - Chinese soil but again entirely under Japanese control, - dutiable goods have, since the imposing of the new tariff this year, been increasingly smuggled by boat.\nOnce landed within the settlement limits the cargo is safe, either for consumption within Antung settlement or to be put on the railway – also under Japanese control – where it can then be conveyed without Customs intervention into Manchuria and discharged duty free at any point.\nThe Chinese customs function in Antung under the following limitations. They exercise adequate control, over the direct import by railway, at the first station after the river crossing. They maintain little more than a face-value footing on a narrow depth, undefined, along the water front. Within the settlement they are unsupported by Chinese authority; Chinese police being entirely excluded from operating. (Even the Chinese post office may not function in the settlement.) Japanese police and the settlement authorities are less than lukewarm in their supports. The public generally barely concedes us the prerogatives of a Government office. Corean and other low-class roughs openly defy, and when occasion demands maltreat out officers, rushing goods through, by boat or sledge, by sheer force.\nSmuggling is non-existent outside the settlement limits. There is no problem there at present. It may be taken that the goal of the smuggled cargoes is for the most part the railway: for distribution, in whole or broken into smaller packages, up country.\nThe problem before the Customs is: whether, by means, say, of armed patrol vessels in the river, to maintain the check that our own Government cannot, and the Japanese will not, provide ashore; or whether, by increased staffing or by means of new stations, to attempt to cover the ground support to the Japanese authorities. The only alternative must be that of a withdrawal to, or the forming of an additional barrier at, some region behind this virtual bridgehead against the Chinese Customs. This last is not practicable on several grounds; moreover, while accounting for cargo leaving there for inland would not deal – as the Customs existing first station on the line does not deal – with smuggled cargoes remaining in the settlement for consumption there.\nTo take the first: strong measures are impracticable for the following reasons:\nThe entire breadth of the river is, in reality, claimed by the Japanese. Were it decided to police the waterfront by means of floating craft – a method that would at best only account for eight months in the year, the remaining months being icebound – the first use of armed force would probably be given the prominence of an “incident”. Apart from this, too, such floating guard would be largely wasted. Goods on their way across from the other side are still within their right. Our duty-collecting stations are on the shore. Until they have attempted to pass these they are within the law.\nBy shore patrols still less would the Japanese permit the use of arms; and in a conflict with smugglers our officers would be, and have already been, treated equally with the smugglers as breaking the peace.\nI do not recommend any steps in the direction of force to meet the situation in the Antung district nor do I think that even another motor boat would appreciably assist such a situation.\nSmuggling by boat or sledge across the river in order to avoid the Customs at the first station on the railway has existed since the opening of the place in 1907. It did not under the old tariff amount to a serious matter for the revenue and the cases brought forward to the Inspectorate rose largely from clandestine movements of rice and salt. With the higher tariff Shingishu (Hsin Wiju) on the Corean side began to be made a depot for cargo destined to be ferried across the river to Antung.\nThe idea of using force being put on one side and the status of the Japanese Railway zone Settlement being what it is, the Customs can only press the Authorities there for what improvement it can secure intreatment. This was done upon the introduction of the higher tariff and there seems reason to see in the Japanese official attitude some realization that greater support must be lent to the Chinese Customs. This is the line that was followed by the late Commissioner, Mr. Fukumoto and his line of action is now being followed up by the present Commissioner, Mr. Bessell.\nJapanese administration on the two sides of the river falls under two distinct authorities, both as to Government and Railway management. On the Shingishu side is the Japanese “Department” of Chosen; on the Antung side is the South Manchurian Railway under the Kwangtung Government, the headquarters of which is situated at Port Arthur.\nEarly in the year Mr. Fukumoto made representations to the Japanese Consul at Antung and as a result two definite steps were effected:\n(a) Japanese merchants were instructed by the authorities at Seoul (Keicho) through the Commissioner of Japanese Customs at Shingishu : “to avail themselves of the railway” when importing goods across the river into Antung.\n(b) the Kwangtung Government at Port Arthur instructed the Consul at Antung that police in the settlement were to “assist the Customs by sending patrols along the foreshore to direct smugglers to report and pay the proper duties”; and by further issuing “a severe warning to suspected smugglers to abandon their practices in future.”\nRegarding the first of these: Mr. Inouye, Commissioner of Japanese Customs at Shingishu tells me that this order is absolutely obeyed. Goods, he said, are no longer stored in the warehouses on the riverside there by the cargo brokers, of whom there are five, licensed by the Customs. And the hundred Corean coolies who used to work the cargo there (and no doubt across the river) have now gone over to Antung to seek work on that side: - “There, probably,” Mr. Inouye added, “to turn their abilities to smuggling against the Japanese side of the water!\nAnd Mr. Bessell says that since the above orders were promulgated the Antung Customs receipts have risen appreciably and show directly the effect of the new rule as far as Shingishu side is concerned.\nMr. Usami, Japanese Consul at Antung, states that he thinks that this riverine smuggling will be “practically put an end to” by the new orders. This is as it may be of course. But no doubt something has been accomplished and this is the line that we must continue to follow, pressing fore the full carrying out of the Japanese promises. That the Customs must rest content with these measures granted by the Japanese; measures which, by the lapse of time may tend to be less thoroughly carried out, or, in their turn, may come to be countered by the smuggling fraternity, is to be deplored; but in the circumstances of our establishment at Antung and of China’s inability to secure a stronger position for us, there seems no present alternative.\nI believe, however, that no little can be done to “clinch” these arrangements officially in higher places, by a visit to the Governor General at Seoul and, thereafter, to the Governor General at Port Arthur, and this I propose to do in the course of the next week.\nThen there are certain further steps that can be taken by the Customs; these are:\n(a) the opening, already proposed, of a station of the Customs at Liutaokou.\n(b) that we should avail ourselves of our right, already established under noted exchanged at the signing of the Customs Railway Agreement of 1919, signed by the Inspector General of Customs and Ijuin, Japanese Minister (River Yalu Frontier Trade Agreement, 1913: pp 775/9, Vol. II, Treaties , Conventions, etc., No: 3. Miscellaneous Serious: No. 30.); and open a Chinese Customs Office on the Corean side of the Yalu.\nWith regard to (a) : The opening of a station at Liutaokou, which is the spot to which this smuggling across the river is carried out, may be said to be a necessary measure if only for the reason that trade is developing towards that end of the settlement; while it will deprive those landing in that neighbourhood with dutiable cargo of their present not altogether unfounded excuse, namely, that it is a mile and a half further up-stream to get to the Customs. The details of carrying this out should be easy of accomplishment with the help of the officials.\nWith reference to (b): we come here to something rather more important, requiring, as it would, some negotiation with the Corean Government before it could be effected.\nIt would give us the advantage of a lookout established upon the farther side of the river. Now that we know definite instructions have been reveived by the Japanese Customs there to discourage the shipping of cargo across the river our presence on the spot would assist in keeping them up to the mark. Duty on such exports as may leave there would be collected by such an office; but its principla use would be as a watch on river traffic.\nNo very great amount of smuggling can occur except of goods that have been brought there by the railway. And this involves temporary storage there; for the Japanese Customs which is in a strong position and keeps a firm hand over shippers no less than importers, permits no export without full formality. With closer relations with the Japanese Customs on the Corean side there should result a mutual assistance that does not spring from the present proximity of the two Customs’ working at the railway station.\nThe Japanese duties are far higher than ours; and the Shingishu Customs maintains a system of patrol along 25 miles of the Corean bank of the River, the upkeep of which, exclusive of buildings, is Yen 330000 per annum. The assistance that the Chinese Customs could render, therefore, must at least equal what we should be asking of them. It is in the direction of such mutual working that we should try to move. Smuggling will never be entirely eradicable by any system in a district poor, full of the turbulent characters associated with frontiers, and lending itself particularly, as regards ground, to clandestine operations. But smuggling in any wholesale form could not flourish greatly with the two Customs’ acting under a fair degree of understanding and good relations.\nI propose, therefore, to discuss the question of opening such an office with the Corean Authorities in a few days.\nThere is one last proposition that I believe should be considered:\n(c) the borrowing of a police guard from the Antung settlement authorities for the protection of Customs officers.\nSince Chinese police may not operate and armed Customs officers are regarded askance in the Settlement, the Antung authorities might, by arrangement, detail a certain makes of police in uniform for a permanent guard to the Customs. These guards would be paid for by us through the Police Department. They would not function as Custom officers; but where rough treatment at the hands of Coreans or others was apprehended they would be detailed under our orders for duty; that duty being only the protection of our officers acting as any Customs officer is expected to act, and must be free to act. I suggest that about twelve such police would be sufficient. They would be under the orders of their own Police Chief except – as above noted – regarding the details of actual post for the time being.\nI have discussed this suggestion with the Japanese Consul and he will look into the arguments for and against it with his Chief of police; regarding it, of course, as merely a tentative suggestion and not as definite arrangement. I propose to go into this question on the same basis with the Governor General – or whoever may discuss these questions with me – when I reach Port Arthur. \nEverything considered I do not regard the question of smuggling at Antung as so grave a one as I had expected to find it. This does not mean that it is not recognized that there has been a deplorable loss to the revenue under the circumstances that have obtained. But I think this has been the result of the hiatus in Customs powers here of the early part of this year and is not a question impossible to deal with. The increase this spring in the tariff caught Customs methods napping at Antung as it has done elsewhere. In seeking the obvious changes in practice called for by the new demands upon us ground has had to be crossed that was in a high degree delicate and demanded a full measure of time and discussion.\nWhen it is said that the status of the Railway Settlement of Antung is hopelessly inequitable to China everything has been said. It is not justifiable to ascribe to individuals, nor even to local and subordinate administrations, the faults in a system so perverse and difficult to handle. The required adjustments in procedure take time to bring about. But Mr. Fukumoto’s appeal through the local Consul appears to have received at the hands of the Various authorities who had to be consulted, quite a fair reception and response, and orders were in the course of time given which have already commenced to show satisfactory results. The further proposals for the consideration of the Inspector General now being forwarded will serve further to prevent loss of revenue on any large scale. All that will then be called for will be some extra activity and watchfulness on our part to see that the new safeguards – such as they are – are at least given their full chance.\nI will report in a later memorandum upon the outcome of my interviews with the Authorities at Seoul and Port Arthur.",
    "reference_list": "考点1：Preventive Service推荐译为缉私事务\n考点2：The Chief Secretary, Inspectorate General of Custom推荐译为总务科税务司\n考点3：South Manchurian Railway zone推荐译为南满洲铁道附属地，或者称为“满铁附属地”\n考点4：“the other half also by suggestion, by the Japanese推荐译为默认为日本主权\n考点5：waterfront推荐译为沿岸\n考点6：station推荐译为分卡，或者海关分卡\n考点7：Chinese customs必须译为中国海关\n考点8：Japanese Railway zone Settlement必须译为日本铁路附属地\n考点9：Mr. Fukumoto推荐译为福本顺三郎，或者福本顺\n考点10：Mr. Bessell推荐译为弼素乐\n考点11：Ijuin必须译为伊集院彦吉\n考点12：“to avail themselves of the railway” when importing goods across the river into Antung推荐译为洋货越江运入安东时，“应当使用铁路”\n考点13：Kwangtung Government必须译为关东厅\n考点14：Keicho推荐译为京城\n考点15：foreshore推荐译为河岸\n考点16：coolies必须译为苦力\n考点17：Mr. Usami必须译为宇佐美珍彦\n考点18：Governor General at Seoul必须译为朝鲜总督\n考点19：Governor General at Port Arthur必须译为关东厅长官\n考点20：Police Department推荐译为警察署\n考点21：The only alternative must be that of a withdrawal to, or the forming of an additional barrier at, some region behind this virtual bridgehead against the Chinese Customs推荐译为唯一的选择是撤退至这些对抗中国海关的事实上的桥头堡后面的一些地区的分卡，或者设立一个新的分卡\n考点22：uniform必须译为制服\n考点23：a few lines推荐译为简述如下\n考点24：settlement推荐译为附属地，或者居留地\n考点25：Japanese “Department” of Chosen推荐译为朝鲜总督府",
    "Primary_Domain": "文学艺术",
    "Secondary_Domain": "传记",
    "prompt_id": "140"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n在自动驾驶系统的设计与实现领域，“实时性”不仅仅是一个技术指标，更是关乎道路安全与系统可靠性的生命线。在高度动态的交通环境中，任何微秒级的延迟都可能在毫米级距离上转化为灾难性的后果。为了剖析这一挑战，研究者们将实时性瓶颈归纳为四个关键环节——传感器采集、数据预处理、决策推演与运动控制——并从架构深度、算法复杂度、硬件约束及通信拓扑四个维度展开多层次剖析。\n首先，传感器层面面临的首要难题在于多源异构数据的同步与融合。激光雷达通常以每秒数十万次帧率捕捉三维点云，但其数据量体量在高分辨率模式下可轻易突破数十GB/s；相机则以高帧率获取二维图像，并配合全景拼接与深度估计，但其网络带宽与显存吞吐能力常常成为制约因素；毫米波雷达提供了优异的抗干扰性能，却在感知精度及点云稠密度方面逊色于LiDAR。如何在毫秒级时间窗口内对上述异源数据进行时空校准、噪声滤除与特征提取，并保证各传感器数据的时间戳误差不超过1 ms，是系统设计的首要攻坚点。\n进入数据预处理阶段，传统的批量化滤波与卡尔曼滤波算法因其多次迭代及矩阵运算开销，被逐渐替换为能够并行执行的滤波网络或轻量化的稀疏滤波变体。例如，基于张量分解技术的三阶滤波网络能够将卡尔曼增益矩阵压缩为低秩近似，从而将运算复杂度从O(n³)降低至O(n² log n)，在保留滤波精度的前提下缩减延迟。但同时，这类方法对系统总体误差累积效应的鲁棒性提出了更高要求，任何压缩近似误差都可能在后续决策层面被放大。\n决策推演环节的核心难点则在于如何在有限的计算预算内，完成对复杂场景中多主体交互、道路拓扑及交通法规的同步评估。经典的基于马尔可夫决策过程（MDP）的路径规划算法，需要在每个离散时间步对潜在动作序列进行回溯搜索，其时间复杂度呈指数爆炸。研究者们引入了分层决策框架，将全局路径规划与局部运动规划解耦，并在高层采用粗粒度的图搜索、A*变体或基于采样的快速随机树算法，而在低层则构建基于深度强化学习的策略网络，以实现对最近时域内避障与车道保持的实时优化。然而，这种分层结构在节点切换时会引入架构中断，若缺少精细的同步机制，就会在决策链条中留下“盲区”，导致短时内无法响应突发事件。\n在运动控制层面，工业界普遍采用模型预测控制（MPC）算法，但其需要在线求解约束最优化问题，而这类问题通常伴随高维非线性函数求导与二次规划（QP）迭代。为了加速求解过程，研究者借助自适应步长策略与多项式逼近技术，将QP子问题近似转化为一阶优化，即可将控制指令计算时延压缩至1–2 ms。但在面对高马力动力学系统或复杂路面摩擦系数变化时，模型误差对MPC的稳定性提出了新的挑战，需要在软实时环境中增加冗余检查与最坏情况回退机制，以避免因求解超时而导致的控制失效。\n硬件层面的优化同样不可或缺。随着硬件加速器的多样化，FPGA、ASIC 与 GPU 在灵活性、功耗与吞吐量上各有千秋。研究团队提出了基于FPGA内置DSP单元的异构多核协同调度框架，该框架将高频率的卷积神经网络（CNN）推理任务映射至FPGA的流水线结构中，而将稀疏矩阵运算与图神经网络推理托付给GPU并行线程。此种交叉调度策略不仅提升了硬件利用率，也使得整体处理延迟在不牺牲精度的前提下下降了近40%。不过，异构计算环境下的任务分配与负载均衡依然是一个NP难题，任何调度错误都可能将过载风险转嫁至系统薄弱环节。\n在通信与拓扑优化方面，车路协同（V2X）与边缘计算的深度融合正逐步改变未来出行的实时性格局。通过在关键路口部署边缘服务器，车辆可以将部分感知与决策任务外包给最近端的边缘单元，以获得更低的通信时延与更高的带宽保障。同时，为了防止网络拥塞引发的丢包与延迟抖动，研究者引入了迭代式传输冗余机制，即在关键帧或决策结果传递时，同时采用多路径传输协议与前向纠错（FEC）编码，以确保在丢包率达到1%时仍能将端到端时延控制在5 ms以内。\n针对极端场景与突发工况，异步迭代调整机制被提出并投入小规模实车测试。该机制允许在主决策链路中断或信息不完整时，启动后备策略——包括基于经验库的保守行为决策与利用模式识别的短时预测——以维持车辆在三秒内的安全可控状态，并在后续通信链路恢复后进行全链路回溯校正与路径再优化。此举既保证了在网络抖动或传感器故障时的安全冗余，又保留了主决策框架的持续学习能力。\n与此同时，为兼顾资源受限的边缘部署需求，轻量化剪枝与知识蒸馏技术在模型训练与推理中被广泛采用。研究表明，通过对原始大模型的网络结构进行梯度敏感度分析，删除微贡献的权重连接后，再以原模型输出作为软标签对精简后模型进行再训练，可在保证原有感知精度95%以上的情况下，将模型参数量与计算量均压缩至原版的30%左右。此外，借助在线蒸馏技术，边缘节点可在实车运行中持续从云端大模型接收更新，以应对道路环境的复杂多变。\n在人工智能与物联网集成方面，多车协同仰赖联邦学习范式。车辆本地在边缘节点上进行增量式微调，并将模型梯度安全加密后上传至云端聚合，生成全局模型后同步下发。此循环既保护了车载数据的隐私安全，又借助大量车辆的多样化场景样本，提升了全局模型对复杂工况的泛化性能。\n从系统架构视角看，云边协同正逐渐演变为三层架构——云端服务器负责全局模型训练与大规模数据挖掘；边缘节点承担在线推理与动态模型更新；终端车辆则完成感知数据获取与最末级控制执行。此分层协作模式在降低单点故障风险的同时，也将99 百分位延迟和尾部延迟等关键指标纳入持续监测，以确保系统在极端拥堵或恶劣天气条件下，依然能保持可接受的响应速度和可靠性\n实时性研究将继续向微秒级做精细化耦合，并在在线学习、跨域传输优化、量子加速器应用等领域展开探索。唯有通过硬件与算法的协同创新、边缘与云端的无缝协作，以及异步与冗余机制的有机结合，才能真正实现毫秒乃至微秒级的实时自动驾驶，为智慧交通的安全与高效奠定坚实基础。",
    "ori_text": "\n\n在自动驾驶系统的设计与实现领域，“实时性”不仅仅是一个技术指标，更是关乎道路安全与系统可靠性的生命线。在高度动态的交通环境中，任何微秒级的延迟都可能在毫米级距离上转化为灾难性的后果。为了剖析这一挑战，研究者们将实时性瓶颈归纳为四个关键环节——传感器采集、数据预处理、决策推演与运动控制——并从架构深度、算法复杂度、硬件约束及通信拓扑四个维度展开多层次剖析。\n首先，传感器层面面临的首要难题在于多源异构数据的同步与融合。激光雷达通常以每秒数十万次帧率捕捉三维点云，但其数据量体量在高分辨率模式下可轻易突破数十GB/s；相机则以高帧率获取二维图像，并配合全景拼接与深度估计，但其网络带宽与显存吞吐能力常常成为制约因素；毫米波雷达提供了优异的抗干扰性能，却在感知精度及点云稠密度方面逊色于LiDAR。如何在毫秒级时间窗口内对上述异源数据进行时空校准、噪声滤除与特征提取，并保证各传感器数据的时间戳误差不超过1 ms，是系统设计的首要攻坚点。\n进入数据预处理阶段，传统的批量化滤波与卡尔曼滤波算法因其多次迭代及矩阵运算开销，被逐渐替换为能够并行执行的滤波网络或轻量化的稀疏滤波变体。例如，基于张量分解技术的三阶滤波网络能够将卡尔曼增益矩阵压缩为低秩近似，从而将运算复杂度从O(n³)降低至O(n² log n)，在保留滤波精度的前提下缩减延迟。但同时，这类方法对系统总体误差累积效应的鲁棒性提出了更高要求，任何压缩近似误差都可能在后续决策层面被放大。\n决策推演环节的核心难点则在于如何在有限的计算预算内，完成对复杂场景中多主体交互、道路拓扑及交通法规的同步评估。经典的基于马尔可夫决策过程（MDP）的路径规划算法，需要在每个离散时间步对潜在动作序列进行回溯搜索，其时间复杂度呈指数爆炸。研究者们引入了分层决策框架，将全局路径规划与局部运动规划解耦，并在高层采用粗粒度的图搜索、A*变体或基于采样的快速随机树算法，而在低层则构建基于深度强化学习的策略网络，以实现对最近时域内避障与车道保持的实时优化。然而，这种分层结构在节点切换时会引入架构中断，若缺少精细的同步机制，就会在决策链条中留下“盲区”，导致短时内无法响应突发事件。\n在运动控制层面，工业界普遍采用模型预测控制（MPC）算法，但其需要在线求解约束最优化问题，而这类问题通常伴随高维非线性函数求导与二次规划（QP）迭代。为了加速求解过程，研究者借助自适应步长策略与多项式逼近技术，将QP子问题近似转化为一阶优化，即可将控制指令计算时延压缩至1–2 ms。但在面对高马力动力学系统或复杂路面摩擦系数变化时，模型误差对MPC的稳定性提出了新的挑战，需要在软实时环境中增加冗余检查与最坏情况回退机制，以避免因求解超时而导致的控制失效。\n硬件层面的优化同样不可或缺。随着硬件加速器的多样化，FPGA、ASIC 与 GPU 在灵活性、功耗与吞吐量上各有千秋。研究团队提出了基于FPGA内置DSP单元的异构多核协同调度框架，该框架将高频率的卷积神经网络（CNN）推理任务映射至FPGA的流水线结构中，而将稀疏矩阵运算与图神经网络推理托付给GPU并行线程。此种交叉调度策略不仅提升了硬件利用率，也使得整体处理延迟在不牺牲精度的前提下下降了近40%。不过，异构计算环境下的任务分配与负载均衡依然是一个NP难题，任何调度错误都可能将过载风险转嫁至系统薄弱环节。\n在通信与拓扑优化方面，车路协同（V2X）与边缘计算的深度融合正逐步改变未来出行的实时性格局。通过在关键路口部署边缘服务器，车辆可以将部分感知与决策任务外包给最近端的边缘单元，以获得更低的通信时延与更高的带宽保障。同时，为了防止网络拥塞引发的丢包与延迟抖动，研究者引入了迭代式传输冗余机制，即在关键帧或决策结果传递时，同时采用多路径传输协议与前向纠错（FEC）编码，以确保在丢包率达到1%时仍能将端到端时延控制在5 ms以内。\n针对极端场景与突发工况，异步迭代调整机制被提出并投入小规模实车测试。该机制允许在主决策链路中断或信息不完整时，启动后备策略——包括基于经验库的保守行为决策与利用模式识别的短时预测——以维持车辆在三秒内的安全可控状态，并在后续通信链路恢复后进行全链路回溯校正与路径再优化。此举既保证了在网络抖动或传感器故障时的安全冗余，又保留了主决策框架的持续学习能力。\n与此同时，为兼顾资源受限的边缘部署需求，轻量化剪枝与知识蒸馏技术在模型训练与推理中被广泛采用。研究表明，通过对原始大模型的网络结构进行梯度敏感度分析，删除微贡献的权重连接后，再以原模型输出作为软标签对精简后模型进行再训练，可在保证原有感知精度95%以上的情况下，将模型参数量与计算量均压缩至原版的30%左右。此外，借助在线蒸馏技术，边缘节点可在实车运行中持续从云端大模型接收更新，以应对道路环境的复杂多变。\n在人工智能与物联网集成方面，多车协同仰赖联邦学习范式。车辆本地在边缘节点上进行增量式微调，并将模型梯度安全加密后上传至云端聚合，生成全局模型后同步下发。此循环既保护了车载数据的隐私安全，又借助大量车辆的多样化场景样本，提升了全局模型对复杂工况的泛化性能。\n从系统架构视角看，云边协同正逐渐演变为三层架构——云端服务器负责全局模型训练与大规模数据挖掘；边缘节点承担在线推理与动态模型更新；终端车辆则完成感知数据获取与最末级控制执行。此分层协作模式在降低单点故障风险的同时，也将99 百分位延迟和尾部延迟等关键指标纳入持续监测，以确保系统在极端拥堵或恶劣天气条件下，依然能保持可接受的响应速度和可靠性\n实时性研究将继续向微秒级做精细化耦合，并在在线学习、跨域传输优化、量子加速器应用等领域展开探索。唯有通过硬件与算法的协同创新、边缘与云端的无缝协作，以及异步与冗余机制的有机结合，才能真正实现毫秒乃至微秒级的实时自动驾驶，为智慧交通的安全与高效奠定坚实基础。",
    "reference_list": "考点1：“基于张量分解的三阶滤波网络”应译为“tensor-decomposition filtering network”\n考点2：“激光雷达通常以每秒数十万次帧率捕捉三维点云”中“每秒数十万次帧率”应译为“at a rate of hundreds of thousands of points per second”，不可译为“at hundreds of thousands of frames per second”",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "应用学科",
    "prompt_id": "174"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n 1995年，上海希望通过设置生态屏障来防止城市的无序扩张，正式启动建设外环绿带。随着人们物质生活水平提高，闲暇时间对游憩活动的需求日益提升。地处乡村与城市交界地带的外环绿带具有独特地理区位及景观资源和多样的土地性质，具有实现城乡融合、面向全市人民提供高质量游憩服务的潜能 ( Jin et al.,2022)。经过30年的发展，外环绿带从防护绿化带到“环上”生态公园带。如何构建高密城区游憩服务场所，提供新型城市生活休闲方式，促进市民与自然互动是当前发展重点。\n绿带的概念起源于英国社会学家霍华德提出的“田园城市”理论。1900年后伦敦城市快速扩张，伦敦郡议会提出设立Green Girdles (Thomas,1970,Masucci et al., 2013)，而后经发展，绿带成为规划界的共识并得到全球推广实施(Schram & Doevendans, 2018). 几十年来，各国的绿带建设都在绿带破碎（Zheng et al.,2020）、各项效益减退（Jun et al.,2012）、城市建设越过绿带成片 (Yang et al., 2007)等争议中不断调整并进行职能转型，建立基于传统绿带的城市外环绿地新体系成为新趋势。\n环城生态公园带是基于城乡融合发展和市民休闲游憩需求的背景，在城市绿带的基础上经过结构优化和功能提升演进形成的城市开放游憩空间( Zhang et al.,2024)。中国多位学者证明包括上海环城生态公园带的高密度城区公园环能帮助原绿带实现空间形态上优化拓展、功能定位上提质增效，回应市民游憩需求( Li et al.,2021,Ge et al.,2022,Zhang et al.,2024)。但当前全球针对环城公园带的系统研究较少，进一步探索从城市绿带到环城生态公园带发展过程中的理论研究和游憩服务提升的实践探索具有重要意义。\n游憩一般指人们在工作或学习忙碌后会寻求额外的放松与娱乐行为(Zhao et al.,2020)，学者普遍认为游憩服务是生态系统文化服务中的一种，通过对游憩资源进行规划、利用和管理，满足游人需求。目前游憩服务供给侧研究集中于游憩服务供给水平测量( Bedimo-Rung et al.,2005, Lee et al.,2013)，诸多学者引用生态系统文化服务供给评估方法，通过recreation potential supply (RPS) and recreation opportunity supply (ROS)两模型建立评价体系(Paracchini et al.,2014)。但当前针对城市绿地系统的游憩服务水平研究仍较少，对城市绿带、公园环等绿地体系的游憩服务缺少系统评价体系，且针对游憩服务的供需匹配研究较少。有研究者引入空间溢出效应，揭示城市绿地游憩服务对周边区域存在近程溢出机制远程耦合影响，认为溢出效应评价与优化是缓解绿地游憩资源分配不公平问题的切入点。(Zhang et al.,2018, Wang et al.,2023)\n溢出效应又叫外溢效应，指组织不仅能够产生活动所预期的效果，也能对组织之外的社会系统产生影响。研究普遍将绿地服务对周边区域产生的经济、社会和环境影响的辐射影响定义为绿地服务的溢出效应(Wu et al.,2023)。近年，有学者基于绿地作为准公共物品具有外部性特点，关注其外溢现象，探究绿地通过空间邻接或空间距离传递，对周边地区的影响机制，并对其外部溢出范围进行科学测度(Chen et al.,2022, Liu et al.,2024)，证明构建空间相关网络对于加强区域合作提升城市绿地服务至关重要(Qu et al.,2024)。但当前绿地服务溢出效应研究仍较少，且多集中于宏观或单一尺度，缺乏中观尺度研究；此外，对溢出效应是绿地游憩服务范围及服务水平科学测度的重要切入点，但对绿地游憩服务溢出研究尚未得到充分关注。\n上海环城生态公园带现存在游憩服务结构布局的空间不均衡与功能效能供需不平衡问题。上海环城生态公园带作为城乡边界和纽带，空间要素混杂且与各类生态空间密切联系，各段地理条件、土地利用现状、及社会经济发展水平存在差异，规划和建设难度大；公园带现无法满足市民对游憩服务的多样化需求，且公园带沿线区域的交通基础及城市功能差异显著，未来在游憩功能配置和服务供给质量方面有较大优化空间。\n缓解环城生态公园带游憩服务问题，溢出效应评价与优化是重要切入点。科学评价其溢出效应，可促进区域协同、提升城市韧性，优化资源配置。相关研究通过分析正向溢出效应，为协同发展提供支持，提升生态公园带的响应能力，增强绿地体系韧性，形成可持续发展格局，同时揭示绿地游憩服务对城市环境的影响机制，识别供需不平衡的关键节点，进一步优化资源配置。",
    "ori_text": "\n\n 1995年，上海希望通过设置生态屏障来防止城市的无序扩张，正式启动建设外环绿带。随着人们物质生活水平提高，闲暇时间对游憩活动的需求日益提升。地处乡村与城市交界地带的外环绿带具有独特地理区位及景观资源和多样的土地性质，具有实现城乡融合、面向全市人民提供高质量游憩服务的潜能 ( Jin et al.,2022)。经过30年的发展，外环绿带从防护绿化带到“环上”生态公园带。如何构建高密城区游憩服务场所，提供新型城市生活休闲方式，促进市民与自然互动是当前发展重点。\n绿带的概念起源于英国社会学家霍华德提出的“田园城市”理论。1900年后伦敦城市快速扩张，伦敦郡议会提出设立Green Girdles (Thomas,1970,Masucci et al., 2013)，而后经发展，绿带成为规划界的共识并得到全球推广实施(Schram & Doevendans, 2018). 几十年来，各国的绿带建设都在绿带破碎（Zheng et al.,2020）、各项效益减退（Jun et al.,2012）、城市建设越过绿带成片 (Yang et al., 2007)等争议中不断调整并进行职能转型，建立基于传统绿带的城市外环绿地新体系成为新趋势。\n环城生态公园带是基于城乡融合发展和市民休闲游憩需求的背景，在城市绿带的基础上经过结构优化和功能提升演进形成的城市开放游憩空间( Zhang et al.,2024)。中国多位学者证明包括上海环城生态公园带的高密度城区公园环能帮助原绿带实现空间形态上优化拓展、功能定位上提质增效，回应市民游憩需求( Li et al.,2021,Ge et al.,2022,Zhang et al.,2024)。但当前全球针对环城公园带的系统研究较少，进一步探索从城市绿带到环城生态公园带发展过程中的理论研究和游憩服务提升的实践探索具有重要意义。\n游憩一般指人们在工作或学习忙碌后会寻求额外的放松与娱乐行为(Zhao et al.,2020)，学者普遍认为游憩服务是生态系统文化服务中的一种，通过对游憩资源进行规划、利用和管理，满足游人需求。目前游憩服务供给侧研究集中于游憩服务供给水平测量( Bedimo-Rung et al.,2005, Lee et al.,2013)，诸多学者引用生态系统文化服务供给评估方法，通过recreation potential supply (RPS) and recreation opportunity supply (ROS)两模型建立评价体系(Paracchini et al.,2014)。但当前针对城市绿地系统的游憩服务水平研究仍较少，对城市绿带、公园环等绿地体系的游憩服务缺少系统评价体系，且针对游憩服务的供需匹配研究较少。有研究者引入空间溢出效应，揭示城市绿地游憩服务对周边区域存在近程溢出机制远程耦合影响，认为溢出效应评价与优化是缓解绿地游憩资源分配不公平问题的切入点。(Zhang et al.,2018, Wang et al.,2023)\n溢出效应又叫外溢效应，指组织不仅能够产生活动所预期的效果，也能对组织之外的社会系统产生影响。研究普遍将绿地服务对周边区域产生的经济、社会和环境影响的辐射影响定义为绿地服务的溢出效应(Wu et al.,2023)。近年，有学者基于绿地作为准公共物品具有外部性特点，关注其外溢现象，探究绿地通过空间邻接或空间距离传递，对周边地区的影响机制，并对其外部溢出范围进行科学测度(Chen et al.,2022, Liu et al.,2024)，证明构建空间相关网络对于加强区域合作提升城市绿地服务至关重要(Qu et al.,2024)。但当前绿地服务溢出效应研究仍较少，且多集中于宏观或单一尺度，缺乏中观尺度研究；此外，对溢出效应是绿地游憩服务范围及服务水平科学测度的重要切入点，但对绿地游憩服务溢出研究尚未得到充分关注。\n上海环城生态公园带现存在游憩服务结构布局的空间不均衡与功能效能供需不平衡问题。上海环城生态公园带作为城乡边界和纽带，空间要素混杂且与各类生态空间密切联系，各段地理条件、土地利用现状、及社会经济发展水平存在差异，规划和建设难度大；公园带现无法满足市民对游憩服务的多样化需求，且公园带沿线区域的交通基础及城市功能差异显著，未来在游憩功能配置和服务供给质量方面有较大优化空间。\n缓解环城生态公园带游憩服务问题，溢出效应评价与优化是重要切入点。科学评价其溢出效应，可促进区域协同、提升城市韧性，优化资源配置。相关研究通过分析正向溢出效应，为协同发展提供支持，提升生态公园带的响应能力，增强绿地体系韧性，形成可持续发展格局，同时揭示绿地游憩服务对城市环境的影响机制，识别供需不平衡的关键节点，进一步优化资源配置。",
    "reference_list": "考点1: “溢出效应”必须译为\"spillover effect\"\n考点2: “绿带破碎”必须译为 \"green belt fragmentation\"\n考点3：“无序扩张”推荐译为“uncontrolled expansion”或“disorderly expansion”或“urban sprawl”\n考点4：伦敦郡议会 必须译为 London County Council，固定译法\n考点5：空间相关网络 必须译为  spatial correlation network，专业术语，固定译法",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "178"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\nTERT在调控核苷酸添加持续性中发挥作用这一观点已获得充分支持。大量分析得出的核心结论是，在核苷酸添加持续性的决定因素方面，TERT与典型逆转录酶（RTs）在机制上具有高度的保守性。\n对逆转录病毒RTs的既往研究表明，保守的RT基序1、2、B、C、E以及“拇指”结构域均参与持续性调控。除少数例外情况，TERT中相应的类似结构已被证实在持续性控制中具有相似作用。\nTERT中三个保守的RT基序对维持最佳持续性至关重要，其中两个位于推测的“手指”结构域（基序1和2），一个位于“手掌”与“拇指”结构域的界面（基序E）。酵母和四膜虫中这些基序的许多点突变，都会导致连续核苷酸添加出现预期的功能损伤。重要的是，在保守位置上，端粒酶和逆转录病毒RTs要优化持续性，都需要完全相同的残基，这表明二者在机制上具有高度的保守性。例如，将酵母TERT的基序E中两个残基替换为HIV-1 RT对应位置的氨基酸，会使酵母端粒酶的持续性增强。HIV-1 RT转录复合物的晶体结构显示，保守的RT基序要么与三磷酸核苷酸结合（基序1和2），要么与引物末端结合（基序E），它们通过促进底物结合来调控持续性，这一作用机制不难理解。\n对保守基序C的分析显示，其在机制保守性方面的情况更为复杂。该基序包含两个恒定的天冬氨酸（Asp）残基，这些残基对金属离子结合和聚合酶化学反应至关重要。逆转录病毒RTs中，Asp对前的两个残基通常是大型疏水氨基酸，但在TERTs中变异性更大。将四膜虫TERT第813位（位于两个保守天冬氨酸前两位）的亮氨酸替换为逆转录病毒RTs特有的酪氨酸，得到的酶持续性增强。相反，将Est2p中Asp对前的两个残基替换为酪氨酸和苏氨酸，会导致持续性显著降低。这些结果表明，基序C对持续性的影响是通过其整体构象和化学反应介导的，而非单个氨基酸。在HIV-1 RT的晶体结构中，Asp对前两位的酪氨酸与DNA引物中倒数第二个核苷酸结合，这为其影响持续性提供了一种合理机制。将TERT中两个天冬氨酸前的残基替换为甲硫氨酸（HIV-1 RT中存在该残基且与引物末端相互作用），这一实验值得关注。不过，HIV-1 RT中该残基的突变似乎不影响聚合功能，但会降低DNA合成的保真度。\n另一组与核苷酸添加持续性相关的残基位于C端结构域。尽管该区域的序列保守性较弱，但酵母和人类TERT的该结构域中，多个突变都会损伤核苷酸添加持续性，这与功能保守性相符。与典型RTs类比，TERT的该结构域被认为构成端粒酶的“拇指”结构域。C端突变对Km值、端粒酶-底物稳定性的影响，以及酵母TERT该结构域具有弱核酸结合活性的证实，进一步支持了这一观点。由于重复添加持续性是端粒酶特有的生化属性，自然会推测端粒酶特异性结构负责这一活性。事实上，已证实能促进重复添加的三组TERT残基，虽分布于RT结构域内外，但主要局限于端粒酶特异性基序中。以下将分别对这些残基进行讨论。\n首先，如前所述，与典型RTs相比，TERT的RT结构域在保守基序A和B之间存在一个大的插入片段，即IFD（插入结构域）。在酵母端粒酶中，该结构域的特定突变会导致重复添加缺陷，并显著降低端粒酶对DNA底物的Km值。然而，酵母端粒酶在体外的重复添加水平天然极低。因此，评估四膜虫和人类等持续性更强的端粒酶中，相应残基的作用具有重要意义。\n第二组与重复添加相关的残基位于人TERT（hTERT）的C端结构域。如前所述，该结构域被认为构成端粒酶的“拇指”结构域。尽管酵母和人类TERT的C端结构域中，许多突变主要损伤核苷酸添加持续性，但hTERT该结构域的几个缺失突变也会降低重复添加，这表明人类端粒酶的“拇指”结构域具有额外功能。\n最后一组有助于重复添加持续性的残基，定位于hTERT的RID1结构域和酵母TERT的同源N-GQ结构域。多项研究表明，该结构域的缺失和点突变会选择性损伤重复添加持续性，并降低端粒酶延伸部分或完全非端粒引物的能力。突变体对端粒DNA的表观Km值也会降低，这再次表明RID1/N-GQ结构域有助于DNA结合。\n与TERT促进重复添加的作用相关的，是端粒酶酶学中的一个经典问题，即锚定位点的身份。对纤毛虫和人类端粒酶的早期功能分析表明，端粒酶包含第二个不依赖模板的DNA底物结合位点。该位点（也称为锚定位点）的存在，是通过5' DNA底物序列对酶的重复添加持续性、结合亲和力和催化速率的影响推断得出的。随后，利用绿草履虫（*E. aediculatus*）和酿酒酵母（*S. cerevisiae*）来源的酶进行的交联实验，确定了TERT大小的蛋白质负责与DNA的5'区域物理接触。进一步研究表明，锚定位点在功能上可分为模板近端和模板远端位点，且可能只有前者对重复添加持续性是必需的。RID1/N-GQ结构域对重复添加持续性和DNA底物识别的作用表明，该结构域可能构成模板近端锚定位点。酵母TERT上DNA交联位点的近期蛋白水解图谱支持了这一观点。已知hTERT的RID1结构域是与端粒酶RNA的假结-模板区域相互作用的位点，该区域也与促进重复添加持续性有关。蛋白质和RNA结构域在锚定位点功能中的相对作用及其相互影响，值得进一步研究。\n由于端粒酶合成端粒DNA重复序列需要TERT和RNA组件，因此这两个组件的稳定组装对酶活性至关重要。已证实TERT的两个结构域介导与端粒酶RNA的相互作用。一个亲和力较高的RNA结合结构域对应于N端延伸区（NTE）的C端部分，该部分包含三个保守的端粒酶特异性基序，分别命名为CP、QFP和T。在酵母、人类和四膜虫中，NTE的这部分已被证明与端粒酶RNA相互作用。令人惊讶的是，尽管该结构域在所有TERT中显然构成高亲和力RNA结合结构，但在不同生物中，它似乎与端粒酶RNA的不同靶标相互作用。在酵母中，包含潜在茎环/假结结构的区域被确定为TERT结合所必需；在人类中，远离模板的保守CR4-CR5区域是高亲和力结构域的靶位点；在四膜虫中，TERT结合需要RNA模板5'侧的几个核苷酸以及茎II，且似乎不涉及保守的假结。保守的蛋白质结构域识别明显不同的RNA结构，这一现象难以解释。一种可能的解释是，CP基序N端的蛋白质区域发挥了作用。酵母、人类和四膜虫TERT的高亲和力RNA结合结构域似乎延伸到这一保守性较低的区域，该区域具有物种特异性特征。因此，高度保守的基序可能形成一个共同的支架，物种特异性结构附着其上，以介导对不同RNA靶标的识别。除了促进端粒酶RNP的稳定组装外，四膜虫的RNA结合结构域还有一个额外作用：帮助确定模板的5'边界。减弱这种相互作用会导致逆转录显著超出正常模板边界。探究其他TERT中的类似突变是否也会影响模板边界的确定，将是一件有趣的事。\n第二个亲和力较低的RNA相互作用显然由RID1/N-GQ结构域介导。同样，不同生物中该结构域的RNA靶标也不同。四膜虫的RNA靶标包含一个茎环和模板3'端紧邻的一段区域（称为模板识别元件）；人类的靶标似乎位于假结-模板结构域，而酵母的靶标尚未确定。如前文所述，RID1/N-GQ结构域已被证明能促进重复添加持续性和酶互补，还需进一步研究以确定RNA相互作用在这些功能中的作用。\n\n",
    "ori_text": "\n\nTERT在调控核苷酸添加持续性中发挥作用这一观点已获得充分支持。大量分析得出的核心结论是，在核苷酸添加持续性的决定因素方面，TERT与典型逆转录酶（RTs）在机制上具有高度的保守性。\n对逆转录病毒RTs的既往研究表明，保守的RT基序1、2、B、C、E以及“拇指”结构域均参与持续性调控。除少数例外情况，TERT中相应的类似结构已被证实在持续性控制中具有相似作用。\nTERT中三个保守的RT基序对维持最佳持续性至关重要，其中两个位于推测的“手指”结构域（基序1和2），一个位于“手掌”与“拇指”结构域的界面（基序E）。酵母和四膜虫中这些基序的许多点突变，都会导致连续核苷酸添加出现预期的功能损伤。重要的是，在保守位置上，端粒酶和逆转录病毒RTs要优化持续性，都需要完全相同的残基，这表明二者在机制上具有高度的保守性。例如，将酵母TERT的基序E中两个残基替换为HIV-1 RT对应位置的氨基酸，会使酵母端粒酶的持续性增强。HIV-1 RT转录复合物的晶体结构显示，保守的RT基序要么与三磷酸核苷酸结合（基序1和2），要么与引物末端结合（基序E），它们通过促进底物结合来调控持续性，这一作用机制不难理解。\n对保守基序C的分析显示，其在机制保守性方面的情况更为复杂。该基序包含两个恒定的天冬氨酸（Asp）残基，这些残基对金属离子结合和聚合酶化学反应至关重要。逆转录病毒RTs中，Asp对前的两个残基通常是大型疏水氨基酸，但在TERTs中变异性更大。将四膜虫TERT第813位（位于两个保守天冬氨酸前两位）的亮氨酸替换为逆转录病毒RTs特有的酪氨酸，得到的酶持续性增强。相反，将Est2p中Asp对前的两个残基替换为酪氨酸和苏氨酸，会导致持续性显著降低。这些结果表明，基序C对持续性的影响是通过其整体构象和化学反应介导的，而非单个氨基酸。在HIV-1 RT的晶体结构中，Asp对前两位的酪氨酸与DNA引物中倒数第二个核苷酸结合，这为其影响持续性提供了一种合理机制。将TERT中两个天冬氨酸前的残基替换为甲硫氨酸（HIV-1 RT中存在该残基且与引物末端相互作用），这一实验值得关注。不过，HIV-1 RT中该残基的突变似乎不影响聚合功能，但会降低DNA合成的保真度。\n另一组与核苷酸添加持续性相关的残基位于C端结构域。尽管该区域的序列保守性较弱，但酵母和人类TERT的该结构域中，多个突变都会损伤核苷酸添加持续性，这与功能保守性相符。与典型RTs类比，TERT的该结构域被认为构成端粒酶的“拇指”结构域。C端突变对Km值、端粒酶-底物稳定性的影响，以及酵母TERT该结构域具有弱核酸结合活性的证实，进一步支持了这一观点。由于重复添加持续性是端粒酶特有的生化属性，自然会推测端粒酶特异性结构负责这一活性。事实上，已证实能促进重复添加的三组TERT残基，虽分布于RT结构域内外，但主要局限于端粒酶特异性基序中。以下将分别对这些残基进行讨论。\n首先，如前所述，与典型RTs相比，TERT的RT结构域在保守基序A和B之间存在一个大的插入片段，即IFD（插入结构域）。在酵母端粒酶中，该结构域的特定突变会导致重复添加缺陷，并显著降低端粒酶对DNA底物的Km值。然而，酵母端粒酶在体外的重复添加水平天然极低。因此，评估四膜虫和人类等持续性更强的端粒酶中，相应残基的作用具有重要意义。\n第二组与重复添加相关的残基位于人TERT（hTERT）的C端结构域。如前所述，该结构域被认为构成端粒酶的“拇指”结构域。尽管酵母和人类TERT的C端结构域中，许多突变主要损伤核苷酸添加持续性，但hTERT该结构域的几个缺失突变也会降低重复添加，这表明人类端粒酶的“拇指”结构域具有额外功能。\n最后一组有助于重复添加持续性的残基，定位于hTERT的RID1结构域和酵母TERT的同源N-GQ结构域。多项研究表明，该结构域的缺失和点突变会选择性损伤重复添加持续性，并降低端粒酶延伸部分或完全非端粒引物的能力。突变体对端粒DNA的表观Km值也会降低，这再次表明RID1/N-GQ结构域有助于DNA结合。\n与TERT促进重复添加的作用相关的，是端粒酶酶学中的一个经典问题，即锚定位点的身份。对纤毛虫和人类端粒酶的早期功能分析表明，端粒酶包含第二个不依赖模板的DNA底物结合位点。该位点（也称为锚定位点）的存在，是通过5' DNA底物序列对酶的重复添加持续性、结合亲和力和催化速率的影响推断得出的。随后，利用绿草履虫（*E. aediculatus*）和酿酒酵母（*S. cerevisiae*）来源的酶进行的交联实验，确定了TERT大小的蛋白质负责与DNA的5'区域物理接触。进一步研究表明，锚定位点在功能上可分为模板近端和模板远端位点，且可能只有前者对重复添加持续性是必需的。RID1/N-GQ结构域对重复添加持续性和DNA底物识别的作用表明，该结构域可能构成模板近端锚定位点。酵母TERT上DNA交联位点的近期蛋白水解图谱支持了这一观点。已知hTERT的RID1结构域是与端粒酶RNA的假结-模板区域相互作用的位点，该区域也与促进重复添加持续性有关。蛋白质和RNA结构域在锚定位点功能中的相对作用及其相互影响，值得进一步研究。\n由于端粒酶合成端粒DNA重复序列需要TERT和RNA组件，因此这两个组件的稳定组装对酶活性至关重要。已证实TERT的两个结构域介导与端粒酶RNA的相互作用。一个亲和力较高的RNA结合结构域对应于N端延伸区（NTE）的C端部分，该部分包含三个保守的端粒酶特异性基序，分别命名为CP、QFP和T。在酵母、人类和四膜虫中，NTE的这部分已被证明与端粒酶RNA相互作用。令人惊讶的是，尽管该结构域在所有TERT中显然构成高亲和力RNA结合结构，但在不同生物中，它似乎与端粒酶RNA的不同靶标相互作用。在酵母中，包含潜在茎环/假结结构的区域被确定为TERT结合所必需；在人类中，远离模板的保守CR4-CR5区域是高亲和力结构域的靶位点；在四膜虫中，TERT结合需要RNA模板5'侧的几个核苷酸以及茎II，且似乎不涉及保守的假结。保守的蛋白质结构域识别明显不同的RNA结构，这一现象难以解释。一种可能的解释是，CP基序N端的蛋白质区域发挥了作用。酵母、人类和四膜虫TERT的高亲和力RNA结合结构域似乎延伸到这一保守性较低的区域，该区域具有物种特异性特征。因此，高度保守的基序可能形成一个共同的支架，物种特异性结构附着其上，以介导对不同RNA靶标的识别。除了促进端粒酶RNP的稳定组装外，四膜虫的RNA结合结构域还有一个额外作用：帮助确定模板的5'边界。减弱这种相互作用会导致逆转录显著超出正常模板边界。探究其他TERT中的类似突变是否也会影响模板边界的确定，将是一件有趣的事。\n第二个亲和力较低的RNA相互作用显然由RID1/N-GQ结构域介导。同样，不同生物中该结构域的RNA靶标也不同。四膜虫的RNA靶标包含一个茎环和模板3'端紧邻的一段区域（称为模板识别元件）；人类的靶标似乎位于假结-模板结构域，而酵母的靶标尚未确定。如前文所述，RID1/N-GQ结构域已被证明能促进重复添加持续性和酶互补，还需进一步研究以确定RNA相互作用在这些功能中的作用。\n\n",
    "reference_list": "考点1： “逆转录酶” 推荐译为 “reverse transcriptase (RT)”\n考点2：“三磷酸核苷酸” 推荐译为 “nucleotide triphosphate”\n考点3： “端粒DNA” 推荐译为 “telomere DNA”\n考点4：文中的 “典型逆转录酶” 描述的是逆转录酶中的原型代表，在原文的语境中强调酶的“原型和典型”，需要翻译为 “prototypical RTs”，不可以翻译为 “canonical reverse transcriptases”。\n考点5： “HIV-1 RT转录复合物” 推荐译为 “HIV-1 RT reverse transcription complex”，避免将“逆转录”误译为“转录”。\n考点6： 首次出现“三磷酸核苷酸”应使用“nucleotide triphosphate”，不要用“nucleoside triphosphate”除非上下文明确强调核苷而非核苷酸。\n考点7： “IFD” 全称推荐译为 “insertion in fingers domain (IFD)” 或 “insertion domain (IFD)”，首次出现需给出全称及缩写并全文统一。",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "116"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。\n以下是你本次的任务：\n2. Lithium-ion batteries in tunnel energy storage system\nThe tunnel energy storage system (TESS) has the characteristics of peak shaving and valley filling, delayed power consumption, power quality optimization, etc. Peak clipping and valley filling is charging when the power is in the “flat” and “valley” periods, and discharging when the power is in the “peak” periods, which can not only save the operating cost of power supply, but also reduce the cost of providing frequency regulation and standby power supply. When the power grid encounters power failure, the energy storage system can be used as a backup power supply to continuously supply power for tunnel lighting and ventilation. In addition, the installation and application of the energy storage system can filter out the disturbance from the power grid, which can be used as a special power quality control device to improve the power supply quality of important loads. From the perspective of energy conservation and emission reduction, the energy storage system transfers the electric energy of low carbon emission power sources to peak load periods during off peak load periods, thereby reducing the consumption of high emission energy, which is conducive to energy conservation and emission reduction. lithium-ion battery (LIB) is an ideal high-energy energy storage battery due to its high specific capacity, small self discharge, long storage time, no memory effect, long lifetime, fast charging and other advantages, which is widely used in TESS.\nAs shown in Fig. 3, the tunnel LIB energy storage system is mainly composed of a battery system, a power converter system (PCS), a battery management system (BMS), an energy management system (EMS), and a monitoring system. Nowadays, LIBs are developing in the direction of higher safety, high environmental protection, high energy density, and long lifetime. As a lithium-ion concentration difference battery, the main components include: cathode and anode materials, electrolytes, separators, and shells.\n2.1. The working principle of lithium-ion batteries\nAs shown in Fig. 4, during the charging and discharging process of LIBs, lithium ions are intercalated and deintercalated back and forth between the positive negative electrode, thereby realizing the mutual conversion of chemical energy and electrical energy. During charging, lithium ions are deintercalated from the lithium-rich positive electrode, enter the electrolyte, pass through the separator, and are transported to be embedded in the negative electrode. At this time, the negative electrode is in a lithium-rich state, while the positive electrode is in a lithium-poor state, and the electrons are transmitted from the positive electrode by the external circuit. To the negative electrode, electrical energy is converted into chemical energy. During discharge, lithium ions are deintercalated from the negative electrode, pass through the electrolyte, pass through the separator, and re-insert into the lithium-poor positive electrode, and electrons are transferred from the negative electrode back to the positive electrode by the external circuit, Return the electric charge to the equilibrium state and realize the conversion of chemical energy to electrical energy.\n2.2. Cathode materials\nAs one of the important components of LIBs, the cathode materials determine the performance of LIBs, and it should meet the following requirements: (1) higher potential and stable platform to ensure high voltage for battery operation; (2) small electrochemical equivalent to ensure large specific capacity of the battery; (3) high lithium ion diffusion coefficient and conductivity to ensure high reversible capacity of the battery; (4) excellent embeddedness and de-embeddedness, small structural change to ensure the long cycle lifetime of the battery; (5) good compatibility with the electrolyte to ensure high chemical and thermal stability of the battery; (6) low price and green environmental protection to ensure that the battery is environmentally friendly. The cathode materials of LIBs can be divided into layered structure, spinel structure and polyanion type (olivine type) according to their structures.\nTypical layered cathode materials are: lithium cobaltate (LiCoO2), lithium nickelate (LiNiO2), lithium manganate (LiMnO2), ternary transition metal oxides. As shown in Fig. 5, LiCoO2, the most representative layered oxide, was first used as a cathode material for commercial LIBs. Its α-NaFeO2 type layered structure has electrochemical stability. However, in the case of deep delithiation, the structure will be severely damaged due to the higher charging voltage, which affects the performance of LIBs. However, it is possible to improve the structural stability and improve the performance of LiCoO2 by increasing the charge-discharge voltage of the LiCoO2 cathode material or by doping other elements (such as Mg, Al, etc.). As LiNiO2, which has attracted more attention recently, although Ni is richer in resources, lower in cost and less harmful to the environment than Co, the radius of Ni2+ and Li are close, which is easy to cause mixed discharge, so LiNiO+2 has poor thermal stability. The researchers have stabilized its structure by doping it with Al elements. LiMnO2 mainly has two structures of monoclinic phase and orthorhombic phase, and its actual specific capacity is higher than that of LiCoO2 and LiNiO2, but its Mn3+ is unstable and easy to transform to Mn4+, resulting in structural variation, which seriously affects its electrochemical stability. It can be stabilized by doping with other elements. Due to the unsatisfactory performance of single LiCoO2, LiNiO2 and LiMnO2, the ternary material LiNixCoyMn1-x-yO2 combines the high conductivity and performance of Co, the high specific capacity of Ni, and the strong stability and safety of Mn, effectively improving its performance,.\nAs shown in Fig. 5, the most representative cathode material of spinel structure is lithium manganate (LiMn2O4), which has the characteristics of low price, simple synthesis process and strong safety. LiMn2O4 (belonging to the Fd3m space group ) has low theoretical and practical specific capacities, and the capacity decays severely during high-temperature cycling because the Jahn-Teller effect occurs during charge-discharge, resulting in severe structural deformation, and due to the action of electrolyte, soluble Mn2+ is produced, which seriously affects the performance of LIBs, so it is not suitable for large-scale power equipment. However, studies have shown that LiMn2O4 can be protected by doping Al, Cr and other elements to stabilize its structure or coating the surface with oxides such as Al2O3 and Y2O3 to prevent direct contact with the electrolyte, thereby improving the performance of LIBs,.\nThe polyanion type (olivine type) cathode material has good stability and safety. As shown in Fig. 5, at present, the main commercial one is lithium iron phosphate (LiFePO4), which is also the most commonly used cathode material for energy storage systems. Its Li and Fe+2+ are paired with O2− to form different LiO6 and FeO6 octahedra and PO4 tetrahedra staggered to form a space skeleton structure. However, due to its own structure, Li transport is limited, resulting in low conductivity and poor performance of LiFePO+4. At present, LiFePO4 can be modified by doping, coating, and nanometerization.\nThe above common cathode materials have stable thermal safety when the temperature does not exceed 650 °C, and they can also be in a stable voltage state when charging. The main factors restricting the thermal safety of cathode materials for LIBs are as follows: a large amount of heat is generated under the condition of heat abuse; it releases oxygen or has strong oxidizability in case of overcharge. Both of these are necessary conditions for TR of LIBs, which will eventually lead to the decline of capacity and performance of LIBs.\n2.3. Anode materials\nThe anode materials, as the carrier of lithium ions and electrons in the process of battery charge and discharge, plays the role of energy storage and release, and should meet : (1) low working potential; (2) good electrochemical stability; (3) higher specific capacity; (4) stable structure and charge-discharge platform; (5) higher electrical conductivity; (6) lower cost and high environmental protection. As shown in Fig. 6, anode materials for LIBs can be divided into: intercalation, alloy and conversion types according to the lithium storage mechanism.\nIntercalation-type anode materials can store lithium by intercalating lithium ions into their structural gaps, and have good stability because they can remain reversible during the intercalation and deintercalation processes and their structure will not be destroyed. At present, typical intercalation anode materials mainly include carbon-based, titanium-based materials, and some layered metal compounds. Among them, carbon-based materials include graphite, soft, hard carbon, carbon nanomaterials (carbon nanotubes, graphene), etc.. As the earliest commercialized and most commonly used anode material, graphite has the characteristics of stable electrochemical performance, high tap density, abundant resources and low cost. However, due to the poor compatibility between graphite and electrolyte, a thicker SEI film will be formed with the electrolyte at the beginning of charge and discharge, causing Li to pass through the SEI film for a long time, resulting in poor battery performance. At present, it can be improved by surface coating, doping and other technologies. Titanium-based materials mainly include TiO+2, Li4Ti5O12, etc., which have been widely studied and developed due to their stable electrochemical performance, environmental protection and no pollution. Fig. 7 is a comparison chart of the advantages and disadvantages of common carbon-based materials.\nAlloy-type anode materials store lithium through an alloying reaction with lithium ions, with ultra-high specific capacity and low charge-discharge platform, such as silicon-based, germanium-based, tin-based materials, etc. As the silicon-based materials with the highest specific capacity among the alloy-type anode materials, they have the characteristics of abundant resources, green environmental protection, and low price. However, due to theirs huge volume expansion during the charging and discharging process, the silicon particles are crushed, fallen off, and the structure collapses. It leads to irreversible loss of capacity, exposes silicon particles to electrolyte, forms a new SEI film, hinders the conduction of lithium ions, and seriously affects the performance of the battery. At present, scientists have improved theirs electrochemical performance through schemes such as silicon nanoization  and silicon-based material composite. Germanium-based, tin-based materials and other alloy-type anode materials also have the problem of drastic volume changes during charging and discharging, resulting in too few practical applications, which can also be modified by certain means.\nConversion-type anode materials store lithium through reversible redox reactions with lithium ions, and have the advantages of higher specific capacity than intercalation-type anode materials, and smaller volume changes during charge and discharge than alloy-type anode materials. Such materials are mainly transition metal compounds, such as oxides, sulfides, fluorides, phosphides, etc.. However, most of the transition metal compounds have low conductivity, low first coulomb efficiency, large and obvious volume change, and high working potential, which greatly affect the performance of LIBs, resulting in shorter life and lower efficiency. At present, most of the current modifications are made by nanosizing the oxide.\nThe thermal safety of anode materials is related to their type, particle size and the stability of SEI film formed by the cathode. If the size particles are made into cathode materials according to a certain proportion, the purpose of expanding the contact area between particles, reducing electrode impedance, increasing electrode capacity and reducing the possibility of active metal precipitation can be achieved. The quality of SEI film directly affects the charging and discharging performance and safety of LIBs. The main methods to improve the quality of SEI film are: weak oxidation of carbon material surface; carbon materials after reduction, doping and surface modification; use spherical or fibrous carbon materials. The safety of anode materials can be improved by reducing the specific surface area of anode materials and improving the thermal stability of SEI films.",
    "ori_text": "\n\n2. Lithium-ion batteries in tunnel energy storage system\nThe tunnel energy storage system (TESS) has the characteristics of peak shaving and valley filling, delayed power consumption, power quality optimization, etc. Peak clipping and valley filling is charging when the power is in the “flat” and “valley” periods, and discharging when the power is in the “peak” periods, which can not only save the operating cost of power supply, but also reduce the cost of providing frequency regulation and standby power supply. When the power grid encounters power failure, the energy storage system can be used as a backup power supply to continuously supply power for tunnel lighting and ventilation. In addition, the installation and application of the energy storage system can filter out the disturbance from the power grid, which can be used as a special power quality control device to improve the power supply quality of important loads. From the perspective of energy conservation and emission reduction, the energy storage system transfers the electric energy of low carbon emission power sources to peak load periods during off peak load periods, thereby reducing the consumption of high emission energy, which is conducive to energy conservation and emission reduction. lithium-ion battery (LIB) is an ideal high-energy energy storage battery due to its high specific capacity, small self discharge, long storage time, no memory effect, long lifetime, fast charging and other advantages, which is widely used in TESS.\nAs shown in Fig. 3, the tunnel LIB energy storage system is mainly composed of a battery system, a power converter system (PCS), a battery management system (BMS), an energy management system (EMS), and a monitoring system. Nowadays, LIBs are developing in the direction of higher safety, high environmental protection, high energy density, and long lifetime. As a lithium-ion concentration difference battery, the main components include: cathode and anode materials, electrolytes, separators, and shells.\n2.1. The working principle of lithium-ion batteries\nAs shown in Fig. 4, during the charging and discharging process of LIBs, lithium ions are intercalated and deintercalated back and forth between the positive negative electrode, thereby realizing the mutual conversion of chemical energy and electrical energy. During charging, lithium ions are deintercalated from the lithium-rich positive electrode, enter the electrolyte, pass through the separator, and are transported to be embedded in the negative electrode. At this time, the negative electrode is in a lithium-rich state, while the positive electrode is in a lithium-poor state, and the electrons are transmitted from the positive electrode by the external circuit. To the negative electrode, electrical energy is converted into chemical energy. During discharge, lithium ions are deintercalated from the negative electrode, pass through the electrolyte, pass through the separator, and re-insert into the lithium-poor positive electrode, and electrons are transferred from the negative electrode back to the positive electrode by the external circuit, Return the electric charge to the equilibrium state and realize the conversion of chemical energy to electrical energy.\n2.2. Cathode materials\nAs one of the important components of LIBs, the cathode materials determine the performance of LIBs, and it should meet the following requirements: (1) higher potential and stable platform to ensure high voltage for battery operation; (2) small electrochemical equivalent to ensure large specific capacity of the battery; (3) high lithium ion diffusion coefficient and conductivity to ensure high reversible capacity of the battery; (4) excellent embeddedness and de-embeddedness, small structural change to ensure the long cycle lifetime of the battery; (5) good compatibility with the electrolyte to ensure high chemical and thermal stability of the battery; (6) low price and green environmental protection to ensure that the battery is environmentally friendly. The cathode materials of LIBs can be divided into layered structure, spinel structure and polyanion type (olivine type) according to their structures.\nTypical layered cathode materials are: lithium cobaltate (LiCoO2), lithium nickelate (LiNiO2), lithium manganate (LiMnO2), ternary transition metal oxides. As shown in Fig. 5, LiCoO2, the most representative layered oxide, was first used as a cathode material for commercial LIBs. Its α-NaFeO2 type layered structure has electrochemical stability. However, in the case of deep delithiation, the structure will be severely damaged due to the higher charging voltage, which affects the performance of LIBs. However, it is possible to improve the structural stability and improve the performance of LiCoO2 by increasing the charge-discharge voltage of the LiCoO2 cathode material or by doping other elements (such as Mg, Al, etc.). As LiNiO2, which has attracted more attention recently, although Ni is richer in resources, lower in cost and less harmful to the environment than Co, the radius of Ni2+ and Li are close, which is easy to cause mixed discharge, so LiNiO+2 has poor thermal stability. The researchers have stabilized its structure by doping it with Al elements. LiMnO2 mainly has two structures of monoclinic phase and orthorhombic phase, and its actual specific capacity is higher than that of LiCoO2 and LiNiO2, but its Mn3+ is unstable and easy to transform to Mn4+, resulting in structural variation, which seriously affects its electrochemical stability. It can be stabilized by doping with other elements. Due to the unsatisfactory performance of single LiCoO2, LiNiO2 and LiMnO2, the ternary material LiNixCoyMn1-x-yO2 combines the high conductivity and performance of Co, the high specific capacity of Ni, and the strong stability and safety of Mn, effectively improving its performance,.\nAs shown in Fig. 5, the most representative cathode material of spinel structure is lithium manganate (LiMn2O4), which has the characteristics of low price, simple synthesis process and strong safety. LiMn2O4 (belonging to the Fd3m space group ) has low theoretical and practical specific capacities, and the capacity decays severely during high-temperature cycling because the Jahn-Teller effect occurs during charge-discharge, resulting in severe structural deformation, and due to the action of electrolyte, soluble Mn2+ is produced, which seriously affects the performance of LIBs, so it is not suitable for large-scale power equipment. However, studies have shown that LiMn2O4 can be protected by doping Al, Cr and other elements to stabilize its structure or coating the surface with oxides such as Al2O3 and Y2O3 to prevent direct contact with the electrolyte, thereby improving the performance of LIBs,.\nThe polyanion type (olivine type) cathode material has good stability and safety. As shown in Fig. 5, at present, the main commercial one is lithium iron phosphate (LiFePO4), which is also the most commonly used cathode material for energy storage systems. Its Li and Fe+2+ are paired with O2− to form different LiO6 and FeO6 octahedra and PO4 tetrahedra staggered to form a space skeleton structure. However, due to its own structure, Li transport is limited, resulting in low conductivity and poor performance of LiFePO+4. At present, LiFePO4 can be modified by doping, coating, and nanometerization.\nThe above common cathode materials have stable thermal safety when the temperature does not exceed 650 °C, and they can also be in a stable voltage state when charging. The main factors restricting the thermal safety of cathode materials for LIBs are as follows: a large amount of heat is generated under the condition of heat abuse; it releases oxygen or has strong oxidizability in case of overcharge. Both of these are necessary conditions for TR of LIBs, which will eventually lead to the decline of capacity and performance of LIBs.\n2.3. Anode materials\nThe anode materials, as the carrier of lithium ions and electrons in the process of battery charge and discharge, plays the role of energy storage and release, and should meet : (1) low working potential; (2) good electrochemical stability; (3) higher specific capacity; (4) stable structure and charge-discharge platform; (5) higher electrical conductivity; (6) lower cost and high environmental protection. As shown in Fig. 6, anode materials for LIBs can be divided into: intercalation, alloy and conversion types according to the lithium storage mechanism.\nIntercalation-type anode materials can store lithium by intercalating lithium ions into their structural gaps, and have good stability because they can remain reversible during the intercalation and deintercalation processes and their structure will not be destroyed. At present, typical intercalation anode materials mainly include carbon-based, titanium-based materials, and some layered metal compounds. Among them, carbon-based materials include graphite, soft, hard carbon, carbon nanomaterials (carbon nanotubes, graphene), etc.. As the earliest commercialized and most commonly used anode material, graphite has the characteristics of stable electrochemical performance, high tap density, abundant resources and low cost. However, due to the poor compatibility between graphite and electrolyte, a thicker SEI film will be formed with the electrolyte at the beginning of charge and discharge, causing Li to pass through the SEI film for a long time, resulting in poor battery performance. At present, it can be improved by surface coating, doping and other technologies. Titanium-based materials mainly include TiO+2, Li4Ti5O12, etc., which have been widely studied and developed due to their stable electrochemical performance, environmental protection and no pollution. Fig. 7 is a comparison chart of the advantages and disadvantages of common carbon-based materials.\nAlloy-type anode materials store lithium through an alloying reaction with lithium ions, with ultra-high specific capacity and low charge-discharge platform, such as silicon-based, germanium-based, tin-based materials, etc. As the silicon-based materials with the highest specific capacity among the alloy-type anode materials, they have the characteristics of abundant resources, green environmental protection, and low price. However, due to theirs huge volume expansion during the charging and discharging process, the silicon particles are crushed, fallen off, and the structure collapses. It leads to irreversible loss of capacity, exposes silicon particles to electrolyte, forms a new SEI film, hinders the conduction of lithium ions, and seriously affects the performance of the battery. At present, scientists have improved theirs electrochemical performance through schemes such as silicon nanoization  and silicon-based material composite. Germanium-based, tin-based materials and other alloy-type anode materials also have the problem of drastic volume changes during charging and discharging, resulting in too few practical applications, which can also be modified by certain means.\nConversion-type anode materials store lithium through reversible redox reactions with lithium ions, and have the advantages of higher specific capacity than intercalation-type anode materials, and smaller volume changes during charge and discharge than alloy-type anode materials. Such materials are mainly transition metal compounds, such as oxides, sulfides, fluorides, phosphides, etc.. However, most of the transition metal compounds have low conductivity, low first coulomb efficiency, large and obvious volume change, and high working potential, which greatly affect the performance of LIBs, resulting in shorter life and lower efficiency. At present, most of the current modifications are made by nanosizing the oxide.\nThe thermal safety of anode materials is related to their type, particle size and the stability of SEI film formed by the cathode. If the size particles are made into cathode materials according to a certain proportion, the purpose of expanding the contact area between particles, reducing electrode impedance, increasing electrode capacity and reducing the possibility of active metal precipitation can be achieved. The quality of SEI film directly affects the charging and discharging performance and safety of LIBs. The main methods to improve the quality of SEI film are: weak oxidation of carbon material surface; carbon materials after reduction, doping and surface modification; use spherical or fibrous carbon materials. The safety of anode materials can be improved by reducing the specific surface area of anode materials and improving the thermal stability of SEI films.",
    "reference_list": "考点1. \"Power Converter System\"必须译为\"功率转换系统\"\n考点2. \"small self discharge\"推荐译为 \"自放电率低\"\n考点3. \"delayed power consumption\" 推荐译为\"延迟用电\"\n考点4. \"standby power supply\" 推荐译为\"待机电源\"\n考点5. \"frequency regulation\" 必须译为\"调频控制\"\n考点6. \"thermal abuse\" 必须译为\"热失控\"\n考点7. \"severe structural deformation\" 推荐译为\"晶格畸变\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "自然科学",
    "prompt_id": "141"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n魅力一词最早是由马克斯·韦伯从宗教文化词汇引入社会、政治、经济等领域的学术概念。具体而言，韦伯将魅力解释为：“能够使个体区分于普通人的非凡品质，从而使其被追随者认可为具有超自然的、超人的或至少是（有）特殊能力的”。基于韦伯对三种组织内部领导权威——即传统型、理性—法定型和克里斯马型的理想类型的论述，之后的学者将魅力应用于探究现代社会中的依赖“英雄主义或个人启示”的领导风格与政治权威。近年来，也有传播学者注意到，魅力同样关乎“饭圈”粉丝将偶像视为“精神领袖”或“神明”的崇拜现象。在将适用于政治、经济等领域中的魅力型领导或克里斯马型权威应用于明星、偶像等特定文化人物时，应当注意到，由于前者掌管着某些社会资源的分配，他们的行动决定会直接影响其他社会成员或集体的生产生活，而后者则相反，他们所具备的制度权力相当有限，正如粉丝在欣赏或崇拜偶像时，并不代表他们抛弃了原有的社会角色。那么，应当如何理解粉丝眼中偶像的特殊魅力呢？有学者认为，在文化范畴，特定人物被多数人认为具备出众能力构成了“魅力”这一概念所指涉的现象，魅力型偶像虽然不是韦伯所关注的权威决策者，他们仍在高度结构化的社会中承担了特定角色，他们的行为与生活方式也会激发某些或较大范围的意愿与兴趣。魅力这一原本关乎社会层面权力结构的概念因此能够与粉丝—偶像关系有所呼应，并被运用于探索偶像崇拜现象背后“个人的选择、超验的情感以及特殊性的存在”。本研究关于魅力的理论回顾首先围绕魅力发展的两个重要阶段，即起源与常规化过程。随后围绕粉丝何以将特定偶像视作与众不同或具备超凡能力，分析影响粉丝—偶像关系存续的具体情景，进而提出偶像魅力的悖论这一理论框架。\n\n1. 魅力的起源\n魅力者（偶像）意味着具备追随者（粉丝）眼中的超凡能力，后者对前者的识别或认可对于判定真正魅力是否发生至关重要。具体而言，魅力来源于追随者的个人投入，这是基于他们因魅力者的某些特质或光环而激发的热情、希望等特定情感。由于追随者对魅力者的“认可”并非基于已有的社会惯例和既定规则，这也说明魅力本身预示了对常规行动或循规蹈矩的日常生活的创新或颠覆，即魅力的“反常性”。\n现有研究对魅力起源的探究基本围绕以下三种假设：（1）行为属性；（2）行动策略；（3）社会背景。首先，魅力者自身的行为属性对塑造魅力光环尤为重要：如个人才能、创造力、保持不败的能力等。具体而言，偶像的外貌、身材、唱跳实力、演技等条件都是促进其“吸粉”的主要因素。其次，魅力者在塑造追随者对个体身份的认知时，可以通过一些实用策略将追随者的自我概念与集体的目标捆绑：如完成具备意义价值的任务、为追随者投射充满希望的愿景、将该愿景表达为一种集体身份等。具体而言，与已经具备社会知名度的明星不同，选秀参赛者或养成系偶像的成名之路往往依赖粉丝的共同投入，综艺节目或经纪公司将粉丝的支持看作决定偶像自身发展命运的关键力量，邀请粉丝共同见证偶像在竞争或练习模式中“洗刷”掉平庸感，最终在大众文化或亚文化的话语体系中脱颖而出。最后，在某些特定的社会背景下，魅力者更容易得到追随者认可：在不安或动荡时期，人们更容易对现状和已有生活感到无助从而幻想新的生活动力。类似地，有研究发现，父母缺席和较低的社会地位都会促使青少年崇拜偶像以寻求补偿。然而，随着他们年龄的增长以及自身认知水平的提升，更为自主的、社会化的成年人将不再只依赖偶像获得心理支撑，他们能够调整自己以适应社会排斥或应对其他伤害。\n\n2.魅力的常规化\n由于魅力者本身具备超凡、创新、与众不同的特质，魅力与秩序的生活或惯常的行为活动之间存在难以调和的矛盾。因此，真正的魅力无法长期维持其本身的存在形态，魅力在秩序生活中存续，可以通过常规化为更加细致的社会实践活动完成。常规化能够避免魅力“被维持追随者日常生活的各种条件以及主导他们的其他力量所取代”。有学者指出，常规化的魅力会使魅力者与追随者之间的关系失去魅力起源过程中至关重要的个人体验。在大众媒介情境下，魅力者与追随者之间的魅力式链接也会面临被解谜的过程，这是因为前者被过度曝光的个人生活和日常行动会使其不再具备神秘感和吸引力。鲍德里亚关于“诱惑”的论述似乎为此提出了合理解释，即常规化的魅力无非是“被窃取的秘密”，而持守秘密才是秘密本身的诱惑力。\n\n3. 魅力的悖论\n然而，也有学者认为，在担忧魅力会在常规化过程中消失的同时，还应考虑到魅力以分散或弱化的形式存在的可能。具体而言，常规化的生活方式和权力运作与人们对魅力者超凡能力的“认可”并非不可调和，这是因为“人对人的控制或支配”是人类社会中一直以来的普遍存在。早前爱德华·希尔斯曾假设，由于所有社会组织都存在能够向外辐射一系列社会规则的中心，那么各种形式的魅力也是由人们对社会中心的认识产生。相较于普通人身上低强度的中心性，魅力者拥有的则是高强度的中心性，其超凡能力是“开启、创造、掌握、转换、维持或毁灭对人们日常生活至关重要的事物”的构成力。\n结合真正魅力对现有秩序和常规生活的挑战与希尔斯对社会秩序中心的强调，克利福德·格尔茨提出应当将魅力视作一种文化现象，并思考魅力者在出现之时被人们认可的原因。具体而言，格尔茨推断以下有关魅力的悖论：一方面，魅力的符号表达需要与常规世界保持距离，以便魅力者向追随者展示超凡能力；另一方面，魅力仍需要徘徊于主导社会事务的意义中心附近，以确保魅力者能够获得追随者的注意，有关魅力的符号与概念也能够被追随者理解。",
    "ori_text": "\n\n魅力一词最早是由马克斯·韦伯从宗教文化词汇引入社会、政治、经济等领域的学术概念。具体而言，韦伯将魅力解释为：“能够使个体区分于普通人的非凡品质，从而使其被追随者认可为具有超自然的、超人的或至少是（有）特殊能力的”。基于韦伯对三种组织内部领导权威——即传统型、理性—法定型和克里斯马型的理想类型的论述，之后的学者将魅力应用于探究现代社会中的依赖“英雄主义或个人启示”的领导风格与政治权威。近年来，也有传播学者注意到，魅力同样关乎“饭圈”粉丝将偶像视为“精神领袖”或“神明”的崇拜现象。在将适用于政治、经济等领域中的魅力型领导或克里斯马型权威应用于明星、偶像等特定文化人物时，应当注意到，由于前者掌管着某些社会资源的分配，他们的行动决定会直接影响其他社会成员或集体的生产生活，而后者则相反，他们所具备的制度权力相当有限，正如粉丝在欣赏或崇拜偶像时，并不代表他们抛弃了原有的社会角色。那么，应当如何理解粉丝眼中偶像的特殊魅力呢？有学者认为，在文化范畴，特定人物被多数人认为具备出众能力构成了“魅力”这一概念所指涉的现象，魅力型偶像虽然不是韦伯所关注的权威决策者，他们仍在高度结构化的社会中承担了特定角色，他们的行为与生活方式也会激发某些或较大范围的意愿与兴趣。魅力这一原本关乎社会层面权力结构的概念因此能够与粉丝—偶像关系有所呼应，并被运用于探索偶像崇拜现象背后“个人的选择、超验的情感以及特殊性的存在”。本研究关于魅力的理论回顾首先围绕魅力发展的两个重要阶段，即起源与常规化过程。随后围绕粉丝何以将特定偶像视作与众不同或具备超凡能力，分析影响粉丝—偶像关系存续的具体情景，进而提出偶像魅力的悖论这一理论框架。\n\n1. 魅力的起源\n魅力者（偶像）意味着具备追随者（粉丝）眼中的超凡能力，后者对前者的识别或认可对于判定真正魅力是否发生至关重要。具体而言，魅力来源于追随者的个人投入，这是基于他们因魅力者的某些特质或光环而激发的热情、希望等特定情感。由于追随者对魅力者的“认可”并非基于已有的社会惯例和既定规则，这也说明魅力本身预示了对常规行动或循规蹈矩的日常生活的创新或颠覆，即魅力的“反常性”。\n现有研究对魅力起源的探究基本围绕以下三种假设：（1）行为属性；（2）行动策略；（3）社会背景。首先，魅力者自身的行为属性对塑造魅力光环尤为重要：如个人才能、创造力、保持不败的能力等。具体而言，偶像的外貌、身材、唱跳实力、演技等条件都是促进其“吸粉”的主要因素。其次，魅力者在塑造追随者对个体身份的认知时，可以通过一些实用策略将追随者的自我概念与集体的目标捆绑：如完成具备意义价值的任务、为追随者投射充满希望的愿景、将该愿景表达为一种集体身份等。具体而言，与已经具备社会知名度的明星不同，选秀参赛者或养成系偶像的成名之路往往依赖粉丝的共同投入，综艺节目或经纪公司将粉丝的支持看作决定偶像自身发展命运的关键力量，邀请粉丝共同见证偶像在竞争或练习模式中“洗刷”掉平庸感，最终在大众文化或亚文化的话语体系中脱颖而出。最后，在某些特定的社会背景下，魅力者更容易得到追随者认可：在不安或动荡时期，人们更容易对现状和已有生活感到无助从而幻想新的生活动力。类似地，有研究发现，父母缺席和较低的社会地位都会促使青少年崇拜偶像以寻求补偿。然而，随着他们年龄的增长以及自身认知水平的提升，更为自主的、社会化的成年人将不再只依赖偶像获得心理支撑，他们能够调整自己以适应社会排斥或应对其他伤害。\n\n2.魅力的常规化\n由于魅力者本身具备超凡、创新、与众不同的特质，魅力与秩序的生活或惯常的行为活动之间存在难以调和的矛盾。因此，真正的魅力无法长期维持其本身的存在形态，魅力在秩序生活中存续，可以通过常规化为更加细致的社会实践活动完成。常规化能够避免魅力“被维持追随者日常生活的各种条件以及主导他们的其他力量所取代”。有学者指出，常规化的魅力会使魅力者与追随者之间的关系失去魅力起源过程中至关重要的个人体验。在大众媒介情境下，魅力者与追随者之间的魅力式链接也会面临被解谜的过程，这是因为前者被过度曝光的个人生活和日常行动会使其不再具备神秘感和吸引力。鲍德里亚关于“诱惑”的论述似乎为此提出了合理解释，即常规化的魅力无非是“被窃取的秘密”，而持守秘密才是秘密本身的诱惑力。\n\n3. 魅力的悖论\n然而，也有学者认为，在担忧魅力会在常规化过程中消失的同时，还应考虑到魅力以分散或弱化的形式存在的可能。具体而言，常规化的生活方式和权力运作与人们对魅力者超凡能力的“认可”并非不可调和，这是因为“人对人的控制或支配”是人类社会中一直以来的普遍存在。早前爱德华·希尔斯曾假设，由于所有社会组织都存在能够向外辐射一系列社会规则的中心，那么各种形式的魅力也是由人们对社会中心的认识产生。相较于普通人身上低强度的中心性，魅力者拥有的则是高强度的中心性，其超凡能力是“开启、创造、掌握、转换、维持或毁灭对人们日常生活至关重要的事物”的构成力。\n结合真正魅力对现有秩序和常规生活的挑战与希尔斯对社会秩序中心的强调，克利福德·格尔茨提出应当将魅力视作一种文化现象，并思考魅力者在出现之时被人们认可的原因。具体而言，格尔茨推断以下有关魅力的悖论：一方面，魅力的符号表达需要与常规世界保持距离，以便魅力者向追随者展示超凡能力；另一方面，魅力仍需要徘徊于主导社会事务的意义中心附近，以确保魅力者能够获得追随者的注意，有关魅力的符号与概念也能够被追随者理解。",
    "reference_list": "考点1. “饭圈”推荐译为“fandom”，不能译为“fan circle”\n考点2. “生产生活”推荐译为“the lives and livelihoods”或根据上下文简化为“the daily lives”\n考点3.“行为属性”推荐译为behavioral attributes 或 properties，不可译为“Behavior Attribution”\n考点4.“保持不败的能力”推荐译为the ability to remain undefeated",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "183"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n第三十届上海电视节白玉兰奖于2025年6月27日晚在上海临港演艺中心落下帷幕，这绝非一场简单的颁奖礼，而是一面赤裸裸的“时代棱镜”，折射出中国社会文化思潮的涌动、观众心理的微妙变迁，以及影视产业经济逻辑的复杂交织。本届白玉兰奖以“三十而励，光影新程”为主题，其评选结果和获奖作品，在社会学意义上精准捕捉并回应了当下中国社会的深层情感需求与文化议题，使其成为一个独特的“社会学样本”。\n白玉兰奖自1988年设立以来，已从上海电视节的组成部分，野蛮生长为中国首个国际性电视奖项，其发展历程本身就是中国电视行业改革与进步的缩影。它始终秉持“坚守专业、秉持公正、鼓励多元、尊重突破、传承匠心、提携新人”的评判原则，致力于发掘和表彰那些具有公共价值和艺术高度的作品。本届奖项共征集到来自五大洲43个国家和地区的近千部作品，其中海外剧报名量激增53.7%，纪录片单元海外作品占比高达六成——这些冰冷的数据，却直观展现了白玉兰奖日益提升的国际影响力与开放视野，以及其作为文化交流桥梁的不可替代性。\n本届白玉兰奖的获奖作品，如《我的阿勒泰》和《山花烂漫时》，之所以能引发如此广泛的社会共鸣，并非偶然，而是它们精准触达了当下中国社会的深层情感需求和文化议题。前者以其独特的地域风情、诗意栖居的生活哲学以及人与自然和谐共生的主题，如同清风拂面，唤醒了都市人对“远方”的向往和对精神本真的回归，满足了人们对美好生活和文化多样性的情感诉求。该剧不仅斩获最佳中国电视剧，更荣获国际传播奖，这无疑证明了其跨越文化界限的普世魅力。\n而《山花烂漫时》则以“七一勋章”获得者张桂梅为原型，深入刻画了她为教育事业无私奉献的伟大精神。这部剧不仅展现了教育公平的艰辛与成就，更传递了信仰、责任和奉献的强大力量，引发了全社会对教育公平、农村女性命运以及个人奋斗价值的广泛讨论和强烈情感共鸣。宋佳对张桂梅的“教科书级别”演绎，获得了原型人物的亲自认可，使得这一故事不仅是荧屏呈现，更成为社会正能量的具象化表达，深刻连接了观众的集体记忆与文化认同。\n然而，在当前影视行业面临“去流量化”和提升公信力的背景下，白玉兰奖的评选导向也并非没有争议，甚至可以说，争议是其公信力保卫战的必然产物。近年来，关于流量明星与实力派之间的提名拉锯战、奖项评选机制透明度以及公正性的讨论屡见不鲜。例如，部分流量演员获得提名曾引发“水分太大”的质疑，与宋佳、马伊琍等实力派的硬核作品形成鲜明对比，这不仅是演技的较量，更是市场流量与艺术价值之间永恒的冲突。甚至有观点认为，蒋欣在《小巷人家》中表现亮眼，却从最佳女主热门“降级”至女配，被解读为团队为求稳而采取的“战术性降维打击”，这无疑将奖项的严肃性降格为一场精密的博弈，引发了公众对奖项权威性的担忧。\n这些争议，从早年《甄嬛传》的遗憾落选，到2015年李雪健未获提名引发的“杰出贡献奖”风波，再到2024年《追风者》的“番位争议”，都曾将白玉兰奖推向舆论的风口浪尖。但每一次争议，都促使奖项机制不断完善，例如引入“评委实名制投票”和公示投票规则，近期更将“提携新人”纳入核心评审原则。这些调整旨在平衡专业性、公共性和行业生态的健康发展，体现了白玉兰奖在面对挑战时，不断自我革新以秉持公正的决心。评委会主席陈宝国言简意赅地阐述了白玉兰奖的评判标准：“温度是艺术感染力，态度是作品的思想内核和艺术家的立场表达，尺度就是衡量这部入围作品是否达到了奖项所要求的高度。”而靳东在获奖感言中强调“内容是王道”，更是对这种趋势的最好注脚。这正是白玉兰奖坚守专业、回归内容本质的评选导向，也是其公信力得以巩固的基石。",
    "ori_text": "第三十届上海电视节白玉兰奖于2025年6月27日晚在上海临港演艺中心落下帷幕，这绝非一场简单的颁奖礼，而是一面赤裸裸的“时代棱镜”，折射出中国社会文化思潮的涌动、观众心理的微妙变迁，以及影视产业经济逻辑的复杂交织。本届白玉兰奖以“三十而励，光影新程”为主题，其评选结果和获奖作品，在社会学意义上精准捕捉并回应了当下中国社会的深层情感需求与文化议题，使其成为一个独特的“社会学样本”。\n白玉兰奖自1988年设立以来，已从上海电视节的组成部分，野蛮生长为中国首个国际性电视奖项，其发展历程本身就是中国电视行业改革与进步的缩影。它始终秉持“坚守专业、秉持公正、鼓励多元、尊重突破、传承匠心、提携新人”的评判原则，致力于发掘和表彰那些具有公共价值和艺术高度的作品。本届奖项共征集到来自五大洲43个国家和地区的近千部作品，其中海外剧报名量激增53.7%，纪录片单元海外作品占比高达六成——这些冰冷的数据，却直观展现了白玉兰奖日益提升的国际影响力与开放视野，以及其作为文化交流桥梁的不可替代性。\n本届白玉兰奖的获奖作品，如《我的阿勒泰》和《山花烂漫时》，之所以能引发如此广泛的社会共鸣，并非偶然，而是它们精准触达了当下中国社会的深层情感需求和文化议题。前者以其独特的地域风情、诗意栖居的生活哲学以及人与自然和谐共生的主题，如同清风拂面，唤醒了都市人对“远方”的向往和对精神本真的回归，满足了人们对美好生活和文化多样性的情感诉求。该剧不仅斩获最佳中国电视剧，更荣获国际传播奖，这无疑证明了其跨越文化界限的普世魅力。\n而《山花烂漫时》则以“七一勋章”获得者张桂梅为原型，深入刻画了她为教育事业无私奉献的伟大精神。这部剧不仅展现了教育公平的艰辛与成就，更传递了信仰、责任和奉献的强大力量，引发了全社会对教育公平、农村女性命运以及个人奋斗价值的广泛讨论和强烈情感共鸣。宋佳对张桂梅的“教科书级别”演绎，获得了原型人物的亲自认可，使得这一故事不仅是荧屏呈现，更成为社会正能量的具象化表达，深刻连接了观众的集体记忆与文化认同。\n然而，在当前影视行业面临“去流量化”和提升公信力的背景下，白玉兰奖的评选导向也并非没有争议，甚至可以说，争议是其公信力保卫战的必然产物。近年来，关于流量明星与实力派之间的提名拉锯战、奖项评选机制透明度以及公正性的讨论屡见不鲜。例如，部分流量演员获得提名曾引发“水分太大”的质疑，与宋佳、马伊琍等实力派的硬核作品形成鲜明对比，这不仅是演技的较量，更是市场流量与艺术价值之间永恒的冲突。甚至有观点认为，蒋欣在《小巷人家》中表现亮眼，却从最佳女主热门“降级”至女配，被解读为团队为求稳而采取的“战术性降维打击”，这无疑将奖项的严肃性降格为一场精密的博弈，引发了公众对奖项权威性的担忧。\n这些争议，从早年《甄嬛传》的遗憾落选，到2015年李雪健未获提名引发的“杰出贡献奖”风波，再到2024年《追风者》的“番位争议”，都曾将白玉兰奖推向舆论的风口浪尖。但每一次争议，都促使奖项机制不断完善，例如引入“评委实名制投票”和公示投票规则，近期更将“提携新人”纳入核心评审原则。这些调整旨在平衡专业性、公共性和行业生态的健康发展，体现了白玉兰奖在面对挑战时，不断自我革新以秉持公正的决心。评委会主席陈宝国言简意赅地阐述了白玉兰奖的评判标准：“温度是艺术感染力，态度是作品的思想内核和艺术家的立场表达，尺度就是衡量这部入围作品是否达到了奖项所要求的高度。”而靳东在获奖感言中强调“内容是王道”，更是对这种趋势的最好注脚。这正是白玉兰奖坚守专业、回归内容本质的评选导向，也是其公信力得以巩固的基石。",
    "reference_list": "考点1： 电影、电视剧名必须翻译正确：“我的阿勒泰”应译为“To the Wonder”、“山花烂漫时”应译为“She and Her Girls”、“小巷人家”应译为“Romance in the Alley”、 “甄嬛传”应译为“Empresses in the palace”、 “追风者”应译为“War of Faith”。 \n考点2： “流量明星”应译为“a star with a huge following ”。\n考点3： “注脚”应译为“illustration”，表示对“内容是王道”的说明，不可直译为“footnote”\n考点4：“三十而励，光影新程”应译为“Thirty & Thriving: Screen Arts’ New Horizon”，这是官方翻译\n考点5：“从最佳女主热门‘降级’至女配”中的女配应译为“Best Supporting Actress”，原文暗指的是最佳女配，而不是普通的女配\n考点6：“上海电视节白玉兰奖“应译为“Shanghai TV Festival Magnolia Awards”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "观点评论",
    "prompt_id": "52"
  },
  {
    "prompt": "翻译，英文翻译成中文。不要输出译文以外的内容。以下是你本次的任务：\nWhat is Behaviorism?\nBehaviorism is a theoretical approach to psychology popularized in the 20th century by John B. Watson and B.F Skinner. This school of thought focuses only on observable behavior and the environmental stimuli that produce it. It is often tied to learning, and asserts that behaviours are learned through interaction with the environment through either classical conditioning or operant conditioning.\nBehaviorism\nIt is no surprise that when you have a bowl of dog food in your hands, your dog becomes the best show dog on earth, effortlessly performing all the tricks it has learned. Sometimes you may even find your dog running through the list of tricks before you tell them which one to do. When you don’t have dog food in your hands, however, your furry friend will likely seem completely disinterested in performing. This behavior can be explained by behaviorism, sometimes referred to as behavioral psychology.\nBehaviorism is a theory of learning; it’s based on the idea that our behavior is learned as a result of interaction with our external environment. Interaction with our external environment can include an interaction with a certain person, a certain object, or with certain surroundings.\nOur behavior is learned through a process called conditioning. Conditioning is a learning process that can lead to habits and is the result of training ourselves to react a certain way in different scenarios.1 Behaviorism presents two main types of conditioning:\nClassical conditioning: when a dog learns to get excited when we walk towards the bag of dog food because the dog has learned that it would mean they get to eat right away.\nOperant conditioning: when a trainer successfully teaches a dog how to sit on command with the help of incentives, such as a treat every time they do it correctly.\nStrong believers of behaviorism argue that with the right conditioning, anyone can be trained to do any task within their capabilities, regardless of one’s personality.\nIn behavioral psychology, there are two types of behavior: overt behavior, which is what everyone sees publicly, and covert behavior, which is inner and private. Behaviorism as a field of study looks only at observable external behaviors rather than internal mental states. Behaviorists argue that since thoughts and emotions cannot be objectively measured, psychology should focus instead on stimulus-response relationships (like a dog’s response to food) that can be observed and analyzed. \nA person who has been punished is not thereby simply less inclined to behave in a given way; at best, he learns how to avoid punishment. – Burrhus Frederic Skinner in his book, Beyond Freedom and Dignity\nKey Terms\nBehaviorism: A theory and school of thought in modern psychology stating that all types of human behavior can be learned through two key types of conditioning: classical conditioning and operant conditioning. \nRadical Behaviorism:  A theory developed by B.F. Skinner that extends traditional behaviorism. It includes not only observable behaviors but also internal events, such as thoughts and feelings, as behaviors subject to the same principles of conditioning. It views all behavior, external and internal, as shaped by the environment and past reinforcement.\nStimulus: Anything that occurs in the environment that elicits a response from an individual.\nResponse: Any observable action or behavior that an organism performs as a result of a stimulus. \nClassical Conditioning: A learning technique that unconsciously pairs a specific action, or stimulus, with the resulting automatic behavioral response. When the action or stimulus is repeated, the automatic behavioral response is eventually learned to be associated with the action.\nOperant Conditioning: A learning technique that employs positive and negative reinforcements in the form of rewards or punishments to encourage an individual to pick up or stop a specific behavior. It’s sometimes referred to as instrumental conditioning.1 There are two types of punishment: positive, where a negative stimulus is added to discourage behavior; and negative, where a pleasant stimulus is removed to decrease undesired behavior. \nPositive Reinforcement: A consequence that aims to strengthen or encourage certain behaviors, such as providing a reward for doing something well.\nGrid Cells: Cells in the brain that help us to know where we are and where we’re going. They’re found in a part of the brain called the entorhinal cortex, and they fire in patterns that form a grid. As we move through space, different grid cells light up in a repeating pattern, helping our brains track our position, even without a map or landmarks.\n\nHistory\nEarly work on behaviorism can be traced back to 1897, when Ivan Pavlov, a Russian physiologist, conducted experiments on the digestion in dogs. Pavlov’s now-famous experiments led him to discover what we call classical conditioning.  It all started when Pavlov noticed the dogs would start salivating when presented with food. When presented with food, the lab assistant would also ring a bell (a neutral stimulus). Over time, the dogs would associate the bell with food. Eventually, the dogs associated the sight of the lab assistant’s white coat (another neutral stimulus) with food, which prompted a salivation response from the dogs even before the food was presented.\nBehaviorism would not be introduced formally until 1913, when American psychologist John B. Watson presented his publication, Psychology as the Behaviorist Views It. In this paper, Watson mentioned that if he provided his own specified environment for a baby to grow up in, he would be able to train them to become a specialist in any profession. Watson claimed this could include law, medicine, art, or even theft.1\nWatson’s formal contribution was so influential that in the following forty years, behaviorism became the dominant school of thought in psychology. Its popularity also reflected the desire to cement psychology as a measurable science, which behaviorism’s focus on observable behavior was able to provide.\nOperant conditioning was introduced by American psychologist B. F. Skinner in the 1938 book, The Behavior of Organisms. Skinner derived his theory by studying rats. He set up a box with a lever, which when pressed would drop a pellet of food onto a tray. Skinner introduced a rat into the box and observed that initially, it would wander around before accidentally pressing the bar. After the first food pellet was released, Skinner noticed that the rat’s rate of bar pressing increased dramatically. Research on Skinner’s experiment eventually led to the principle of reinforcement,2 a term used in operant conditioning to describe an action that increases the chances of certain behavior.\nTowards the end of the 1900s, the cognitive psychology revolution resulted in the diminishing popularity of behaviorism as the mainstream school of thought. Psychologists started turning to cognitive science to study human behavior, due to behaviorism’s failure in considering important mental processes.6 However, many insights from behaviorism were not forgotten and are used regularly to this day.\nThe principles of reinforcement and punishment, for example, remain central to behavior change, influencing everything from parenting techniques to workplace motivation and educational strategies. Similarly, behavioral conditioning is still widely applied in therapy, particularly in treating phobias, anxiety, and addictions through techniques like systematic desensitization and exposure therapy.\nMarketing and advertising also rely on behaviorist principles, using rewards and associations to shape consumer behavior. Take loyalty programs, for example, which use positive reinforcement to keep people coming back time and again. Each time a customer buys something, they earn a point, eventually working their way up to a free drink or a considerable discount. This operant conditioning encourages repeat purchases by associating spending with a desirable reward. \nPeople\nIvan Pavlov\nA Russian physiologist whose groundbreaking discovery of classical conditioning in the 1980s was influential in shaping behaviorism. Sometimes referred to as Pavlovian conditioning, classical conditioning was discovered accidentally while Pavlov studied salivation in dogs. Upon realizing the significance of his conditioning discovery, Pavlov spent the rest of his career studying this type of learning.\nJohn B. Watson\nAn American psychologist who was renowned for formally introducing and popularizing behaviorism. His work in this field was groundbreaking and incredibly influential, establishing behaviorism as the mainstream school of thought in psychology in the mid-1900s. Watson burned a significant amount of his letters and papers, except for some reprints of his academic work, which made it difficult to understand his earlier thoughts on behaviorism.\nBurrhus Frederic (B.F.) Skinner\nAn American psychologist and behaviorist who is commonly referred to as the father of operant conditioning. B.F. Skinner introduced this theory in his 1938 book, The Behavior of Organisms, which was influential in reinforcing behaviorism as a mainstream school of thought in psychology.\nClaude Shannon\nAn American mathematician and computer scientist who was dubbed the ‘father of information theory’ and played a pioneering role in the development of artificial intelligence. His most well-known work was his groundbreaking 1948 paper, A Mathematical Theory of Communication, which introduced the concept of binary digits (bits) as the fundamental unit of information. However, he’s also the creator of Theseus, the maze-solving mouse, which was an early experiment in artificial intelligence and machine learning. \nJoseph Wolpe\nSouth African psychiatrist who was one of the most influential figures in behavioral therapy during the twentieth century. Wolpe’s main area of research was in reciprocal inhibition techniques, a behavioral therapy method based on opposites. The principle is simple: two opposing responses cannot occur at the same time, such as being relaxed and anxious simultaneously. The idea of reciprocal inhibition techniques is to weaken an undesired response (like anxiety) by pairing it with a response that is incompatible with it (like relaxation). \nEdward Tolman\nAn American psychologist who is best known for developing the concept of purposive behaviorism. His work rejected the stimulus-response model of behaviorism and paved the way for further developments in the field. ",
    "ori_text": "What is Behaviorism?\nBehaviorism is a theoretical approach to psychology popularized in the 20th century by John B. Watson and B.F Skinner. This school of thought focuses only on observable behavior and the environmental stimuli that produce it. It is often tied to learning, and asserts that behaviours are learned through interaction with the environment through either classical conditioning or operant conditioning.\nBehaviorism\nIt is no surprise that when you have a bowl of dog food in your hands, your dog becomes the best show dog on earth, effortlessly performing all the tricks it has learned. Sometimes you may even find your dog running through the list of tricks before you tell them which one to do. When you don’t have dog food in your hands, however, your furry friend will likely seem completely disinterested in performing. This behavior can be explained by behaviorism, sometimes referred to as behavioral psychology.\nBehaviorism is a theory of learning; it’s based on the idea that our behavior is learned as a result of interaction with our external environment. Interaction with our external environment can include an interaction with a certain person, a certain object, or with certain surroundings.\nOur behavior is learned through a process called conditioning. Conditioning is a learning process that can lead to habits and is the result of training ourselves to react a certain way in different scenarios.1 Behaviorism presents two main types of conditioning:\nClassical conditioning: when a dog learns to get excited when we walk towards the bag of dog food because the dog has learned that it would mean they get to eat right away.\nOperant conditioning: when a trainer successfully teaches a dog how to sit on command with the help of incentives, such as a treat every time they do it correctly.\nStrong believers of behaviorism argue that with the right conditioning, anyone can be trained to do any task within their capabilities, regardless of one’s personality.\nIn behavioral psychology, there are two types of behavior: overt behavior, which is what everyone sees publicly, and covert behavior, which is inner and private. Behaviorism as a field of study looks only at observable external behaviors rather than internal mental states. Behaviorists argue that since thoughts and emotions cannot be objectively measured, psychology should focus instead on stimulus-response relationships (like a dog’s response to food) that can be observed and analyzed. \nA person who has been punished is not thereby simply less inclined to behave in a given way; at best, he learns how to avoid punishment. – Burrhus Frederic Skinner in his book, Beyond Freedom and Dignity\nKey Terms\nBehaviorism: A theory and school of thought in modern psychology stating that all types of human behavior can be learned through two key types of conditioning: classical conditioning and operant conditioning. \nRadical Behaviorism:  A theory developed by B.F. Skinner that extends traditional behaviorism. It includes not only observable behaviors but also internal events, such as thoughts and feelings, as behaviors subject to the same principles of conditioning. It views all behavior, external and internal, as shaped by the environment and past reinforcement.\nStimulus: Anything that occurs in the environment that elicits a response from an individual.\nResponse: Any observable action or behavior that an organism performs as a result of a stimulus. \nClassical Conditioning: A learning technique that unconsciously pairs a specific action, or stimulus, with the resulting automatic behavioral response. When the action or stimulus is repeated, the automatic behavioral response is eventually learned to be associated with the action.\nOperant Conditioning: A learning technique that employs positive and negative reinforcements in the form of rewards or punishments to encourage an individual to pick up or stop a specific behavior. It’s sometimes referred to as instrumental conditioning.1 There are two types of punishment: positive, where a negative stimulus is added to discourage behavior; and negative, where a pleasant stimulus is removed to decrease undesired behavior. \nPositive Reinforcement: A consequence that aims to strengthen or encourage certain behaviors, such as providing a reward for doing something well.\nGrid Cells: Cells in the brain that help us to know where we are and where we’re going. They’re found in a part of the brain called the entorhinal cortex, and they fire in patterns that form a grid. As we move through space, different grid cells light up in a repeating pattern, helping our brains track our position, even without a map or landmarks.\n\nHistory\nEarly work on behaviorism can be traced back to 1897, when Ivan Pavlov, a Russian physiologist, conducted experiments on the digestion in dogs. Pavlov’s now-famous experiments led him to discover what we call classical conditioning.  It all started when Pavlov noticed the dogs would start salivating when presented with food. When presented with food, the lab assistant would also ring a bell (a neutral stimulus). Over time, the dogs would associate the bell with food. Eventually, the dogs associated the sight of the lab assistant’s white coat (another neutral stimulus) with food, which prompted a salivation response from the dogs even before the food was presented.\nBehaviorism would not be introduced formally until 1913, when American psychologist John B. Watson presented his publication, Psychology as the Behaviorist Views It. In this paper, Watson mentioned that if he provided his own specified environment for a baby to grow up in, he would be able to train them to become a specialist in any profession. Watson claimed this could include law, medicine, art, or even theft.1\nWatson’s formal contribution was so influential that in the following forty years, behaviorism became the dominant school of thought in psychology. Its popularity also reflected the desire to cement psychology as a measurable science, which behaviorism’s focus on observable behavior was able to provide.\nOperant conditioning was introduced by American psychologist B. F. Skinner in the 1938 book, The Behavior of Organisms. Skinner derived his theory by studying rats. He set up a box with a lever, which when pressed would drop a pellet of food onto a tray. Skinner introduced a rat into the box and observed that initially, it would wander around before accidentally pressing the bar. After the first food pellet was released, Skinner noticed that the rat’s rate of bar pressing increased dramatically. Research on Skinner’s experiment eventually led to the principle of reinforcement,2 a term used in operant conditioning to describe an action that increases the chances of certain behavior.\nTowards the end of the 1900s, the cognitive psychology revolution resulted in the diminishing popularity of behaviorism as the mainstream school of thought. Psychologists started turning to cognitive science to study human behavior, due to behaviorism’s failure in considering important mental processes.6 However, many insights from behaviorism were not forgotten and are used regularly to this day.\nThe principles of reinforcement and punishment, for example, remain central to behavior change, influencing everything from parenting techniques to workplace motivation and educational strategies. Similarly, behavioral conditioning is still widely applied in therapy, particularly in treating phobias, anxiety, and addictions through techniques like systematic desensitization and exposure therapy.\nMarketing and advertising also rely on behaviorist principles, using rewards and associations to shape consumer behavior. Take loyalty programs, for example, which use positive reinforcement to keep people coming back time and again. Each time a customer buys something, they earn a point, eventually working their way up to a free drink or a considerable discount. This operant conditioning encourages repeat purchases by associating spending with a desirable reward. \nPeople\nIvan Pavlov\nA Russian physiologist whose groundbreaking discovery of classical conditioning in the 1980s was influential in shaping behaviorism. Sometimes referred to as Pavlovian conditioning, classical conditioning was discovered accidentally while Pavlov studied salivation in dogs. Upon realizing the significance of his conditioning discovery, Pavlov spent the rest of his career studying this type of learning.\nJohn B. Watson\nAn American psychologist who was renowned for formally introducing and popularizing behaviorism. His work in this field was groundbreaking and incredibly influential, establishing behaviorism as the mainstream school of thought in psychology in the mid-1900s. Watson burned a significant amount of his letters and papers, except for some reprints of his academic work, which made it difficult to understand his earlier thoughts on behaviorism.\nBurrhus Frederic (B.F.) Skinner\nAn American psychologist and behaviorist who is commonly referred to as the father of operant conditioning. B.F. Skinner introduced this theory in his 1938 book, The Behavior of Organisms, which was influential in reinforcing behaviorism as a mainstream school of thought in psychology.\nClaude Shannon\nAn American mathematician and computer scientist who was dubbed the ‘father of information theory’ and played a pioneering role in the development of artificial intelligence. His most well-known work was his groundbreaking 1948 paper, A Mathematical Theory of Communication, which introduced the concept of binary digits (bits) as the fundamental unit of information. However, he’s also the creator of Theseus, the maze-solving mouse, which was an early experiment in artificial intelligence and machine learning. \nJoseph Wolpe\nSouth African psychiatrist who was one of the most influential figures in behavioral therapy during the twentieth century. Wolpe’s main area of research was in reciprocal inhibition techniques, a behavioral therapy method based on opposites. The principle is simple: two opposing responses cannot occur at the same time, such as being relaxed and anxious simultaneously. The idea of reciprocal inhibition techniques is to weaken an undesired response (like anxiety) by pairing it with a response that is incompatible with it (like relaxation). \nEdward Tolman\nAn American psychologist who is best known for developing the concept of purposive behaviorism. His work rejected the stimulus-response model of behaviorism and paved the way for further developments in the field. ",
    "reference_list": "考点 1：\"theoretical approach\" 应译为 \"理论取向 / 理论范式\"\n考点 2：\"Classical conditioning\" 应译为 \"经典条件作用\"\n考点 3：\"Operant conditioning\" 应译为 \"操作条件作用 / 工具性条件作用\"\n考点 4：\"overt behavior\" 应译为 \"外显行为\"\n考点 5：\"covert behavior\" 应译为 \"内隐行为\"\n考点 6：\"the cognitive psychology revolution\" 应译为 \"认知心理学革命\"\n考点 7：\"show dog\" 应译为 \"表演犬 / 赛级犬\"\n考点 8：\"running through the list of tricks\" 中 ”running“应译为\"都过一遍\"\n考点 9：\"dubbed the 'father of information theory\" 应译为 被誉为 \"信息论之父\"\n考点 10：\"reciprocal inhibition techniques\" 应译为 \"交互抑制技术\"\n考点 11：\"purposive behaviorism\" 应译为 \"目的行为主义\"\n考点 12：\"instrumental conditioning\" 应译为 \"工具性条件作用\"\n考点 13：\"Pavlovian conditioning\" 应译为 \"巴甫洛夫式条件作用 \"\n考点 14：\"Psychology as the Behaviorist Views It\" 应译为 \"《行为主义者眼中的心理学》\"\n考点 15：\"principle of reinforcement\" 应译为 \"强化原理\"",
    "Primary_Domain": "学术论文",
    "Secondary_Domain": "社会科学",
    "prompt_id": "94"
  },
  {
    "prompt": "翻译，中文翻译成英文。不要输出译文以外的内容。\n以下是你本次的任务：\n\n\n郁金香、风车、木鞋是很多游客提起荷兰时说得最多的事物。尤其是郁金香，它不仅是荷兰国花，更成为旅游的亮丽名片。荷兰郁金香规模宏大，种植面积达到7000多公顷，占全球产量的65％，且品种极为丰富，拥有8000多个品种，其中绝大多数为荷兰自主培育。每到郁金香花开时，荷兰便会迎来大批来自世界各地的游客。荷兰凭借郁金香这一独特标识，成功塑造了全球最具吸引力的春季旅游胜地，并通过系统化的旅游开发、产业协同和品牌推广策略，让郁金香旅游成为荷兰经济发展的重要推动力。\n郁金香为荷兰带来的价值\n荷兰旅游部门数据显示，每年春季约有200万人次的国际游客因花而来，创造超过5亿欧元的经济效益。\n郁金香对荷兰的影响力可以概括为以下几点：\n郁金香蕴含荷兰文化特点。16世纪，郁金香从土耳其经由奥地利引入荷兰，彼时作为珍稀花卉备受追捧。荷兰人持续改良种植技术，提高产量与质量，加之温室栽培技术的进步，使荷兰成为全球最大的郁金香球茎生产国与出口国之一，也成为荷兰文化的重要象征。在荷兰，从家庭装饰到公共场所，郁金香图案随处可见，形成了独特的郁金香文化氛围。自2012年起，荷兰将每年1月的第三个星期六 设立为国家“郁金香日”。\n荷兰郁金香旅游产品多元。荷兰依托郁金香开发了丰富多样且颇具特色的产品，涵盖观赏型、体验型、节庆型等多种类型。每年郁金香盛开的5月，荷兰会举办“郁金香节”。大量游客前来观赏郁金香花海，领略自然风光，体验异域风情。游客可选择花田骑行，在微风中穿梭花海；也能花田泛舟，乘船深入花田内部，近距离欣赏郁金香；还可乘飞机飞越花田，从空中俯瞰这片壮丽的花之海洋。以库肯霍夫公园为例，该公园位于阿姆斯特丹近郊小镇利瑟，被誉为“欧洲花园”。每年种植700万株球茎花卉，其中郁金香超450种，15公里长的花径穿梭于百年古树、镜面湖泊与风车间。每年春季，公园都会举办郁金香花展，这是全球规模最大、最为著名的花卉展览之一。2023年公园还创新推出“郁金香声音之旅”，游客扫码即可聆听每种花卉背后的历史故事。\n郁金香对荷兰经济发展具有重要作用。郁金香作为富有魅力的花卉，其旅游价值日益凸显，带动了一系列相关产业发展，形成了独特的发展模式。一是促进消费增长。游客的到访为荷兰带来可观的旅游收入，酒店、餐饮、交通等行业均因郁金香旅游而受益。二是带动相关产业发展。郁金香旅游推动了花卉种植、花卉贸易、园艺设计等产业的进步。花农通过种植郁金香获取收益，花卉贸易因郁金香的畅销而繁荣，园艺设计行业也因花田景观设计需求得以发展，设计师为花田设计出各类精美的图案，又吸引更多游客前来观赏。三是促进文化交流，传播荷兰文化。郁金香旅游吸引了来自不同国家和地区的游客，促进了不同文化的交流与融合。游客在欣赏郁金香的同时，也深入了解了荷兰的历史、文化和风俗习惯，增进了各国之间的相互理解和友谊。此外，荷兰的传统手工艺品、美食等也借助郁金香旅游得到更广泛传播，让更多的人了解并喜爱荷兰文化。\n据荷兰中央统计局数据，2023年，荷兰游客过夜总数达4974万夜，同比增长8.1％，国际游客过夜数显著上升23％，至2042万夜，成为推动荷兰旅游业增长的关键因素。国际游客主要来自英国、美国和德国，也不乏来自中国、日本、韩国的亚洲游客。",
    "ori_text": "郁金香、风车、木鞋是很多游客提起荷兰时说得最多的事物。尤其是郁金香，它不仅是荷兰国花，更成为旅游的亮丽名片。荷兰郁金香规模宏大，种植面积达到7000多公顷，占全球产量的65％，且品种极为丰富，拥有8000多个品种，其中绝大多数为荷兰自主培育。每到郁金香花开时，荷兰便会迎来大批来自世界各地的游客。荷兰凭借郁金香这一独特标识，成功塑造了全球最具吸引力的春季旅游胜地，并通过系统化的旅游开发、产业协同和品牌推广策略，让郁金香旅游成为荷兰经济发展的重要推动力。\n郁金香为荷兰带来的价值\n荷兰旅游部门数据显示，每年春季约有200万人次的国际游客因花而来，创造超过5亿欧元的经济效益。\n郁金香对荷兰的影响力可以概括为以下几点：\n郁金香蕴含荷兰文化特点。16世纪，郁金香从土耳其经由奥地利引入荷兰，彼时作为珍稀花卉备受追捧。荷兰人持续改良种植技术，提高产量与质量，加之温室栽培技术的进步，使荷兰成为全球最大的郁金香球茎生产国与出口国之一，也成为荷兰文化的重要象征。在荷兰，从家庭装饰到公共场所，郁金香图案随处可见，形成了独特的郁金香文化氛围。自2012年起，荷兰将每年1月的第三个星期六 设立为国家“郁金香日”。\n荷兰郁金香旅游产品多元。荷兰依托郁金香开发了丰富多样且颇具特色的产品，涵盖观赏型、体验型、节庆型等多种类型。每年郁金香盛开的5月，荷兰会举办“郁金香节”。大量游客前来观赏郁金香花海，领略自然风光，体验异域风情。游客可选择花田骑行，在微风中穿梭花海；也能花田泛舟，乘船深入花田内部，近距离欣赏郁金香；还可乘飞机飞越花田，从空中俯瞰这片壮丽的花之海洋。以库肯霍夫公园为例，该公园位于阿姆斯特丹近郊小镇利瑟，被誉为“欧洲花园”。每年种植700万株球茎花卉，其中郁金香超450种，15公里长的花径穿梭于百年古树、镜面湖泊与风车间。每年春季，公园都会举办郁金香花展，这是全球规模最大、最为著名的花卉展览之一。2023年公园还创新推出“郁金香声音之旅”，游客扫码即可聆听每种花卉背后的历史故事。\n郁金香对荷兰经济发展具有重要作用。郁金香作为富有魅力的花卉，其旅游价值日益凸显，带动了一系列相关产业发展，形成了独特的发展模式。一是促进消费增长。游客的到访为荷兰带来可观的旅游收入，酒店、餐饮、交通等行业均因郁金香旅游而受益。二是带动相关产业发展。郁金香旅游推动了花卉种植、花卉贸易、园艺设计等产业的进步。花农通过种植郁金香获取收益，花卉贸易因郁金香的畅销而繁荣，园艺设计行业也因花田景观设计需求得以发展，设计师为花田设计出各类精美的图案，又吸引更多游客前来观赏。三是促进文化交流，传播荷兰文化。郁金香旅游吸引了来自不同国家和地区的游客，促进了不同文化的交流与融合。游客在欣赏郁金香的同时，也深入了解了荷兰的历史、文化和风俗习惯，增进了各国之间的相互理解和友谊。此外，荷兰的传统手工艺品、美食等也借助郁金香旅游得到更广泛传播，让更多的人了解并喜爱荷兰文化。\n据荷兰中央统计局数据，2023年，荷兰游客过夜总数达4974万夜，同比增长8.1％，国际游客过夜数显著上升23％，至2042万夜，成为推动荷兰旅游业增长的关键因素。国际游客主要来自英国、美国和德国，也不乏来自中国、日本、韩国的亚洲游客。",
    "reference_list": "考点1： “郁金香日”应译为“National Tulip Day”。\n考点2： “库肯霍夫公园”应译为“Keukenhof Park” \n考点3：“节庆型”推荐译为“festival-themed types”",
    "Primary_Domain": "新闻资讯",
    "Secondary_Domain": "新闻报道",
    "prompt_id": "69"
  }
]